the query optimizer models data distribution and access paths to make the optimal plan choice for a given query. sometimes the plan selection is poor because of modeling limitations  outdated statistics  incorrect optimization heuristics  etc. hence it is useful to examine the plan choice made by the optimizer from an execution perspective and to impose validation rules on the actual execution plan to evaluate plan suitability. this approach treats the optimizer as a black box. the plan validation is based on the queries and data instead of the optimizer implementation details. 
this paper describes {xpc}  a rule-based tool for microsoft sql server  that helps users and developers achieve a better understanding of plan performance. we apply ideas similar to code profilers  to examine plan execution performance along with heuristic rules to the actual execution profile and probe for inefficiencies. this paper describes the overview and implementation of {xpc} and presents rules showing how {xpc} is useful in targeting plan performance issues. 
keywords 
xml  query plan  optimizer  performance statistics  data warehousing  performance test 
1. introduction 
the optimizer  in microsoft sql server selects a plan for a given query based on a cost model  the database metadata  database statistics  system resources  memory  io  cpu   and the query itself. it uses a complex modeling process and several heuristics to arrive at a plan that it believes is correct and also optimal  often though the plan can perform poorly against an actual database.  
poor performance can result due to modeling assumptions  outdated statistics  system resource assumptions etc. it is useful to have a tool for database engine users  dba  application writers  and architects  and designers  developers  customer support  to understand the source of plan inefficiencies. for example  engine designers can use it to understand why a particular join strategy resulted in poor performance whereas another known join order has better performance. customer support can use such a tool to help narrow down the possible causes of poor performance to particular characteristics of a plan e.g. wrong join order. 
database users can benefit by gaining an understanding of why certain predicates work better than others or how the underlying data distribution is causing plans to be effectively single threaded even when the plan is a parallel plan. 
another strategy used to debug plan performance is to contrast against a plan that was previously performing well and examine plan changes that could have led to differing performance. 
{xpc} is a tool that can help all the cases above. {xpc} provides information that helps understand the impact of operators by comparing the actual cost with the estimated cost. it helps pinpoint certain well known causes of poor performance and it helps improve plan comparison. 
{xpc} depends on existing features in microsoft sql server to capture and materialize runtime information in a user and program friendly form. the collection mechanism is already built into microsoft sql server. using the analogy of code profilers  {xpc} adds an analysis engine which can be applied to the actual execution profile to probe for inefficiencies. {xpc} is also extensible to accommodate more information from microsoft sql server  if additional probes exist. 
1. related work 
there exists a rich body of literature that leverages feedback from query execution to detect or correct issues in query optimizer using cardinality feedback   distinct page counts   etc.  the novelty here is the set of rules we use. 
there are also tools  that make use of plan comparison as an analysis strategy. in previous work  the comparisons are usually structure based and can only report changes to operator ordering. these tools also don't estimate the impact of the changes. our approach uses summaries and heuristics to explain the changes 

 
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  or republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee. 
dbtest'1  june 1  1  vancouver  bc  canada. 
copyright 1 acm 1-1-1/1...$1. 
 
and their impact better.  
1. background 
plans in sql server are represented as binary trees. each node at the interior and leaves of the tree represents an operator. leaf operators represent a scan or seek on a table or some other rowset. interior operators represent transformations like join  sort etc. 
we distinguish plans to be of two types; compile and execution  or runtime  plans. a compile plan is the plan that is suggested by the query optimizer. an execution plan is one that is used by the query execution engine. it possibly differs from the compile plan in the uses of resources e.g. degree of parallelism. an execution plan also has additional runtime information attributed to each operator like total number of rows processed  threads used  rows processed per thread etc. 
several executions of the same query may share the same compile plan but will have unique execution plans. the execution plan is not cached. it can be materialized when explicitly requested. 
microsoft sql server provides two ways of displaying compile and execution plans  i.e.  text-based  or xml  based. showplan xml  is an xml representation of a compile plan  while statistics xml  is an xml representation of an execution plan. we need statistics xml as our input plan for most rules. 
1. framework 
the core idea behind {xpc} is to use the runtime statistics from an execution plan as input and run them through an analysis engine. the rule based engine then generates summaries based on the execution of rules. these rules can be extremely simple or complex. the resulting summaries can also be similarly diverse. the summaries generated can be studied in isolation to look at a single plan performance or compared to each other to contrast plan changes and correlate those with plan performance. the summaries can also be generated on compile plans but since these contain a subset of the data in an actual execution  the summaries will also have less information. in the model above  each step of an automatable process is encapsulated as rules to be evaluated by the analysis engine. 
 
figure 1. {xpc} architecture 
the basic architecture is simple  as shown in figure 1. it consists of a mechanism to collect plans  compile or execution  followed by an analysis engine. the plan can be collected in a batch fashion or part of the results returned with each query. the xml format of plans allows for great flexibility and ease in implementing the analysis engine 
the analysis engine is a collection of rules and temporary plan scoped tables. we implement the analysis engine using microsoft sql server in two different ways for flexibility of use. in one case  the engine is a set of scripts that create the necessary tables and then evaluate the rules. in the second case  the engine is implemented as a set of stored procedures wrapping the rules and stored in a database.  
each rule is a piece of code that operates either directly on the plan or on plan derived data in the temporary tables. each rule performs some computation on the data and then stores the results in the temporary and or results tables and or flushes them to a log. there is great freedom in implementing a rule. currently we use a mixture of xquery  and t-sql  to write rules. there is no rule validation of any kind yet and it's up to the rule author to ensure that the source and destination of the rule exist when the rule is evaluated. we can handle any number of rules since each rule is a separate body of code. the rules are evaluated sequentially. rule evaluation is ordered by query ordering in the script or in the case of stored procedures by numbering the stored procedures in an auxiliary table. rules can use temporary tables or share data  subject to the conditions above  to ease implementation or improve performance. users have access to the source and can add rules using the conventions above. section 1 describes the detailed implementation of rules using stored procedures. 
for example  one rule is to determine the sum of rows processed by all operators. we implemented this rule as a t-sql statement that sums the actual rows processed by each operator from a temporary table that has a row per operator and a column in each row for the number of rows processed by the operator. in this case the temporary table is expected to have been populated by rules preceding this rule. the summary in the log is a header explaining the sum followed by the actual value obtained. if we wanted to modify the rule above so that it summed only the rows processed by table scan operations we would introduce a predicate on the operator type to filter unnecessary rows. thus rule implementation is tied closely to the conventions in the input plan as well as the overall analysis engine implementation. 
1. example {xpc} rules 
the set of rules used in our engine is a collection of heuristics based on our experience and deemed useful in determining performance hotspots or regressions. the set of rules is diverse in complexity and scope. some rules look at the entire plan  while some look at only information local to an operator. some rules simply transform the plan or aggregate data in the plan to make comparison or evaluation easier. 
1 sample transformation rules 
one set of transformation rules operates on the plan to convert a full blown plan into a plan that has only the operators at the leaf of the plan and the join operators thus making it a skeleton highlighting join orders. the output is useful to determine join order and makes comparison of join order in plans easier. 
another set of transformation rules filters operators of certain types e.g. nested loop joins and then extract properties of these joins such that these can be examined and compared. 
1 sample aggregation rules 
one set of aggregation rules  uses the code profiler analogy and generates a value for the number of exclusive and inclusive rows processed by each operator and its sub-tree. this makes comparing two plans easier to determine the source of a change in the amount of data processed by a plan or to determine the chain of rowsets and predicates that cause a lot of work to be performed. 
another set of aggregation rules generates skew measures for the number of rows processed at every parallel operator. these figures help determine if work is evenly balanced amongst all the threads in a parallel operator and if not  help estimate the dispersion. 
a third set of rules computes the ratio of total rows processed by the plan to the total rows processed only at the leaf level. this ratio could be seen as the  reprocessing ratio . ideally a good plan drops unnecessary rows early  thus achieving a low reprocessing ratio. the lowest reprocessing ratio that could be achieved is one. 
a fourth set of rules computes the total set of rows processed by all exchange operators in a plan. this helps pinpoint possible scalability issues. 
1 sample domain specific rules 
another set of rules in {xpc} are domain specific. these rules verify assumptions in a specific domain to detect domain related issues. here we outline rules for data warehousing environments. for example  in data warehousing environments  the following best practices should hold: 
best practice 1: indexes and statistics are pre-built and carefully designed during the data warehousing deployment process. hence  any query should be efficiently answered by existing indexes and statistics  i.e.  microsoft sql server optimizer shouldn't recommend additional indexes and statistics. 
best practice 1: tables are usually organized in star-schema. star queries on top of the star-schema usually reduce the number of rows from the fact table by placing predicates on dimension tables.  
best practice 1: in order to manage large quantities of data  fact tables are usually partitioned on specific dimensions. most queries are also designed such that only a few partitions will be touched. the remaining partitions should be eliminated by a good plan. 
best practice 1: star queries usually perform aggregations and groupings on top of the data returned from fact tables. these operators are very cpu intensive  hence parallelism in encouraged. 
best practice 1: in order to write analysis queries  sub queries are used to encapsulate certain datasets and multiple levels of aggregations should be applied on top. 
we implement domain specific rules inside {xpc} to detect violations of the best practices given above. for example  to cover best practice 1  we have missing statistics and missing indexes rules to detect any statistics and indexes useful to the optimizer but not created. with this rule fired  users can either directly leverage the missing information reported by optimizer  or they can use the database tuning advisor  dta  perform a more thorough investigation. 
to cover best practice 1  we have rules to detect joins that produced more rows than the number of rows in their input fact tables. this helps spot user query errors where they mistakenly join two fact tables directly  without aggregating them first. 
to cover best practice 1  given the partitioning dimension  we have rules which can detect whether partition elimination is performed by a plan. 
to cover best practice 1  we have rules to compute the number of serial and parallel operators and compare the total operator cost of serial operators and parallel operators. these provide insight into whether the query plan performance is unnecessarily limited. besides the parallelism  the number of rows returned by each individual thread is also computed. this number is used to determine the skew between different threads and hence detect any potential scalability issue. 
for example  an {xpc} rule for detecting scalability issues can compute performance impact based on the actual number of rows processed and the observed skew and then assuming perfectly balanced execution or zero skew. the impact information is stored as percentage improvement in a results table  which can later be aggregated to provide an overview for the workload. 

figure 1 scalability rule with impact 
figure 1 demonstrates an overview of the impact of scalability issues detected for a given data warehousing workload. this workload is a 1gb data warehouse based on retail customer data. there are over 1 queries in the workload. with impact data  engineers using {xpc} have an accessible tool to understand performance issues for the workload. in this particular example  1% of this workload has scalability issues that reduce performance by more than 1% from the maximum possible if this particular issue is fixed.  
to cover best practice 1  we have rules which can detect patterns that are repeated in the plan and report any potential repeated work. 
a short primer on how to write a new rule is in section 1.  
1. known limitations 
{xpc} is a rule based engine and the rules are based on previous domain experience. hence these rules are neither an exhaustive set nor are they universally applicable  collectively though they help triage issues effectively. these rules also need to be updated frequently to stay on top of the issues with changes in the query engine and customer scenarios. 
{xpc} doesn't assume access to the actual database and schema and hence it is limited in the scope of its rules to the information available in the execution plan. 
{xpc} in its current implementation doesn't address all sql server features.  
1. conclusion and future work 
performance regression analysis for complex systems such as microsoft sql server is a challenging task. performance issues can be found in any layer of the engine. query plans are a way to expose performance problems inside the query optimizer. with query plans and related statistics persisted in xml format  we have shown how {xpc} can easily identify known performance issues and narrow the investigation space. we close the performance loop by looking at the suggestions from {xpc}.one future work item is to further integrate investigation logic inside {xpc} to triage performance issues automatically. 
we aim to add newer rules to support the evolution of sql server and integrate {xpc} with supportability improvements like dynamic management views  dmvs   or additional properties in the input plan to enable better performance drill down. we also aim to add probes to collect time spent in each operator thus making the data available closer to code profilers. we hope to extend the idea to support other services shipped by the sql business unit e.g. sql server analysis services that use plans to guide execution. 
1. acknowledgments 
our acknowledgements to the members of the performance team  the query optimizer developer team  and the data warehouse scalability testing improvement team  especially alejandro hernandez saenz for providing performance data about microsoft sql server 1. we also thank vivek narasayya and manoj syamala for their valuable feedback on making this paper better. we would also like to thank umachandar jayachandran  uc  for his help with xquery and mostafa mokhtar for his help in testing the tool.  
1. appendix 
1 how to add new rules to xpc 
 
in the xpc implementations we use the xml format of the plan. the plan schema is public and can be found as an xsd . 
to show how to add a new rule to xpc  we consider the real world problem of wide or narrow plans. a brief discussion can be found in duncan bart's blog . the gist is that during insert  update or delete  iud  microsoft sql server can choose either of one of two types of plans - narrow or wide. the plans are chosen such that the cpu overhead and io activity is minimized. narrow plans however visually hide the fact that indexes other than the clustered index are being affected. the information is there but one needs to dig deeper. in any case it's good to know whether an iud plan is wide or narrow.  
we show how to detect an iud plan and whether it's wide or narrow. an iud plan has exactly one of the logical operator types -  insert    update  or  delete . in the case of a wide iud plan the plan also has the  sequence  logical operator. the above conditions lead to testing for the presence of the said logical operators in the plan. below we show fragments of from a narrow update plan and a wide update plan. these are not complete plans and show only the operators and not the complete set of data associated with them. below the plans is a rule to detect iud narrow or wide plans based on the discussion above. 
the plans show the operators and how they are nested. each operator also has operator specific information which we have stripped out but can be found in the xsd. the difference in the narrow and wide plans should be obvious by looking at the operators. in the narrow plan there is only one  update  logical operator whereas the wide plan has one per index updated. one fragment of information that we have kept for one operator is the runtimeinformation. this is information is per thread and helps us to detect issues like execution skew. 
the rule as written below assumes access to the whole plan. this is always true in xpc implementations. in the script form the plan would be a global variable and in the stored procedure form it would be an input variable. the rule extracts the logicalop attribute of every relop element in the plan. we then obtain the distinct operators type and compare them against the list of operator types we are looking for. since a non iud plan will have neither  the count of operator types detected will be 1.a narrow iud plan will have only one of  insert    update  or  delete  types. in addition  a wide plan has the  sequence  operator. hence we have a count of 1 for a narrow plan or 1 for a wide plan. a count greater than 1 is an error. 
thus using public information and an intuition for what problems are interesting we can create new rules with ease. 
 
figure 1 stripped narrow update plan 
 
figure 1 wide update plan 
figure 1 gives the rule to detect whether and insert / update / delete plan is a wide or narrow plan. 
 
figure 1 iud wide narrow plan rule 
 
1 xpc rule engine implementation using 
stored procedures 
there are multiple ways to implement the xpc rules. we have implemented the xpc rules using xml data type with its operations  and t-sql in sql server 1. our implementation has following benefits: 
first  it's very easy to deploy. the whole implementation is encapsulated as stored procedures  and can be installed on any sql server 1 with proper permissions. 
second  it's self-contained. there is no dependency on external libraries. all the functionality implemented using xml technologies already embedded in sql server 1. 
third  it's easy to extend. for example  sql server 1 and sql server 1 have different ways of handling dynamic partition elimination  1  1 . two separate store procedures implemented respectively for each release. new rules can be easily implemented as additional stored procedures. 
fourth  it's very flexible. xquery and t-sql are both very powerful high-level languages to let developers make flexible pattern matching and relational data manipulation. xquery can easily filter out minor differences like expression numbers and only focus on invariant query structure  while t-sql enables flexible control flow for internal decision logic of the rule. 
 
figure 1 helper procedures - call structure 
figure 1 gives overall structure of stored procedures. in general  there are two types of stored procedures. the first type of stored procedures is helper procedures. these helper procedures can help retrieve the query plans from customer traces  sp fromtrace  or stored query plan files  sp fromfile . they also make it easy to batch process a list of files stored in a directory  sp fromdir . the helper procedures also can keep track of errors  setup and store impact analysis tables. 
 
figure 1 rule procedures - call structure 
the second type of stored procedures is rule procedures. each rule is implemented in a single procedure. figure 1 demonstrates existing stored procedures for known issues. here rules are used to detect known performance issues than can exist in a query plan. there are two general categories of procedures depending on different types of input plans  i.e.  compiled query plan  showplan xml  without runtime statistics  or actual query plan  statistics xml  with runtime statistics. showplan xml contains only a subset of information of statistics xml  however showplan xml is still useful when a user cannot collect the full statistics xml due to query timeout or other concerns. different rules can also be grouped together as composite rules to cover particular application domains. for example  sp knownissues groups rules for all data warehousing issues. 
each rule can be divided into two types of operations: plan pattern matching and aggregation. the plan pattern matching extracts the interesting part of the plan for this rule. this is implemented by xml data type operations based on xpath and xquery technologies. for example  the following statement extracts all the  table spool  operators from a given query plan stored in xml variable  plan. for details of how to use xml data type operations in sql server 1  please refer to . 
 
figure 1 plan pattern matching 
the second type of operations is aggregating data extracted from the matched part of the query plans into impact of this issue. this can be easily implemented using table manipulation languages like t-sql. 
there are several impact analysis tables created as result of rule processing. these tables can be queried further to understand the distribution of issues and also the impact of each issue. table 1 summarizes different types of tables created in our current implementation. 
table 1 internal table types 
table type  description  issues found  all issues found for one given query plan  files issues found  all issues found for a list of query plans.   issue   impact of one specific issue for a given query plan  files  issue   impact of one specific issue for a list of query plans   
