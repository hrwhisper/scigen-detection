we consider the problem of detecting anomalies in high arity categorical datasets. in most applications  anomalies are defined as data points that are 'abnormal'. quite often we have access to data which consists mostly of normal records  along with a small percentage of unlabelled anomalous records. we are interested in the problem of unsupervised anomaly detection  where we use the unlabelled data for training  and detect records that do not follow the definition of normality.
¡¡a standard approach is to create a model of normal data  and compare test records against it. a probabilistic approach builds a likelihood model from the training data. records are tested for anomalousness based on the complete record likelihood given the probability model. for categorical attributes  bayes nets give a standard representation of the likelihood. while this approach is good at finding outliers in the dataset  it often tends to detect records with attribute values that are rare. sometimes  just detecting rare values of an attribute is not desired and such outliers are not considered as anomalies in that context. we present an alternative definition of anomalies  and propose an approach of comparing against marginal distributions of attribute subsets. we show that this is a more meaningful way of detecting anomalies  and has a better performance over semi-synthetic as well as real world datasets.
categories and subject descriptors: h.1  database management : database applications - data mining
general terms: algorithms  performance  experimentation
keywords: anomaly detection  machine learning
1. introduction
¡¡with the ever increasing amount of data being collected universally  it gets more important and challenging to spot

 this work is funded in part by cdc under award 1-r1hk1 and by nsf under award iis-1.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee.
kdd'1  a ugus t 1  1  san jos e  c al i f or ni a  u sa .
copyright 1 acm 1-1-1/1 ...$1.
unusual or unexpected observations. anomaly detection aims to address this issue from a statistical datamining framework.
¡¡anomalies can be defined as anything that is 'different' from 'normal' behavior. hence  we need to first define 'normality'. usually this is specified as a probability model from which observations are assumed to be drawn. we also need a similarity measure to compare the observations with respect to the model.
¡¡detecting anomalies in observations is important in many different respects. a traditional form of anomaly detection is in industrial process control. time-series data from various sensors are monitored to detect out of control processes. in most applications  we are interested in the detection of emergence of new phenomena unexplained by the previous model. for example  in astronomical datasets  astronomers want to detect new interesting space objects. in applications such as bio-surveillance and customs monitoring  detecting suspicious activity in high dimensional data is the goal of anomaly detection. anomaly detection can also be used to automatically detect data entry errors  which can then be corrected.
¡¡however  forming a general framework for anomaly detection is a difficult challenge as the definition of normality is typically very domain specific. this has led to independent efforts for various domains.
¡¡first  we give a summary of the related work. we then present the problem statement  along with our algorithms for anomaly detection. we show ways of speeding up the computation and making it more memory efficient. this is followed by the experimental setup  where we describe the datasets used  and the evaluation procedure. the results of our algorithms on the datasets are presented next. we conclude with a discussion of possible extensions of the current work.
1. related work
¡¡anomaly detection applied to network intrusion detection has been an active area of research since it was proposed by denning . traditional anomaly detection approaches build models of normal data and detect deviations from the normal model in observed data. a survey of these techniques is given in . one approach is to use sequence analysis to determine anomalies. a method of modeling normal sequences using look ahead pairs and contiguous sequences is presented in   and a statistical method to determine frequent sequences in intrusion data is presented in . lee et al.  uses a decision tree model over normal data and ghosh et al.  uses a neural network to obtain the model. eskin  uses a probability distribution model from the training data to determine anomalous data. they use a mixture model to explain the presence of anomalies. a clustering based approach to detecting anomalies in a dataset is used in  and . one-class svms  1  1  and genetic algorithms  have also been used to classify anomalies in this context.
¡¡anomaly detection is also commonly applied in time series data to detect unusual fluctuations compared to past data points  1  1  1  1 . another area of considerable recent interest is spatial anomaly detection .
¡¡the methods described so far apply to real valued data or work in a supervised setting when we have labeled training data. we now describe methods that apply to the problem of interest  i.e.  on categorical datasets in an unsupervised setting.
1 unsupervised methods applied to categorical datasets
1.1 association rule based approaches
¡¡the task of association rule mining has received considerable attention especially  in the case of market basket analysis . an association rule is an expression of the form x   y   where x and y are sets of items. given a database of records  or transactions  d  where each record t ¡Ê d is a set of items  x   y expresses that whenever a record t contains x  then t probably also contains y . the confidence of the rule is the probability p y |x . the support of the rule is the number of training cases where both x and y are present. instead of sets of items  x and y can also be considered to be the events that an attribute of t takes some particular values.
¡¡association rule mining is commonly used in the analysis of market-basket data  where the target of mining is not predetermined. chan et al.  have developed a rule learning method lerad to detect anomalies. they consider rules of the form x   y   where x and y are mutually exclusive subsets of attributes taking on particular values. they seek combinations of x and y with large values of p y |x . the anomaly score of a record depends on p !y |x   where y   though expected  is not observed when x is observed. the main disadvantage of this method is that it learns a very small subset of all the possible rules. we have used this method as one of the baseline methods for comparison of our algorithms.
¡¡balderas et al.  mine hidden association rules  or rules that are not common  but confident. such rules are assumed to represent the rare anomaly class.
¡¡wsare developed by wong et al.  also uses rules to identify anomalies. but in this case  the rules are learnt from a historical dataset  and are applied on a collection of records from the current time interval  to detect unusual counts of various cases.
1.1 likelihood based approaches
¡¡in these approaches  'normal' data is modeled as a probability distribution. any test record that has an unusually low likelihood based on the probability model is flagged as anomalous. for multivariate categorical data  dependency trees and bayesian networks are common representations of a probability density model. dependency trees have been used to detect anomalies in . we choose a bayesian network as the standard model against which we compare our algorithm. hence  we give an overview of this method next.
1.1 anomaly detection using bayes network
¡¡a bayesian network is a popular representation of a probability model over the attributes for categorical data because of its parsimonious use of parameters  and efficient learning and inference techniques. bayes net have been used for detecting anomalies in network intrusion detection  1  1   detecting malicious emails  and disease outbreak detection . any good structure and parameter learning algorithm is appropriate to learn the model. for our experiments  we used the optimal reinsertion algorithm  to learn the structure  and then did a maximum likelihood estimation of the network parameters. once the model is built  to test any record we find its complete record likelihood given the probability model. test records that have unusually low likelihood are then flagged as anomalies.
training
1. construct a conditional ad tree over the training dataset  ¡ì1.1 .
1. determine the dependence between all attribute setsup to size k by computing the mutual information between them  ¡ì1 .
1. construct the cache for denominator counts  ¡ì1.1 . testing: scoring a test record t
1. for each mutually exclusive and dependent pair of attribute sets a and b  ¡ì1 :
 a  compute r at bt   ¡ì1 .
1. compute the overall conditional score of the record t from all the r-values calculated above   1.1 .¡ì
figure 1: conditional anomaly test algorithm.
training
1. construct a marginal ad tree over the dataset
 ¡ì1.1 .
1. compute the marginal count histograms over thetraining data  ¡ì1.1 .
testing: scoring a test record t
1. for each attribute set a with up to k attributes:
 a  compute qval at   ¡ì1 .
1. compute the overall marginal score of the record t as the minimum q-value calculated above   1 .¡ì
figure 1: marginal anomaly test algorithm.
1. approach
¡¡suppose we are given a set of records comprised of several attributes. the data contains both normal and anomalous records. however  we do not have any labeling of the data. the problem is to identify the anomalous records among them. first we need to define 'normality' with respect to the given data. here  we make an assumption that in the training data a majority of records are normal and there are only a few anomalous records. this means we can build a model of all the data with minimal harm caused by the anomalous records. we discuss several ways of approaching this problem in the following sections.
¡¡figures 1 and 1 give an overview of the two proposed algorithms used to test for anomalous records. we will explain the steps in detail in the following sections.
¡¡our current work is motivated by the need to detect unusual shipments among all imports into the country. each record corresponds to a container that is being imported. it has attributes describing the container  its contents  and its transport as outlined in table 1.
attribute namearitycountry1foreign port1us port1shipping line1shipper name1importer name1commodity description1size1weight1value1table 1: features in piers dataset
1 conditional probability tests
¡¡we will illustrate a problem using the likelihood based approach to detect anomalies in this context. consider the attribute shippername  which has a very high arity of more than 1. in this case  as in many real world problems  the distribution of values of high arity attributes is very skewed. some of the values are common  while a large number of them are very rare. when we construct a probability distribution of the data  these rare attribute values contribute to a skewed distribution. if a record has shippername as one of the rare values  then the record's likelihood is dominated by this term. this means that rare values will cause these records to look very unusual. but often  an attribute having a rare value might not be useful information. in our data  more than 1% of the instances  contain a value of shippername that occurs only once in the training data.
¡¡consider a particular test record t and the attributes shippername and country. we define p snt ct  = p shippername =snt  country=ct   where snt and ct are the shippername and country of the test record t respectively. in general  let a be a set of attributes. define p at  = p a = at   where at is the corresponding set of values of a in the test record t.
¡¡we are interested in detecting unusual combinations of attribute values. for example  say shippername = sn1 always occurs with country=c1 and never with country=c1.
then a record t having shippername=sn1 and country=c1 is considered unusual or anomalous. this corresponds to the probability p sn1 c1 . but we have to be careful in interpreting this. consider a situation where country=c1 occurs very rarely in the data. in this case  the fact that shippername=sn1 has never occurred with country=c1 can be explained by the rarity of seeing records from country=c1. it might not mean that for shipments coming from country=c1  it is unusual to see shippername=sn1. here  we do not have enough data to support the hypothesis that this is really anomalous. to take care of this fact  we can normalize the joint probability of these attributes with the marginal probability p countryt . now  if p countryt  has a low value  the ratio  will no longer be small. but  the same argument applies to the attribute shippername  and hence  we also normalize with respect to p shippernamet . the quantity we now consider is the ratio.
¡¡in general  we consider the ratio for attributes a and b. an unusually low value of this ratio suggests a strong negative dependence between the occurrences of at and bt in the training data. when we observe them together in the test record t  we can reasonably say that it is anomalous. this also ensures we have seen enough cases of at and bt in the training data to support the hypothesis of negative dependence. we quantify this notion of minimum support in ¡ì1.1.
¡¡to generalize this idea to more than two attributes  we can consider attribute sets instead of single attributes. for example  we can consider whether the combination of attribute set a = {shippername  weight} and the attribute set b = {country  commodity} is unusual. the ratio that we consider here is:
p at bt 
r at bt  = 
p at p bt 
p shippernamet weightt countryt commodityt 
= 
p shippernamet weightt p countryt commodityt 
¡¡similarly  we can compare any two subsets of attributes  the only constraint being that there should be no common attribute among them. let us call this ratio the r-value of the record t for the attribute sets a and b. considering all possible subsets would require computation time exponential in the number of attributes. therefore  we only consider subsets up to size k. also  we want to avoid comparing attribute sets that are completely independent. we compute the mutual information ¦Ì a b  between two attribute sets a and b  and calculate r at bt  only if the mutual information is greater than a threshold. we define a and b to be dependent if 
	¦Ì a b  ¡Ý ¦Â¦Ì	 1 
where  ¦Â¦Ì is a threshold parameter  set to 1 in our experiments.
¡¡thus  for a given record  we consider all pairs of dependent and mutually exclusive subsets having up to k attributes  and calculate the corresponding r-values.
¡¡a ratio of the form r = pp a a b p b   has been proposed as a measure of suspicious coincidence by barlow . it states that two candidate fragments a and b should be combined into a composite object ab if the probability of their joint appearance p a b  is much higher than the probability expected in case of statistical independence p a p b . it has also been used to investigate unsupervised learning of complex visual stimuli by human subjects . here large values of r are interesting as it signifies a suspicious coincidence of the events co-occurring. we are interested in exactly the opposite situation  where low r values signify that the events do not co-occur naturally. if they are observed together  then we treat it as an anomaly.
1.1 partitioning the training data
a further generalization is to use a ratio of the form:
  where a b and c are mutu-
ally exclusive subsets of attributes with at most k elements. this ratio is similar to the previous formula  but here we consider the probabilities conditioned on a set of attributes. it is equivalent to partitioning the training data and considering only a subset to estimate the probabilities  consisting only of records that match the test record t in a subset of attributes  c.
1.1 combining evidence across different attribute sets
¡¡one disadvantage of our method is that it considers only a subset of attributes at a time. the final score of a record is the minimum score obtained over all such subsets. but  the score reflects the behavior of only a particular subset of size up to 1k  ignoring the values of other attributes. here  we make an assumption that maximum of 1k attribute values indicate anomalous behavior. in many practical problems this assumption is reasonable.
¡¡but  as shown in the results using artificial anomalies  when the number of anomalous attributes is larger than 1k  comparing against a joint distribution might give more accurate results.
¡¡to solve this problem  we can combine the evidence across different attribute sets. we use the following heuristic to score the record t:
1. order the r-values in ascending order. consider onlythe ordered values r1 to rq which are less than a threshold ¦Á  described in the next section .
1. initialize: score = 1  and u = ¦Õ.
1. for i = 1 to q
 a  if there is any common attribute between the attributes defining ri and u  then skip to the next value of i.
 b  else  score = score   ri  and include the attributes defining ri in u.
¡¡this heuristic computes the product of the selected rvalues corresponding to mutually exclusive sets of attributes.
the intuition is that if the attribute subsets were not only disjoint  but also independent  then this would be the r-value for the larger combined set of attributes.
p at bt p ct dt 
r at bt  ¡Á r ct dt  = 
p at p bt p ct p dt 
p at bt ct dt 
= 
p at ct p bt dt 
	= r  at ct   bt dt  	 1 
¡¡here  we assume  a ¡Í c  and  b ¡Í d . in general  this assumption does not hold  but the heuristic gives a reasonable strategy to combine evidence from multiple r-values.
1.1 user specified pruning of the search space
¡¡in many applications we can use domain information to restrict our search space. for example  consider the attributes country and city. given the value of city  the value of country is fixed. we do not need to test if there is a rare combination of these two attributes. in general  if there is a hierarchical structure of the attributes  we do not want to compare between the higher and lower level attributes. one exception is the case of searching for data entry errors  which is another potential application of our algorithm.
¡¡a user may simply be uninterested in some combinations of attributes. for example  a medical diagnosis tool may not care about an anomalous combination of patient demographic features. it may only be interested in anomalous sets of symptoms or symptoms in combination with demographics.
¡¡in either case  our algorithms can easily ignore special combinations of attributes. this improves computational speed by reducing the search space  and will produce results that are more meaningful to the end user.
1.1 estimating the probability values
¡¡for calculating the r-value r at bt  of a test record t  we need to estimate the marginal probability values from the training data. the mle estimate is  where c at  is the count of training cases where a = at. n is the total number of training records. a problem with this estimator is that when c at bt  = 1  then r at bt  = 1. regardless of the threshold ¦Á  all such cases will be flagged as anomalies.
¡¡to avoid this problem  we calculate the expected value of pa = p at  with a bayesian prior. given the record t  each attribute behaves as binary. the attribute set a can have two possible values at and 'not at'.
	p data|pa  = binomial n pa 	 1 
	p data pa 	p pa 
	p pa|data  =	|	 	 1 
p data 
	p pa|data  ¡« pac at  1   pa n c at 	 1 
	p pa|data  ¡« beta c at  + 1 n   c at  + 1 	 1 
here we assume an uniform prior over pa. hence e pa  =
c nat+1 +1.
1.1 bound on the counts
from eqn. 1 above  we can calculate:
.
¡¡to compute this ratio we need the counts c at   c bt  and c at bt . we use a caching technique to cache these counts as described in ¡ì1.1. to make this caching tractable  we compute a lower bound for c at  and c bt .
the record t is interesting when r at bt  ¡Ü ¦Á.
	c at bt  + 1	n + 1	n + 1
	= 	¡Á	¡Á	¡Ü ¦Á
	n + 1	c at  + 1	c bt  + 1
	c at bt  + 1	n + 1
	= 	¡Á	  ¦Á
	n + 1	c at  + 1
 because   n + 1     c bt  + 1  
c at bt  + 1
=    ¦Á
c at  + 1
1
=    ¦Á
c at  + 1
 because  c at bt  ¡Ý 1 
	1	 1 
¡¡similarly  c bt    ¦Á1   1. hence  we need to consider only the cases where c at  and c bt  are greater than this bound.
1.1 using ad trees for computing counts
¡¡the required counts are conjunctive counting queries on the dataset  and can be efficiently queried using an ad tree . the ad tree building algorithm scans the dataset once  and precomputes information needed to answer every possible query in time independent of the number of records. the parameter leaflist size can be adjusted to obtain a tradeoff between the memory used and the query response time. note that for our algorithm  we will never need an ad tree of depth greater than 1k.
1 computational speedup
1.1 reducing arity
¡¡the memory required to build an ad tree significantly depends on the arity of the attributes. we use the result from eqn. 1 to reduce the arity of each attribute. consider an attribute value lt of attribute l in test record t. let a and b be two attribute sets  such that l ¡Ê a  or equivalently it could belong to b   and we want to calculate the value of r at bt . the r-value will be of interest only when c at    ¦Á1   1 and c bt    ¦Á1   1. since l ¡Ê a  c lt  ¡Ý c at . this implies 1. so we can ignore all values li of l where c li    ¦Á1   1. all such values are called rare values of attribute l. all other values are called common values of attribute l. any r-value that includes the attribute l corresponding to a rare value  will always be greater than ¦Á. so  we can replace all rare values by a generic rare value. while computing the r-value of attribute sets a and b we skip the computation if either at or bt contains any rare value. we can ignore missing values originally present in the dataset in a similar fashion. this scheme of keeping only the common values significantly reduces the arity of each attribute and drastically reduces the memory required to build the ad tree. this also ensures that if any ratio r at bt  is anomalous  then there is a minimum support of ¦Á1 training cases corresponding to the attribute values at and bt.
1.1 caching values
¡¡even though the ad tree structure retrieves the counts quite efficiently  it has some overhead because it tries to store the results for all possible queries  whereas  we are interested only in some special cases as described below. we can improve the query response time by building an additional cache that is more specialized for the task. we build an ad tree as the base query module. we then build a more specialized cache as described below  by obtaining
the relevant counts from the ad tree. this caching scheme gives 1 to 1 times speedup in computation.
caching the denominator values
let there be m attributes in the dataset  numbered from
1 to m. there are attribute combinations  considering up to k attributes in each combination. we call these s composite attributes. we create a tree data structure where each node represents a composite attribute  i.e.  a set of attributes. the root node represents the null set. it has m children  each representing the unary set of the corresponding attribute. let q be the highest attribute number in the set represented by node n. then n has m-q children  child i corresponding to the union of the set represented by n  and attribute number q+i. we limit the depth of the tree to k. the complete tree has s+1 nodes  corresponding to each composite attribute and the null set. now  for each composite attribute  we find the common values  ¡ì1  present in the dataset. we store the count of the number of occurrences for each common value of each composite attribute in the corresponding node. as noted above  the counts c at  and c bt  are needed only when they are greater than ¦Á1   1  i.e.  when they are common . hence all the counts that we need to compute the denominator of any r-value  are precomputed in our cache. it takes o k  time to retrieve any count stored in the cache.
caching the numerator values
¡¡unlike the denominator counts  the numerator counts can correspond to rare value combinations  i.e.  c at bt  can be as small as zero . it becomes infeasible to store counts for all possible combinations of values for all attributes  as a caching scheme  it is actually equivalent to the full blown ad tree  which does the job more efficiently . however  given a test record t  it is possible to cache the corresponding counts for all attribute combinations  as each combination now represents a fixed set of values. we see that we can reuse the computation of probability values p at bt . for example  we compute p countryt shippert foreignportt weightt  when a={country  shipper} and b={foreign port  weight}. we have the same value for a={country  shipper  foreign port} and b={weight}. therefore  each time before computing the value of p at bt   we first check if it has been already calculated. if not  we compute its value  obtaining relevant counts from the ad tree. we then cache this value in our tree cache structure for future use. this reduces the number of  relatively  expensive ad tree queries.
¡¡note that the cached values are useful only for a particular test record. for a new test record we clear the cache and start over.
1 marginal probability tests
¡¡while computing the r-value  we normalize with respect to the marginal probabilities. this means that an unusually low marginal probability value will not be detected by this method. that is fine because we want to detect unusual pairings of sets of attributes  rather than just detecting a rare combination. but in some cases  detecting rare combinations might also be useful.
¡¡we define qval at   the q-value of an attribute set a for the test record t as the sum of p a = at  and all values of p a  that are smaller or equal to p a = at . here at is the corresponding set of values of the attributes in a in the test record t.
qval at  = x p x  where  x ¡Ô {x : p x  ¡Ü p at }	 1  x¡Êx
¡¡this is parallel to the standard definition of p-value for continuous variables  which sums over values that are more extreme than the current value. in our definition for the case of categorical attributes  more extreme corresponds to values that have a probability less than the current value.
¡¡the q-value of an attribute gives an indication of rarity of its occurrence. an attribute set a is considered anomalous in record t if qval at  ¡Ü ¦Ám  where ¦Ám is a predetermined threshold.
1.1 implementation
¡¡computing the qval at  of an attribute set a in test record t is somewhat more complicated than calculating the r-value. to calculate qval at   we not only need to know c at   but also the counts for all other possible values ai of a such that  c ai  ¡Ü c at . when dealing with composite attributes  the number of possible values it can have becomes exponentially large. even if all the counts are cached  going through each of them for every test becomes prohibitive.
¡¡instead  for every composite attribute a  we store the histogram h of the number of times different values occur in the training dataset. for example we precompute the fact that a has h 1  values occurring only once  h 1  values occurring twice and in general  h i  values occurring i times. when testing attribute set a in record t  we compute c at   and compare that to the precomputed histogram. we compute the quantity crarer = pi¡Üc at  i   h i . normalizing with respect to the number of data-points n  gives the desired qval at . we still need to get the count c at   and unlike the conditional method  we are especially interested in rare values. hence  we cannot reuse the ad tree constructed for the conditional method. we construct another ad tree without any reduction of arity from the original dataset. we call this the marginal ad tree. we use a bigger leaf-list size to keep the size of the tree manageable .
¡¡note that all the information in the conditional ad tree is also contained in the marginal ad tree. but  we still maintain the conditional ad tree separately as it is faster to query from the smaller tree for the conditional method.
1. experimental setup
1 datasets
1.1 piers dataset
¡¡our first dataset consists of records describing containers imported into the country. each record consists of 1 attributes. most of the attributes are categorical  such as the country of origin  the departing and arriving ports  shipping line etc. there are three real valued attributes  the size  weight and value of the container. we have categorized these to five discrete levels.
¡¡since there were no labels in the original data  we create synthetic anomalies by randomly flipping attribute values.
we first partition the dataset into training and testing sets. we randomly choose 1% of the data as a test set  and the remaining 1% is the training set. the dataset used for generating these results has 1 records so the training set has 1 records and the test set has 1. we modify a random 1%  i.e. 1  of the test set records to be anomalies. for each record that is modified  a random set of up to l attributes is chosen. the values for these attributes are reassigned by drawing from the corresponding attribute marginals. the higher the value of l  greater the degree of anomaly.
¡¡apart from randomly flipping attribute values  we use another method to create anomalies in the test data. the training data is from the month of june 1. we randomly pick 1 records from a different month  june 1   and replace 1 randomly chosen records in the test set. we deliberately do not include records from june 1 that have attribute values not present in the training data. otherwise  detecting those anomalies is a trivial task.
1.1 kdd cup 1 network connections dataset
¡¡we have used a network connection records dataset from kdd cup 1   which contained a wide variety of intrusions simulated in a military network environment. each record is a vector of extracted feature values from a connection record obtained from the raw network data. the extracted features included the basic features of an individual tcp connection such as its duration  protocol type  number of bytes transferred etc. other features of an individual connection were obtained using some domain knowledge  and included the number of file creation operations  number of failed login attempts  whether root shell was obtained  and others. finally there were a number of features computed using a two second time window. these included the number of connections to the same host as the current connection  the number of connections to the same service  etc. in total there are 1 features  most of them taking continuous values. the continuous features were discretized to 1 levels.
¡¡the goal of the kdd dataset was to produce a good training set for learning methods that use labeled data. hence  the proportion of attack instances to normal ones is very large. to create more realistic data  we have reduced the number of attack records to about 1% of the test dataset. there are a total of 1 types of attack. some of the attacks which are denial of service or probing attacks are much easier to detect than other attacks. we have selected four kinds of attacks - mailbomb  guess password  warezmaster and apache1. correspondingly  we created four test sets containing 1% records of the particular attack type  and 1% normal records. we used other normal records for training our model.
1 training
¡¡we build our model  which includes the conditional ad tree  the marginal ad tree  the mutual information matrix  cache for the denominator counts ¡ì1.1 and the marginal count histograms using the training data. building these comprise the training phase.
1 testing

 a  algorithm performances for l = 1 b  algorithm performances for l = 1
1	1	1	1	1
detection rate
 c  algorithm performances for l = 11
	1.1.1.1.1
detection rate
 d  algorithm performances for inserted records from different monthfigure 1: comparison of algorithm performances for the piers dataset. the x axis is the fraction of the true anomalies found by the algorithm. the y axis is the fraction of predicted anomalies that were true anomalies. the curves are created by varying the threshold parameter ¦Á. curves that are higher and farther to the¡¡for each test record t  we consider every possible pair of composite attributes  that are mutually exclusive and depenright are better.
dent  see eqn.1 . for each such pair  a and b  we compute r at bt . the minimum r-value is assigned as the score of the record t. in some cases we have used the combining evidence heuristic  ¡ì1.1  to assign score to a record. for the kdd dataset  we have also considered the partitioning method described in ¡ì1.1. here we consider all possible mutually exclusive subsets a  b and c to compute the ratio rval at bt|ct .
1 evaluation
¡¡we evaluate our methods against a likelihood based approach using a bayes network representation and association rule based learner lerad . the conditional and marginal models are evaluated separately. for the conditional and marginal methods  we vary the value of ¦Á between 1 to 1 to generate points on the curve. for the bayes network method  we vary the likelihood threshold. in our plots  the x-axis represents the detection rate  i.e.  the proportion of total true anomalies that are detected. the y-axis gives the corresponding precision of detection  i.e.  the ratio of number of true positives to the total number of predicted positives. a higher curve denotes better performance.
1. results
1 containers dataset
¡¡in figure 1 we show the comparison our methods  conditional and marginal  against the bayes net likelihood method and lerad  on the cbp dataset. the data points correspond to particular threshold parameter values. the points denote the average performance over 1 randomly generated test sets for each algorithm. the 1% confidence error bars are much smaller than the marker sizes. hence any difference that appears in the plots is statistically significant.

 a  apache1 b  mailbomb1
1.1.1.1
¡¡detection rate  c  snmpguess 1
1	1	1	1	1	1
detection rate
 d  comparison for all attack types1figure 1: performance over the network connections kdd cup 1 dataset¡¡in figure 1 a  we see the performance of the methods when l = 1  i.e.  the anomalies are generated by flipping just one attribute value. for the conditional method  we set k = 1 for all the experiments. this means we consider up to three attributes in each composite attribute. we see that the conditional method performs best  followed by the marginal method. both these methods outperform the bayes net and lerad significantly.
¡¡figures 1 b  and 1 c  shows the performance when l = 1 and l = 1 respectively. our methods outperform the bayes net method and lerad. as mentioned previously  we take k = 1 for the conditional method. this means that we consider up to six attributes while computing a r-value. even though the bayes net models the likelihood of all the attributes combined together  the conditional and marginal methods still perform better.
¡¡figure 1 d  shows the performance when the anomalies are actually records inserted from a different month. we see that the marginal method performs the best  followed by the conditional method. the bayes net method and lerad perform very poorly in comparison. the superlative performance of the marginal method can be explained by the fact that records from the other month have combinations of attribute values that are not present in the training set. the conditional method ignores these values  while the marginal method takes advantage of this fact.
1 kdd cup 1 network connections dataset
¡¡on the network connections dataset  we see that some attack types are easier to detect than others. figure 1 shows the performance comparison of the different methods for some of the attack types. as number of attributes is quite large  we have used up to k = 1 attribute combinations. this means that up to four attribute values are considered at a time. for the conditional method  we have used the heuristic to combine evidence  ¡ì1.1  from different attribute sets. here  we have also compared the performance of the partitioning method ¡ì1.1.
datasettraining sizetest sizenumber oftrainingtestingmemoryattributestime  secs time  secs  mb piers111.1.1.1kdd cup 1 1 11.1table 1: time and space requirement for bayes network method
datasettraining sizetest sizenumber ofktrainingtestingmemorymarginalattributestime  secs time  secs  mb memory  mb piers1111111.111.11kdd cup 1 1 11.11111table 1: time and space requirement for conditional and marginal methods¡¡the marginal method performs very poorly in this case and starts with a large number of false positives even at the lowest sensitivity level. since this dataset has a very large number of attributes  there is a high chance that even for normal records  there is a value of an attribute combination that is not present in the training data. this leads to flagging of a large number of records as maximally anomalous. hence  we haven't shown the marginal algorithm curve for the plots as it performs very poorly.
¡¡we have evaluated the performance of each algorithm over 1 randomly chosen test sets of size 1 each. we show the average performance for each attack type. for attack types mailbomb and snmpguess we also show the 1% confidence error bars.
¡¡for attack type apache1 in figure 1 a   the original conditional method performs worse than the bayes net likelihood approach. but using the combining evidence heuristic results in a much better accuracy. here  the conditional method is able to detect almost all the attacks with a very high precision rate.
¡¡for attack types mailbomb and snmpguess  the conditional method performs slightly better than the bayes net method. using the partitioning of training data in the conditional method results in similar or better performance to the basic method. here we see that the error bars are quite large. figure 1 d  gives a better comparison of performance between the methods. this plots the difference of detection precision between the conditional method and the bayes net method. a positive difference means that the conditional method has higher precision. we see that for five of the attack types considered  the difference is mostly above zero. but  for the attack type guess password the bayes net method performs significantly better. here  the error bars represent 1% confidence intervals.
1. future work
¡¡the current work focuses on finding single records that are anomalous. sometimes in real world applications we are more interested in detecting groups of unusual records that deviate from the norm  rather than detecting the records separately. for example  in astronomical datasets  we might be more interested in an unusual phenomenon if it keeps repeating at some interval. just observing one such instance may not be significant  as it could be attributed to some measurement error. in biosurveillance  we might be interested in the emergence of a new disease by detecting a group of unusual but similar cases. it is especially relevant in network security monitoring  as we can detect a new pattern of user behavior from a group of records. this can signal possible malicious behavior.
¡¡an important challenge here is to define what can be considered as a group. we need to specify a similarity measure  and group records on the basis of it. if the data has temporal and/or spatial components  they provide a natural measure for grouping. for temporal analysis  we propose to group records on the basis of a temporal unit such as a day. we can extend the method of comparison of marginal and conditional probability distributions of all records in the current day  to the historical data. similarly  for a spatial analysis  grouping can be predetermined such as by zip code or area. it can also be computed dynamically similar to spatial scan. apart from this  we can also use the association based dissimilarity measures such as methods presented in  1  1  for grouping records.
¡¡another possible improvement is the way we deal with real valued attributes. since we deal with actual probability values p rather than probability densities p  all the real values are discretized to perform the analysis. but by discretizing the values we lose some information  such as the ordering of values. while estimating counts to determine the p values  we can borrow information from neighboring bins in case of discretized attributes.
¡¡currently  we have a fixed number of levels for discretization. it is conceivable that different real attributes have varying characteristics  and discretizing into the same number of levels is not the best solution. we can use different clustering techniques to determine appropriate levels.
