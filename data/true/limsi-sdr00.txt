　in this paper we describe the limsi spoken document retrieval system used in the trec-1 evaluation. this system combines an adapted version of the limsi 1 hub-1e transcription system for speech recognition with text-based ir methods. compared with the limsi trec-1 system  this year's system is able to index the audio data without knowledge of the story boundaries using a double windowing approach. the query expansion procedure of the information retrieval component has been revised and makes use of contemporaneous text sources.
　experimental results are reported in terms of mean average precision for both the trec sdr'1 and sdr'1 queries using the same 1h data set. the mean average precision of this year's system is 1 for sdr'1 and 1 for sdr'1 for the focus unknown story boundary condition with a 1% word error rate.
1. introduction
　this paper describes the limsi broadcast news indexating and retrieval system developed for the trec-1 spoken document retrieval track. compared with the limsi trec-1 sdr system  both the speech transcription system and the information retrieval component have been improved. concerning the speech recognizer  we have both sped up the decoder and slightly reduced the word error rate. the query expansion procedure of the information retrieval component has been revised and the capability to index nonsegmented audio streams for the unknown story boundaries condition has been added.
　duringour developement work we investigatedthe impact of various system parameters on the ir results including: the transcriber speed  the epoch of the texts used for query expansion  the query expansion term weighting strategy  the query length  and the use of non-lexical information.
　most of the reported results here were obtained using the trec-1 sdr'1 conditions  i.e. the trec-1 data collection consisting of 1 hours of broadcast news from the period of february through june 1. this data includes 1 stories and has an associated set of 1 queries.
　the remainder of this paper is as follows: in the next three sections we provide an overview of the broadcast news indexation and information retrieval components  followed by an investigation of the impact of decodingspeed and the consequence of the word error rate on the information retrieval process. the subsequent two sections address query expansion and the use of non-lexical information. we then describe how we addressed the unknown story boundary condition and the terse query condition in this year's evaluation. comparative results are given on the development queries from sdr'1 and this year's query set  and some conclusions are made.
1. transcription system overview
　the limsi broadcast news transcription system  consists of an audio partitioner  and a speech recognizer  1  1 . the goal of audio partitioning is to divide the acoustic signal into homogeneous segments  labeling and structuring the acoustic content of the data. partitioning consists of identifying and removing non-speech segments  and then clustering the speech segments and assigning bandwidth and gender labels to each segment. the result of the partitioning process is a set of speech segments with cluster  gender and telephone/wideband labels  which can be used to generate metadata annotations. the partitioning approach used in the limsi bn transcription system relies on an audio stream mixture model . each component audio source  representing a speaker in a particular background and channel condition  is modeled by a gmm. the segment boundaries and labels are jointly identified by an iterative maximum likelihood segmentation/clustering procedure using gmms and agglomerative clustering.
　for each speech segment  the word recognizer determines the sequence of words in the segment  associating start and end times and an optional confidence measure with each word. the speaker-independent large vocabulary  continuous speech recognizer makes use of n-gram statistics for language modeling and of continuous density hmms with gaussian mixtures for acoustic modeling. word recognition is usually performed in three steps: 1  initial hypothesis generation  1  word graph generation  1  final hypothesis generation. the hypotheses are used in cluster-based acoustic model adaptation using the mllr technique  prior to word graph generation  and all subsequent decoding passes. the final hypothesis is generated using a 1-gram language model.
　for all the experimental results given in this paper  the following training conditions were used. the acoustic models were trained on about 1 hours of american english broadcast news data. the phone models are position-dependent triphones  with about 1 tied-states for the largest model set. the state-tying is obtained via a divisive  decision tree based clustering algorithm. wideband and telephone band sets of gender-dependent acoustic models were built using map adaptation of si seed models. fixed language models were obtained by interpolation of -gram backoff language models trained on 1 different data sets: 1 m words of bn transcripts; 1 m words of nab newspaper texts and ap wordstream texts; 1 m words corresponding to the transcriptions of the acoustic training data. the interpolation coefficients of these lms were chosen so as to minimize the perplexity on the hub1 nov1 evaluation data. the 1-gram lm contains 1m bigrams  1m trigrams and 1m fourgrams.
　the recognition word list contains 1 words. the word pronunciations are based on a 1 phone set  1 of them are used for silence  filler words  and breath noises . a pronunciation graph is associated with each word so as to allow for alternate pronunciations  including optional phones. frequent inflected forms have been verified to provide more systematic pronunciations. as done in the past  compound words for about 1 frequent word sequences subject to reduced pronunciations were included in the lexicon as well as the representation of the most frequent acronyms as words.
1. information retrieval
　the automatically generated partition and word transcription can be used for indexation and information retrieval purposes. techniques commonly applied to automatic text indexation were applied to the automatic transcriptions of the broadcast news radio and tv documents. these classical techniques are based on document term frequencies  where the terms are obtained after standard text processing  such as text normalization  tokenization  stopping  stemming and named-entity identification.
　in order to be able to apply the same ir system to different text data types  automatic transcriptions  closed captions  additional texts from newspapers or newswires   all of the documents are preprocessed in a homogeneous manner. this preprocessing  or tokenization  is the same as the text source preparation for training the speech recognizer language models   and attempts to transform the texts to be closer to the observed american speaking style. the basic operations include translating numbers and sums into words  removing all the punctuation symbols  removing case distinctions and detecting acronyms and spelled names. however removing all punctuations implies that certain hyphenated words such as anti-communist  non-profit are rewritten as anti communist and non profit. while this offers advantages for speech recognition  it can lead to ir errors. to avoid ir problems due to this type of transformation  the output of the tokenizer  and recognizer  is checked for common prefixes  in order to rewrite a sequence of words such as anti communist as a single word. the prefixes that are handled include anti  co  bi  counter. a rewrite lexicon containing compound words formed with these prefixes and a limited number of named entities  such as los-angeles  is used to transform the texts. similarly all numbers less than one hundred are treated as a single entity  such as twentyseven .
　in order to reduce the number of lexical items for a given word sense  each word is translated into its stem  as defined in  1  1   or  more generally  into a form that is chosen as being representative of its semantic family. the stemming lexicon  derived from the umass 'porterized' lexicon   contains about 1 entries and was constructed using porter's algorithm on the most frequent words in the collection  and then manually corrected.
　two approaches for ir were explored for sdr'1 and this year  the first based on the popular tf idf weigthing scheme and the second using a markovian term weighting  1  1  1 .
　for the tf idf approach  the score of document for a query is given by the okapi-bm1 formula 1  1 . it is the sum over all the terms in the query of:
tf
	cw		qtf
tf
where tf is the number of occurrences of term in document  i.e. term frequency in document   is the number of documents containing term at least once  is the total number of documents in the collection  is the length of document divided by the average length of the documents in the collection  and qtf the number of occurrences of term in the query.
　for the second approach the score of a story is obtained by summing the query term weights mw which are the unigram log probabilities of the terms given the story model once interpolated with a general english model:
	mw	qtf
　the text of the query may or may not include the index terms associated with relevant documents. one way to cope with this problem is to use query expansion based on terms present in retrieved documents on the same  blind relevance feedback  brf  or other  parallel blind relevance feedback  pbrf  data collections . for sdr'1 we combined the two approches in our system. for pbrf we used 1 months of commercially available broadcast news transcripts from the period jun-dec 1 . this corpus contains 1 stories and 1 m words. for a given query  the terms found in the top documents from the baseline search are ranked by their offer weight   and the top terms are added to the query. since only the terms with best offer weights are kept  the terms are filtered using a stop list of 1 common words  in order to increase the likelihood that the resulting terms are relevant.
　table 1 gives the results for both cw and mw term weightings for the sdr'1 data set. four experimental configurations are reported: baseline search  base   query expansion using brf  brf   query expansion with parallel brf  pbrf  and query expansion using both brf and pbrf  brf+pbrf . for brf and pbrf  the terms are added to the query with a weight of 1. for brf+pbrf  the terms from each source are added with a weight of 1. the results clearly demonstrate the interest of using both brf and pbrf expansion techniques  as consistent improvementsare obtained over the baseline system for the two conditions  r1 and s1 . brf is found to be more effective for both the s1 condition  the recognizer transcripts  and the r1 condition  the manual transcripts .
datameth.basebrfpbrfbrf+pbrfr1ktf idf1111unigram1111s1ktf idf1111unigram1111table 1: comparison of ir results on the sdr'1 data set using both okapi and markovian term weightings   =1  =1  =1  =1  =1 . r1: reference transcript. s1: automatic speech transcription. k: known story boundary condition.
　the two ir approaches are seen to yield comparable results . only small differences in information retrieval performance as given by the mean average precision were observed for automatic and manual transcriptions when the story boundaries are known.
1. decoding speed
　processing time is an important factor in making a speech transcription system viable for automatic indexation of radio and television broadcasts. when only concerned by the word error rate  it is common to design systems that run in 1 times real-time or more. although it is usually assumed that processing time is not a major issue since computer power has been increasing continuously  it is also known that the amount ofdata appearing on informationchannelsis increasing very rapidly. therefore processing time is an important factor in making a speech transcription system viable for audio data mining and other related applications. constraints on the computational resources led us to reconsider some of the system design issues  particularly those concerning the acoustic models and the decoding strategy. we investigated the design of a system which performs well with computational resources in the range 1 to 1xrt on commonly available platforms. a new decoder was implemented with which broadcast data can be transcribed in few times real-time with only a slight increase in word error rate when compared to our best system.
　a 1-gram single pass dynamic network decoder has been developed. it is a time-synchronous viterbi decoder with dynamicexpansion of lm state conditionedlexical trees  1  1  1  with acoustic and language model lookaheads. the decoder can handle position-dependent  cross-word triphones and lexicons with contextual pronunciations. it makes use of various pruning techniques to reduce the search space and computation time  including three hmm-state pruning beams and fastgaussianlikelihoodcomputations. it can also generate word graphs and rescore them with different acoustic and language models. faster than real-time decoding can be obtained using this decoder with a word error under 1%  running in less than 1 mb of memory on widely available platforms such pentium iii or alpha machines.
　the decoder by itself does not solve by itself the problem of reducing the recognition time as proper models have to be used in order to optimize the recognizer accuracy at a given decoding speed. in general  better models have more parameters  and therefore require more computation. however  since the models are more accurate  it is often possible to use a tighter pruning level  thus reducing the computational load  without any loss in accuracy. thus  limitations on the available computational resources affect the design of the acoustic and language models. for each operating point  the right balance between model complexity and pruning level must be found.
　in order to assess the effect of the recognition time on the information retrieval results we transcribed the 1 hours of broadcast news data  the trec sdr'1 data set - epoch feb1 to jun1  using two decoder configurations: a single pass 1xrt system and a three pass 1xrt system. the sdr'1 test data consists of 1 stories and an associated set of 1 queries with on average 1 words. although story boundaries are available  this information is not used by the speech recognizer. the information retrieval results are given in term of mean average precison  map   as is done for the trec benchmarks. word error rates are measured on a 1h test subset . for comparison  results are also given for manually produced closed captions. in order for the same ir system to be applied to different text data types  automatic transcriptions  closed captions  additional texts from newspapers or newswires   all of the documents are preprocessed in a homogeneous manner. this preprocessing  or tokenization  is the same as the text source preparation for training the speech recognizer language models.
　table 1 gives the word error rates and ir results for the three sets of transcriptions with and without query expansion. query expansion uses blind relevance feedback  brf 
transcriptionswerrbasebrfclosed-captions-111xrt1%111xrt1%11table 1: impact of the word error rate on the mean average precision using the sdr'1 conditions using a 1-gram document model.
pbrf'1brf+pbrf'1pbrf'1.1.1.1table 1: comparison of query expansion schemes on the sdr'1 data with known story boundaries.
on both the audio document collection and some commercially available broadcast news transcripts predating the audio corpus  jun-dec 1 vs feb-jun 1 . with query expansion comparable ir results are obtained using the closed captions and the 1xrt transcriptions  and a small degradation  1% absolute  is observed using the 1xrt transcriptions.
1. query expansion
　in our sdr'1 system query expansion was done by adding terms present in retrieved documents on the same data collection and in an independent set of texts. for pbrf we made use of 1 months of commercially available broadcast news transcripts for covering the period of june through december 1   1 stories and 1 m words . however  the sdr'1 specifications as well as the sdr'1 specifications  allow us to use texts  except for bn transcripts  covering exactly the same epoch of the audio data. therefore this year we implemeted pbrf using 1 sources of contemporary newspaper data: the new york times  the los angeles times and the washington post. the parallel corpus conatined a total of 1 m words and 1 k documents between jan1 and jun1. experiments with these texts on the sdr'1 show that pbrf using contemporary texts offers a significant performance gain compared with a pbrf using texts predating the audio data. in fact we found that we no longer needed to combine both brf and pbrf  since prbf with the new texts gave comparable benefits.
　this year we also changed the term weighting used with query expansion  using a weight proportional to the offer weight as defined in  1  1 . this approach allowed us to significantly increase the number of expansion terms  going from 1 terms with the previous approach to 1 terms with the term weighting. the sum of the weights for the expansion terms is set to the number of added terms  i.e.  1. table 1shows the combinedimprovment obtained withthe new query expansion scheme on the sdr'1 data. these results were obtained using the okapi term weighting with a parameter setting  b=1  k=1  and a slighlty different stemmer from that used for the results reporter earlier in this paper.

1
1 1 1 1 1 1 1 1
number of speaker turns
figure 1: histogram of the number of speaker turns per section in the 1 hub-1 data set.
1. non-lexical information
　the broadcast news transcription system also provides non-lexical information along with the word transcription. this information is available in the partition of the audio track  which identifies speaker turns. we investigated the use of automatically detected speaker changes for locating document boundaries. statistics were made on the 1 english hub-1 training data set  which consists of about 1 hours of radio and television broadcast news with manual transcription and speaker identification. on this set  1 sections were manually marked as report sections and used as documents for the sdr'1 evaluation. among them  1 sections  about 1%  start without a manually annotated speaker change. this means that using only speaker change information for detecting document boundaries would result in 1% missed boundaries. this figure would likely increase with the use of automatically detected speaker changes. at the same time  1 of the total of 1 speaker turns occur in the middle of a document  which gives almost a 1% false alarm rate. a more detailed analysis shows that about 1% of the sections involve a single speaker  but that the distribution of the number of speaker turns per section falls off very gradually from 1 to 1 speakers  cf. figure 1 . false alarms are not as harmful as missed detections  since it is possible to merge adjacent turns into a single document in subsequent processing. however these results show clearly that even perfect speaker turn boundaries cannot be used as the primary cue for locating document boundaries. they can be used to refine the placement of a document boundary located near a speaker change.
　besides speakerturns  changes in the background acoustic conditions can be detected by the audio partitioner and can be considered as indicators of story boundaries. we did not investigate this because the background conditions were not manually marked in the 1 english hub-1 corpus.
we investigated using simple statistics on the durations of

figure 1: distribution of document durations in the hub1 and sdr'1 data sets.
the documents in the sdr'1 data set. a histogram of the 1 sections is shown in figure 1. one third of the sections are shorter than 1 seconds. the histogram has a sharp peak around1 seconds  and a smaller  flat peak around1 minutes  resulting in a bimodal distribution of document length. very short documents are typical of headlines which are uttered by single speaker  whereas longer documents are more likely to contain data from multiple talkers. this distribution led us to consider using a multi-scale segmentation of the audio stream into documents. similar statistics were measured on the sdr'1 data using the knowndocument boundaries. the distribution  shown in lower part of figure 1 is quite similar to that of the sdr'1 data  with an additional  small peak at 1 seconds.
1. unknown story boundary condition
　as proposed in   we first segmented the audio stream into overlapping documents of a fixed duration. as a result of optimization using the trec-1 sdr queries  we chose a 1 second window duration with a 1 second overlap. since there are many stories significantlyshorter than1s in broadcast shows  see figure 1  we conjunctured that it may be of interest to use a double windowing system in order to better target short stories. the window size of the smaller window was selected to be 1 seconds. so for each query  we independently retrieved two sets of 1 documents  one set for each window size. then for each document set  document recombination is done by merging overlapping documents until no further merges are possible. the score of a combined document is set to maximum score of any one of the components. for each document derived from the 1s windows  we produce a time stamp located at the center point of the document. however  if any smaller documents are embedded in this document  we take the center of the best scoring document. this way we try to take avantage of both window sizes. the map using a single 1s window and the double windosing strategy are shown in table 1.
mode1s1s + 1sbaseline11pbrf11table1: unkownstory boundary condition development results on sdr'1 data.
1. terse queries
　a new component of this year's evaluation was the use of terse queries for indexation. since terse forms of the 1 queries were not available  we generated a set for use in system development. these were generated based on the instructions given to the assessors that developed the sdr'1 short and terse queries. different group members used these general instructions to independently generate terse versions of the sdr'1 queries. these were then compiled and a single form was selected. the resulting sdr'1 terse queries contain on average 1 words per query to be compared to 1 words for the regular  short  queries.
　we carried out retrieval experiments with these terse queries using the system parameter values tuned for the short queries. the retrieval results are given on table 1 for both the known and unknown story boundary conditions on the sdr'1 data. we can see that there is only about a 1% absolute reduction of the mean average precision when the short queries are replaced by the terse queries. given this small degradation we did not try to modify our system to better optimize performance on the terse queries.
1. results
　retrieval results for the sdr'1 evaluation system are given in tables 1 and 1 for both sdr'1 and sdr'1 queries. it is clear from these resultsthat the system behavoir is quite different on the two query sets. first the sdr'1

　　although no specific written guidelines were available  john garofolo kindly described the instructions given to the assessors.
modeshort queriesterse queriesr1k11s1k11s1u11table 1: retrieval results with short and terse queries on the sdr'1 data. r1: reference transcript. s1: automatic speech transcription. k: known story boundary condition. u: unknown story boundary condition.
queries appear to be significantly more difficult  with a 1% relative reduction in the mean average precision compared to the sdr'1 queries. second  we get significantly better results with the terse queries than with the short queries  while we observed a slight loss on our sdr'1 terse queries. the average length of the sdr'1 terse queries  1  is not significantly different from the average length of our sdr'1 terse queries  1   but there is a substantial difference in the number of new words compared to the short queries. the sdr'1 terse queries introduce 1 new words with 1 words in common the the sdr'1 short queries  whereas we had only 1 new words in our sdr'1 terse queries with 1 words in common. these numbers show that our sdr'1 terse queries were essentially shorter versions of the corresponding short query  whereas the sdr'1 terse queries appear to be a reformulation of the sdr'1 short queries.
modequeries'1queries'1short	terseshort	terser1k1	11	1s1k1	11	1table 1: retrieval results on sdr'1 and sdr'1 data with known story boundaries. r1: reference transcript. s1: automatic speech transcription. k: known story boundary condition.
modequeries'1queries'1short	terseshort	terser1u1	-1	1b1u1	-1	1s1u1	11	1table 1: retrieval results on sdr'1 and sdr'1 data with unknown story boundaries. r1: reference transcript. b1: baseline automatic speech transcription. s1: automatic speech transcription. u: unknown story boundary condition.
1. conclusion
　in this paper we have described the limsi trec-1 spoken document retrieval system. this system is based on the 1 limsi system  with a few substantial modifications. first  the decoder of the speech recognizer has been replaced by a new  faster decoder able to transcribes broadcast data in several  1 to 1  times real-time with only a slight increase in word error rate when compared to our best system and with a word error of about 1% for essentially real-time decoding. second  the query expansion procedure of the information retrieval component has been revised and makes use of contemporaneous text sources. thirdly  a double windowing approach has been developed to localize stories for the unknown boundary condition.
　the experimental results show that only a moderate ir performance degradation is obtained in spoken document retrieval with a close to real-time system  and that generally speaking  the transcription quality of our system is not a limiting factor given todays ir techniques.
acknowledgements
　this work has been partially financed by the european commission under the ist-1 alert project and the french ministry of defense. we also thank patrick paroubek for providing the terse versions of the sdr'1 query set used for system development.
