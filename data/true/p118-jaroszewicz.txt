we consider a model in which background knowledge on a given domain of interest is available in terms of a bayesian network  in addition to a large database. the mining problem is to discover unexpected patterns: our goal is to find the strongest discrepancies between network and database. this problem is intrinsically difficult because it requires inference in a bayesian network and processing the entire  potentially very large  database. a sampling-based method that we introduce is efficient and yet provably finds the approximately most interesting unexpected patterns. we give a rigorous proof of the method's correctness. experiments shed light on its efficiency and practicality for large-scale bayesian networks and databases.
categories and subject descriptors
h.1  database management : database applicationsdata mining
general terms
algorithms  experimentation  performance
keywords
bayesian networks  association rules  sampling
1. introduction
모the general task of knowledge discovery in databases  kdd  is the  automatic extraction of novel  useful  and valid knowledge from large sets of data  . however  most data mining methods - such as the apriori algorithm  - are bound to discover any knowledge that satisfies the chosen usefulness criterion  including  typically very many  rules that are already known to the user. tuzhilin et al.  1  1  1  have studied the problem of finding unexpected rules relative to a set of rules that encode background knowledge.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee.
kdd'1  august 1  1  chicago  illinois  usa.
copyright 1 acm 1-1-x/1 ...$1.
bayesian networks provide not only a graphical  easily interpretable alternative language for expressing background knowledge  but they also provide an inference mechanism; that is  the probability of arbitrary events can be calculated from the model. intuitively  given a bayesian network  the task of mining interesting unexpected patterns can be rephrased as discovering itemsets in the data which are much more - or much less - frequent than the background knowledge suggests.
모an algorithm which performs this discovery task exactly has been discussed by jaroszewicz and simovici . this approach  however  incurs two intrinsic problems. the first problem is the necessary exact inference in the bayesian network - which is known to be a very hard problem. the second is the necessity to process the entire database in order to assess all patterns and identify the most interesting ones. inference can be approximated by sampling from the joint distribution of the network; evaluating the interestingness of patterns can be approximated by evaluating patterns on a random sample instead of the entire database. however  a discovery algorithm which follows this approach cannot come with the guarantee of finding the patterns which actually maximize the interestingness criterion. we devise an efficient sequential sampling algorithm which approximates the inference in the network and draws a sample from the database in such a way that the resulting interesting attribute sets are  with high probability 1 붻  the most interesting ones up to some small difference in interestingness 붼  where 붼 and 붻 are user-adjustable parameters.
모bayesian networks are widely used in practice; for instance  volkswagen uses a bayesian model in their production planning and scheduling system ; it contains 1 nodes with between 1 and 1 possible values. finding discrepancies between a huge model and the  very large  transaction database is a difficult and relevant problem.
모the rest of this paper is organized as follows. we discuss related work in section 1 and introduce our framework and notation in section 1. in section 1  we present the sampling algorithm for finding frequent itemsets that are most interesting relative to background knowledge and our main result on its correctness. we study the behavior of this algorithm empirically in section 1. section 1 concludes.
1. related work
모the apriori algorithm  finds frequent itemsets and  succeedingly  all sufficiently confident rules over these itemsets. many measures of interestingness of rules and itemsets have been discussed  e.g.   1  1  1  1  . a fundamental shortcoming of all of these interestingness measures is that neither of them takes into account whether discovered knowledge is entailed by previously available background knowledge.
모some algorithms take background knowledge expressed as rules into account during the discovery process  1  1  1 . these methods assess the unexpectedness of a new pattern given the background rules on a purely syntactic basis  without inference. that is  they discover rules that are unexpected given the background rules  rather than rules that are unexpected given what can be inferred from the background rules. for instance  if  a   b  and  b   c  were known  then  a   c  would still be considered an unexpected pattern. a more detailed discussion of data mining with background knowledge can be found in .
모bayesian networks are a powerful representational scheme for background knowledge; they are graphical models  easy to understand and modify. bayesian networks encode the joint distribution over all attributes. inference mechanisms are well understood; general inference in bayesian networks is a hard problem that can be approximated by sampling  e.g.   . the inference problem given values of some random variables is approximated by mcmc methods . jaroszewicz and simovici  define interestingness of a pattern as difference between observed frequency and inferred probability. their algorithm finds all itemsets whose interestingness is above 붼 but  unfortunately  relies on exact inference - which is tractable for small networks.
모it is straightforward to replace the exact inference by sampling-based approximate inference  but we would like to do this in such a way that the algorithm's output maintains a well-defined optimality property. sampling algorithms  estimate the interestingness of patterns by drawing examples from the database. the most elementary sampling schemes  calculate worst-case sample bounds  often based on hoeffding's inequality. the sample size necessary for a desired 붼/붻 level of optimality can be reduced substantially by employing data-dependent  sequential sampling  1  1 . here  the data are processed incrementally; the necessary sample size is determined online  dependent on characteristics of the data that have already been processed.
모practical sequential sampling algorithms have been studied for interestingness functions which are averages over the data  such as accuracy   1  1  1  as well as for more general interestingness functions . these algorithms minimize the number of database accesses needed to find  with high probability  all approximately sufficiently interesting  or the n most interesting patterns. unfortunately  all of these methods assume that the bottleneck in the assessment of candidate patterns lies only in the database access. by contrast  in our problem setting we need to manage uncertainty originating from limited database access as well as uncertainty originating from approximate inference in the bayesian network.
1. problem setting
모in this section  we introduce the necessary notation and define the problem that we will solve in the following.
	we are given a database d with attributes z	=
{a1 ... am }; attributes are categorical with finite domains dom a . pid i  denotes the probability that an attribute set i   z assumes a vector of values i in the database d.
모a bayesian network bn is a set of random variables  corresponding to our attributes  z = {a1 ... am} which constitute the vertices of a directed  acyclic graph  a set of edges e   z 뫄 z  and  for each vertex ai with direct
ancestors par ai   a conditional distribution pai|par ai . a bayesian network defines a joint distribution pzbn =
.
모given an attribute set i and values i  we write pibn i  to denote the probability of itemset i = i as determined by a bayesian network bn. according to   we define the unexpectedness  or interestingness  of an event i = i as i i i  = |pid i    pibn i | - the absolute difference between an event's probability inferred from the network  and observed in the database. we will now leverage the definition of unexpectedness of events to interestingness of attribute sets: an attribute set i is interesting  if there is an event i = i for which inferred and observed probability diverge.
모definition 1. given a bayesian network bn and data d  the interestingness of attribute set i is defined in equation 1.
	 	 1 
		 1 
the definition of interestingness refers to pibn i   the exact probability of i = i inferred from the network  and pid i   the probability of i = i in the  potentially very large  database. pibn i  can be estimated by sampling from the network; pid i  by sampling from the database. since the network has no cycles we can always draw from the conditional distributions p ai|par ai   of each vertex ai after the values of all parents have been drawn. thus we obtain a sample sbn of independent assignments of values to the attributes according to pbn. after additionally drawing records sd from d independently under uniform distribution  we obtain an estimate i  i i  as in equation 1  and of i  i  in equation 1. p id i  is the relative frequency of i = i in sample sd  and p ibn i  the relative frequency of i = i in sbn.
		 1 
	 	 1 
a special case occurs when the bayesian network is too large for exact inference but the database is compact and pid can be determined exactly. in this case  only pibn has to be approximated by p ibn  but sd can be the entire database d and therefore p id = pid.
모a possible problem setting would be to find all attribute sets whose interestingness exceeds some 붼. however  from the user's point of view it is often more natural to constrain the number of returned patterns  rather than the somewhat less intuitive interestingness value. we therefore define the n most interesting attribute sets problem as follows.
모definition 1. let d be a database over attributes z and bn a bayesian network. the n most interesting attribute sets problem is to find n attribute sets h = {i1 ... in}; ij   z  such that there is no other attribute set i1 which is more interesting than any of h  equation 1 . there is no i1   z : i1뫍 h  i i1    mini i   1 
i뫍h
any solution to the n most interesting attribute sets problem has to calculate the i i  which requires exact inference in the bayesian network and at least one pass over the entire database. we would like to find an alternative optimality property that can be guaranteed by an efficient algorithm. we therefore define the n approximately most interesting attribute sets problem as follows.
모definition 1. let d be a database over itemsets z and bn a bayesian network. the n approximately most interesting attribute sets problem is to find n attribute sets h = {i1 ... in}; ij   z  such that  with high probability 1   붻  there is no other attribute set i1 which is 붼 more interesting than any of h  equation 1 .
with confidence 1   붻  there is no i1   z :
	i1뫍 h and i i1    mini i  + 붼	 1 
i뫍h
1. fast discovery of interesting attribute sets
모we are now ready to present our solution to the n approximately most interesting attribute sets problem. the aprioribns algorithm is presented in table 1; it refers to confidence bounds provided in table 1. we will now briefly sketch the algorithm  then state our main theorem  and finally discuss some additional details and design choices.
모aprioribns generates candidate attribute sets like the apriori algorithm does: starting from all one-element sets in step 1  candidates with i+1 attributes are generated in step 1g by merging all sets which differ in only the last element  and pruning those with infrequent subsets.
모in each iteration of the main loop  we draw a batch of database records and observations from the bayesian network. only one such batch is stored at a time and the sample size and frequency counts of all patterns under considerations are updated; the batch is deleted after an iteration of the loop and a new batch is drawn. the interestingness of each attribute set i is estimated based on nbn i  observations from the network and nd i  database records.
모there are two mechanisms for eliminating patterns which are not among the n best ones. these rejection mechanisms are data dependent: if some attribute sets are very uninteresting  only few observations are needed to eliminate them from the search space and the algorithm requires few sampling operations. step 1c is analogous to the pruning of low support itemsets in apriori. pid i  can be interpreted as the support of the itemset i = i with respect to the database  and pibn i  as the support of i = i with respect to the network. the interestingness - which is the absolute difference - can be bounded from above by the maximum of these. no superset of i can be more frequent than i and therefore all supersets can be removed from the search space  if this upper bound is below the currently found n-th most interesting attribute set. since only estimates p ibn i  and p id i  are known  we add a confidence bounds ei and es to account for possible misestimation.
모the pruning step is powerful because it removes an entire branch  but it can only be executed when an attribute set is very infrequent. therefore  in step 1d  we delete an attribute set i1 if its interestingness  plus confidence bound  is below that of the currently n-th most interesting pattern  minus confidence bound . we can then delete i1 but since interesttable 1: aprioribns: fast discovery of the approximately most interesting attribute sets input: bayesian network bn  database d over attributes z  approximation and confidence parameters 붼 and 붻  the desired number of interesting itemsets n.
1. let i 뫹 1  iteration ; generate initial candidates c1 = {{ai} : ai 뫍 z}; let h1 뫹 c1  itemsets under consideration ; for all i 뫍 h1  initialize nbn i  = 1 and nd i  = 1  bayesian network and database sample size for itemset i .
1. repeat until break:
 a  draw batch of observations sibn according to pbn and a batch of database records sid at random from d.
 b  for all i 뫍 hi  increment nd i  by |sid|; increment nbn i  by |sibn|; update frequency counts p id  p ibn  and consequently  i i   equation 1 . let hi  be the n best itemsets in hi  according to the current i .
 c  for all i1 뫍 hi   hi : if
	i뫍	dom 
 then remove i1 and all its supersets from hi and ci.  for ei and es  refer to table 1; neither i1 nor any superset will ever become a champion. 
 d  for all i1 뫍 hi   hi : if

then remove i1 from hi.  i1 is most likely not a
champion but its supersets might still. 
 e  if ci =   and for all i 뫍 hi   i1 뫍  hi   hi  :

then break.
 f  let nbn = mini뫍hi nbn i   nd = mini뫍hi nd i ; if ci =   and

	ed  n	 n  	pi뫍hi |dom i |	a 뫞 1
then break.
 g  ci+1 뫹 generate new candidates from ci.
 h  let hi+1 뫹 hi 뫋 ci+1; let i 뫹 i + 1.
1. return the n best itemsets  according to i   from hi.
table 1: confidence bounds used by aprioribns
based on hoeffding inequality  sampling from bayesian network and data. 	based on hoeffding inequality  all data used  sampling from bayesian network only.	r	q 1
es i 붻  = ei i 붻  =	1nbn1  i  log 1|dom 붻 i | 	ed nbn 붻  =	1nbn log 붻based on normal approximation  sampling from bayesian network and data.ei i 붻  = z1 	붻	maxi뫍dom 	 i 
	dom 	 based on normal approximation  all data used  sampling from bayesian network only.	dom 	 	dom ingness does not decrease monotonically with the number of attributes  we cannot prune the entire branch.
모there are two alternative stopping criteria. if every attribute set in the current set of  champions  hi   minus an appropriate confidence bound  outperforms every attribute outside  plus confidence bound   then the current estimates are sufficiently accurate to end the search  step 1e . this stopping criterion is data dependent: if there are hypotheses which clearly set themselves apart from the rest of the hypothesis space  then the algorithm terminates early.
모in addition  the algorithm may terminate if all estimates are tight up to . this worst-case criterion uses bounds which are independent of specific hypotheses  data independent  and a fixed amount of allowable error is set aside for it. its purpose is to guarantee that the algorithm will always terminate. as long as the candidate set ci is not empty  there are still hypotheses which have not yet been assessed at all. in this case  the search cannot yet terminate. after exiting the main loop  the n apparently most interesting attribute sets are returned.
모aprioribns refers to error bounds which are detailed in table 1. we provide both  exact but loose confidence bounds based on hoeffding's inequality  and their practically more relevant normal approximation. statistical folklore says normal approximations can be used for sample sizes from 1 onwards; in our experiments  we encounter sample sizes of 1 or more. z denotes the inverse standard normal cumulative distribution function and nbn nd the minimum sample size  from bayesian network and database  respectively  for any i 뫍 h. we furthermore distinguish the general case in which samples are drawn from both  the bayesian network and database  from the special case in which the database is feasibly small and therefore p id = pid  samples are drawn only from the network. we are now ready to state our main result on the optimality of the result returned by our discovery algorithm.
모theorem 1. given a database d  a bayesian network bn over nodes z  and parameters n  붼  and 붻  the aprioribns algorithm will output a set of the n approximately most interesting attribute sets h . that is  with probability 1   붻  there is no i1   z with i 뫍1 h  and i i1    mini뫍h  i i  + 붼. furthermore  the algorithm will always terminate  even if the database is an infinite stream ; the number of sampling operations from the database and from the bayesian network is bounded by .
모the proof of theorem 1 is given in the appendix. we will conclude this section by providing additional design decisions of the algorithm. a copy of the source code is available from the authors for research purposes.
모in step 1a  we are free to choose any size of the batch to draw from the network and database. as long as ci 1=    the greatest benefit is obtained by pruning attribute sets in step 1c  all supersets are removed from the search space . when ci =    then terminating early in step 1e becomes possible  and rejecting attribute sets in step 1d is as beneficial as pruning in step 1c  but easier to achieve. we select the batch size such that we can expect to be able to prune a substantial part of the search space  ci 1=     terminate early  or reject substantially many hypotheses  ci =   .
모we estimate the batch size required to prune 1% of the hypotheses by comparing the least interesting hypothesis in hi  to a hypothesis at the 1-th percentile of interestingness. we find the sample size that satisfies the precondition of step 1c for these two hypotheses  this is achieved easily by inverting ei and es . if ci =    then we analogously find the batch size that would allow us to terminate early in step 1e and the batch size that would allow to reject 1% of the hypotheses in step 1d and take the minimum. in order to efficiently update the interestingness of many attribute sets simultaneously  we use a marginalization algorithm similar to the one described in .
1. experiments
모theorem 1 already guarantees that the attribute sets returned by the algorithm are  with high probability  nearly optimal with respect to the interestingness measure. but we still have to study the practical usefulness of the method for large-scale problems. in our experiments  we will first focus on problems that can be solved with the exact discovery method aprioribn  and investigate whether the sampling approach speeds up the discovery process  while  call only the core part of their algorithm aprioribn  we use this term to refer to the entire exact discovery method . more importantly  we will then turn towards discovery problems with large-scale bayesian networks that cannot be handled by known exact methods. we will investigate whether any of these problems can be solved using our samplingbased discovery method.
모in order to study the performance of aprioribn and aprioribns over a range of network sizes  we need a controlled environment with bayesian networks of various sizes and corresponding datasets. we have to be able to control the divergence of background knowledge and data  and  in order to assure that our experiments are reproducible  we would like to restrict our experiments to publicly available data. we create an experimental setting which satisfies these requirements. for the first set of experiments  we use data sets from the uci repository and learn networks from the data using the b-course  website. these generated networks play the role of expert knowledge in our experimentation. in order to conduct experiments on a larger scale  we start from large bayesian networks  generate databases by drawing from the network  and then learn a slightly distorted network from the data which again serves as expert knowledge  see below for a detailed description . for the small uci datasets  the algorithm processes the entire database whereas  for the large-scale problems  aprioribns samples from both  the database and the network.
모we first compare the performance of aprioribn and aprioribns using the uci data sets. for all experiments  we use 붼 = 1  붻 = 1  and n = 1. we constrain the cardinality of the attribute sets to maxk. here  the databases are small and therefore only the network is sampled and p id = pid for all i. table 1 shows the performance results. the |z| column contains numbers of attributes in each dataset  t s  computation time  nbn the number of samples drawn from the bayesian network  maxi  and maxi are the estimated and actual interestingness of the most interesting attribute set found by aprioribns and aprioribn  respectively.
모we refrain from drawing conclusions on the absolute running time of the algorithms because of a slight difference in the problems that aprioribn and aprioribns solve  finding all sufficiently versus finding the most interesting rules . we do  however  conclude from table 1 that the relative benefit of aprioribns over aprioribn increases with growing network size. for 1 nodes  aprioribns is many times faster than aprioribn. more importantly  aprioribns finds a solution for the audiology problem; aprioribn exceeds time and memory resources for this problem.
모the most interesting attribute set has always been picked correctly by the sampling algorithm and its estimated interestingness is close to the exact value. the remaining 1 most interesting sets were not always picked correctly  but remained within the bounds guaranteed by the algorithm.
모we will now study how the execution time of aprioribns depends on the maximum attribute set size maxk. figure 1 shows the computation time for various values of maxk for the lymphography data set. note that the search space size grows exponentially in maxk and this growth would be maximal for maxk = 1 if no pruning was performed. by contrast  the runtime levels off after maxk = 1  indicating that the pruning rule  step 1c of aprioribns  is effective and reduces the computation time substantially.
모let us now investigate whether aprioribns can solve discovery problems that involve much larger networks than

maxk
figure 1: computation time versus maximum attribute set size maxk for lymphography data.
aprioribn can handle. we draw 1 million observations governed by the munin1 network from the bayesian network repository. we then use a small part of the resulting dataset to learn a bayesian network. thus  the original network plays the role of a real world system  from which the dataset is obtained  and the network learned from a subset of the data plays the role of our imperfect knowledge about the system. by varying the sample size m used to build the network we can affect the quality of our 'background' knowledge. the munin1 network has 1 attributes. exact inference from networks of this size is very hard in practice. table 1 shows the results for various values of m and maxk = 1...1. we sample at equal rates from the bayesian network and from data; both numbers of examples are therefore equal and denoted by n in the table. we use the same setting for the next experiment with the munin1 network containing 1 attributes. the problem is huge both in terms of the size of bayesian network and the size of data: the file containing 1 million rows sampled from the original network is over 1gb large  and 1 rows sampled by the algorithm amount to almost 1gb. the experiment took 1 hours and 1 minutes for maxk = 1.
모figure 1 summarizes tables 1 and 1  it details the relationship between the number of nodes in the network and the computation time of aprioribn and aprioribns. we observe a roughly linear relationship between logarithmic network size and the logarithmic execution time  figure 1 shows a model fitted to the data. from these experiments  we conclude that the aprioribns algorithm scales to very large bayesian networks and databases  yet it is guaranteed to find a near-optimal solution to the most interesting attribute set problem with high confidence. we can apply the exact aprioribn algorithm to networks of up to about 1 nodes. using the same computer hardware  we can solve discovery problems over networks of more than 1 nodes using the sampling-based aprioribns method.
1. conclusion
모we studied the problem of discovering unexpected patterns in a database. we formulated the approximately most interesting attribute sets problem and developed an algorithm which solves this problem. aprioribns uses samplingbased approximate inference in the bayesian network and  when the database is large  also samples the data.
모we proved that aprioribns always finds  with high confidence  the approximately most interesting attribute sets.
dataset|z|maxknbnaprioribns: maxi aprioribn: maxiaprioribns: t s aprioribn: t s ksl11.1.11lymphography11.1.11lymphography11.1.11soybean11.1.11soybean11.1.11annealing11.1.11annealing11.1.11splice11.1.11audiology11.1-1-audiology11.1-1-table 1: evaluation on networks learned from uci datasets.table 1: results for the munin networks.
dataset|z|mmaxkt s nmaxi munin1111munin1111munin1111munin1111munin1111munin1111munin1111munin1111munin1111
bayesian network nodes
figure 1: network size and computation time.
we studied aprioribns empirically using moderately sized as well as large-scale bayesian networks and databases. from our experiments  we can draw the following main conclusions.  1  the relative performance benefit of aprioribns over the corresponding exact method aprioribn increases with the network size. for moderately sized networks  aprioribns can be many times faster than aprioribn.  1  more importantly  while aprioribn scales to networks with about 1 nodes  we can apply aprioribns to bayesian networks of 1 nodes and databases of several gigabytes using the same hardware.
acknowledgments
t.s. is supported by the german science foundation under grant sche 1-1.
