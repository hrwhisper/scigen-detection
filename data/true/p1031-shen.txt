current approaches to develop information extraction  ie  programs have largely focused on producing precise ie results. as such  they suffer from three major limitations. first  it is often difficult to execute partially specified ie programs and obtain meaningful results  thereby producing a long  debug loop . second  it often takes a long time before we can obtain the first meaningful result  by finishing and running a precise ie program   thereby rendering these approaches impractical for time-sensitive ie applications. finally  by trying to write precise ie programs we may also waste a significant amount of effort  because an approximate result - one that can be produced quickly - may already be satisfactory in many ie settings.
모to address these limitations  we propose iflex  an ie approach that relaxes the precise ie requirement to enable best-effort ie. in iflex  a developer u uses a declarative language to quickly write an initial approximate ie program p with a possible-worlds semantics. then iflex evaluates p using an approximate query processor to quickly extract an approximate result. next  u examines the result  and further refines p if necessary  to obtain increasingly more precise results. to refine p  u can enlist a next-effort assistant  which suggests refinements based on the data and the current version of p. extensive experiments on real-world domains demonstrate the utility of the iflex approach.
categories and subject descriptors
h.m  information systems : miscellaneous
general terms
experimentation  languages
1.	introduction
모over the past decade  the problem of information extraction  ie  has attracted significant attention. given a collection of text or web pages  many solutions have been devel-
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee.
sigmod'1  june 1  1  vancouver  bc  canada.
copyright 1 acm 1-1-1/1 ...$1.
oped to write programs that extract structured information from the raw data pages  see  1  1  for recent tutorials .
모virtually all of these solutions  however  have focused only on developing precise ie programs: those that output exact ie results. as such  they suffer from several major limitations. first  during the course of developing an ie program  we often cannot execute a partially specified version of the program  and even if we can  it is not clear what the produced result means. this makes it hard to probe whether the extraction strategy pursued by the program is promising  and in general produces a long  debug loop   especially over complex ie programs.
모second  partly because of the above limitation  it often takes a long time  days or even weeks  before we can obtain the first meaningful result  by finishing and running a precise ie program . this long lag time is not acceptable to timesensitive ie applications that need extraction results quickly. finally  by trying to write precise ie programs we may also waste a significant amount of effort. in many extraction settings  perhaps an approximate result - one that can be produced quickly - is already satisfactory  either because an exact result is not required  e.g.  in mining or exploratory tasks   or because the approximate result set is already so small that a human user can sift through it quickly to find the desired answer.
모to address the above limitations  in this paper we argue that in many extraction settings  writing ie programs in a best-effort fashion is a better way to proceed  and we describe iflex  iterative flexible extraction system   an initial solution in this direction. in iflex  a developer u quickly writes an initial approximate extraction program p. then u applies the approximate program processor of iflex to p to produce an approximate result. after examining this result  u can refine p in any way he or she deems appropriate. for this refinement step  u can enlist the next-effort assistant of iflex  which can then suggest particular spots in p that can be further refined  to maximize the benefit of u's effort . then  u iterates with the execution and refinement steps until he or she is satisfied with the extracted result. the following example illustrates the above points.
모example 1. given 1 web pages  each listing a house for sale  suppose developer u wants to find all houses whose price exceeds $1 and whose high school is lincoln. then to start  u can quickly write an initial approximate ie program p  by specifying what he or she knows about the target attributes  i.e.  price and high school in this case . suppose u specifies only that price is numeric  and suppose further that there are only nine house pages where each page contains at least one number exceeding 1 as well as the word  lincoln . then iflex can immediately execute p to return these nine pages as an  approximate superset  result for the initial extraction program. since this result set is small  u may already be able to sift through it and find the desired houses. hence  u can already stop with the ie program.
모now suppose that instead of nine  there are actually 1 house pages that contain at least one number exceeding 1 as well as the word  lincoln . then iflex will return these 1 pages. at this point  u realizes that the ie program p is  underspecified   and hence will try to refine it further  to  narrow  the result set . to do so  u can ask the next-effort assistant to suggest what to focus on next. suppose that this module suggests to check if price is in bold font  and that after checking  u adds to the ie program that price is in bold font. then iflex can leverage this  refinement  to reduce the result set to only 1 houses. now u can stop  and sift through the 1 houses to find the desired ones. alternatively  u can try to refine the ie program further  enlisting the next-effort assistant whenever appropriate.
모this example underscores the key idea underlying iflex: instead of requiring the developer to invest significant time up front to write relatively complete ie programs before being able to run them and obtain some results  iflex can produce meaningful results from whatever approximate programs the developer has written so far. then  as the developer devotes more time refining the programs  iflex produces increasingly precise results.
모while attractive  realizing the above key idea however raises several difficult challenges. the first challenge is to develop a language for writing approximate ie programs with well-defined semantics. toward this goal  we extend xlog  a datalog variant recently proposed for writing declarative ie programs . the extension  called alog  allows developers to write approximate extraction rules as well as specify the types of approximation involved. we then show that alog programs have possible-worlds semantics.
모given alog programs  the second challenge is then to build an efficient approximate processor for these programs. toward this goal  we first consider how to represent approximate extracted data. we show that current representations are not succinct enough for approximate ie results  and then develop a much more compact text-specific representation called compact tables. we then show how to efficiently execute alog programs over compact tables.
모finally  when refining an alog program p  we consider how the next-effort assistant can identify spots in p where the  next effort  of developer u would best be spent. we formulate this as a problem in which the assistant can ask u a question  e.g.  is price in bold font     and then u can add the answer to this question to p  as a refinement . the key challenge is then to define the question space as well as a way to select a good question from this space. we describe an initial solution to this problem  one that efficiently simulates what happens if u answers a certain question  and then selects the question with the highest expected benefit.
모to summarize  in this paper we make the following contributions:
  introduce iflex  an end-to-end iterative approximate  solution for best-effort ie. as far as we know  this is the first in-depth solution to this important problem.
  introduce a declarative language to write approximate ie programs with well-defined semantics.
  develop techniques to efficiently represent and perform query processing on approximate extracted text data.
  develop a novel simulation-based techniqueto efficiently assist the developer in refining an approximate ie program.
  perform extensive experiments over several real-world data sets which show that iflex can  a  quickly produce meaningful extraction results   b  successfully refine the results in each iteration using the next-effort assistant  and  c  quickly converge to precise extraction results  in a relatively small number of iterations.
1.	approximate ie programs
모we now describe how to write approximate ie programs. our goal is to extend a precise ie language for this purpose. many such languages have been proposed  such as uima  gate  lixto  and xlog  1  1  1  1 . as a first step  in this paper we will extend xlog  a recently proposed datalog variant for writing declarative ie programs   leaving extending other ie languages as future research . we first describe xlog  and then build on it to develop alog  a language for writing approximate programs for best-effort ie.
1	the xlog language
we now briefly describe xlog  see  for more details .
syntax and semantics: like in traditional datalog  an xlog program p consists of multiple rules. each rule has the form p : q1 ... qn  where the p and qi are predicates  p is called the head  and the qi's form the body. each predicate atom in a rule is associated with a relational table. a predicate is extensional if its table has been provided to program p  and intensional if its table must be computed using the rules in p. currently  xlog does not allow rules with negated predicates or recursion.
모a key distinction of xlog  compared to datalog  is that it can accommodate inherently procedural steps of real-world ie with p-predicates and p-functions. a p-predicate q has the form    where the ai and bi are variables. predicate q is associated with a procedure g  e.g.  written in java or perl  that takes an input tuple  u1 ... un   where ui is bound to ai  i 뫍  1 n   and produces as output a set of tuples  u1 ... un v1 ... vm . a p-function
  takes as input a tuple  u1 ... un  and returns a scalar value.
모example 1. figure 1.a shows an xlog program that extracts houses with price above $1  area above 1 square feet  and a top high school. this program contains two p-predicates  extracthouses x p a h  and extractschools y s   and one pfunction approxmatch h s . the p-predicate extracthouses x  p a h   for example  takes as input a document x and returns all tuples  x p a h  where p  a  and h are the price  area  and high school of a house listed in x  respectively. the p-function approxmatch h s   for example  returns true iff two text spans  i.e.  document fragments  h and s are  similar  according to some similarity function  e.g.  tf/idf .
모among all types of p-predicate  we single out a special type called ie predicate. an ie predicate is a p-predicate that extracts one or more output spans from a single input document or span. for example  extracthouses x p a h  in figure 1.a is an ie predicate that extracts the attributes p  a  and h from x. similarly  extractschools y s  extracts a school name s from y.
모one of the head predicates of an xlog program p is called a query  and the result of p is the relation computed for the query predicate using the rules in p. we define this result by
r1: houses x p a h  :- housepages x   extracthouses x p a h 
r1: schools s  :- schoolpages y   extractschools y s 

r1: q x p a h  :- houses x p a h   schools s   p 1  a 1  approxmatch h s 
 a 
cozy house on quiet street          	$1
1 windsor ave.  champaign
sqft: 1
high school: vanhise highamazing house in great location!       $1


1 stonecreek blvd.  cherry hills	






sqft: 1	






high school: basktall hs	top high schools and location  page 1 
basktall   cherry hills
franklin   robeson
vanhise   champaigntop high schools and location  page 1 
hoover   akron
skyline   dubuque
ossage  lynnevillex1 x1
 b 
figure 1: example xlog program.
applying traditional datalog semantics  e.g.  the least-model semantics  to the rules in p  using the associated relations for the p-predicates and p-functions in p.
모example 1. we illustrate xlog by stepping through a conceptual execution of the program in figure 1.a  assuming that housepages consists of the two documents x1 and x1  and that schoolpages consists of the two documents y1 and y1  all in figure 1.b . for each document x in housepages  rule r1 invokes extracthouses x p a h  to extract the price  area  and high school of the listed house in x  e.g.  to extract the tuple  x1  1  vanhise high   from x1 . next  rule r1 invokes extractschools y s  for each document y in the schoolpages relation  e.g.  to extract three tuples  y1  basktall     y1 
 franklin    and  y1  v anhise   for y1 . finally  rule r1 joins the extracted houses and schools relations  keeping all tuples  x p a h  where document x lists a house with price p above $1  area a above 1 square feet  and high school h being listed in a school page y in schoolpages. in this example  rule r1 produces the tuple  x1 1  basktall hs  .
usage and limitations: to write an xlog program for an ie task  a developer u first decomposes the task into smaller tasks. next  u writes an xlog program that reflects this decomposition   making up  p-predicates and p-functions as he or she goes along. finally  u implements made-up predicates and functions  e.g.  with c++ or java procedures. for example  when writing the xlog program in figure 1.a  u makes up and then implements p-predicates extracthouses and extractschools  and p-function approxmatch.
모to implement a procedure  e.g.  for a p-predicate   u typically starts by examining the raw data and identifying domain constraints involving text features of the target attributes  e.g.   price is numeric    school name is bold  . next  u writes code  e.g.  perl modules  to extract text spans that satisfy these constraints  then writes additional code to further chop  merge  and filter the text spans  to eventually output the desired extraction result. once done  u  plugs  the implemented procedures into the xlog program  executes the program  and analyzes the results for debugging purposes.
모as described  u often must spend a significant amount of time developing the procedures  and these procedures must be fairly complete before u can run the ie program to obtain some meaningful result. this in turn often makes the development process difficult  time-consuming  and potentially wasteful  as discussed in section 1. to address these problems  we develop a best-effort ie framework in which we can quickly write approximate ie programs using alog  an xlog extension.
1	best-effort ie with alog
모given our observations with xlog  we propose that a besteffort ie framework provide support for the developers to:
  declare any domain constraints regarding text features of the attributes they are extracting  with as little extra programming as possible.
  write approximate ie programs and obtain well-defined approximate results  such that the more effort the developer puts in  the more precise the results are.
our proposed language  an extension of xlog called alog  provides such support. to write an alog program  a developer u can quickly start by writing an initial xlog program  which is  skeletal  in the sense that it lists all the necessary ie predicates  but does not yet have any associated procedures for them.
모in the next step  instead of implementing these procedures in their entirety - as is done during the process of developing an xlog program - u instead implements them only partially  doing only as much work as he or she deems appropriate.
모specifically  consider a particular ie predicate q. to implement q  u partially writes one or more description rules  each declaring a set of domain constraints about the textual features of the  target  attributes that e extracts  e.g.   price is numeric  . each description rule r therefore can be viewed as a way to extract approximate values for the target attributes. next  u encodes the type of approximation by annotating r. such an annotation in effect gives rule r a possible-worlds interpretation  by  translating  the single relation defined by r under xlog semantics into a set of possible relations.
모finally  u executes the so-obtained partial ie program  examines the result  refines the program further by augmenting the description rules  executes the newly revised program  and so on  until satisfied. in the rest of this section we describe the above steps in more detail.
1.1	writing an initial program
모as discussed  to develop an alog program  a developer u begins by writing an initial set of traditional xlog rules. these rules form a  skeleton  of p  in the sense that each ie predicate  in the rules  is  empty : it is not associated with any procedure yet. figure 1.a shows a sample skeleton program  which is the same program shown in figure 1.a   where the ie predicates extracthouses a p a h  and extractschools y s  do not have any associated procedure.
1.1	writing predicate description rules
syntax: in the next step  instead of writing procedural code for each ie predicate q  as in traditional xlog   u  partially implements  q by writing one or more predicate description rules  or  description rules  for short  to describe q using domain constraints.
모for example  rule s1 in figure 1.b describes the ie predicate extracthouses x p a h . it asserts that p  a  and h are text spans from x  and that p and a are numeric. thus  when provided with a document x as the input  this rule defines a relation  x p a h  where p  a and h are extracted from x  and p and h take on numeric values. similarly  rule s1 in figure 1.b describes extractschools y s  and asserts that s is a bold-font text span from document y.
모in general  a description rule r has the form q : q1 ... qn  just like a traditional xlog rule  except that the head q is an ie predicate. rule r's semantics are similar to that of an xlog rule  except that r only defines a relation when it is provided with all of the required input. that is  whenever we assign constant values to the input variables in the head of r  r defines a relation r such that for any assignment of constants to the other variables in r  if every predicate in the body of r is satisfied  then the tuple generated for the rule head  using the assignment  is also in r.
using description rules to capture domain constraints: developer u typically builds description rules by adding domain constraints about the extracted attributes as predicates to the body of the rules. a domain constraint f a  = v states that feature f of any text span that is a value for attribute a must take value v. for example  rule s1 in figure 1.b imposes two domain constraints: numeric p  = yes and numeric a  = yes. in each iteration u can refine each description rule by adding more domain constraints.
모in general  text features capture common characteristics of text spans that we often are interested in extracting. example features include numeric  bold-font  italic-font  underlined  hyperlinked  preceded-by  followed-by  min-value  and max-value. each feature takes values such as yes  distinctyes  no  distinct-no  and unknown. for example  bold-font s  = distinct-yes means that s is set in bold font  but the text surrounding s is not. iflex currently uses a rich set of built-in features  section 1.1 briefly discusses how to select good features   but more can be easily added  as appropriate for the domain at hand. to add a new feature f  a developer needs to implement only two procedures verify and refine.  note that this is done only once  not per writing an alog program.  verify s f v  checks whether f s  = v  and refine s f v  returns all sub-spans t from s such that f t  = v  see section 1 for more details .
writing safe description rules: consider the following
rule
extracthouses x p a h  : numeric p  = yes 
numeric a  = yes
모which states that p and a are numeric. this rule is not safe because it produces an infinite relation given an input document x  since p and a can take on any numeric value  and h can take on any value . intuitively  this is because the rule does not indicate where p  a  and h are extracted from. to address this problem  iflex provides a built-in from x y  predicate that conceptually extracts all sub-spans y from document x. then  u can use this predicate to indicate that p  a  and h are extracted from document x. figure 1.b shows the resulting safe description rules  using the from predicate.
모in general  a description rule is safe if each non-input variable in the head also appears in the body  either in an extensional or intensional predicate  or as an output variable in an ie predicate. for example  rule s1 in figure 1.b is safe because the non-input variables p  a  and h all appear as output variables in from predicates in the body.
1.1	encoding approximation types using annotations
모as described above  the combination of an alog rule and related description rules defines a way to approximately extract some attributes. for example  rules s1 and s1 in figure 1.b together describe a way to approximately extract p  a  and h.
모when writing such rules  a developer u often knows the type of approximation he or she is using. hence  we want to provide a way for u to declare such approximation types. we then exploit this information to better process alog programs. currently  we focus on providing support for two common types of approximation: those about the existence of a tuple  and about the value of an attribute in a tuple  respectively. we allow a developer u to annotate an alog rule to indicate these approximation types.
모specifically  an existence annotation indicates that each tuple in the relation r produced by a rule r may or may not exist.
모definition 1  existence annotation . let p be the head of a rule r that produces relation r under the normal xlog semantics. then adding an existence annotation to r means replacing p with  p  . this produces a rule r뫣 that defines a set of possible relations r  which is the powerset of the tuples in r.
모an attribute annotation indicates that an attribute takes a value from a given set  but we do not know which value.
모definition 1  attribute annotation . suppose the head of rule r is p a1 ... ai ... an . then annotating attribute ai means replacing the head with p a1 ... haii ... an  to produce rule r뫣. suppose that r defines relation r under the normal xlog semantics. then r뫣 defines the set r of all possible relations that can be constructed by grouping r by a1 ... ai 1 ai+1 ... an and selecting one value for ai in each group.
모we can easily generalize definition 1 to annotating multiple attributes. in this case  each possible relation is constructed by first grouping r by all non-annotated attributes  then selecting one value for each annotated attribute in each group. the following example illustrates both existence and attribute annotations.
모example 1. evaluating rule s1 in figure 1.a together with rule s1 in figure 1.b would produce the houses table in figure 1.d  which contains all tuples  x p a h  where x is in housepages  p  a  and h are extracted from x  and p and a are numeric.
모now suppose we know that each document x in housepages contains information about exactly one house  i.e.  x forms a key in the true houses relation . then we can annotate attributes p  a  and h to produce rule in figure 1.c. evaluating rule would produce the set of possible houses relations as represented in figure 1.e  where each possible relation is constructed by selecting just one value  from the corresponding set of values  for each table cell  see section 1 for more details . this way  each possible houses relation contains exactly one tuple for each document x  thus accurately reflecting our knowledge of the domain.
모similarly  evaluating rules s1 in figure 1.a together with rule s1 in figure 1.b would produce the schools table in figure 1.d  which contains all tuples  s  where s is a bold span coming from a document y in schoolpages.
모clearly  not all bold spans in each document y are schools. thus  we can add an existence annotation to rule s1 to produce rule in figure 1.c. evaluating  would produce the set of possible schools relations represented in figure 1.e  where each possible relation consists of a subset of the extracted tuples.
모we represent the annotations for a rule r with a pair  f a   where the boolean f is true iff r has an existence annotation  and a is the set of attributes in the head predicate of r that have attribute annotations.
alog semantics: the result of an alog program p is then the set of all possible relations we can compute for the query predicate in p. defining this set reduces to defining the set of all possible relations that each alog rule r in p computes. let r be p : q1 ... qn. then we compute r as follows. we know that each predicate qi is associated with a set of relations ri. if we select a relation ri 뫍 ri for each qi  then we can evaluate p  in the traditional xlog semantics  to obtain a relation r.
s1: houses x p a h  :- housepages x   extracthouses x p a h 
s1: schools s  :- schoolpages y   extractschools y s 
s1: q x p a h  :- houses x p a h   schools s   p 1 
모모모모a 1  approxmatch h s   a 
s1: extracthouses x p a h  :- from x p   from x a   from x h 	 d 
numeric p =yes  numeric a =yes
	houses	schools

xpahx1{ 1 
1 
1 }{ 1 
1 
1 }{ cozy    cozy house    ...  
 vanhise high    high } x1{ 1 
1 
1 }{ 1 
1 
1 }{ amazing    amazing house   ...   
 basktall hs    hs }
s basktall s1: extractschools y s  :- from y s   bold-font s =yes
 b  
s'1: houses x  p   a   h   :- housepages x   extracthouses x p a h   s'1: schools s   :- schoolpages y   extractschools y s  
s'1: q x p a h  :- houses x p a h   schools s   p 1 
	  a 1  approxmatch h s 
	 c 	 e 
figure 1: alog program and execution.모let the annotations of r be  f a . then we must apply these annotations to r  in order to obtain the true set of relations presented by p  when each qi receives a relation ri as the input . to do so  we first apply attribute annotations a to r  as described in definition 1. this produces a set of relations ra. next  if r has an existence annotation  i.e.  f is true   then we create the set of relations raf  where each relation in this set is a subset of a relation in ra. the set raf is then the true set of relations presented by p  when each qi receives a relation ri as the input . if f is false  then
raf is set to be ra.
모the set of all possible relations that rule r computes is then the union of all sets raf that can be computed as described above  by assigning to the qi's a different combination of the relations ri's .
모example 1. the following is a conceptual procedure to evaluate rule in figure 1.a over the set of possible relations for houses and schools represented in figure 1.e. select one possible houses relation h and one possible schools relation s. then  evaluate  using h and s to produce an intermediate set of possible relations  in this particular case  we produce a set with just one possible relation because does not have any annotations . repeat this process for every possible pair of houses and schools relations h and s. the output of is the union of all intermediate sets of possible relations.
1.1 executing  revising  and cleaning up alog programs
모once developer u has written an initial alog program p  which consists of the skeleton xlog rules  description rules for ie predicates  and possibly also annotations   he or she can execute p to obtain an approximate extraction result  see the next two sections .
모then  u can revise p by adding more domain constraints to the description rules. to find effective constraints  u can enlist the next-effort assistant  as section 1 will discuss.
모eventually  either p has been revised to the point where it produces precise ie results  in which case u can stop   or to the point where u feels that adding more domain constraints will not help improve the extraction result. in this latter scenario  u may want to just write a  cleanup procedure  in a procedural language  e.g.  perl  rather than continue to revise p declaratively  by adding more domain constraints . one such scenario occurs when an ie task involves a subtask that is hard to express declaratively. for example  suppose that u wants to extract publication citations and their last authors from dblp. while it may be relatively easy to extract citations and all of their authors by asserting domain constraints declaratively  it may be cumbersome to extract the last author  since alog does not naturally handle ordered sequences . therefore  a more natural solution would be to assert domain constraints to extract citations and their author list  and then write a cleanup procedure to extract the individual authors and select the last author.
모to incorporate a cleanup procedure g  u simply needs to declare a new p-predicate p and associate g with it. afterward  u can use p in his or her alog program just like any other p-predicate.
1.	representing approximate data
모we now describe a data model to represent the approximate extracted data that alog rules produce.
approximate tables: recall from section 1 that alog accounts for two types of approximation: the existence of a tuple and the value of an attribute in a tuple. to represent these types  we can extend the relational model by introducing approximate tables  or a-tables for short  where an a-table is a multiset of a-tuples. an a-tuple is a tuple  v1 ... vn   where each vi is a multiset of possible values. an a-tuple may be annotated with a ' '  in which case it is also called a maybe a-tuple . figure 1.e shows for example a-tables for the houses and schools relations  here for clarity we have omitted the set notation for the x attribute . an a-table t represents the set of all possible relations that can be constructed by  a  selecting a subset of the maybe a-tuples and all non-maybe a-tuple in t  then  b  selecting one possible value for each attribute in each a-tuple selected in step  a .
compact tables: a-tables however are typically not succinct enough in our setting  where an alog rule may produce a huge number of possible extracted values. for example  in figure 1.e  the cells for attribute h in houses enumerate every sub-span in each house page  and schools contains one tuple for every bold sub-span in the school pages.
모therefore  iflex employs compact tables  a much more compact version of a-tables specifically designed for approximate extracted text. the key idea is to exploit the sequential nature of text to  pack  the set of values of each cell into a much smaller set of so-called assignments  when possible.
모toward this goal  we define two types of assignments: exact and contain. an assignment exact s  encodes a value that is exactly span s  modulo an optional cast from string to numeric . for example  exact  1   encodes value 1. as
houses
xpahx1{exact 1   exact 1   exact 1 }{exact 1   exact 1   exact 1 }{contain  cozy ... high  } x1{exact 1   exact 1   exact 1 }{exact 1   exact 1   exact 1 }{contain  amazing ... hs  }schools
sexpand {contain  basktall ... champaign    contain  hoover ... lynneville  }  
figure 1: compact tables.
shorthand  we will sometimes write exact s  as simply s. an assignment contain s  encodes all values that are s itself or sub-spans of s. for example  the assignment contain  cherry hills   encodes all values that are spans inside cherry hills   e.g.   ch    cherry   etc. .
모given this  each cell c in a compact table contains a multiset of assignments: c = {m1 s1  ... mn sn }  where each mi is either exact or contain and each si is a span. let v mi si   be the set of values encoded by mi si . then  the set of values v c  encoded by cell
for example  consider the first a-tuple in the houses relation in figure 1.e  where the cell for attribute h has possible values { cozy    cozy house  ...   vanhise high    high }.

since these possible values are all the sub-spans of the span
 cozy...high  from document x1  we can condense the cell for{contain  cozy...high  }. similarly  we can con-

dense the possible values for h in the second a-tuple with another contain assignment. the compact table for houses in figure 1 shows the result of condensing the houses a-table in figure 1.e  using assignments.
모next  consider the schools table in figure 1.e. we can condense the a-tuples of this table by representing them all with one compact tuple  expand { basktall   ...  lynneville  } . in general  if t is a compact tuple with cells  c1 ... ci ... cn   where ci = expand v1 ... vk   then t can be expanded into the set of compact tuples obtained by replacing cell ci with an assignment exact vj :  c1 ... exact vj  ... cn   where 1 뫞 j 뫞 k. we call ci an expansion cell.
모expansion cells can still be condensed further. for example  consider again the compact tuple  expand { basktall   ...  lynneville  } . notice that the values { basktall   ...   lynneville  } is the set of all sub-spans of the two bold spans basktall ... champaign in document y1 and hoover ... lynneville in document y1. thus  we can condense these values using two assignments contain s1  and contain s1   where s1 = basktall ... champaign  and s1 = hoover ... lynneville . as a result  we can further condense the compact tuple into an equivalent tuple  expand {contain s1 }  contain s1   . figure 1 shows the result of condensing the schools table in figure 1.e  using expansion cells. we can now define compact tables as follows:
모definition 1  compact table . a compact table is a multiset of compact tuples. a compact tuple is a tuple of cells  c1 ... cn  where each cell ci is a multiset of assignments or an expansion cell. a compact tuple may optionally be designated as a maybe compact tuple  denoted with a ' '.
모a compact table t represents a set of possible relations r. we can conceptually construct r by first converting t into an a-table t뫣  then converting t뫣 into the set of possible relations r  as described earlier.
모we convert t into the a-table t뫣 as follows. let t 뫍 t be a compact tuple with expansion cell c. then  we replace t with the set of compact tuples t   as described earlier. if t is a maybe compact tuple  then we modify each compact tuple u 뫍 t to be a maybe compact tuple. we continue this process until t has no more expansion cells. finally  we convert t into the a-table t뫣 by converting each cell c into one with a set of possible values instead of assignments. that is  if cell c has assignments {m1 s1  ... mn sn }  then we replace those assignments with the set of values
모we note that the compact table representation is not a complete model for approximate data in that it is not expressive enough to represent any finite set of possible relations . for example  compact tables cannot represent mutual exclusion among tuples  e.g.  a relation contains either tuple t1 or tuple t1  but not both .
모nevertheless  in this paper we start with compact tables for two reasons. first  they can already express two common types of extraction approximation  the existence of a tuple and the value of an attribute   and thus can accommodate a broad variety of ie scenarios. second  they exploit text properties  and hence enable efficient ie processing  as discussed in the next section. in future work we plan to explore complete  but non-text-specific representations  e.g.  those in  1  1   for representing approximate ie results.
1.	approximate query processing
모we now describe the approximate query processor that generates and executes an execution plan for an alog program p. first  we unfold the non-description rules in p to produce a program p뫣. suppose the body of a rule r1 in p has an ie predicate q  and that q appears in the head of a description rule r1. then we unfold r1 by replacing q in r1 with the body of r1  unifying variables if necessary. we repeat this process until only ie predicates with associated procedures appear in the program. for example  in figure 1.c  after unfolding rules   and   using the description rules s1 and s1   rules  and  are transformed into the rules shown in figure 1.a.
모next  we construct a logical plan fragment h for each rule r in p뫣  as described in . initially  we ignore all annotations  compiling h as if it processes ordinary relations. figure 1.b shows the plan fragments we compile for the rules in figure 1.a  for simplicity  we ignore projections .
모then  we change each plan fragment h to work over compact tables instead of ordinary relations  in three steps. first  we convert each extensional relation into a compact table by changing the contents of each cell that has a document or span value v to instead have the value {exact v }. second  we modify each operator in h to take compact tables as input and produce a compact table as output. third  we append an  annotation operator  뷍 to the root of h  where 뷍 converts the set of relations output by h into another set of possible relations  taking into account the annotations of the rule r that h corresponds to.
모finally  we form a final execution plan g by  stitching  together the plan fragments  unifying variables if necessary  see  . figure 1.c shows the result of stitching together the plan fragments in figure 1.b based on the program in figure 1.a.
모in the rest of this section  we address the challenges involved to convert h to work over compact tables. we start by showing how to adapt relational operators and p-predicates to process compact tables. then  we show how to efficiently evaluate domain constraints to extract text from compact
s'1: houses x  p   a   h   :- housepages x  	s'1	s'1	s'1	효pproxmatch h s 
s'1: q x p a h  :- houses x p a h   schools s   housepages x  housepages x   p 1  a 1  approxmatch h s  houses x p a h  schools s 
	 a 	 b 	 c 
figure 1: compiling alog programs.tables. finally  we define the 뷍 operator that converts sets of possible relations based on the annotations in the rules.
모recall that the compact table representation is not a complete model. it turns out that compact tables also are not closed under relational operators  meaning that when applying a relational operator to compact tables  we cannot always exactly represent the output with another compact table.
모therefore  in the rest of this section we develop operators such that the execution plan produces an  approximate approximation   for a program p. specifically  we adopt a superset semantics for query execution  meaning that the result of the execution is guaranteed to be a superset of the possible relations defined by the program. in future work  we plan to explore other execution semantics  e.g.  one that minimizes the number of incorrect tuples .
1	modifying relational operators and p-predicates
모we now discuss how to modify relational operators  i.e.  select  join  project  and p-predicates in execution plans to work over compact tables. projection is straightforward since we ignore duplicate detection. thus  we focus on selections and 붿-joins.
모consider evaluating a selection on a compact table. intuitively  to ensure superset semantics we want the results to contain all compact tuples that may satisfy the selection condition. to illustrate  consider applying a selection condition p   1 to the first compact tuple in the houses table in figure 1. since x1 contains no possible price greater than 1  we can safely drop this tuple. on the other hand  we must keep the tuple for page x1 because it contains the possible price 1.
모in general  we evaluate a selection 횭 with selection condition f over a compact table t as follows. for each compact tuple t 뫍 t with cells  c1 ... cn   we evaluate the selection condition f over every possible tuple  v1 ... vn   where vi 뫍 v ci  for 1 뫞 i 뫞 n. if f is satisfied for any possible tuple  then we add t to t뫣. also  if f is satisfied for some but not all of the possible tuples  we set t to be a maybe compact tuple. to reduce the number of possible tuples we consider  we enumerate possible values for only those attributes involved in f  e.g.  when selecting on the price p  only enumerate possible values for the price .
모we adapt 붿-joins over compact tables t1 ... tn in a similar fashion except that we evaluate the 붿 condition on all compact tuples in the cartesian product t1뫄...뫄tn. however  implementing certain other types of joins over compact tables  such as approximate string joins  is significantly more involved. in the full paper  we describe our solution for approximate string joins .
모finally  to evaluate a p-predicate p over a compact table t  we take the union of the results of evaluating p over each compact tuple t 뫍 t. to evaluate p over a compact tuple t  we first convert t into an equivalent set of compact tuples u that have no expansion cells by repeatedly replacing each expansion cell c in t with t  section 1 . then  for each compact tuple u 뫍 u  we enumerate the possible tuples v that u represents  and invoke p for each v 뫍 v . let p v  be the tuples produced by p with input tuple v. we then convert p v  into a set of compact tuples by making each cell a set of assignments  i.e.  by changing any cell with span value s to be {exact s } . finally  we set each tuple in p v  to be a maybe compact tuple if u represents more than one possible tuple  i.e.  if |v |   1 .
1	optimizing alog rules
모consider the plan fragment 횩old-font s =yes from y s   of the plan from figure 1.c. conceptually  the ie predicate from y s  extracts every possible span from an input document y. to speed this up  in practice the from predicate instead produces the compact tuple  y expand {contain y }   to avoid enumerating all possible spans in y. in general suppose we apply from y s  to an input compact tuple  y   where y is the set of assignments {m1 s1  ... mn sn }  representing possible values for y . then  from y s  produces compact tuple  y s   where s is expand {contain s1   ...  contain sn } .
모however  this can still result in slow execution when applying domain constraints. for example  suppose that in the plan fragment 횩old-font s =yes from y s    the from predicate produces the compact tuple  y  expand contain y   . a naive method to apply the domain constraint bold-font s  = yes would be to to enumerate all possible spans in y and keep only those that are in bold font.
모instead  a more natural and efficient strategy would be to scan document y once and find all maximal spans {s1 ... sn} in y that are in bold font  e.g.  by using a perl regular expression . then  we output the set of assignments {contain s1   ...  contain sn }. this way  we avoid enumerating all possible spans in y.
모in general  we optimize selections involving domain constraints as follows. first  in iflex each text feature f is associated with two procedures verify and refine. verify s f v  returns true if f s  = v  and false otherwise. refine s f v  returns all maximal sub-spans s뫣 of s for which verify s뫣 f v  is true. a sub-span s뫣 is maximal if we cannot extend it either to the left or the right to obtain a sub-span s뫣뫣 for which verify s뫣뫣 f v  is true.
모then  to evaluate a selection 횲 where k is a domain constraint  we use verify and refine as follows. let t뫣 be the result of evaluating 횲 over a compact table t  where k is the constraint f a  = v. then t뫣 will be a compact table with the same structure as the input t  except that each cell for attribute a has been transformed by applying k. in particular  let c and c뫣 be two corresponding cells of t and t뫣 for attribute a  and let c = {m1 s1  ... mn sn }. then

where a k mi si   denotes the set of assignments resulting from applying the constraint k to assignment mi si . also  if c is an expansion cell we set c뫣 to be an expansion cell.
모we now describe how to compute a k mi si  . recall that mi si  encodes a set of values for attribute a. our goal is to remove as many values as possible  from mi si   that do not satisfy verify a f v . to do so  we consider two cases:
case 1: if mi si  is an exact assignment  then we can simply invoke verify si f v . thus  a k mi si   returns the empty set if verify si f v  evaluates to false  and returns mi si  otherwise.
case 1: if mi si  is a contain assignment  then we iteratively refine si. to do this we call refine si f v  to obtain all maximal sub-spans x in si such that f x  = v. for each such region x  refine produces an assignment contain x  or exact x . to see why  consider the web page snippet price: 1. only two left.  suppose k1 is  italics price  = yes . then price is in italics and hence can be any sub-span of
 price: 1 . consequently  applying refine to the above snippet will produce contain  price: 1  . on the other hand  consider the snippet  price: 1. only two left.  suppose k1 is italics price  = distinct-yes . then we know that price is in italics  but its surrounding text is not. consequently  it can only be 1  and applying refine to the above snippet will produce exact  1  .
모there is however a minor complication when evaluating alog rules involving more than one domain constraint for an attribute a. let k1 ... kn be the constraints we need to apply for an attribute a in an execution plan. suppose refining an assignment with constraint k1 yields an assignment m s   and further refining m s  with constraint k1 yields an assignment m뫣 s뫣 . then it is possible that span s뫣 does not satisfy k1. however  each span that a k1 mi si   finally outputs must satisfy all constraints k1 ... kn. hence  we always check all sub-spans created with kj for violation of k1 k1 ... kj 1. it is easy to prove that any order of applying k1 ... kn produces the same final set of assignments.
1	defining the annotation operator
모as the final step to generate an execution plan for alog program p  we define the annotation operator 뷍 that converts a set of possible relations by applying the annotations of the rules in p. suppose r is an alog rule with annotations  f a   and suppose h is a plan fragment we have produced for a rule r  ignoring the annotations of r. then  the output of the plan 뷍 f a  h  is the set of the possible relations defined by r  taking into account the annotations  f a  .
모implementing 뷍 to handle existence annotations is trivial: we make every compact tuple that 뷍 outputs to be a maybe compact tuple. hence  in the rest of this section we focus on handling attribute annotations.
모suppose we are evaluating the plan 뷍 f a  h   and that plan fragment h produces compact table s. our default strategy is to first convert s into an a-table t  see section 1   evaluate 뷍 over t  and then convert the result back into another compact table. thus  in the rest of this section  we describe bannotate  an implementation of 뷍 that takes as input an a-table t and outputs another a-table t뫣. converting between a-tables and compact tables is straightforward and thus we do not discuss it further. in the full paper we
nameage{ alice    bob  }{1}{ alice    carol }{1  1}{ dave }{1}nameage{ alice }{1 1}{ bob }{1}{ carol }{1}{ dave }{1}t1  alice  	{1  1  1}
	 	  bob  	{1}
	 	  carol  	{1  1}
	 	  dave  	{1}
	 a 	 b 	 c 
figure 1: handling attribute annotations.
discuss optimizing this process to evaluate 뷍 over compact tables directly  without converting them to a-tables .
the bannotate algorithm: consider evaluating the following alog rule r: person name hagei  :  q1 ... qn. this rule r defines a set of possible relations r  each with attributes  name age . suppose that we have compiled a plan fragment h for rule r  ignoring the attribute annotation in r for age. then  when evaluating the plan 뷍 false {age}  h   the bannotate algorithm for the 뷍 operator takes the a-table produced by h and outputs another a-table that represents a superset of r.
모suppose that h produces the a-table t1  shown in figure 1.a. intuitively  because of the attribute annotation for age in rule r  any possible relation in r will have at most one tuple for each of the four distinct possible name values   alice    bob    carol   or  dave  .
모therefore  bannotate outputs the a-table t1  shown in figure 1.b  which has one a-tuple for each of the possible distinct name values in t1. in each a-tuple  name age   name has one possible distinct name value n  and age is the set of all age values a that can be associated with n  i.e.  the tuple  n a  appears in at least one possible relation in r . the first three a-tuples in t1  for the three names  alice  
 bob   and carol   are maybe a-tuples because not all possible relations have tuples for those three names. however  the last a-tuple  { dave } {1}  is not a maybe a-tuple because every possible relation in r will contain a tuple for  dave   either   dave  1  or   dave  1  .
모in general  suppose we are evaluating an operator 뷍 f a  over an input a-table t with attributes  a1 ... an . for simplicity  for now assume that f = false  and that a = {an}  i.e.  we are only considering one attribute annotation for attribute an . then  we proceed in two steps.
모in the first step  we create an index i over t. each entry in i is a pair  n v   where the key n is a tuple of values  v1 ... vn 1   and v is a set of all possible values of v such that the tuple  v1 ... vn 1 v  appears in at least one possible relation represented by t. to build this index  for each a-tuple t 뫍 t  we iterate through every possible tuple  v1 ... vn  that t represents  and add vn to the values associated with the key  v1 ... vn 1  in i  creating a new entry if necessary . for example  figure 1.c shows the index we build for the a-table t1  given an attribute annotation for age.
모in the second step  we use i to construct the output atable t뫣. first  we set t뫣 to be initially empty. then  for each entry  n v   in i  where n is the tuple  v1 ... vn 1   we add a new a-tuple t to t뫣  where t =  {v1} ... {vn 1} v  . finally  we set t to be a maybe a-tuple if not all possible relations represented by input a-table t has a tuple for  v1 ... vn 1 . that is  t is a maybe a-tuple iff t뫣 does not contain any a-tuple t =  {v1} ... {vn 1} u  for some nonempty set of values u. for example  in t1 in figure 1.b  the first output a-tuple  { alice } {1 1}  is a maybe a-tuple because the input table t1 has no a-tuple  { alice } u  for any set of values u. on the other hand  the a-tuple  { dave } {1}  in t1 is not a maybe a-tuple because atable t1 has an a-tuple  { dave } u   where u = {1}.
모suppose we are evaluating 뷍 f a  over a-table t with attributes  a1 ... an   where a has multiple attribute annotations. without loss of generality  suppose a = {a1 ... ak}. then  we perform a process similar to the one above  except that we construct an index ii for each attribute ai 뫍 a. note that each index will have the same set of keys. then  for each key n in the indexes we construct an output atuple. let n =  v1 ... vk . then  we construct the a-tuple
 {v1} ... {vk} uk+1 ... un   where ui is the set of values associated with key n in index ii for k   i 뫞 n.
1.	the next-effort assistant
모the next-effort assistant can suggest ways to refine the current ie program by asking the developer u questions such as  is price in bold font  . if u chooses to answer the question  iflex forms a new constraint from the answer and incorporates the constraint into the ie program. we now discuss this process in detail.
1	question selection strategies
the space of questions: we consider questions of the form  what is the value of feature f for attribute a    where f is a text span feature  see section 1.1 . example features include  but are not limited to  bold-font  italic-font  hyperlinked  preceded-by  followed-by  min-value  and max-value. for the above question  suppose that u answers v. then iflex adds the predicate f a  = v to the description rule that that  implements  the ie predicate that extracts attribute a. thus  at any point in time the space of possible questions contain all  feature attribute  questions whose answers are still unknown. we now discuss two strategies to select the next best question from this space.
sequential strategy: this strategy selects questions based on a predefined order over the question space. currently  we rank the attributes in decreasing importance   in a domainindependent fashion  taking into account factors such as whether an attribute participates in a join  commonly appears in a variety of web pages  etc. then given the ranked list a1 ... an  we first ask questions related to attribute a1. once these are exhausted  we move to a1  and so on.
simulation strategy: this strategy selects the question that is expected to reduce by the largest amount the size of the current result. consider a question d regarding feature f of attribute a. let v be the set of possible values for f  and p be the current alog program being developed. also  let g p  a f v   be a new alog program that is the result of adding f a  = v to the rule in p that is extracting a. then the expected number of results after asking d is x pr x answers v|asks d  몫 |exec g p  a f v   | 
v뫍v
where |exec g p  a f v   | is the size of the result that would be obtained if iflex executes the modified alog program. we compute this quantity by carrying out the execution  effectively simulating the case that u answers v.
모each probability pr answers v|d  is set to be  1 붸 /|v |  where 붸 is the probability that u chooses not to answer the question  e.g.  by selecting the option i do not know  . this makes the simplifying assumption that u gives each answer v 뫍 v with equal probability. we are currently examin-
domaindatatablestable descriptionsnum pagesmovies1 pagesebertroger ebert's greatest movies list1imdbimdb top 1 movies1prasannaprasanna top movies1dblp1 pagesgarcia-molinahector garcia-molina pubs list1sigmodsigmod papers '1-'1icdeicde papers '1-'1vldbvldb papers '1-'1books1 pagesamazonamazon query on 'database'1barnesbarnes & noble query on 'database'1table 1: real-world domains for our experiments.
ing how to better estimate these probabilities from the data being queried.
모simulating |g p  a f v  | for all feature/value pairs can be costly. hence  we optimize this process using both subset evaluation and reuse  as described in section 1.
notifying the developer of convergence: to provide more effective interaction  the assistant detects and notifies u when the result for a query appears to have  converged  to the correct result. to do so  in each iteration it monitors both the number of tuples in the result set as well as the number of assignments produced by the extraction process. if these numbers remain constant for k iterations  currently set to 1   the assistant notifies u that convergence appears to have happened. then  u can either stop or continue in more iterations until he or she is satisfied. in section 1 we evaluate the effectiveness of this notification method.
1.1	discussion
we now discuss general issues regarding the assistant.
ease of answering questions: first  the assistant should ask questions that the developer can answer quickly and accurately. toward this end  we have carefully designed the features f1 ... fn so that the resulting questions focus on the appearance  e.g.  bold-font   location  e.g.  does this attribute lie entirely in the first half of the page    and semantics  e.g.  what is a maximal value for price   of the attributes. in our experiments we found that developers were able to answer these questions quickly and accurately  after some visual inspection; if unsure  the developer answered  i do not know  .
more types of feedback: the assistant can be extended to handle more types of feedback  beyond question answering. for example  it can ask the developer to mark up a sample title. if this title is bold  then the assistant can infer that for the question  is title bold    the answer cannot be  no  but can be yes or sometimes  . hence  when searching for the next best question  the assistant does not have to simulate the case of the developer's answering  no  to this question  thus saving time. exploiting other types of feedback effectively is an important future research direction.
1	multi-iteration optimization
모recall that during the development process  the developer iteratively refines and executes ie programs  and that in each iteration the assistant simulates program execution to search for promising questions for the developer. consequently  optimizing program execution across iterations is critical to reduce development time as well as to maximize the utility of the assistant. for this goal  we employ two complementary solutions: reuse and subset evaluation.
모the idea behind reuse is simple. when executing plan p in iteration n  we keep track of all intermediate results
domainie taskdescriptioninitial programmoviest1imdb top movies with fewer than 1 votest1 title  :- imdb x   extractimdb x title votes   votes   1t1ebert top movies made between 1 and 1t1 title  :- ebert x   extractebert x title year   1 뫞 year  year   1t1movie titles that occur in imdb  ebert  and prasanna's top moviest1 title1  :- imdb x   ebert y   prasanna z   extractimdb x title1   extractebert y  title1   extractprassana z  title1  

similar title1 title1   similar title1 title1 dblpt1garcia-molina journal pubst1 title  :- garcia-molina x   extractpublications x  title  journalyear   journalyear 뫛 nullt1vldb short publications of 1 or fewer pagest1 title  :- vldb x   extractvldb x  title  firstpage  lastpage   lastpage   firstpage + 1t1sigmod/icde pubs sharing authorst1 title  :- sigmod x   extractsigmod x title authors1   
icde y   extracticde y title authors1   similar authors1 authors1 bookst1b&n books with price over $1t1 title  :- barnes x   extractbarnes x title b&n price   b&n price   1t1amazon books whose list price equals the new price and used price is less than the new pricet1 title  :- amazon x   extractamazon x listprice newprice usedprice   listprice = newprice  usedprice   newpricet1books that are cheaper at amazon than at barnest1 title1  :- amazon x   extractamazon x title1 newprice   barnes y   extractbarnes x title1 b&n price  

similar title1 title1   newprice   b&n pricetable 1: ie tasks for our experiments. e.g.  intermediate compact tables . let cn be the set of these results. then when executing p in iteration  n + 1   we reuse cn to avoid re-extracting and re-executing from the scratch. to do so  we  a  examine the developer's feedback in iteration  n+1  to find new attributes that this feedback  touches    b  re-extract values for these attributes using cn  then  c  re-execute the parts of plan p that may possibly have changed  again using cn. we omit further details for space reasons.
모we employ reuse in conjunction with a new technique  subset evaluation  for the purpose of selecting questions to suggest to the developer. the idea is to simply execute plan p over only a subset of the input documents  thus dramatically reducing execution time. currently  the subset is created via random sampling  though more sophisticated creation methods are possible   and its size is set to be 1% of the original set  depending on how large this original set is. iflex employs reuse as discussed above for both subset evaluation and full execution.
1.	empirical evaluation
모we now describe experiments to evaluate the effectiveness of iflex. we start with experiments on three real-world domains  sections 1-1 . then  we describe experiments with the data of dblife  a currently deployed ie application  section 1 .
domains and ie tasks: we considered three real-world domains for our experiments: movies  dblp  and books. in each domain we first downloaded a set of web pages  between 1 . next  for each domain we partitioned the pages into groups  where each group had related content. then within each group we divided each page into a set of records  e.g.  a fragment of an amazon page describing information about one book  and stored the records as tuples in a table. table 1 describes the characteristics of these tables.
모table 1 describes the nine ie tasks that we perform over the tables  and their initial xlog program  before adding predicate description rules  annotations  and cleanup procedures . these tasks require extracting a variety of attributes  such as the title and year of movies from imbd  ebert  and prasanna pages  the title  journal year  and page numbers of publications from various dblp pages  and the title  and prices of books from barnes and amazon pages.
methods: to evaluate iflex  we compare it with xlog  the method in which we write a precise xlog program  and im-
tasknum tuples per tablemanualxlogiflext1111111t1111111t11111  1 111  1 t1111111t111111빣1t1111빣11빣1  1 t111111빣1t111111빣1t1111빣11빣1  1 table 1: run time performance over 1 ie tasks.
plement any necessary ie predicate using perl code . as a sanity-check baseline  we also consider manual  the method in which we manually inspect and collect the answers from the raw data.
1	overall performance
모table 1 shows the run time of the manual  xlog  and iflex methods. the first column lists the nine ie tasks described earlier. the second column lists for each task three scenarios  where the first two scenarios require performing the ie tasks on a subset of the tuples  achieved via random sampling of the input pages   and the third scenario involves all tuples for each table.
모for the 1 scenarios  the remaining columns show the run times of the three different methods. all times  averaged over 1 volunteers  are rounded to the minutes  and are counted from when the method is shown the web pages  until when the correct result is produced  for non-iflex methods  or when the next-effort assistant of iflex notifies the developer that it has converged. in the iflex column  the total run time is shown first  and the portion of that time that was spent writing cleanup code  if required  is shown in parenthesis.
domaintasknum
tuples per tablenum 
correct
tuplesnum tuples after each iteration  bold/italic entries when in reuse mode num 
questions askedtotal time
 min superset 
size11111moviest1111.1%t11111.1%t1-111111.1%dblpt11111.1%t11111.1%t1111111.1%bookst11111.1%t11111111%t111111111%table 1: effects of soliciting domain knowledge in iflex.모the results show that  as expected  manual does not scale to large data sets. we stopped manual in several cases  marked with  -  in the figure   after it became clear that the method was not scalable. xlog scales better; it spent most of the time in writing and debugging the perl code corresponding to the various ie predicates. however  iflex achieves significantly better performance than xlog  reducing run time by 1% in all 1 scenarios.
모the run-time results without the cleanup time clearly suggest that iflex can produce meaningful ie results quickly  much earlier than can be done with the precise-ie method
xlog .
모the run-time results with the cleanup time suggest that iflex can also produce precise ie results much faster than can be achieved with xlog. this is due to two reasons. first  developers can declaratively write domain constraints quickly in iflex  rather than spend time implementing these constraints in procedural languages  as is the case with xlog. second  the next-effort assistant can help the developers refine the ie programs effectively  as we discuss below. 1 effectiveness of the next-effort assistant
모recall that the next-effort assistant poses questions to the developer  to add constraints   and notifies the developer when the ie program has converged. we found that by just answering those questions  iflex converged to the correct result in 1 out of 1 scenarios  described earlier . in the four remaining cases  not shown due to space limitation   it converged to 1%  1%  1%  and 1% of the correct result set  respectively. the cases of 1% and 1% occurred when the number of tuples returned was relatively small  1 and 1 tuples   which could be easily corrected with manual post-processing. the results suggest that the assistant can effectively help the developer refine a best-effort ie program and notify him or her of convergence.
모in the next step  we evaluated the effectiveness of the next-effort assistant in iterating with the developer to solicit feedback. table 1 shows iflex's performance per iteration  in nine randomly selected ie scenarios. in each iteration we report  among others  the number of tuples in the result  and the execution method  i.e.  subset evaluation  indicated by number in normal font  or reuse  by number in bold italic font. for example  task t1 over 1 tuples started in subset evaluation mode  producing 1 tuples for the first iteration. after interacting with the developer in only one iteration  iflex reduced the result to 1 tuples. after two more iterations with no further reduction  iflex converged  and switched to reuse mode to compute the complete result. thus after only 1 questions in 1 iterations  iflex produced the correct 1 tuples. the results in table 1 suggest that the assistant solicited knowledge effectively  to converge in only a few iterations  1  to highly accurate result sets.
we also compared the sequential and simulation schemes
domaintasktuples /tablecorrect tuplesguidance schemenum 
iterationsquestions askedtotal time  min superset sizemoviest11seq111%sim111%t11seq111%sim111%t11seq111%sim111%dblpt11seq111%sim111%t11seq111%sim111%t11seq111%sim111%bookst11seq111%sim111%t11seq111%sim111%t11seq111%sim111%table 1: evaluating question selection strategies.
for question selection. for each of the nine ie scenarios in table 1  we measured the performance of iflex using each scheme. in all cases sequential was faster  because question selection was very efficient  i.e.  no simulation required . however  in four out of nine cases the questions asked via sequential selection were not nearly as useful for zooming in on the correct results as those asked via simulation. the extracted results were as much as 1 times larger than the correct results  suggesting that the better results obtained via simulation are well worth the additional cost when selecting questions.
1	evaluation on a real-world system
모finally  we evaluated the practicality of iflex by employing iflex over one day's snapshot  1 web pages  1 mb  of the crawled data of dblife  a structured web portal for the database community that we have been developing . this data set was significantly more heterogeneous than those used in the above domains  movies  dblp and books   and included a wide variety of web pages such as personal homepages  conference homepages  and the dbworld mailing list.
모we employed iflex to write three ie programs  described in figure 1  that correspond to similar programs in dblife. we found that iflex was flexible enough to accommodate relatively complex ie tasks over heterogeneous data such as those found in dblife. a key reason for this is that iflex provides a rich library of built-in text features that includes not only  syntactic  features  e.g.  numeric  bold-font   but also  higher-level  features. examples of such features include prec-label-contains which indicates whether the preceding label  i.e.  a header of a section in the text  of a span contains a certain string  and in-list that indicates whether a span is part of a list. for instance  to complete the program for the panel task  figure 1   we implemented the two following predicate descriptions:

extractpanelist d x  :  match d p x  personpattern p  
   = yes 
taskdescriptionqueryiflex
 min panelfind  x y  where person x is a panelist at conference y
onpanel x y  :- docs d   extractpanelists d x   extractconference d y 1  1 projectfind  x y  where person x works on project yworkson x y  :- docs d   extractowner d x   extractprojects d y 1  1 chairfind  x y z  where person x is a chair of type y at conference zchair x y z  :- docs d   extractchairs d x   
extractconference d y   extracttype x z 1  1 table 1: experiments on dblife data.

extractconf d y  : from d y  intitle y  = yes 
startswith y    a-z  a-z  a-z +    ends with y   1 d|1 d d|1 d d    maxlength y  = 1
모figure 1 shows that developing ie programs that produce exact ie results took 1 minutes each  using iflex. in contrast  developing comparable precise-ie ie programs in dblife  using perl scripts  took 1 hours  we do not keep track of the exact amount of time  as they were developed several years ago . this result further suggests that iflex can help reduce the time it takes to develop ie programs.
모for the above three ie tasks  the final ie programs obtained with iflex took 1  1  and 1 seconds to run  respectively. these times were comparable to the execution times of the corresponding ie programs in dblife  developed in perl and tuned extensively several years ago . while anecdotal  this result does suggest that the approximate query processor proves quite efficient even on large data sets.
1.	related work
모information extraction has received much attention  e.g.   1  1  1  1  1  1   see also  1  1  for recent tutorials   and many solutions have been proposed to make developing ie programs easier. these include compositional frameworks  1  1  as well as declarative languages  1  1 . however  these solutions are difficult to use for best-effort ie because they provide little or no support for writing approximate ie programs with well-defined semantics  as iflex does. notable exceptions are  1  1  1 . these works propose declarative languages to write ie programs that may produce approximate results. these languages however do not have an explicit possible-worlds semantics  as alog does.
모recent work has shown how to generate and represent approximate ie results from probabilistic graphical models  e.g. crfs   using a model similar to a-tables . in contrast  iflex produces approximate ie results using a declarative language  and uses compact tables to efficiently represent highly approximate extracted data that often arises in best-effort ie. many other works have studied representing and processing approximate or uncertain data in general  e.g.   1  1  1  1  1  . however  they have not considered the text-specific challenges we address  such as representing the large number of possible extracted values a best-effort ie program may produce.
모the next-effort assistant of iflex is similar in spirit to soliciting user feedback in a dataspace system  as described in . also  the iflex system builds on an earlier work on approximate wrapper processing . finally  the control project  has also studied interactive query processing  but for data analysis in relational settings  not for ie over text as in our current work.
1.	conclusion and future work
모despite recent advances  writing ie programs remains a difficult problem  largely because developers often try to obtain precise ie results. to address this problem  we have proposed iflex  an approach that relaxes the precise-ie requirement to enable best-effort ie. we have described how developers can use iflex to quickly write an initial approximate ie program p  obtain approximate results quickly  then refine p to obtain increasingly more precise results. as a near-term future work we plan to consider more expressive languages and data models for approximate ie. for the longer term  it would be interesting to consider how iflex can be applied to other contexts  such as best-effort data integration  that seeks to provide approximate answers over a set of data sources. this context can potentially ben-
efit from the ideas of best-effort ie  query processing  and developer interaction described in iflex.
