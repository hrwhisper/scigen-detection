there has been a great deal of hype about amazon's simple storage service  s1 . s1 provides infinite scalability and high availability at low cost. currently  s1 is used mostly to store multi-media documents  videos  photos  audio  which are shared by a community of people and rarely updated. the purpose of this paper is to demonstrate the opportunities and limitations of using s1 as a storage system for general-purpose database applications which involve small objects and frequent updates. read  write  and commit protocols are presented. furthermore  the cost  $   performance  and consistency properties of such a storage system are studied.
categories and subject descriptors
h.1  database management : physical design; h.1  database management : systems-concurrency   distributed databases
general terms
algorithms  design  experimentation  performance
keywords
cloud computing  database  aws  concurrency  eventual consistency  storage system  cost trade-off  performance  sqs  s1  ec1  simpledb
1.	introduction
　the web has made it easy to provide and consume content of any form. building a web page  starting a blog  and making both searchable for the public have become a commodity. arguably  the next wave is to make it easy to provide services on the web. services such as flickr  youtube  secondlife  or myspace lead the way. the ultimate goal  however  is to make it easy for everybody to provide such services - not just the big guys. unfortunately  this is not yet possible.
　clearly  there are non-technical issues that make it difficult to start a new service on the web. having the right business idea and
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee.
sigmod'1  june 1  1  vancouver  bc  canada.
copyright 1 acm 1-1-1/1 ...$1.
effective marketing are at least as difficult on the web as in the real world. there are  however  also technical difficulties. one of the most crucial problems is the cost to operate a service on the web  ideally with 1 〜 1 availability and acceptable latency. to run a large-scale service like youtube  several data centers all around the world are needed. but  even running a small service with a few friends involves a hosted server and a database which both need to be administrated. running a service becomes particularly challenging and expensive if the service is successful: success on the web can kill! in order to overcome these issues  utility computing  aka cloud computing  has been proposed as a new way to operate services on the internet .
　the goal of utility computing is to provide the basic ingredients such as storage  cpus  and network bandwidth as a commodity by specialized utility providers at low unit cost. users of these utility services do not need to worry about scalability because the storage provided is virtually infinite. in addition  utility computing provides full availability; that is  users can read and write data at any time without ever being blocked; the response times are  virtually  constant and do not depend on the number of concurrent users  the size of the database  or any other system parameter. furthermore  users do not need to worry about backups. if components fail  it is the responsibility of the utility provider to replace them and make the data available using replicas in the meantime. another important reason to build new services based on utility computing is that service providers only pay for what they get; i.e.  pay by use. no investments are needed upfront and the cost grows linearly and predictably with the usage. depending on the business model  it is even possible for the service provider to pass the cost for storage  computing  and networking to the end customers because the utility provider meters the usage.
　the most prominent utility service today is aws  amazon web services  with its simple storage service  s1  as the most popular representative. today  aws and in particular s1 are most successful for multi-media objects. smugmug  www.smugmug.com   for instance  is implemented on top of s1 . furthermore  s1 is popular as a backup device. for instance  there already exist products to backup data from a mysql database to s1 . in summary  s1 is already a viable option as a storage medium for large objects which are rarely updated. the purpose of this work is to explore whether s1  and related utility computing services  are also attractive for other kinds of data  i.e.  small objects  and as a general-purpose store for web-based applications.
　while the advantages of storage systems like s1 are compelling  there are also important disadvantages. first  s1 is slow as compared to an ordinary locally attached disk drive. second  storage systems like s1 were designed to be cheap and highly available  see above   thereby sacrificing consistency . in s1  for instance  it might take an undetermined amount of time before an update to an object becomes visible to all clients. furthermore  updates are not necessarily applied in the same order as they were initiated. the only guarantee that s1 gives is that updates will eventually become visible to all clients and that the changes persist. this property is called eventual consistency . if an application has additional consistency requirements  then such additional consistency guarantees must be implemented on top of s1 as part of the application.
　the purpose of this paper is to explore how web-based database applications  at any scale  can be implemented on top of utility services like s1. the paper presents various protocols in order to store  read  and update objects and indexes using s1. the ultimate goal is to preserve the scalability and availability of a distributed system like s1 and achieve the same level of consistency as a database system  i.e.  acid transactions . unfortunately  it is not possible to have it all because of brewer's famous cap theorem . given the choice  this work follows the distributed systems' approach  thereby preserving scalability and availability and maximizing the level of consistency that can be achieved under this constraint. as a result  we will not even try to support acid transactions because we feel that it is not needed for most web-based applications   whereas scalability and availability are a must. we will show how certain transactional properties  e.g.  atomicity and durability  can be implemented; however  we will only sketch  section 1  what it takes to implement full acid transactions and why these approaches do not scale.
　we are aware that the results presented in this paper capture merely a snapshot  november 1  of the current state-of-theart in utility computing. given the success of s1  it is likely that there will be competitors with different features on the market place soon. furthermore  it is likely that amazon itself will add features and possibly provide new services with additional guarantees. in fact  amazon already changed the interface of one of its services  sqs  and introduced a new service  simpledb  in early 1. nevertheless  we believe that the results presented in this paper will remain applicable because they study fundamental tradeoffs of distributed data management based on utility computing. if amazon decides to provide additional features and guarantees  then amazon itself will need to use similar protocols as those studied in this work.
in summary  this paper makes the following contributions:  here
s1 is used as a placeholder for more general utility computing by amazon and other providers. 
  show how small objects which are frequently updated by concurrent clients can be implemented using a distributed storage system like s1.
  show how a b-tree can be implemented on top of a storage system like s1.
  present protocols that show how different levels of consistency can be implemented using s1.
  present the results of performance experiments with the tpc-
w benchmark in order to study the cost  response time and $  of running a web-based application at different levels of consistency on s1.
　the remainder of this paper is organized as follows: section 1 describes aws  i.e.  s1  sqs  and ec1 . section 1 presents the proposed architecture to build web-based database applications on top of aws. sections 1 and 1 present the protocols to implement reads and writes on top of s1 at different levels of consistency. sections 1 also cover the implementation of a b-tree on s1. section 1 summarizes the most significant results of performance experiments with the tpc-w benchmark. section 1 discusses related work. section 1 contains conclusions and suggests possible avenues for future work.
1.	what is aws 
　this section presents the functionality and properties in terms of performance and consistency of three services of the amazon web services  aws : s1  sqs  and ec1. recently  simpledb was added to the aws family of services; unfortunately  too late to be studied as part of this work. aws is currently the most prominent provider of utility computing. aws is used in the remainder of this study as a basis for studying the development of web-based applications on utility computing. other providers such as adobe share are beginning to appear on the market place. the results of this work are applicable to all utility services which provide a read/write interface in order to persist data in a distributed system.
1	s1
　s1 is amazon's simple storage system. conceptually  it is an infinite store for objects of variable size  minimum 1 byte  maximum 1 gb . an object is simply a byte container which is identified by a uri. clients can read and update s1 objects remotely using a soap or rest-based interface; e.g.  get uri  returns an object and put uri  bytestream  writes a new version of the object. a special get-if-modified-since uri  timestamp  method allows to retrieve the new version of an object only if the object has changed since the specified timestamp. this feature is useful in order to implement caching based on a ttl protocol  section 1 . furthermore  userdefined metadata  maximum 1 kb  can be associated to an object and can be read and updated independently of the rest of the object. this feature is useful  for instance  to record a timestamp of the last change  section 1 .
　in s1  each object is associated to a bucket. that is  when a user creates a new object  the user specifies into which bucket the new object should be placed. s1 provides several ways to scan through objects of a bucket. for instance  a user can retrieve all objects of a bucket or only those objects whose uris match a specified prefix. furthermore  the bucket can be the unit of security: users can grant read and write authorization to other users for entire buckets. alternatively  access privileges can be given on individual objects.
　s1 is not for free. it costs usd 1 to store 1 gb of data for one month. in comparison  a 1 gb disk drive from seagate costs usd 1 today. assuming a two year life time of a disk drive  the cost is about usd 1 per gb and month  power consumption is not included . given that disk drives are never operated at 1 percent capacity and considering mirroring  the storage cost of s1 is in the same ballpark as that for regular disk drives. therefore  using s1 as a backup device is a no-brainer. users  however  need to be more careful to use s1 for live data because every read and write access to s1 comes with an additional cost of usd 1 per 1 get requests  usd 1 per 1 put requests  and usd 1 to usd 1 per gb of network bandwidth consumed  the exact rate depends on the total monthly volume of a user . for this reason  services like smugmug use s1 as a persistent store  yet operate their own servers in order to cache the data and avoid interacting with s1 as much as possible .
　another reason to make aggressive use of caching is latency. table 1 shows the response time of get requests and the overall bandwidth of get requests  depending on the page size  defined below . these experiments were executed using a mac  1 ghz
1.1.111111page size  kb resp. time  secs bandwidth  kb/secs operationtime  secs table 1: resp. time  bandwidth of s1  vary page size
intel core duo with 1 gb of ram  connected to the internet and s1 via a fast internet connection.  the results of a more comprehensive performance study of s1 are reported in .  the results in table 1 support the need for aggressive caching of s1 data; reading data from s1 takes at least 1 msecs  column 1 of table 1  which is two to three orders of magnitudes longer than reading data from a local disk. writing data to s1  not shown in table 1  takes about three times as long as reading data. while latency is an issue  s1 is clearly superior to ordinary disk drives in terms of throughput: virtually  an infinite number of clients can use s1 concurrently and the response times shown in table 1 are practically independent of the number of concurrent clients.
　column 1 of table 1 shows the bandwidth a client gets when reading data from s1. it becomes clear that an acceptable bandwidth can only be achieved if data are read in relatively large chunks of 1 kb or more. therefore  small objects should be clustered into pages and a whole page of small objects should be the unit of transfer. the same technique to cluster records into pages on disk is common practice in all state-of-the-art database systems  and we adopt this technique for this study.
　amazon has not published details on the implementation of s1 and it does not give any guarantees. taking  as a reference for amazon's design principles  even though  describes a different system   it seems that s1 replicates all data at several data centers. each replica can be read and updated at any time and updates are propagated to replicas asynchronously. if a data center fails  the data can nevertheless be read and updated using a replica at a different data center; reconciliation happens later on a last update wins basis. this approach guarantees full read and write availability which is a crucial property for most web-based applications: no client is ever blocked by system failures or other concurrent clients. furthermore  this approach guarantees persistence; that is  the result of an update can only be undone by another update. additional guarantees are not assumed in this paper. the purpose of this work is to show how such additional consistency guarantees can be provided on top of s1. in order to exploit s1's  apparent  last update wins policy  all protocols make sure that there is sufficient time between two updates to the same s1 object  i.e.  several seconds  section 1 .
1	sqs
　sqs stands for simple queueing system. sqs allows users to manage a  virtually  infinite number of queues with  virtually  infinite capacity. each queue is referenced by a uri and supports sending and receiving messages via a http or rest-based interface.  we use the http interface in this work.  as of november 1  the maximum size of a message is 1 kb using the restbased interface and 1 kb for the http interface. any bytestream can be put into a message; there is no pre-defined schema. each message is identified by a unique id. based on that id  a message can be read  locked  and deleted from a queue. more specifically  sqs supports the following methods which are relevant for this work:
  createqueue uri : creates a new queue.
  send uri  msg : sends a message to the queue identified by
send1receive1delete1table 1: response times of sqs
the uri parameter. returns the id of the message in that queue. the message id becomes an integral part of the message and is visible to clients which receive the message.
  receive uri  number-of-msg  timeout : receives number-ofmsg messages from the top of a queue. number-of-msg must be 1 or smaller. if the queue has less than number-of-msg messages or only a subset of the messages are available  e.g.  due to node failures at amazon   then sqs may return less than number-of-msg messages. the returned messages are locked for the specified timeout period; i.e.  the messages are not visible via receive calls  or other read operations  to other clients during this timeout period. this feature makes it possible to ensure that each message is processed at most once  and yet  avoid that messages are lost if a client fails while processing a message.
  delete uri  msg-id : deletes a message from a queue based on its message id. typically  this method is called after a client has completely processed the message.
  addgrant uri  user : allow another user to send and receive messages to/from a queue.
in addition to these methods  there are several other methods  but none of these other methods are used in this study.
　like s1  sqs is not for free. the cost is usd 1 to send 1 messages. furthermore  the network bandwidth costs at least usd 1 per gb of data transferred. as for s1  the cost for the consumed network bandwidth decreases  the more data is transferred. usd 1 per gb is the minimum for heavy users.
　table 1 lists the round trip times of the most critical sqs operations used in this study; i.e.  the operations that impact the performance of a web-based application built using sqs. each call to sqs either returns a result  e.g.  receive returns messages  or returns an acknowledgment  e.g.  send  delete . the round trip time is defined as the total  wallclock  time between initiating the request from the application and the delivery of the result or ack  respectively. for these experiments  the message size was fixed to 1 bytes  but the sensitivity to the message size is low.
　again  amazon has not published any details on the implementation of sqs. it seems  however  that sqs was designed along the same lines as s1. the messages of a queue are stored in a distributed and replicated way  possibly on many machines in different data centers. clients can initiate requests at any time; they are never blocked by failures or other clients and will receive an answer  or ack  in constant time. for instance  if one client has locked all messages of a queue as part of a receive call  then another concurrent client which initiates another receive call will simply get an empty set of messages as a result. since the queues are stored in a distributed way  sqs only makes a best-effort when returning messages in a fifo manner. that is  there is no guarantee that sqs returns the first message of a queue as part of a receive call or that sqs returns the messages in the right order. we have made experiments and as a rule of thumb it can be expected that sqs returns only every tenth relevant message. for instance  if a queue contains 1  unlocked  messages and a client asks for the top 1 messages  then sqs is likely to return about 1 messages as a result for that request. an important assumption made in this work is that no messages are ever lost. in fact  this property does not hold for sqs because sqs deletes messages after fifteen days. fortunately  in all situations where this assumptions is made  there are work-arounds which are not reported in this paper for brevity and ease of presentation.
1	ec1
　ec1 stands for elastic computing cloud. ec1 is a service which allows clients to rent machines  cpu + disks  for a client-specified period of time. technically  the client gets a virtual machine which is hosted on one of the amazon servers. the cost is usd 1 per hour  i.e.  usd 1 per month   regardless of how heavily the machine is used. one interesting aspect of ec1 is that all requests from ec1 to s1 and sqs are free. from a performance perspective  it is attractive to run applications on ec1 if the data is hosted on s1 because that way the computation is moved to the data  i.e.  query shipping and stored procedures . ec1 is also attractive to implement a distributed infrastructure such as a global transaction counter  section 1 . the experiments reported in this paper  section 1  were carried out using our own servers and without ec1. studying the trade-offs of ec1 is beyond the scope of this paper  but definitely an important avenue for future work.
1.	using s1 as a disk
　as mentioned in section 1  utility computing with s1 promises infinite scalability  availability  and throughput. furthermore  s1 has a similar read / write interface as an ordinary disk drive. thus  s1 looks like a great candidate to implement a database. this section shows that many textbook techniques to implement tables  pages  b-trees  and logging can be applied to implement a database on top of s1. so  the purpose of this section is to highlight the commonalities between a disk-based and s1-based database system. the reader should not be surprised by anything said in this section. sections 1 and 1  then  highlight the differences.
1	client-server architecture
　figure 1 shows the proposed architecture of an s1 database. this architecture has a great deal of commonalities with a distributed shared-disk database system . clients retrieve pages from s1 based on the pages' uris  buffer the pages locally  update them  and write them back. as mentioned in section 1  the unit of transfer is a page which contains typically several records or index entries. following the general db terminology  we refer to records as a bytestream of variable size whose size is constrained by the page size. records can be relational tuples or xml elements and documents. blobs can be stored directly on s1 or using the techniques devised in ; all these techniques are applicable in a straightforward way so that blobs are not discussed further in this paper.
　within a client  there is a stack of components that support the application. this work focuses on the two lowest layers; i.e.  the record and page managers. all other layers  e.g.  the query processor  are not affected by the use of s1 and are  thus  considered to be part of the application. the page manager coordinates read and write requests to s1 and buffers pages from s1 in local main memory or disk. the record manager provides a record-oriented interface  organizes records on pages  and carries out free-space management for the creation of new records. applications interact with the record manager only  thereby using the interface described in the next subsection.
throughout this work  we use the term client to refer to software

figure 1: shared-disk architecture
artifacts that retrieve pages from s1 and write pages back to s1. depending on the application  the software architecture of figure 1 can be implemented by different hardware configurations. for instance  the page manager  record manager  and parts of the application could be executed on ec1 or on machines in a separate data center which is the configuration used by smugmug  and possibly other large-scale applications. alternatively  it is possible that the whole client stack is installed on  say  laptops or handheld computers  e.g.  mobile phones  in order to implement a fancy web 1 application in which users share data via s1. in such a configuration  no additional infrastructure is needed in addition to aws in order to operate the web 1 application. this configuration  therefore  fits well the needs of providers of new services on the web  as described in the introduction. for ease of presentation  such a configuration is assumed in the remainder of this paper. hence  if not stated otherwise  it is assumed that application  record  and page manager run on a single machine and in a single process. the techniques studied in this paper  however  are also applicable to other configurations.
　all protocols proposed in this work were designed to support a large number of concurrent clients; possibly in the thousands or even millions. it is assumed that the utility provider  i.e.  s1  can support such a large number of clients and guarantees  pretty much  constant response times  independent of the number of concurrent clients. furthermore  the utility provider guarantees a high degree of availability and durability; that is  clients can read and write pages from/to s1 at any moment in time without being blocked and updates are never lost by the utility provider. all these properties must be preserved in the application stack at the client. as a result  the protocols must be designed in such a way that any client can fail at any time without blocking any other client. that is  clients are never allowed to hold any locks that would block the execution at other clients. furthermore  clients are stateless. they may cache data from s1  but the worst thing that can happen if a client fails is that all the work of that client is lost. obviously  fulfilling all these requirements comes at a cost: eventual consistency . that is  it might take a while before the updates of one client become visible at other clients. furthermore  ansi sql-style isolation and serialization  are impossible to achieve under these requirements. following   we believe that strict consistency and acid transactions are not needed for most web-based applications  whereas scalability and availability are a must. the goal of this paper is to bring as much db technology as possible into this environment  to maximize consistency  and to achieve other transactional guarantees  e.g.  atomicity and monotonicity . furthermore  this paper shows the limits and implications of implementing full db-style transactional support in such an architecture  section 1 .
　in the remainder of this section  the record manager  page manager  implementation of indexes  logging  and security issues are described in more detail. metadata management such as the management of a catalogue which registers all collections and indexes is not discussed in this paper. it is straightforward to implement on top of s1 in the same way as the catalogue of a relational database is stored in the database itself.
1	record manager
　the record manager manages records  e.g.  relational tuples . each record is associated to a collection  see below . a record is composed of a key and payload data. the key uniquely identifies the record within its collection. both key and payload are bytestreams of arbitrary length; the only constraint is that the size of the whole record must be smaller than the page size. physically  each record is stored in exactly one page which in turn is stored as a single object in s1. logically  each record is part of a collection  e.g.  a table . in our implementation  a collection is implemented as a bucket in s1 and all the pages that store records of that collection are stored as s1 objects in that bucket. a collection is identified by a uri. the record manager provides functions to create new objects  read objects  update objects  and scan collections.
　create key  payload  uri : creates a new record into the collection identified by uri. there are many alternative ways to implement free-space management   and they are all applicable to an s1 database. in our implementation  free-space management is carried out using a b-tree; this approach is sometimes also referred to as index-organized table. that is  the new record is inserted into a leaf of a b-tree. the key must be defined by the application and it must be unique. in order to implement keys which are guaranteed to be unique in a distributed system  we used uuids generated by the client's hardware in our implementation.
　read key  uri : reads the payload information of a record given the key of the record and the uri of the collection.
　update key  payload  uri : update the payload information of a record. in this study  all keys are immutable. the only way to change a key of a record is to delete and re-create the record.
delete key  uri : delete a record.
　scan uri : scan through all records of a collection. to support scans  the record manager returns an iterator to the application.
　in addition to the create  read  update  and scan methods  the api of the record manager supports commit and abort methods. these two methods are implemented by the page manager  described in the next section. furthermore  the record manager exposes an interface to probe b-tree indexes  e.g.  range queries ; the implementation of b-trees is described in section 1.
1	page manager
　the page manager implements a buffer pool for s1 pages. it supports reading pages from s1  pinning the pages in the buffer pool  updating the pages in the buffer pool  and marking the pages as updated. the page manager also provides a way to create new pages on s1. all this functionality is straightforward and can be implemented just as in any other database system. furthermore  the page manager implements the commit and abort methods. we use the term transaction for a sequence of read  update  and create requests between two commit or abort calls. it is assumed that the write set of a transaction  i.e.  the set of updated and newly created pages  fits into the client's main memory or secondary storage  flash or disk . if an application commits  all the updates are propagated to s1 and all the affected pages are marked as unmodified in the client's buffer pool. how this propagation works is described in section 1. if the application aborts a transaction  all pages marked modified or new are simply discarded from the client's buffer pool  without any interaction with s1. we use the term transaction liberally in this work: our protocols do not give acid guarantees in the db sense  as motivated in section 1. the assumption that the write set of a transaction must fit in the client's buffer pool can be relaxed by allocating additional overflow pages for this purpose on s1; discussing such protocols  however  is beyond the scope of this paper and rarely needed in practice.
　the page manager keeps copies of s1 pages in the buffer pool across transactions. that is  no pages are evicted from the buffer pool as part of a commit.  an abort only evicts modified and new pages.  pages are refreshed in the buffer pool using a time to live  ttl  protocol: if an unmodified page is requested from the buffer pool after its time to live has expired  the page manager issues a get-if-modified request to s1 in order to get an up-to-date version  if necessary  section 1 .
1	b-tree indexes
　b-trees can be implemented on top of the page manager in a fairly straightforward manner. again  the idea is to adopt existing textbook database technology as much as possible. the root and intermediate nodes of the b-tree are stored as pages on s1  via the page manager  and contain  key  uri  pairs: uri refers to the appropriate page at the next lower level. the leaf pages of a primary index contain entries of the form  key  payload ; that is  these pages store the records of the collection in the index-organized table  section 1 . the leaf pages of a secondary index contain entries of the form  search key  record key . that is  probing a secondary index involves navigating through the secondary index in order to retrieve the keys of the matching records and then navigating through the primary index in order to retrieve the records with the payload data. as mentioned in section 1  holding locks must be avoided as much as possible in a scalable distributed architecture. therefore  we propose to use b-link trees  and their use in a distributed system as proposed by  in order to allow concurrent reads and writes  in particular splits   rather than the more mainstream lockcoupling protocol . that is  each node of the b-tree contains a pointer  i.e.  uri  to its right sibling at the same level. at the leaf level  this chaining can naturally be exploited in order to implement scans through the whole collection or through large key ranges.
　a b-tree is identified by the uri of its root page. a collection is identified by the uri of the root of its primary index. both uris are stored persistently as metadata in the system's catalogue on s1  section 1 . since the uri of an index is a reference to the root page of the b-tree  it is important that the root page is always referenced by the same uri. implementing this requirement involves a slightly modified  yet straightforward  way to split the root node. another deviation to the standard b-tree protocol is that the root node of a b-tree in s1 can be empty; it is not deleted even if the b-tree contains no entries.
1	logging
　the protocols described in sections 1 and 1 make extensive use of redo log records. in all these protocols  it is assumed that the log records are idempotent; that is  applying a log record twice or more often has the same effect as applying the log record only once. again  there is no need to reinvent the wheel and textbook log records as well as logging techniques are appropriate . if not stated otherwise  we used the following  simple  redo log records in our implementation:
   insert  key  payload : an insert log record describes the creation of a new record; such a log record is always associated to a collection  more precisely to the primary index which organizes the collection  or to a secondary index. if such an insert log record is associated to a collection  then the key represents the key value of the new record and the payload contains the other data of the record. if the insert log record is associated to a secondary index  then the key is the value of the search key of that secondary index  possibly composite  and the payload is the primary key value of the referenced record.
   delete  key : a delete log record is also associated either to a collection  i.e.  primary index  or to a secondary index.
   update  key  afterimage : an update log record must be associated to a data page; i.e.  a leaf node of a primary index of a collection. an update log record contains the new state  i.e.  after image  of the referenced record. diffing  logical logging  or other optimized logging techniques are not studied in this work for simplicity; they can be applied to s1 databases in the same way as to any other database system. entries in a secondary index are updated by deleting and reinserting these entries.
by nature  all these log records are idempotent: in all three cases  it can be deduced from the database whether the updates described by the log record have already been applied. with such simple update log records  however  it is possible that the same update is applied twice if another update overwrote the first update before the second update. this property can result in indeterminisms as shown in section 1. in order to avoid these indeterminisms  more sophisticated logging can be used such as the log records used in section 1.
　if an operation involves updates to a record and updates to one or several secondary indexes  then separate log records are created by the record manager to log the updates in the collection and at the secondary indexes. again  implementing this functionality in the record manager is straightforward and not different to any textbook database system.
　most protocols studied in this work involve redo logging only. only the protocols sketched in sections 1 require undo logging. undo logging is also straightforward to implement by keeping the before image in addition to the after image in update log records  and by keeping the last version of the record in delete log records.
1	security
　obviously  security is a concern in the open architecture shown in figure 1. everybody has access to s1  but of course  not everybody should have access to a client's personal data. fortunately  s1 gives clients control of the data. a client who owns a collection  implemented as an s1 bucket  can give other clients read and/or write privileges to the collection  i.e.  bucket  or individual pages of that collection. unfortunately  s1 does not support fine-grained security and flexible authorization using  e.g.  sql views. to do that  an additional security infrastructure is needed which can  luckily  be implemented on top of s1  too. designing and implementing such an infrastructure is an important avenue for future research.
　one important feature of the architecture of figure 1 is that clients need not trust the utility provider. all data can be stored in s1 in an encrypted form. in order to give different sets of clients access to different sets of pages  different encryption keys can be used. in this case  the header of the page indicates which key must be used to decrypt and re-encrypt the page in the event of updates  and this key must be shared by all the clients who may access that page.

figure 1: basic commit protocol
　using sqs  furthermore  it is possible to implement several security scenarios. it is possible  for example  to assign a curator for a collection. in this scenario  all updates must be approved by the curator before they become visible to other clients. while the updates wait for approval  clients continue to see the old version of the data. although  this paper will not come back to the implementation of such scenarios  their implementation using sqs should become clearer after reading the next section.
1.	basic commit protocols
　the previous section showed that an s1 database system can have a great deal of commonalities with a traditional textbook database system. this section addresses one particular issue which arises when concurrent clients commit updates to records stored on the same page. if no care is taken  then the updates of one client are overwritten by the other client  even if the two clients update different records. the reason is that the unit of transfer between clients and s1 in the architecture of figure 1 is a page  rather than an individual record. this issue does not arise in a  shareddisk  database system because the database system coordinates updates to the disk s ; however  this coordination limits the scalability  number of nodes/clients  of a shared-disk database. this issue does not arise in the way that s1 is used conventionally because today s1 is mostly used to store large objects so that the unit of transfer to s1 can be the object; for small objects  clustering several objects into pages is mandatory in order to get acceptable performance  section 1 . obviously  if two concurrent clients update the same record  then the last updater wins. protocols to synchronize concurrent update transactions are sketched in section 1.
　the protocols designed in this section preserve the features of utility computing with s1: clients can fail anytime  clients can read and write data at constant time  clients are never blocked by concurrent clients  and distributed web-based applications can be built on top of aws only  without the need to build or administrate any additional infrastructure. again  the price to pay for these features is reduced consistency: in theory  it might take an undetermined amount of time before the updates of one client become visible at other clients. in practice  the time can be controlled  thereby increasing the cost  in $  of running an application for increased consistency  i.e.  a reduced propagation time .
1	overview
　figure 1 demonstrates the basic idea of how clients commit updates. the protocol is carried out in two steps:
  in the first step  the client generates log records for all the updates that are committed as part of the transaction and sends them to sqs.1
  in the second step  the log records are applied to the pages stored on s1. we call this step checkpointing.1
this protocol is extremely simple  but it serves the purpose. assuming that sqs is virtually always available and that sending messages to sqs never blocks  the first step can be carried out in constant time  assuming a constant or bounded number of messages which must be sent per commit . the second step  checkpointing  involves synchronization  section 1   but this step can be carried out asynchronously and outside of the execution of a client application. that is  end users are never blocked by the checkpointing process. as a result  virtually 1 percent read  write  and commit availability is achieved  independent of the activity of concurrent clients and failures of other clients. furthermore  no additional infrastructure is needed to execute this protocol; sqs and s1 are both utility services provided by aws  and the hope is that similar utility services will be supported by other providers soon.
　the simple protocol of figure 1 is also resilient to failures. if a client crashes during commit  then the client resends all log records when it restarts. in this case  it is possible that the client sends some log records twice and as a result these log records may be applied twice. however  applying log records twice is not a problem because the log records are idempotent  section 1 . if a client crashes during commit  it is also possible that the client never comes back or loses uncommitted log records. in this case  some log records of the commit have been applied  before the failure  and some log records of the commit will never be applied  thereby violating atomicity. indeed  the basic commit protocol of figure 1 does not guarantee atomicity. atomicity  however  can be implemented on top of this protocol as shown in section 1.
　in summary  the simple protocol of figure 1 preserves all the features of utility computing. unfortunately  it does not help with regard to consistency. that is  the time before an update of one client becomes visible to other clients is unbounded in theory. the only guarantee that can be given is that eventually all updates will become visible to everybody and that all updates are durable. this property is known as eventual consistency . in practice  the freshness of data seen by clients can be controlled by setting the checkpoint interval  section 1  and the ttl value at each client's cache  section 1 . setting the checkpoint interval and ttl values to lower values will increase the freshness of data  but it will also increase the  $  cost per transaction  section 1 . another way to increase the freshness of data  at increased cost  is to allow clients to receive log records directly from sqs  before they have been applied to s1 as part of a checkpoint. for brevity  this latter technique is not elaborated in more detail in this paper.
the remainder of this section describes the details of the basic commit protocol of figure 1; i.e.  committing log records to sqs  step 1  and checkpointing  step 1 .
1	pu queues
　figure 1 shows that clients propagate their log records to socalled pu queues  i.e.  pending update queues . in theory  it would be sufficient to have a single pu queue for the whole system. however  it is better to have several pu queues because that allows multiple clients to carry out checkpoints concurrently: as shown in section 1  a pu queue can only be checkpointed by a single client at the same time. specifically  we propose to establish pu queues for the following structures:
  each b-tree  primary and secondary  has one pu queue associated to it. the pu queue of a b-tree is created when the b-tree is created and its uri is derived from the uri of the b-tree  i.e.  the uri of the root node of the b-tree . all insert and delete log records are submitted to the pu queues of b-trees.
  one pu queue is associated to each leaf node of a primary b-tree of a collection. we refer to these leaf nodes as data pages because they contain all the records of a collection. only update log records are submitted to the pu queues of data pages. the uris of these pu queues are derived from the corresponding uris of the data pages.
1	checkpoint protocol for data pages
　checkpoints can be carried out at any time and by any node  or client  of the system. a checkpoint strategy determines when and by whom a checkpoint is carried out  section 1 . this section describes how a checkpoint of update log records is executed on data pages; i.e.  leaf nodes of the primary index of a collection. the next section describes how checkpoints of insert and delete log records are carried out on b-trees.
　the input of a checkpoint is a pu queue. the most important challenge when carrying out a checkpoint is to make sure that nobody else is concurrently carrying out a checkpoint on the same pu queue. for instance  if two clients carry out a checkpoint concurrently using the same pu queue  some updates  i.e.  log records  might be lost because it is unlikely that both clients will read the exactly same set of log records from the pu queue  section 1 . one solution to synchronize checkpoints is to designate machines to carry out checkpoints on particular pu queues. this approach is referred to as watchdog or owner in section 1  but it is not used in this work because it does not degrade gracefully in the event that one of these designated machines fail  section 1 . the alternative is to allow any client which has write permission to carry out checkpoints and to implement a lock in order to guarantee that two clients do not checkpoint the same pu queue concurrently.
　as shown in figure 1  such a lock can be implemented using sqs. the idea is to associate a lock queue to each pu queue. both  the pu queue and the lock queue are created at the time a new page is created in s1. at every point in time  a lock queue contains exactly one message which can be regarded as a token. this token message is created when the lock queue is created and nobody is allowed to send messages to a lock queue or delete the token message. when a client  or any other authority  attempts to do a checkpoint on a pu queue  it tries first to receive and lock the token message from the lock queue of that pu queue. if the client receives the token message  then the client knows that nobody else is concurrently applying a checkpoint on that pu queue and proceeds to carry out the checkpoint. as part of the receive request to the lock queue  the client sets a timeout to lock the token message. during this timeout period the client must have completed the checkpoint; if the client is not finished in that timeout period  the client aborts checkpoint processing and propagates no changes. if the client does not receive the token message at the beginning  the client assumes that somebody else is carrying out a checkpoint concurrently. as a result  the client terminates the routine.
in summary  update log records are applied in the following way:
1. receive urioflockqueue  1  timeout . if the token message is returned  continue with step 1; otherwise  terminate. the timeout on the token message should be set such that steps 1 to 1 can be executed within the timeout period.
1. if the leaf page is cached at the client  refresh the cachedcopy with a get-if-modified call to s1. if it is not cached  get a copy of the page from s1.
1. receive uriofpuqueue  1  1 . receive as many log records from the pu queue as possible.  1 is the upper bound for the number of messages that can be received within one sqs call.  the timeout can be set to 1 because the log records in the pu queues need not be locked.
1. apply the log records to the local copy of the page.
1. if steps 1 to 1 were carried out within the timeout specifiedin step 1  plus some padding for the put   put the new version of the page to s1. if not  terminate.
1. if step 1 was successful and completed within the timeout delete all the log records which were received in step 1 from the pu queue using the delete method of sqs.
in step 1  it is possible that the data page must be split because the records grew. for brevity  this paper does not describe all the details of splitting nodes. in our implementation  splitting pages is carried out along the lines of  so that clients which read a page are not blocked while the page is split. in step 1  the put method to s1 is considered to be atomic. the token from the lock queue received in step 1 need not be unlocked explicitly; the token becomes automatically visible again  after the timeout expires.
　this protocol to propagate updates from an sqs queue to s1 is safe because the client can fail at any point in time without causing any damage. if the client fails before step 1  then no damage is made because neither the state on sqs nor on s1 have changed. if the client fails after step 1 and before the deletion of all log records from sqs in step 1  then it is possible that some log records are applied twice. again  no damage is caused in this case because the log records are idempotent  section 1 . in this case  indeterminisms can appear if the pu queue contains several update log records that affect the same key. at part of a subsequent checkpoint  these log records may be applied in a different order so that two different versions of the page may become visible to clients  even though no other updates were initiated in the meantime. these indeterminisms can be avoided by using the extended logging mechanism for monotonic writes described in section 1 as opposed to the simple log records described in section 1.
　setting the timeout in step 1 is critical. setting the value too low might result in starvation because no checkpoint will ever be completed if the pu queue has exceeded a certain length. on the other hand  a short timeout enables frequent checkpoints and  thus  fresher data. for the experiments reported in section 1  a timeout of 1 seconds was used.
1	checkpoint protocol for b-trees
　as mentioned in section 1  there is one pu queue associated to each b-tree for inserts and deletes to that b-tree. primary and secondary indexes are checkpointed in the same way; only the leaf nodes of a primary index  i.e.  data pages  are treated specially. checkpointing a b-tree is more complicated than checkpointing a data page because several  b-tree  pages are involved in a checkpoint and because splitting and deleting pages are frequent. nevertheless  the basic ideas are the same and can be summarized in the following protocol sketch:
1. obtain the token from the lock queue  same as step 1 
section 1 .
1. receive log records from the pu queue  step 1  section 1 .
1. sort the log records by key.
1. take the first  unprocessed  log record and navigate throughthe b-tree to the leaf node which is affected by this log record.
reread that leaf node from s1 using s1's get-if-modified method.
1. apply all log records that are relevant to that leaf node.
1. if the timeout of the token received in step 1 has not expired  with some padding for the put   put the new version of the node to s1; otherwise terminate  same as step 1  section 1 .
1. if the timeout has not expired  delete the log records whichwere applied in step 1  from the pu queue.
1. if not all log records have been processed yet  goto step 1. otherwise  terminate.
as part of step 1  nodes might become empty or be split. again  we cannot describe all the details in this paper due to space constraints and refer the interested reader to the technical report. as mentioned in section 1  our implementation adopts the techniques of  to make sure that concurrent readers are not blocked by splits and deletions carried out by a checkpoint.
1	checkpoint strategies
　the purpose of the previous two sections was to show how checkpoints are implemented. the protocols were designed in such a way that anybody can apply a checkpoint at any time. this section discusses alternative checkpoint strategies. a checkpoint strategy determines when and by whom a checkpoint is carried out. along both dimensions  there are several alternatives.
　a checkpoint on a page  or index  x can be carried out by the following authorities:
  reader: a reader of x.
  writer: a client who just committed updates to x.
  watchdog: a process which periodically checks pu queues.
  owner: x is assigned to a specific client which periodically checks the pu queue of x.
in this work  we propose to have checkpoints carried out by readers and writers while they work on the page  or index  anyway. establishing watchdogs to periodically check pu queues is a waste of resources and requires an additional infrastructure to run the watchdogs. likewise  assigning owners to pu queues involves wasting resources because the owners must poll the state of their pu queues. furthermore  owners may be offline for an undetermined amount of time in which case the updates might never be propagated from the pu queue to s1. the advantage of using watchdogs and assigning owners to pu queues is that the protocols of sections 1 and 1 are simplified  no lock queues are needed  because no synchronization between potentially concurrent clients is required. nevertheless  we believe that the disadvantages outweigh this advantage.
　the discussion of whether checkpoints should be carried out by readers or writers is more subtle and depends on the second question of when checkpoints should be carried out. in this work  we propose to use writers in general and readers only in exceptional cases  see below . a writer initiates a checkpoint using the following condition:
  each data page records the timestamp of the last checkpoint in its header. for b-trees  the timestamp is recorded in the metadata  section 1  associated to the root page of the btree. for b-trees  the s1 maintained metadata  rather than the root page  is used to store this information because checkpointing a b-tree typically does not involve modifying the root and rewriting the whole root in this event would be wasteful. the timestamp is taken from the machine that carries out the checkpoint. it is not important to have synchronized clocks at all machines; out-of-sync clocks will result in more or less frequent checkpoints  but they will not affect the correctness of the protocol  i.e.  eventual consistency at full availability .
  when a client commits a log record to a data page or b-tree  the client computes the difference between its current wallclock time and the timestamp recorded for the last checkpoint in the data page / b-tree. if the absolute value of this difference is bigger than a certain threshold  checkpoint interval   then the writer carries out a checkpoint asynchronously  not blocking any other activity at the client . the absolute value of the difference is used because out-of-sync clocks might return outrageous timestamps that lie in the future; in this case  the difference is negative.
the checkpoint interval is an application-dependent configuration parameter; the lower it is set  the faster updates become visible  yet the higher the cost  in usd  in order to carry out many checkpoints. the trade-offs of this parameter are studied in section 1. obviously  the checkpoint interval must be set to a significantly larger value than the timeout on the lock queue for checkpoint processing used in the protocols of sections 1 and 1. for a typical web-based application  the checkpoint interval should be set to  say  1 seconds whereas timeouts on lock queues should be set to 1 seconds. clearly  none of the protocols devised in this work are appropriate to execute transactions on hot-spot objects which are updated thousands of times per second.
　unfortunately  the writer-only strategy has a flaw. it is possible that a page which is updated once and then never again is never checkpointed. as a result  the update never becomes visible. in order to remedy this situation  it is important that readers also initiate checkpoints if they see a page whose last checkpoint was a long time ago: a reader initiates a checkpoint randomly with a probability proportional to 1/x if x is the time period since the last checkpoint; x must be larger than the checkpoint interval.  the longer the page has not been checkpointed after the checkpoint interval expired  the less likely a checkpoint is needed in this approach.  initiating a checkpoint does no block the reader; again  all checkpointers are carried out asynchronously outside of any transaction. of course  it is still possible that an update from a pu queue is never checkpointed in the event that the data page or index is neither read nor updated; we need not worry about this case  however  because the page or index is garbage in this case.
　the proposed checkpointing strategy makes decisions for each data page and each index individually. there are no concerted checkpointing decisions. this design simplifies the implementation  but it can be the source for additional inconsistencies. if a new record is inserted  for instance  it is possible that the new record becomes visible in a secondary index on s1 before it becomes visible in the primary index. likewise  the query select count *  from collection can return different results  depending on the index used to process this query. how to avoid such phantoms and achieve serializability is discussed in section 1; unfortunately  serializability cannot be achieved without sacrificing scalability and full availability of the system.
1.	transactional properties
　the previous section showed how durability can be implemented on top of s1 with the help of sqs. no update is ever lost  updates are guaranteed to become visible to other clients  eventual consistency    and the state of records and indexes persist until they are overwritten by other transactions. this section describes how additional transactional properties can be implemented. again  the goal is to provide these additional properties at as low as possible additional cost  monetary and latency   but without sacrificing the basic principles of utility computing: scalability  availability  and no need to operate an additional infrastructure. it is shown that atomicity and all client-side consistency levels described in  can be achieved under these constraints whereas isolation and strict consistency cannot. the protocols described in this section are layered on top of the basic protocols described in the previous section.
1	atomicity
　atomicity involves that all or none of the updates of a transaction become visible. atomicity is not guaranteed using the basic commit protocol depicted in figure 1. if a client fails while processing a commit of a transaction  it is possible that the client already submitted some updates to the corresponding pu queues whereas other updates of the transaction are lost due to the failure.
　fortunately  atomicity can be implemented using additional atomic queues which are associated to each client. each client maintains one or several of such atomic queues on sqs; for ease of presentation  we assume that each client has a single atomic queue. rather than committing log records directly to the pu queues  the client commits the log records to its atomic queue first. for this purpose  every log record is annotated with an additional field which carries an id of that commit: this id must uniquely identify a transaction on that client; different clients can use the same id for different transactions. for efficiency  the client packs as many log records as possible into a single message to the atomic queue; it is not necessary to send the log records to the atomic queue individually. once the client has written all log records of the transaction to its atomic queue  the client sends a special commit id  record to the atomic queue  thereby using the same id as in the log records. in that commit record  the client also indicates the number of log records that were committed so that they can all be recovered more safely from the atomic queue. after that  the client starts submitting all log records to the pu queues just as in the basic commit protocol. if there are no failures  then the client deletes all log records from the atomic queue. that is  the commit operates in three steps which must be carried out in this order:
  send all log records to the atomic queue. the commit record is sent last.
  send all log records to the corresponding pu queues. delete a message with log records from the atomic queue after all the log records packed into that message have been sent to the corresponding pu queues.
  delete the commit record from the atomic queue.
after the first step  the commit is complete. the second and third steps can be carried out asynchronously; the application can continue and does not need to wait until these steps are completed.
　when a client fails  the client checks its atomic queue at restart. winners are all log records which carry the same id as one of the commit records found in the atomic queue; all other log records are losers. losers are deleted immediately from the atomic queue and never propagated to a pu queue. winners are propagated to the corresponding pu queue and deleted after they have been propagated to the pu queue. a commit record may only be deleted from the atomic queue after all the log records of the corresponding transaction have been propagated to pu queues. of course  clients can fail after restart and while scanning the atomic queue. such failures cause no damage. it is possible that log records are propagated to pu queues twice or even more often  but that is not an issue because the application of log records is idempotent.
1	consistency levels
　tanenbaum and van steen describe different levels of consistency in their book . the highest level of consistency is strict consistency. strict consistency mandates that  every read on a data item x returns a value corresponding to the result of the most recent write on x  . strict consistency can only be achieved by synchronizing the operations of concurrent clients; isolation protocols are discussed in the next section  section 1 . as stated in   strict consistency is never needed in practice and even considered harmful. this section discusses how the other  weaker  levels of consistency described in  can be achieved. the focus is on so-called client-side consistency models  because they are the basis for the design of most web-based services :
monotonic reads:.  if a client  process 1 reads the value of a data item x  any successive read operation on x by that client will always return the same value or a more recent value  . this property can be enforced by keeping a record of the highest commit timestamp for each page which a client has cached in the past. if a client receives an old version of a page from s1  older than a version the client has seen before   the client can detect that and reread the page from s1.
monotonic writes:.  a write operation by a client on data item x is completed before any successive write operation on x by the same client  . this level of consistency can be implemented by establishing a counter for each page  or index  at a client  as for monotonic reads  and incrementing the counter whenever the client commits an update to that page  or index . the pairs  client id  counter value  of the latest updates of each client are stored in the header of each page and in the log records. as a result  the log records can be ordered during checkpointing and out of order log records can be detected in the event that sqs does not return all relevant records of a pu queue  section 1 . if an out-of-order log record is found during checkpointing  that log record is not applied and its application is deferred to the next checkpoint.
read your writes:.  the effect of a write operation by a client on data item x will always be seen by a successive read operation on x by the same client  . this property is automatically fulfilled in the architecture of figure 1 if monotonic reads are supported.
write follows read:.  a write operation by a client on data item x following a previous read operation on x by the same client  is guaranteed to take place on the same or a more recent value of x that was read  . this property is fulfilled because writes are not directly applied to data items; in particular  the posting a response problem described in  cannot occur using the protocols of section 1.
　in similar ways  several data-centric consistency levels defined in  can be implemented on s1  e.g.  fifo consistency . going through the details is beyond the scope of this work.
1	isolation: the limits
　multi-version  e.g.  snapshot isolation   and optimistic concurrency control  e.g.  bocc   appear to be good candidates to implement isolation and  thus  strict consistency in an s1 database system. indeed  many aspects of these protocols can be implemented without sacrificing scalability and availability. in the following  we will sketch our implementation of snapshot isolation and bocc on s1 and show their limitations.
　snapshot isolation: the idea of snapshot isolation is to serialize transactions in the order of the time they started . when a transaction reads a record  it initiates a time travel and retrieves the version of the object as of the moment when the transaction started. when a transaction commits  it compares its write set to the write sets of all transactions that committed earlier and started later; the intersection must be empty. to the best of our knowledge  snapshot isolation has not been implemented in a distributed system yet. the time travel can be implemented in the same way using s1 as in a traditional database system. the commit involves synchronization; essentially  a strict 1pl protocol must be applied on the pu queues in the commit phase. the real problem of implementing snapshot isolation in a distributed system is establishing a global counter in order to put a global order on all transactions. whenever a transaction begins or commits  the transaction must increment this global counter. such a counter can be implemented on top of s1  and ec1   but it may become a bottleneck and is a single point of failure in the system.
　bocc: like snapshot isolation  backward-oriented concurrency control  can be implemented in an s1-based database. since bocc makes stronger guarantees  it supports serializability   however  the limitations of implementing bocc in a distributed system are even higher. like snapshot isolation  the implementation of bocc involves the use of a global counter to mark the beginning and commit of all transactions. furthermore  bocc requires that only one transaction commits at the same time. this requirement can be prohibitive with thousands of concurrent clients so that only relaxed versions of bocc are conceivable.
1.	experiments and results
1	software and hardware used
we implemented the protocols presented in sections 1 and 1 and
conducted experiments in order to study their trade-offs in terms of latency and cost  $ . these are the two critical metrics when using s1 as compared to an ordinary disk drive: in all other metrics  s1 beats conventional technology. this section reports on experiments carried out with the following configurations of increasing levels of consistency:
  basic: the basic protocol depicted in figure 1. as stated in section 1  this protocol only supports eventual consistency.
  monotonicity: the protocols described in section 1 on top of the basic protocol. these protocols support full clientside consistency  i.e.  monotonic reads and writes  read your writes  and write follows read .
  atomicity: the atomicity protocol of section 1 in addition to the monotonicity protocols on top of the basic protocol. this is the highest level of consistency supported by the protocols presented in this work.
we do not study snapshot isolation and bocc because they require additional infrastructure and do not have the same properties in terms of scalability and availability.
　as a baseline  we implemented a  na： ve  way to use s1 as a store. in this na： ve approach  the commit operation writes all dirty pages directly back to s1  rather than carrying out the basic two step protocol of figure 1. this na： ve way to use s1 is subject to lost updates; so  it will not even implement the eventual consistency level achieved in the basic protocol.
　all four variants studied  na： ve  basic  monotonicity  and atomicity  support the same interface at the record manager as described in section 1. as a result  the benchmark application code is identical for all four variants. furthermore  the implementation of read  write  create  index probe  and abort operations in the record manager  page manager  and b-tree index are identical. the variants only differ in their implementation of commits and checkpoints.
　this section only reports on results carried out with a single client that ran on a mac with a 1 mhz intel processor  section 1 . we also carried out experiments with varying numbers of clients. the results  cost per transaction  latency  are the same as the results with a single client  so the multi-client results are not discussed here for brevity. in all experiments reported here  the page size of data pages was fixed to 1 kb and the size of b-tree nodes was 1 kb. the ttl parameter of the client's cache was set to 1 seconds  and the cache size was limited to 1 mb. in experiments 1 and 1  the checkpoint interval was set to 1 seconds. in experiment 1  this parameter was varied. since we are not aws premium customers  the cost per gb of network traffic was usd 1 in all experiments.
1	tpc-w benchmark
　to study the trade-offs of the alternative protocols  we used a sub-set of the tpc-w benchmark . the tpc-w benchmark models an online bookstore with queries asking for the availability of products and an update workload that involves the placement of orders. in all experiments reported here  we used a complex customer transaction that involves the following steps:  a  retrieve the customer record from the database;  b  search for six specific products;  c  place orders for three of the six products. in all cases  customers and products were chosen randomly.
　the purpose of the experiments was to study the running times and cost  $  of transactions for different consistency levels. experiments 1 and 1  consequently  report on running times and cost. furthermore  the benchmark was used in order to study the impact of the checkpoint interval parameter on the cost.
avg.max.na： ve11basic11monotonicity11atomicity11table 1: running time per transaction  secs 
1	experiment 1: running time  secs 
　table 1 shows the average and maximum execution times in seconds per transaction. the absolute numbers are high. these high execution times  however  were expected: as mentioned in section 1  s1 has about two to three orders of magnitude higher latency than an ordinary local disk drive and interaction with s1 and sqs dominated the overall running times in all our experiments. despite these high execution times  we believe that the results are acceptable in an interactive environment such as a web 1 application. each transaction simulates about twelve clicks of a user  e.g.  searching for products  adding a product to the shopping cart  and none of these clicks  except for the commit  takes longer than a second.
　somewhat surprisingly  the higher the level of consistency  the lower the overall running times. the reason lies in details of the various commit protocols. na： ve has the highest running time because it writes all affected pages of the transactions directly to s1. the commit  and  thus  the transaction  is complete once this process has been carried out. the other approaches are faster because they propagate log records only to sqs; these log records  of course  are much smaller than the pages. atomicity has the fastest commit because it sends less messages to sqs as part of a commit because the log records can be batched as described in section 1. in all approaches  the latency of the commit can be reduced by sending several messages in parallel to s1 and sqs; in the current implementation  the messages are sent one by one.
　table 1 also shows the maximum running times. the variances are fairly low. in all our experiments over the last weeks  the variance of s1 and sqs was negligible. significant variance in running times were only caused by caching effects. furthermore  monotonicity has a higher overall running time if pages must be re-read from s1 due to a consistency violation  e.g.  monotonic read .
1	experiment 1: cost  $ 
　table 1 shows the overall cost per 1 transactions. this cost was computed by running a large number of transactions  several thousands   taking the cost measurements of aws  and dividing the total cost by the number of transactions. comparing tables 1 and 1  a somewhat inverse effect can be seen. while the latency decreases with an increasing level of consistency  due to peculiarities of the protocols   the cost in $ clearly increases. for the highest level of consistency  atomicity   the cost per transaction is almost twenty times as high as for the na： ve approach which is used as a baseline. in particular  the interaction with sqs can become expensive. a great deal of the cost is spent to carry out checkpoints and/or to process the atomic queue for the atomicity approach  column 1 of table 1 . this cost can be reduced by setting the checkpoint interval to a larger value  experiment 1 ; thereby reducing the freshness of data. the cost to process transactions cannot be tuned and depends fully on the protocol used and the  application and/or userdefined  activity of the transaction.
　again  the absolute values in table 1 are less significant than the differences between the various variants. for a bookstore  a transactional cost of about 1 milli-dollars  i.e.  1 cents  is probably affordable because transactional costs in this order of magnitude are
totalchckp. + atomic q.transactionna： ve11.1basic111monotonicity111atomicity111table 1: cost per 1 transactions  $ 

figure 1: cost per 1 transacts.  vary checkpoint interval
only incurred if the client carries out complex updates  i.e.  orders books . for many web 1 applications  such costs are too high so that they need to move to lower levels of consistency. overall  however  we expect the transactional costs to decrease in the future  following moore's law and with competitors to aws appearing on the market place.
1	experiment 1: vary checkpoint interval
　figure 1 shows the  total  cost in $ per 1 transactions as a function of the checkpoint interval for basic and atomicity. monotonicity  not shown  is somewhere in between basic and atomicity; na： ve  not shown  is independent of the checkpoint interval. the running times of transactions are also independent of this parameter because checkpoints are carried out outside of transactions.
　increasing the checkpoint interval is a good way to control cost. in the workload of our experiments  a checkpoint interval below 1 seconds effectively involved initiating a checkpoint for every update that was committed; so  setting the checkpoint interval below 1 seconds does not make much sense. with a checkpoint interval above 1 seconds  the cost is quickly reduced. the curve flattens after about 1 secs; for a checkpoint interval of ±  the curve would converge to about $ 1 per 1 transactions which is the base cost to execute a transaction in our workload  table 1 . while the overall shape of the curve is similar independent of the workload  the exact cut-off points and the best setting of the checkpoint interval depends on the workload and in particular on the skew in the update pattern. of course  the right setting of this parameter also depends on the freshness of the data that the application requires.
1.	related work
