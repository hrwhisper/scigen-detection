we present sets  an architecture for efficient search in peer-to-peer networks  building upon ideas drawn from machine learning and social network theory. the key idea is to arrange participating sites in a topic-segmented overlay topology in which most connections are short-distance  connecting pairs of sites with similar content. topically focused sets of sites are then joined together into a single network by long-distance links. queries are matched and routed to only the topically closest regions. we discuss a variety of design issues and tradeoffs that an implementor of sets would face. we show that sets is efficient in network traffic and query processing load.
categories and subject descriptors
h.1  information search and retrieval : clustering  search process  selection process; h.1  systems and software : distributed systems  performance evaluation  efficiency and effectiveness 
general terms
algorithms  performance  design
keywords
peer-to-peer  p1p   distributed information retrieval  small world networks  topic-driven query routing  topic segments.
1.	overview
　peer-to-peer  p1p  networks have received considerable attention recently. such networks are characterized by a very large number of participating sites that span wide area networks and cooperatively share content with each other. the first generation of p1p networks focused on collections of music files. however  the real potential for such networks lies in the sharing of valuable enterprise documents.
　as a first step towards building p1p applications  researchers have proposed protocols for performing efficient
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee.
sigir'1  j uly 1 - a ugus t 1  1   toronto  canada copyright 1 acm 1-1/1. . .$1. 1.
key lookups by constructing distributed hash tables  dhts   1  1 . a dht is simply a hash table that is partitioned among a collection of sites. a lookup for a key is routed efficiently to that site which is responsible for storing that key. however  a search query is more complex than simple key lookups. it is not clear how a key lookup service could be used to build an efficient search application.
　distributed information retrieval  has studied problems associated with searching distributed heterogeneous repositories. researchers have focused on identifying architectures  1  1  1  and models  1  1  1  that can search hundreds of repositories. in this context  researchers have investigated common resource description languages   schemes for repository selection  and merger of ranked lists . heterogeneity in search interfaces has led implementors to converge on mediator-based architectures  1  1  1  in which wrappers for each participant repository rewrite the query and interpret the ranked lists returned.
　p1p networks are distributed. however  their characteristics are markedly different from distributed information retrieval systems:  a  the number of participants  usually pcs  is in tens to hundreds of thousands   b  each site downloads a common binary. this allows an architect to enforce a common resource description language and search interface   c  p1p networks are dynamic. site lifetimes are short  a few hours  and arbitrary  whims of the site owner   and  d  p1p networks are low-cost systems built on the principle of utilizing unused computing resources. often  there is no central server that acts as a mediator for statistics collation  repository selection  query rewriting and ranked list merging. a common strategy adopted by popular p1p networks like gnutella  kazaa and morpheus is to retrieve results by flooding a query to as many participants as possible. this clearly wastes network resources.
　in this paper  we bridge the gap between distributed information retrieval and p1p networks by proposing sets  a topic-segmentation based network that provides efficient search on p1p networks. the architecture is modular and allows advances in distributed information retrieval to be  plugged  in cleanly. we provide a rigorous evaluation of sets. in the course of such analysis  we are able to assign a measure of the quality of document clustering that is simple  precise and exact in our context.
1	topic-segmented networks
　the philosophy underlying sets is to arrange sites in a network such that a search query probes only a small subset of sites where most of the matching documents reside. in particular  sets partitions sites into topic segments such that sites with similar documents belong to the same segment. each topic segment has a succinct description called the topic centroid. sites are arranged in a segmented network that consists of two kinds of links. short distance links connect sites within a segment. long distance links connect pairs of sites from different segments. when a search query is initiated  it is forwarded to other sites using a topic-driven routing protocol. first  topic centroids are used to select a small set of relevant topic segments. next  the selected segments are probed in sequence. a probe to a particular segment proceeds in two steps: first  the query is routed along long distance links to reach a random site belonging to the target segment. next  the short distance links are used to propagate the query to all/most/few sites within a segment. can the above philosophy enable efficient search over p1p networks  the answer depends on  a  the quality of the topic segments and  b  the efficiency of topic-driven routing. the two goals can be met only if we architect each of the following building blocks efficiently:
a topic segment construction: how do we partition sites into topic segments 
b topic segment maintenance: how are segments maintained as sites join and leave  and/or their document collections change over time 
c topic segment selection: which segments  and in what sequence  do we probe to answer a query 
d global routing: how is a query forwarded to  some member of  a particular segment 
e local routing: once a query reaches some site within a specific segment  how is it propagated to all/most/few sites within that segment 
　the first three building blocks relate to topic segments and the last two to topic-driven query routing. each building block poses interesting problems that we discuss next.
a. topic segment construction
we need to group sites with similar content together into topic segments. heterogeneity and autonomy of sites pose challenges to good topic segmentation. sites often have documents drawn from diverse topics. autonomy of sites implies that the system cannot dictate the placement of documents. a good segmentation should yield high recall from low query processing cost  i.e.  the average number of sites that are probed to evaluate a query.
　note that topic segmentation poses a complex clustering problem with a surprisingly clean objective function - query processing cost. we emphasize that the objective function is simple and exact. typical studies of clustering formulate it as an optimization work with objective functions that require a leap of faith for interpretation in the application domain. our measure remains cleanly related to our application even though our methodology envelops issues like connections and routing that go beyond clustering.
b. topic segment maintenance
in a p1p network sites leave and join without notice. moreover  the set of documents at each site changes over time. maintaining consistent global knowledge of topic centroids in the face of such changes is challenging.
　two issues that arise due to centroid re-computation are that  a  new centroids have to be disseminated to all the sites  and  b  sites re-assign themselves to new segments if they discover that they no longer belong to their current segment. the first problem requires an efficient mechanism for informing all sites about new centroids. the second problem requires a solution that ensures that site re-assignment is done smoothly over time. for stability  it should not so happen that a large set of sites suddenly decide to migrate. c. topic segment selection
when a query is initiated  we need to identify a small set of topic segments that will be probed. the challenge lies in designing an algorithm for ranking segments by matching a given query against their descriptions. recall depends crucially on the choice of segments identified for probing.
　once a small set of segments are identified  the query is forwarded to each segment in the set in two steps: global routing forwards the query to some site in the target segment. then  local routing propagates the query to a subset of sites within the segment.
d. global routing
the goal of global routing is to forward a query to a target topic segment using long distance links. the challenge lies in designing a scheme that maintains network connectivity and routes queries in few hops without requiring too many long distance links per site. moreover  the scheme should work in the presence of frequent arrival and departure of sites without notice.
e. local routing
once a query reaches some site within a segment  it is propagated to a carefully chosen subset of sites within that segment using short distance links. the design of intra-segment routing protocols is an interesting problem by itself. the protocol depends upon the particular domain of documents and the expectations from the search system on the whole. layout of the paper: section 1 explores related work. section 1 describes the sets architecture. section 1 discusses the experimental methodology. section 1 contains experimental results. section 1 concludes the paper.
1.	related work
　gnutella and freenet are the best-known examples of p1p search networks. sets retains many of the best aspects of these systems  decentralized operation  sites operating as true peers and fully dynamic sites . gnutella relies on broadcasts to answer queries. since broadcast is unscalable  gnutella adopts heuristics  e.g.  time-to-live fields  that constrain query propagation radius and result in reduced recall. freenet replicates documents across the network in the hope that documents matching a query can be located close to the querying site. other improvements have been suggested  1  1  1  1 . however  there are no guarantees on recall.
　distributed hash tables  dhts   1  1  1  arrange the network to answer lookup queries. psearch  proposes using dhts for search. a global index for each term is placed at the site that is responsible for the term. it remains to be seen if network traffic for index updates necessitated by site joins  leaves and document movements can be supported.
　the preferred architecture for distributed information retrieval has been mediator-based. a mediator collects metadata from different participating collections. queries are sent to the mediator who selects relevant collections  rewrites the query for each collection and forwards the rewritten query to the selected collections  1  1  1 . this architecture was shown to scale to tens of thousands of collections with best performance under a domain-influenced  logical  organization . correspondingly  sites have also been clustered around  global concepts   1  1  and clusters arranged in a hierarchy  1  1  to allow retrieval through navigation or search. information about each cluster is collected at a mediating router which then routes queries to relevant clusters. p1p networks tend to be characterized by the absence of such stable infrastructural units.
　the principle of topic segmentation in sets is based on the cluster hypothesis which states that  closely associated documents tend to be relevant to the same requests  . our measure of efficacy is analogous to cluster retrieval  but goes beyond it to concretely quantify and explore the trade-offs between cost and quality entailed.
　xu et. al.  demonstrated that organizing collections into topics when combined with language models improves retrieval. as in   the assumption is that collections at a single site are large enough that organizing them into clusters is meaningful. we observe that individual collections in p1p networks are small. documents are already partitioned into sites and cannot be migrated from one site to be placed at another.
　social network theory hypothesizes that information flows occur along ties in a networked society. the theory distinguishes between  strong ties  between close associates and  weak ties  between acquaintances. while strong ties are  short distance  as they stay within groups   weak ties are  long distance  connecting people with different social characteristics . in sets  a site maintains both short and long distance links to discover information.
　a social network typically exhibits the small-world phenomenon . pairs of individuals are connected through short chains of acquaintances. moreover  individuals can often discover such chains. kleinberg  proposed a network topology which allows messages to be routed between arbitrary pairs of sites in few hops. in sets  topic segments are organized into a similar network.
1.	sets: architecture
　a distinguished site a in a p1p network is responsible for specific administrative tasks while it participates in the network as a peer. for example  it pushes out and maintains code-bases  provide an inlet to the network by supplying addresses of a small set of currently active peers  etc. note that a runs in the background providing passive support and is not involved in active run-time operations.
1	topic segment construction
　deducing a compact representation of documents at a site is an interesting problem by itself. a robust solution is the unigram model  wherein the representation is either a list of words with their frequencies of occurrence  1  1  or a statistic derived from them . better results were obtained recently by using a set of representative related words  or using language modeling with collections organized by clustering documents . however  we use the simpler unigram model of representation as follows.
　each document is represented as a term vector normalized to unit length. the terms of a document are the stemmed words that occur within it. stop words and highly frequent words are removed from the term vector. each remaining term is assigned a value in the vector equal to its weighted term frequency  which is 1+logtf. this statistic has two advantages as compared to the tf-idf measure:  a  it produces higher quality clusters   and  b  it does not require global information for computation. a site has a collection of documents and is represented by a term vector of unit length called the site vector. it is formed by normalizing the sum of all term vectors for documents at that site.
　we experimented with two ideas for generating topic segments:  a  cluster document vectors  and  b  cluster site vectors. in either case a generates c clusters where c is a parameter fixed at the outset. each cluster corresponds to a topic segment and their centers constitute topic centroids. knowledge of the c topic centroids is global.
　when a new site joins the network  it obtains the current set of c topic centroids from a. it then computes its own site vector and identifies the segment whose centroid is closest to its site vector. the site then uses global routing  section 1  to obtain the identity of some site that currently belongs to this segment. short distance links are established within this segment as described in section 1. long distance links are established as described in section 1.
1	topic segment maintenance
　the set of c topic centroids changes over time as sites join/leave and their document collections change. we now discuss how centroids are recomputed and disseminated.
　for dynamic maintenance of centroids  two pieces of information are exchanged between a and all other sites:  a  every site sends its initial site vector  and changes over time to its site vector  to a and  b  a hands the new topic centroids to all sites. clearly  recomputing and disseminating topic centroids for every change in topology or document collection at a site is impractical. if each site communicated each small update to a individually  a would easily be swamped. also  a would require very high bandwidth to disseminate recomputed clusters for each change. we propose a simple and clean solution for these problems: leases. leases
topic centroids are recomputed at regular intervals of time at a. the interval between successive re-computations is a tunable parameter t. whenever the current set of topic centroids is made known to a site  the set is tagged with a lease: a random number drawn uniformly from the interval  1 t . a site contacts a only when its lease expires. at that time  it informs a about changes in its site vector  and a hands it the current set of centroids  along with a new lease. what do leases yield  a site now contacts a roughly twice every t time units rather than for every small update. since leases are drawn uniformly from  1 t   the times at which sites contact a are staggered. the bandwidth requirements at a are thus spread over the entire lease period. at any moment  sites belong to at most two different sets of topic centroids  corresponding to successive incarnations of centroids . from the perspective of global consistency  there is a problem: sites that remember the old set of centroids might no longer be assigned to the closest topic segment  among the new set of centroids . this may result in increased query processing load as the number of sites probed per query is likely to increase because of an imperfect view of the clustering. there is also a loss in recall because the cluster to which a site is currently  incorrectly  assigned might not be probed at all for queries that match documents at this site. provided t is chosen such that successive sets of centroids do not differ significantly  the increase in query processing load and loss in recall is not significant.
migration to new segment
when a site receives a new set of centroids  it might realize that it no longer belongs to the topic segment that it currently lies in. the site then deletes itself from the network and re-joins. deletions and joins are carried out as per global routing and local routing protocols  sections 1 and 1 . we assume that t was chosen such that topic centroids do not move significantly. this means that over t time units  only a small fraction of sites would have to migrate to new topic segments. the use of leases makes the load on the network due to such migration fairly uniform over the network lifetime. it is very unlikely that a large collection of sites suddenly decides to migrate together.
1	topic segment selection
　a query is a set of terms and can be represented by a normalized term vector called the query vector. when a query is issued  the similarity between the query vector and each topic centroid is computed. the similarity scores are used to rank the c segments in descending order with ties broken arbitrarily. the top r ＋ c segments are then deemed relevant  where r is a tunable parameter.
　the similarity function used has immense bearing on recall. the cori algorithm  1  1  has been shown to perform well  but requires global information and high maintenance traffic when documents have been clustered . we experimented with the simpler cosine distance function which needs minimal information for computation.
　a query message consisting of the query vector and the target topic segment id is composed  one for each of the r relevant segments. the r query messages are issued in parallel. each is first routed to some site in the target segment using global routing. next  local routing further propagates the query within a segment. we experimentally show  section 1  that a small value of r suffices for high recall.
1	global routing
　given a collection of sites  the goal of global routing is to forward a query message along long distance links to some site that belongs to the target segment. in a companion paper  we describe a randomized protocol  for global routing. the key idea is to arrange the sites in a unit ring  ordered by segment id. each site has a link to each of its immediate neighbors and a small number of long distance links drawn from a family of harmonic distributions. we show that if each site has k links  then a query message can be routed in o  log1 n /k  hops  where n is the total number of sites. the protocol is simple yet scalable that provides low latency even when sites join and leave frequently. global routing is further investigated in .
1	local routing
　once a query reaches some site within a target segment  local routing propagates the query further within the segment. we argue that local routing is heavily influenced by the specific domain in which sets is deployed.
　different domains have different expectations and impose different constraints on the search systems employed. for example  when sharing music files  users are satisfied with tens of results. in contrast  a network for sharing patent information requires close to 1% recall. similarly  when a network is formed on pcs with 1kbps modems  users require search to be efficient in its bandwidth usage. sets implementors would devise local routing tuned to their domain. we believe that the rest of sets is flexible enough to impose very few restrictions on the design of local routing. we now describe one possible architecture for local routing. the idea is to arrange sites within a topic segment as a random graph with constant degree m  where m is a parameter fixed at the outset. our evaluations  section 1  were performed assuming such a local routing architecture:
  site insertion: a new site establishes short distance links with m sites chosen uniformly at random from among the current members of the segment  where m is a parameter fixed at the outset. with high probability  a random site to connect to can be discovered by carrying out a random walk of size o log n  over short distance links   where n is the current number of sites in the segment.
  site deletion: a departing site simply terminates its short distance links. its former neighbors establish links with other members of the segment.
  query propagation: queries are forwarded to all members of a segment by flooding: each site that receives a query first checks if it has seen this query before. if so  the query is dropped. otherwise  the query is forwarded to each of its neighbors except the one from which the query was just received.
  query evaluation: upon receiving a query  a site evaluates it against its documents. matches are directly reported to the site where the query originated. failure to produce any matches is not reported to any site.
1.	evaluation methodology
　sets has two major components: topic segmentation and topic-driven query routing. in this section  we discuss how the quality of each is evaluated.
　our evaluation differs from previous research in distributed retrieval in several ways. first  we utilize testbeds with tens of thousands of sites  albeit with fewer documents per site  for our experiments. second  whereas other efforts have studied the effect of organizing documents in the testbed corpus by source  publication date  etc.  1  1  1   we study the impact of having documents organized into sites according to the humans who created them. finally  we quantify and explore aspects of cost vs quality tradeoff in vector-space retrieval when less than 1% recall is acceptable.
performance metrics
our focus is not on providing better merging functions to improve precision  but rather on topic segmentation and its effect on search efficiency for any given level of recall. given this focus on the efficacy of topic segmentation  we restrict ourselves to studying recall. specifically  we measure recall as a function of network load under a simple  binary  notion of whether a document matches a query.
　the quality of topic segmentation is measured by query processing cost  defined as the average number of sites that are probed to evaluate a query. if the quality of topicsegmentation is poor  irrelevant sites will evaluate the query. thus more topic segments are explored for a given level of recall. a good segmentation  on the other hand  would assign relevant sites to the same segment yielding the same level of recall from exploring a few segments.
　the quality of topic-driven query routing is measured by bandwidth and latency per query. bandwidth requirements are proportional to the total number of messages sent. latency is the time elapsed from query issue to the time at which the first answer is received.
document sets
we evaluated sets over three different datasets:
a trec-1-ap: documents from ap newswire in trec cds 1 and 1 include text and author fields. we deemed each author to be a site and associated documents to sites in the natural manner. documents that did not have a valid author field were excluded. the text of an article was used to construct its document vector. this resulted in 1 documents shared by 1 sites.
b reuters: the news articles that comprise the reuters corpus  vol. 1  include text and author fields. we deemed each author to be a site and associated documents to sites as above. the text of an article was used to construct its document vector. this led to 1 documents shared by 1 sites.
c citeseer: since the above datasets are not large enough to evaluate sets at the truly large scales it is capable of  we compiled a new dataset as follows. we crawled the computer science directory of the citeseer library  to obtain a list of research papers. for each paper  we recorded its title  abstract and url from which citeseer obtained it. we deemed each unique url to denote a site. the set of papers available off a url is the collection of documents for the corresponding site. this resulted in 1 documents shared by 1 sites.
query generation and answer determination
the queries for trec-1-ap were obtained from trec1 ad hoc topics  1 . the text in the title fields was stemmed and stop-words were removed to obtain a conjunction query. this query set thus had 1 queries with average length 1 and standard deviation 1. the answer for a query comprised of documents in the dataset that were determined to be relevant for the corresponding topic by trec-1 ad hoc query assessors. we note that topics 1 were chosen because relevance judgments for each of these included documents in trec-1-ap.
　each query for reuters and citeseer was obtained by first choosing a document at random and then choosing 1 terms uniformly at random from its vector. our query set comprised of 1 such queries. the answer for a query comprised of all documents that contained every term in the query.
1.	performance evaluation
　all tests were run on all the datasets; where the results are similar we present results on one of the datasets for brevity.
1	topic segment construction
　our measure of quality of topic segmentation is query processing cost. we note that this cost is tied to the segment selection and local routing scheme used. given a query  the segment selection first ranks the centroids by similarity to the query and then chooses a small set of segments to probe. it is local routing that determines which sites within a segment will actually be probed. here we assume

figure 1: topic-segmentation on trec-1-ap obtains higher recall by processing queries at fewer but relevant sites.
that when the segment selection decides to probe a segment  local routing will probe all sites within that segment.
recall vs query processing cost
we studied three segment selection schemes: a  random: topic segments were ordered randomly  b  cosine: segments were ordered by the cosine similarity between the query vector and topic centroids and c  optimal: for each query  segments were ordered by the ratio  number of matching documents  :  number of sites in segment . the random ordering serves as a baseline to compare gains against a system  e.g.  gnutella  that does not use topic segmentation. the optimal ordering on the other hand is derived from an omniscient central server with complete knowledge of all documents and segments and is further allowed to pick the best ordering for each query at run-time. clearly such ordering is infeasible in practice  but serves as a useful benchmark for comparisons as a theoretical limit.
　figure 1 plots recall vs query processing cost. the topic segments used in the experiment were constructed by clustering site vectors of trec-1-ap. the curves are drawn for various choices of the number of topic segments c ranging from 1 to 1. we observe that cosine outperforms random substantially  returning 1   1% recall by exploring only 1% of the network. we discuss the optimal ordering curves in section 1.
basis of clustering: documents versus sites
in figure 1  we plot recall vs query processing cost for citeseer with c ranging from 1 to 1. the curves are drawn for two methods for topic segment construction:  a  clustering of document vectors  and  b  clustering of site vectors. the optimal  site-based cosine and random curves are drawn for corresponding segment selection schemes on a network clustered by sites. the document-based cosine curve is drawn for cosine segment selection on a network clustered by documents. we see that site vector clustering outperforms document vector clustering across a broad range of c values - it consistently returns higher recall for the same processing cost.
　why does site vector clustering outperform document vector clustering  the reason is that the documents at a site are

figure 1: topic-segmentation on citeseer repository shows that site-based clustering outperforms document-based clustering.

figure 1: left: skew in segment site population. right: skew in segment document population. both are for site-based clustering of citeseer repository.
often drawn from diverse topics. if clusters are derived from document vectors  a site tends to get assigned to that topic that dominates its document collection. since site classification is influenced greatly by the dominant topic  queries for documents corresponding to subordinate topics suffer. site vector clustering alleviates the situation by accommodating this heterogeneity. clusters that are formed now can reflect a mix of topics and sites are assigned according to their aggregate collections. documents at such sites can be easily located leading to improved performance.
　we also observe that the site-based curves are markedly similar to those obtained on trec-1-ap in figure 1. henceforth  we report only on results obtained on the larger scale citeseer noting that similar results were obtained on trec-1-ap and reuters datasets.
quality of clusters
in figure 1  we plot the distribution of segment populations for citeseer using site-based clustering. the number of topic segments c is varied from 1 to 1. we observe that for small values of c the distribution of both site and paper populations is skewed. however  as c increases the skew decreases and segments tend to become equi-sized.
　in table 1  we depict the 1 most significant terms in a sample of 1 topic segment for c=1 with site-based clustering. the labels indicated in parentheses were manually assigned. as can be observed  site-based clustering is quite successful in forming focussed segments.
1  compilers 1  crypto 1  databases 1  internet compilsecurquerijavagarbagattackdatabaswebpolymorphauthentretrievserverhaskellcryptographxmlinternetloopencryptschemaclientfigure 1: sample topic segments obtained by clustering site vectors for the citeseer repository.

figure 1: left: recall curves pull up for increasing c  however with diminishing returns. right: values of r for 1% recall increase almost linearly with c.
choice of number of clusters  c
in the left sub-figure of figure 1  we plot recall vs query processing cost for citeseer using site-based clustering and cosine segment selection. the number of topic segments c is varied from 1 to 1. we observe that recall increases as c increases but with diminishing returns. as c increases  topic segments become smaller and more focussed resulting in lowered cost of probing a segment. however  such gains come at the cost of increased processing load at administrator site a. thus fixing c involves a trade-off between increased recall and increased resource consumption at a.
1	topic segment maintenance
　sets requires an administrative site a that provides passive support for maintaining a topic-segmented network. let us study the communication and processing demands that sets imposes on a. suppose there are n sites participating in the network. each of the n sites will send changes in their site vector to a and accept c new topic centroids over a duration of t minutes. the administrator a has to cluster site vectors into c clusters during this time.
　assume an average of t terms per site  1b term ids  and no compression of term vectors. as described in section 1  on average each site contacts a twice in t minutes. on average  a has an in-bound traffic of 1〜1t 〜n = 1tn bytes in t minutes. similarly  assuming an average of t terms per topic segment description  a has an out-bound traffic of  bytes in t minutes.
　let us assume that 1 terms  t = 1 minutes  c = 1 and 1m bits per second t1 line. assuming that 1% of the bandwidth is consumed by networking overhead  tcp/ip headers   a can support n =
1 sites. for a corporate set-
ting with a 1m bits per second t1 line  a can support n = 1 sites. we note that these numbers are in fact pessimistic as they do not account for any optimizations. for example  most site vectors will not change in successive t = 1 minutes. such sites can save bandwidth by sending a  no change  message to a. the bandwidth requirements for a are thus reasonable.
　let us now consider processing costs at a. suppose a uses k-means algorithm to cluster site vectors into c clusters. folklore has it that k-means converges in 1 iterations. we implemented a cache-aware disk-resident k-means algorithm that produces c=1 clusters in about 1 minutes  and c=1 clusters in about 1 minutes for 1 sites on a pentium ii processor with 1mb memory. fresh clusters can thus be generated within the time-scales involved.
1	topic segment selection
　when a query is generated  segment selection selects a small subset of topic segments that appear most promising. ranking of topic segments is done by comparing the query vector with topic centroids. the segments could be probed in sequence or in parallel.
impact of ranking function
we have already mentioned the three methods studied for ordering segments for probing. figure 1 shows that the performance of the optimal is extremely good  with recalls between 1% and 1% being obtained from evaluating the query at just 1% of the network. the gap in the optimal and cosine curves indicates the difference between the distributed implementation in sets and an omniscient central ordering that can compute the best ordering for each query and topic segmentation. there is no guarantee that a distributed system like sets can attain the performance of optimal  but we do note that no approach based on topic segmentation can exceed the performance of optimal. choice of r  the number of relevant segments
once an ordering of cluster segments has been determined  queries are issued in parallel to explore the most relevant r topic-segments. users are often satisfied with the top few answers. the implementor then has the choice of stopping the query after exploring just the initial r topic-segments. the remaining topic-segments can be explored if the user really would like to obtain more results. thus  the choice of r depends on the expectations of users in the domain.
　what is a good value for r  the number of relevant segments  consider a network over citeseer with site-based clustering and cosine segment selection. let us fix recall at 1%. we simulated sets for different values of c and computed the number of topic-segments r that were necessary to obtain 1% recall. the results are shown in the right sub-figure of figure 1. we observe that r increases almost linearly with c over a large range of values for c. we also note that r is roughly a quarter the value of c for c − 1. this observation suggests a useful rule-of-thumb to us: we can set r 《 c/1 in this design.
1	global routing
　figure 1 plots the bandwidth and latency used by global routing on citeseer repository. we simulated global routing with 1 long distance links per site and a random ordering of topic segments along the ring. we assumed that queries originate from any site at random. we let segment selection identify the top ten topic segments for each query  r=1 . the union of these segments gives a query profile  i.e.  a distribution over topic segments. the average latency per query is 1 hops. latency increases with c  the number of clusters. this is because average cluster size diminishes with increasing c. as a consequence  global routing

1
	1	1	1	1	1.1.1.1.1
	position of cluster center along ring	position of cluster center along ring
figure 1: bandwidth and latency requirements for global routing on 1 sites in citeseer repository.

figure 1: bandwidth and latency requirements for local routing on 1 sites in citeseer repository.
has to home in on a smaller subset of sites  requiring more hops. the average bandwidth shows high variance. this is an artifact of the routing protocol and is discussed in .
1	local routing
　we argued earlier that the design of local routing is influenced by the particular domain in which sets is deployed. yet  its design is of importance as the bandwidth and latency observed here dominate the total cost as we show below. we simulated local routing using the scheme detailed in section 1 with m=1 neighbors per site. for each query in the query set  we let segment selection determine the relevance of topic segments and then probed the segments in sequence. figure 1 plots bandwidth and latency vs observed recall on citeseer with 1 sites.
　bandwidth for a given recall decreases with increasing c. as c increases  topic segments become smaller and more focussed. fewer segments have to be explored leading to lower bandwidth usage. also notice that bandwidth costs here are substantially higher than global routing. latency increases with increasing c. the reason is that topic segments are probed in sequence. as c increases  there are more topic segments that need to be probed to provide the same recall. the plot also indicates that response times are low as the first answers are received quickly.
　notice also that 1% of recall is attained at a quarter of the total bandwidth and latency costs. thus  if we altered our scheme to probe just r=c/1 top segments  the bandwidth and latency costs would be correspondingly smaller. hence we conjecture that domain requirements will heavily influence the optimal design for local routing.
1.	conclusions and future work
　we presented sets  an architecture for efficient search in p1p networks. the underlying philosophy is to arrange participating sites into an overlay network such that queries can quickly reach small regions of the network where most of the matching documents reside. towards this end  sets builds a topic-segmented network and employs a topic-driven query routing protocol. we discussed a variety of design issues and trade-offs that an implementor of sets would face. through a series of systematic experiments  we showed that sets provides good recall with good network  small latency and bandwidth per query  and query processing performance. these results clearly suggest that sets is a viable architecture for organizing content sharing p1p networks.
　as future work  we plan to adapt sets to handle large swings in population characteristics  and develop protocols to change the number of topic-segments at run-time.
