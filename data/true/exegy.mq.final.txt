   exegy's submission for the trec 1 million query track consisted of results obtained by running the queries against the raw data  i.e.  the data was not indexed. the hardwareaccelerated streaming engine used to perform the search is the exegy text miner  xtm   developed at exegy  inc. the search engine's architecture is novel: xtm is a hybrid system  heterogeneous compute platform  employing general purpose processors  gpps  and field programmable gate arrays  fpgas  in a hardware-software co-design architecture to perform the search. the gpps are responsible for inputting the data to the fpgas and reading and postprocessing the search results that the fpgas output. the fpgas perform the actual search and due to the high degree of parallelism available  including pipelining  are able to do so much more efficiently than the gpps. for the million query track the results for a particular query were obtained by searching for the exact query string within the corpus. this brute force approach  although na¡§ ve  returned relevant results for most of the queries. the mean-average precision for the results is 1 and 1 using the umass and the neu evaluation tools  respectively. more importantly  xtm completed the search for the entire set of the 1 queries on the unindexed data in less than two and a half hours.
1 introduction
this is exegy's first year at trec. exegy has developed a hardware-accelerated streaming search system  named the exegy text miner  xtm   that enables fast searching of data. the purpose of exegy's participation in the trec 1 million query track was to test xtm's capabilities  with respect to both efficiency and efficacy. through this process we have learned to express how we can accommodate these sophisticated queries and we hope that it may provide encouragement and insight for others to develop on heterogeneous compute platforms. given xtm's capability for highspeed massive streaming searching  we decided to query against the raw data itself  i.e.  the data was not indexed or otherwise preprocessed for the purpose of searching. we are not suggesting that xtm obviates the need for indexing. in fact  we see xtm complementing indexing. the indexing approach to searching has proved highly successful and is employed widely. however  for applications that require searching in streaming  real-time  data  such as news feeds  indexing adds additional  and unnecessary  latency to the search process. in such a scenario a system like xtm can prove highly beneficial. the same argument applies to quasi-static datasets  i.e.  datasets that are updated frequently. even for data at rest  if the corpus is queried infrequently  then one can fore-go indexing. to reiterate  we envision xtm being used in scenarios where indexing is not the most efficient solution. an application where indexing and xtm can be used together is for data that have indexed metadata. this indexed metadata can be used to trim the dataset and the filtered dataset can be quickly streamed through xtm.
   the paper is organized as follows. in section 1 we briefly describe the architecture and functionalities of xtm. section 1 describes the experiments we performed on the gov1 corpus using xtm and discusses the results we obtained. section 1 concludes the paper.
1 exegy textminer
exegy textminer  xtm  is a streaming text search and data mining engine that combines hardware  software  and firmware to create a powerful solution for quickly searching through massive data stores. xtm is a hybrid system  heterogeneous compute platform  employing general purpose processors  gpps  and field programmable gate arrays  fpgas  in a hardware-software co-design architecture optimized for data flow to perform searching and filtering. thus  xtm combines both the speed of hardware and the flexibility of software to provide a fast  efficient massive search engine. the gpps handle the input to and output from the fpgas as well as the post-processing of the results that the fpga outputs. the fpga performs the actual searching. due to the massive parallelism available  the fpga can perform the searching orders of magnitude more efficiently than a gpp.
   xtm includes three search functionalities to address the needs of a real-world search system: exact matching  approximate matching  and regular expression matching. fig. 1 shows a view of how the search process is structured.

figure 1: conceptual view of the search functionalities.
   in fig. 1  file streaming is the process of the gpps controlling the streaming of files in to the fpga. the fpga contains the three types of search modules. when the user specifies a search query  the system dynamically loads the appropriate configuration  or configurations  into the fpga and streams the data set through the fpga to execute portions of the search algorithm. these search modules can be used in different combinations using the boolean and proximity operators. the search results are streamed out to the gpps which then performs various flavors of post-processing depending upon the input query. following is a brief description of the search modules and the boolean and proximity operators .
  exact matching: xtm can search for up to 1 exact terms simultaneously. a  term  is defined as an 1 byte string. the exact matching module is essentially a bloom filter  which uses rabin-karp hash functions . a bloom filter is a space-efficient probabilistic data structure that is used to test whether or not an element is a member of a set. using bloom filters it is possible that false positives can occur  but false negatives are never possible. the number of false positives increases as the number of elements in the set increases  and all other parameters of the bloom filter remain fixed . the algorithm is as follows. the terms to be searched for are hashed into a bit-vector position. this hashing is performed by the gpp and the hash table is passed to the fpga. the bloom filter is implemented on the fpga. the text to be searched is streamed into the fpga  then hashed  and then the pre-computed hash table is checked for the presence of a term. as mentioned earlier  a hit can either be a match or a false positive  hashing collision . in either case  the hit is delivered from the fpga to the gpp where software determines whether it was an actual match or a false positive. xtm actually uses two different hash functions for the bloom filter to reduce the number of false positives.
  approximate matching: xtm provides the capability to search for terms using approximate or  fuzzy  matching criteria . with approximate matching  terms can be specified with a number of character substitutions. approximate matching also allows for terms to be specified as case sensitive or case insensitive. finally  there is provision for wild-carding  where an individual character can be designated as  don't care  and will match any character. this functionality is especially useful for applications that use optical character recognition or speech to text processes as such applications may mistakenly substitute similar letters. there is provisioning for simultaneously searching up to 1 terms using approximate matching.
  regular-expression matching: xtm provides the ability to search for text that matches a set of rules or patterns  such as looking for phone numbers  email addresses  social-security numbers  monetary values  etc. this regular-expression matching can be performed concurrently for up to 1 rules. xtm provides support for the entire perl regular-expression set. the implementation of the regular-expression matching module is described in more detail in the paper by brodie  taylor  and cytron . briefly  the simplest and most practical mechanism for recognizing patterns specified using regular expressions is a finite state machine  fsm . the regular-expression matching engine uses an array of high-performance fsm processors instantiated in the fpga to simultaneously search for multiple regular-expressions. in addition  each fsm employs several novel optimizations to maximize the throughput. one of the key optimizations is examining multiple input symbols per transition in the fsm.
  boolean and proximity operators: in addition  xtm also has provisions for complex boolean  proximity  and position operators to allow using combinations of the search functionalities. examples of boolean operators are or  and  and not. an example of the proximity operator is near that allows searching for two strings within a certain distance of each other. for example  the query  query number 1 in the 1 query set :
 swimming near pools  and  tacoma near dc 
expresses the conditions: the term  swimming  is found within 1 characters of the term  pools ; the term  tacoma  is found within 1 characters of the term  dc ; and both the previous conditions should hold. software is responsible for boolean and proximity operations; the fpga returns results that include position information to the gpp and then software sorts through the results to weed out cases where the boolean or proximity constraints do not hold.
   along with all these features  xtm operates at a sustained bus-bandwidth limited throughput of about 1 gb/s. the available bus-bandwidth is 1 gb/s and the peak throughput of xtm is as-high-as 1 gb/s.
1 experiments
the task for the million query track was to run a set of 1 queries against the gov1 corpus. the gov1 corpus is a collection of web data crawled from web sites in the .gov domain in early 1. the collection is believed to include a large proportion of the .gov pages that were crawlable at that time  including html and text  plus the extracted text of pdf  word  and postscript files. any document larger than 1 kb was truncated to that size. binary files are not included in the data. the gov1 collection includes 1 million documents for a total size of 1 gb. we tried different combinations of the xtm functionalities to accomplish the searching task in the most efficient manner and to obtain the most relevant results.
   the queries posed a lot of challenges. for example  there were several sources of ambiguities in the queries like misspellings or grammatical errors or use of abbreviations for names of u.s. states  there were a few spanish queries or queries with proper nouns making detection of spelling mistakes hard  and some queries consisted of a single word or a phrase that was very common in the corpus.
   the first approach we tried was the prevalent  bag-of-words  approach. the stop words were removed from the queries  we used oracle's default stop-list for this purpose  and the remaining words were searched in the corpus. approximate matching was used to deal with misspellings and proved very successful. however  as mentioned in the previous section  the approximate matching module can only deal with 1 terms at a time making its use impractical for the 1 queries. another approach that we tried was that after the removal of all the stop words from the queries  treat the query as a single string and use the proximity operators between the terms of the query. more specifically  we inserted a near operator between successive terms of the query and made the search distance twice the length of the query string or 1 characters  whichever was larger  in order to not miss any relevant results. the individual query terms were matched using the exact-matching engine. this approach  however  was again too slow as the boolean and proximity checking is performed by software which is unable to handle the large number of results returned by the fpga.
   as in the previous approach  it was obvious that the exact matching module of xtm with its simultaneous 1-term matching capability was the right choice for the search task. this time  however  we decided not to use any proximity operators. for each query  the exact match engine searched for instances of the exact query string in the corpus. the queries were split into subsets of 1 queries  to keep the number of terms under 1  and each subset was run against the dataset using the exact matching module. the throughput for each subset of queries was around 1 gb/s  i.e.  for each subset  the entire gov1 corpus was queried in a little over 1 minutes. thus  all the 1 queries were completed in less than two and a half hours. we would like to point out that single-word queries  such as query 1  the word  back   and queries consisting of very common phrases  such as query 1   the department of state   returned a lot of results which took unusually long to process. such queries severely impacted the throughput. relevance was calculated by counting the number of occurrences of a query string in the returned documents  i.e.  the relevance score was set equal to the number of occurrences of the query string in the document. the relevance calculations were performed in software on the gpp.
   trying to match the entire query string exactly is a rather na¡§ ve approach that has the downside that it did not return any results for many of the queries. out of the 1 queries  the exact matching approach returned results for only 1 queries. however  again since the whole query was being searched for  the results returned were indeed very relevant. a preliminary investigation of the results shows that the mean-average precision for exegy's results is 1 and 1 using the umass and the neu evaluation tools  respectively.
1 conclusion
the brute-force approach to searching that exegy employed for the trec 1 million query track had mixed results. matching the entire query string for the 1 queries against the corpus yielded results for only about 1% of the queries  a definite downside. on the upside  the documents that were retrieved for the 1 queries were indeed relevant as is apparent from the high mean-average precision obtained using the umass evaluation tool. another positive was that the data was not indexed and even then using xtm the entire query process was completed in under two and a half hours. comparing this to the conventional index generation and searching approach we see situations were xtm has clear advantages. for e.g.  streaming data or quasi-static datasets where throughput is a very sensitive issue. for data sets that are queried infrequently xtm can obviate the need to provide extra storage for the index. xtm can also be envisioned as complementing indexing-based search engines in situations where the indexed metadata can be used to pare down the corpus and xtm can stream this reduced dataset to perform the required search. further research and development on this problem is under way and we plan to use the lessons learned from the million query track to enhance xtm.
acknowledgment
the authors would like to thank the organizers of the trec 1 million query track and the nist assessors and the other track participants for judging the documents.
