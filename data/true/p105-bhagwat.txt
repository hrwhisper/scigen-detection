we present a document routing and index partitioning scheme for scalable similarity-based search of documents in a large corpus. we consider the case when similarity-based search is performed by finding documents that have features in common with the query document. while it is possible to store all the features of all the documents in one index  this suffers from obvious scalability problems. our approach is to partition the feature index into multiple smaller partitions that can be hosted on separate servers  enabling scalable and parallel search execution. when a document is ingested into the repository  a small number of partitions are chosen to store the features of the document. to perform similarity-based search  also  only a small number of partitions are queried. our approach is stateless and incremental. the decision as to which partitions the features of the document should be routed to  for storing at ingestion time  and for similarity based search at query time  is solely based on the features of the document.
　our approach scales very well. we show that executing similarity-based searches over such a partitioned search space has minimal impact on the precision and recall of search results  even though every search consults less than 1% of the total number of partitions.
categories and subject descriptors
h.1  information storage and retrieval : content
analysis and indexing-indexing methods; h.1  information storage and retrieval : information search and retrieval- search process; h.1  information storage and retrieval :
systems and software-distributed systems

 this research was done while the author was a research associate at hewlett packard labs  palo alto
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee.
kdd'1  august 1  1  san jose  california  usa.
copyright 1 acm 1-1-1/1 ...$1.
general terms
algorithms  management  performance
keywords
similarity-based search  scalability  index partitioning  distributed indexing  document routing
1. introduction
　finding textually similar files in large document repositories is a well researched problem  motivated by many practical applications. one motivation is the need to identify near duplicate documents within the repository  to eliminate redundant or outdated files and improve user experience . archival systems  1  1  need to identify content overlap between files to save storage space by using techniques such as delta-compression  1  1 . other applications arise in information management: similarity based retrieval can be used to find all versions of a given document  e.g. for compliance  security  or plagiarism detection purposes. notice that in this paper we are concerned with textual document similarity  where two documents are deemed to be similar if they share significant stretches of text. this is in contrast to natural language based approaches where the linguistic structure of the document is taken into account.
　the operation that is the object of our study is similarity based retrieval. here  a query document q is presented to the system. the aim is to find all the documents d1 d1 ... dn in the repository that are similar to q  the most similar documents being presented first.
　while finding textually similar documents can in principle be achieved by a pairwise comparison of the query doc-
ument with each one of the documents in the repository using a program such as unix diff  this is clearly very inefficient. to solve this problem  the following framework is commonly used: from every document  a set of features are extracted  such that if two documents are similar  their sets of features overlap strongly  and if they are dissimilar  their sets of features do not overlap. thus  the problem of document similarity is reduced to one of set similarity. then  an inverted index  1  1  is created mapping features to documents. upon the presentation of the query document q  its features are extracted  and used to query the inverted index. the result is a set of documents that share some features with q; these are then ranked with the document sharing most features coming first. various authors have developed techniques for extracting features from a document: manber   broder etal.  1  1   kulkarni etal.  and forman etal. . all these approaches generate very specific features: when two documents share even a single feature  they share a relatively large stretch of text  tens of characters . as a result  when the inverted index is consulted  relatively few documents are returned. this is in contrast with techniques such as bag of words analysis  where most documents are expected to share at least a few words.
　a single feature index becomes a bottleneck as the size of the repository gets very large  and the index needs to simultaneously handle a large number of updates and queries. such a situation is typical of document management systems for large enterprises  as well as archival systems dealing with large  continuous streams of documents. one solution is to partition the feature index into a number of subindices  placing each partition on a different server  so that the servers can be updated and queried in parallel. the partitioning scheme used must be such that only a small fraction of the partitions need to be accessed for each update and query. here  the most obvious schemes  such as using a
distributed hash table  dht   1  1  1  1  to store the  pairs fail. in this scheme  the partitioning of the index is based on the hash of the individual features. for example  given 1k servers  each hosting a hash table  and the pair  that needs to be added to the index  the first k bits of the hash of the feature are used for identifying the server that this particular pair needs to be added to. the problem is that there is no locality of reference for the individual feature hashes: each one of the document features is routed independently  most likely to a different server. as a result  a large number of servers will need to be accessed for each document update and query.
　in this paper we present an alternative index partitioning and document routing scheme; one that does not route each individual feature of every document independently  but rather routes all the features in a document together. the outline of our scheme is as follows:
  at ingestion time  i.e. when a document is being added to the repository  the document's features are extracted using a feature extraction algorithm. based on these features  a fraction of the index partitions are chosen  and the document is routed to these partitions  i.e. the document's features are sent to these partitions and added to the index there. we call the algorithm by which the partitions are chosen the document routing algorithm.
  at query time  the same same feature extraction and document routing algorithms are used for choosing the partitions to query. the chosen partitions are queried with the document's features  and the results are merged.
　this situation has been depicted in figure 1. notice that the choice of which servers to contact  both at ingestion and query time  is entirely based on the contents of the document; at no time do we have to have an interaction with the partitions to determine which one should be chosen. this sets us apart from approaches which apply a clustering algorithm  1  1  1  to all the documents in the repository;

figure 1: our solution for document routing
these approaches need to use knowledge of the existing clusters to route the new document. our approach  by contrast  is incremental and stateless: only the contents of the document are used to decide which partitions it should be routed to. as a result  we have a very lightweight  client based routing capability.
1. background
　as stated above  our work assumes the existence of a mechanism to extract features from documents  such that document similarity is reduced to set similarity. we use the jaccard index as a measure of set similarity. let h be an algorithm for extracting features from documents  where h f  stands for the set of features extracted by h from document f. then  the similarity measure of two documents f1 and f1 according to jaccard index is

　there are a number of feature extraction algorithms in the literature that satisfy the requirements above. shingling  is a technique developed by broder for near duplicate detection in web pages. manber   brin etal.  and forman etal.  have also developed feature extraction methods for similarity detection in large file repositories.
　for the experiments reported in this paper  we used a modified version of the chunk based feature extractor described by forman etal. . this algorithm is described below.
1 chunk based feature extraction
　content-based chunking  as introduced in   is a way of breaking a file into a sequence of chunks so that chunk boundaries are determined by the local contents of the file. the basic sliding window algorithm is the prototypical content-based chunking algorithm. this algorithm is as follows: an integer  a  is chosen as the desired average chunk size. a fixed width sliding window is moved across the file  and at every position k  the fingerprint  fk  of the contents of this window is computed. this fingerprint is calculated using a technique known as rabin's fingerprinting by random polynomials . the position k is deemed to be a chunk boundary if fk mod a = 1. we actually use the tttd chunking algorithm   a variant of the basic algorithm that works better. see  for details.
　the rationale for using content-based chunking for similarity detection is that if two files share a stretch of content larger than the average chunk size  it is likely that they will share at least one chunk. this is in contrast to using fixed size chunks  where inserting a single byte at the beginning would change every chunk due to boundary shifting.
　we use the characteristic fingerprints of chunks  see below  as the features of the file. again  the intuition is that if two files are similar  they share a large number of chunks  and thus their feature sets overlap strongly; if they are dissimilar  they will not share any chunks  and thus their feature sets will be disjoint.
　here is the feature extraction algorithm in more detail. this algorithm uses a hash function  h  which is an approximation of a min-wise independent permutation  see section 1 below . there are three steps in our feature extraction algorithm:
1. the given file is first parsed by a format specific parser.we handle a range of file formats  including pdf  html  microsoft word and text. the output of the parser is the text in the document.
1. the document text is divided into chunks using thetttd chunking algorithm . the average chunk size chosen for these experiments was 1 bytes.
1. for each chunk  a characteristic fingerprint is computed  as follows: let {s1 s1 ...sn} be the overlapping q-grams in the chunk  i.e. the set of all subsequences of length q in the chunk. then the characteristic fingerprint of the chunk is the minimum element in the set {h s1  h s1  ...h sn }  where h is the hash function described above. for the experiments in this paper we chose q to be 1.
　to summarize  the features of the document are the characteristic fingerprints of the chunks of the document. this algorithm has been demonstrated to produce good features for document similarity. we will not discuss its properties further here  since it is not the subject of this paper.
1 the structure of feature indices
　in this section  we describe the structure of the feature indices  be they a monolithic feature index for all the documents in the repository  or one of the indices corresponding to a partition of the bigger index.
　figure 1 depicts one of the possible designs of a feature index. the index key is the feature itself. each feature points to the list of files that it occurs in. this design is analogous to that of an inverted keyword index  1  1  used commonly in information retrieval systems. this index contains lookup information for every file that has been routed to it at ingestion time.
h1 ★ f1 f1 f1
h1 ★ f1 f1
....
h... 1 ★ f1
figure 1: feature index
1 building the feature indices
　when a new file  fn  needs to be added to the repository an entry for each feature in h fn  must be added to the feature index. for every feature in h fn   if an entry already exists in the feature index  then the detail for that entry is appended with fn. if no entry is found then a new entry for that feature is inserted. if fn is routed to multiple partitions this process is repeated at every one of the destination partitions.
1 querying feature indices
　when a feature index needs to be accessed to find files in the repository similar to a query file  fq  then the index is queried using each feature in h fq . the set of files similar to fq is the set
   i hi  
1＋i |h fq |
where i hi  is the set of all the files that hi points to in the feature index i. each file in the result set is ranked based on its jaccard similarity index with respect to fq.
　if multiple partitions need to be queried for fq then the above querying process is carried out for every partition. the results obtained from each partition are collated such that the set of all the files similar to fq is given by

where the set r is the set of all the partition numbers that were queried for fq.
1. partitioning the feature index
　as mentioned before  our main interest in this paper is to partition the index i into a number of sub-indices i1 i1 ... ik while preserving the following properties:   each one of the partitions has the structure described in section 1  i.e. it is a reverse map from features to files.
  at ingestion time  the features of each file  fn  are used to choose m partitions to which the file will be routed. we call m the routing factor and m k. the chosen partitions receive all the features of the file  i.e. h fn  is added to each one of the chosen partitions. this algorithm is the document routing algorithm.
  at query time  given the query document fq  the same document routing algorithm is used to choose which partitions to query. the query process for each partition is as described in section 1. the chosen partitions are queried in parallel and independently; there is no background communication among them. the results of the queries from the chosen partitions are merged to form the answer to the query.   even though we query only a small subset of the partitions  i.e. m is much smaller than k  there is minimal loss of recall compared to the case where there is one global index.
　we first describe the document routing algorithm and then provide the justification for why it works.
1 the document routing algorithm
the input to the algorithm is
  h fn   the set of features of the document fn
  an integer k  the number of partitions
  an integer m  the routing factor
　we assume that m   k  and |h fn | − m. the feature extraction algorithm  h  extracts features using a minwise independent hash function as explained in section 1. the routing algorithm computes a set of integers r = {r1 r1 ... rm 1} where 1＋i m. r1 r1 ... rm 1 are the partitions to which the document will be routed. the document routing algorithm is as follows:
1. compute botm h fn   where botm is a function that picks the m smallest integers in a set. in other words  for a set of integers s where |s| − m  botm s    s  |botm s | = m   and x （ botm s  … y （ s   x ＋ y.
1. for every hash h in botm h fn   compute  h mod k . r is the set of the resulting integers  r = {h mod k|h （ botm h fn  }. the document is now routed to all the partitions indicated by r.
m
bottom featuresfilechunk
based set of botmmod k target feature featurespartitions extraction
figure 1: document routing algorithm
the routing algorithm has been depicted in figure 1.
1 why it works
　the routing algorithm is based on a generalization of broder's theorem . broder's theorem relies on the notion of a min-wise independent family of permutations. the following definition and theorem are from .
　definition 1. let sn be the set of all permutations of  n . the family of permutations f   sn is min-wise independent if for any set x    n  and any x （ x  when p is chosen uniformly and at random from f we have

　in practice  truly min-wise independent permutation are expensive to implement. practical systems use hash functions that approximate min-wise independent permutations.
　theorem 1. consider two sets s1 and s1  with h s1  and h s1  being the corresponding sets of the hashes of the elements of s1 and s1 respectively  where h is chosen uniformly and at random from a min-wise independent family of permutations. let min s  denote the smallest element of the set of integers s.

　broder's theorem states that the probability that the two sets s1 and s1 have the same minimum hash element is the same as their jaccard similarity measure.
　now  consider two files fi and fj  and let m = 1  i.e. we route each file to only one partition. according to the theorem above  and the definition of similarity measure between two files  the probability that h f1  and h f1  have the same minimum element is the same as the similarity measure of the two files. in other words  if the two files are very similar  the minimum elements of h f1  and h f1  are the same with high probability. but if the minimum elements are the same  the two files will be routed to the same partition  since the partition number to which they are routed is the minimum element modulo k  the number of partitions. while the probability of being routed to the same partition is high when the two files are very similar  the probability drops significantly when the degree of overlap between the two files goes down. for example  if half the features of the two files are the same  and the two files have the same number of features  the jaccard similarity measure of the two files is 1  i.e. there is only one third chance that they would be routed to the same partition.
　to overcome this problem  we route the files to more than one partition  i.e. we choose m   1. the intuitive justification for using the bottom m features for routing is that if by chance a section of a file changes such that the minimum feature is no longer in the set of features  the second least feature will now become the minimum feature with good probability. our experiments and the theorem below show that with m a modest number  less than 1   we have a very good chance that two files with a fair degree of similarity will be routed to at least one common partition.
　to formalize our intuition  we can generalize the broder theorem as follows:
	and	be two sets. let
and	“	1 .	let	1 =	m 	  1   and	1 =
             where h is a min-wise independent hash function. then

let s = i/u  i.e. s is the jaccard similarity measure between s1 and s1. a good approximation of the above  when m is small and u is large  is

 is a small error factor in the order of 1/u.
　when we translate this lemma to the case of documents  we get the following:
　corollary 1. let f1 and f1 be two documents with similarity measure s. when they are each routed to m partitions using the algorithm above  the probability that there will be at least one partition to which both of them are routed is at least 1    1   s m
　now  consider the case where the document f1 has been ingested into the system  and we now wish to use f1 as the query document to do similarity based retrieval. let us say that the similarity measure of f1 and f1 is 1  and m  the routing factor  is 1. since the same routing algorithm is used for ingestion and query processes  and for the query to succeed it suffices that at least one partition be in common between the two files  the probability that we find the document f1 when we query with f1 is better than 1%. contrast this with the case where m = 1  when the probability of finding f1 is only 1%.
　the following sections discuss the experimental setup and results.
1. experimental setup
　the experimental data set consisted of 1 files. these were hewlett packard's internal support documents in html format. there were 1 unique features extracted from this set. a randomly selected subset  fq  of 1 files was chosen from the original corpus to be used as query files. the rest of the files  the set fd  was our document repository. our goal was to find for every file fq （ fq the files in fd that were highly similar to fq. the similarity measure between two files was calculated using their features as explained in section 1.
　since fd was our document repository every file fd （ fd was used to build the partitions using the document routing algorithm as explained in section 1. every file in fq was then used to query the partitions as explained in section 1 to find similar files to itself in fd. the number of partitions  k  were varied from 1 through 1. the routing factor  m  used to route every file in fd  for building the partitions  and in fq  for querying the partitions  was also varied from 1 through 1.
　the result set for every query in fq using a single nonpartitioned index was then used as a standard to judge the quality of results produced when the index was partitioned.
1. results

figure 1: effect of the routing factor on the average similarity measure
　in the first set of experiments we have compared the quality of results obtained when using a single monolithic feature index  k=1  to search for similar files with those obtained when we had multiple partitions  k   1 . first  a monolithic feature index was built using every file in fd. next  for every query file fq （ fq the set of files similar to it were identified by querying the monolithic feature index. each file  fr  in the result set for every query fq was then ranked based on its jaccard similarity index with fq. the file with the highest similarity measure was the file that was most similar to the query file and hence  the best result. the best result  thus calculated  was recorded for every query file. the average similarity measure  calculated as the average of the best results for all fq  was then calculated for the entire query set fq.
　the next round of experiments was conducted with increasing number of partitions  k 1. for every value of k  the routing factor  m for every file in fd and fq was varied from 1 through 1. once again  the first step was to build the partitions using fd for the appropriate values of k and m. using the same values for k and m files in fq were used to query the partitions. the results obtained from the respective partitions were collated and the best result was recorded for every fq （fq. the average similarity measure  for every k and m combination  was then calculated for fq. figure 1 shows the effect of increasing the number of partitions  k  and the routing factor  m  on the average similarity measure of fq. in the figure  the data point corresponding to k = 1 and m = 1 corresponds to the average similarity measure for fq with one monolithic index. this value is 1. we can see that for k = 1 and m = 1 this value is less than 1. this is because with increasing number of partitions while using only the minimum feature  m=1  to route the query file it is possible to not find the best match  or the file with the highest similarity measure. when m=1 even a single change that affects the minimum feature of the query file can prevent us from finding the best match as has been explained in section 1. the overall average similarity measure for fq  thus  reduces. however  as we increase m  we improve our chances of finding the best result because we now route every file fd （ fd and fq （ fq to multiple partitions. we can see that even with m=1 there is a significant improvement in the average similarity measure of fq for all values of k. for k=1 m=1 this value is more than 1. this means that for a large percentage of query files we are being able to find the file in fd that shares the highest content overlap with them. for m   1 the average similarity measure for all values of k is 1 which means that for every query file we were able to find the best match.

figure 1: effect of the number of partitions on the overall recall
　figure 1 depicts the average recall obtained for all the queries for increasing values of m and for k = 1. the recall for every query was calculated as the fraction of the size of the result set obtained when k 1 with respect to the original size of results with k=1. the ideal recall  thus  is 1.

figure 1: identical and disjoint top-1 lists  1 partitions
the graph in figure 1 depicts the average recall for k=1 for increasing values of m in two forms. the first form is the overall recall which takes into account the complete result set obtained for every query. the second form is the recall for only a subset of the result set - specifically the top-1 results in the result set. in this case we retained only the top-1 results for every query. we can see that for m=1 the overall recall is 1% whereas the recall for the corresponding top-1 results is 1%. this result shows us that though with k = 1 and m = 1 we were able to fetch only 1% of the total result set on an average  this subset contained most of the highest ranking results. this means that we were able to retain and produce the strong resemblances between documents.
　we may have lost some of the weak similarity relationships but this loss is acceptable given the gain in scalability. moreover  for many applications  only the documents with the strongest similarity to the query are of interest  and the low-similarity hits may not be of interest or get filtered out. for example  in the case of a standard search engine users are interested in only the the top few results of their query or the first page of results returned by the search engine. in such a situation the recall achieved by our routing algorithm with respect to the top-1 results is sufficient. however  if an application requires that every similar document to a query be found  then one can easily adopt a policy of querying each and every partition instead of just m out of k. such a scheme will preserve the original recall of every query as was the case when there existed just one index k = 1 .
　figure 1 shows us exactly how many of the top-1 results with k = 1 were identical or disjoint when compared to those with k = 1. this data was obtained using techniques developed by fagin . identical results were those in which the contents of results were preserved with k=1. disjoint results were those in which none of the contents of the original top-1 results with k = 1 were preserved when k=1. the rest of the top-1 results for k=1 contained at least one of the original top-1 results. we can see that as m increases  even with m=1  more than 1% of the top-1 lists were identical and less than 1% were disjoint. this means that overall more than 1% of the queries returned at least one of their top results.
　figure 1 depicts the average partition sizes as compared with the size of the monolithic index for increasing values

figure 1: %average partition sizes for increasing values of the routing factor
of m. the average partition sizes have been shown as a percentage of the size of the monolithic index. the partition size is the number of keys in the partition - the number of features indexed at every partition. this size does not take into account the list of files that every feature occurs in. even if we had accounted for it we would observe the same trend as has been shown in the figure. we can see that with k=1 and m=1 the average partition size is less than 1% of the size of the monolithic index.
　we have already seen from our previous results that with k =1 and m=1 we obtain very good average similarity for our queries  figure 1  more than 1% of the queries returned their top-1 results identical to when k = 1 and more than 1% of the top-1 results contained at least one of the original top-1 results. we can clearly see that our routing algorithm has performed very well while reducing the individual partitions to more manageable sizes  enabling the parallel execution of similarity based searches while at the same time has not compromised the quality of our results.
1. related work
　routing keyword queries to promising sources of information has been an active area of research in the field of distributed information retrieval and peer-to-peer networks  1  1  1  1 . cooper  and lu etal.  use past information about query results to guide queries to promising sources in peer-to-peer and federated information systems. distributed hashing has also been studied widely. litwin etal.  proposed scalable distributed data structures based on linear hash tables for parallel and distributed computing. distributed hash tables dht  have also been widely used in the area of peer-to-peer systems to distribute and locate content without having to flood every node in the system with content and queries. content addressable network  can    chord   pastry  and tapestry  are some of the dht implementations used in a distributed environment. manku  has categorized the dht routing methods into deterministic and randomized. oceanstore  is an infrastructure that provides access to data stored across a large-scale globally distributed system and uses the tapestry dht protocol to route queries and place objects close to their access points with the objective of minimizing latency  preserving reliability and maximizing the network bandwidth utilization. past  is an internet scale global storage utility that uses pastry's routing scheme. past routes a file to be stored to k nodes within the network such that those node identifiers are numerically closest to the file identifier. pastiche  is a peer-to-peer data backup facility that aims to reduce the storage overhead by identifying nodes that share common data at a sub-file granularity. pastiche aims to conserve storage space by identifying overlapping content using techniques introduced in the low-bandwidth network file system . in order to route data to appropriate nodes  pastiche needs to access and maintain an abstract of the file system's contents.
1. discussion and future work
　the document routing algorithm is an effective method for scalable and parallel similarity-based searches. the documents are routed based solely on their contents to only a small fraction of the total partitions while still being able to preserve the precision of the results. we conclude that this algorithm is a good scalable solution.
　similarity-based searches in large scale repositories is only one of the applications for our document routing algorithm. besides archival systems our document routing algorithm can be used to distribute and locate content in peer-to-peer cooperative storage and backup systems  1  1  1  and distributed storage systems  1  1 . such systems can save storage space by routing documents to nodes that are expected to store similar content. the recipe for a document  consisting of the feature hashes can be used to locate it without having to consult a large number of indices.
　the future work in this direction would consist of evaluating schemes that allow the dynamic growth in the number of partitions. we will investigate methods to divide those partitions that become overloaded and the effects of such a scheme on the quality of our results. we will also investigate the efficacy of our partitioning scheme for large scale archival systems that need to identify similar files within their repositories with the intention of conserving storage space. what we gain by partitioning the feature indices  used primarily for the de-duplication of archival data  and using our partitioning method may cost us some storage space as we miss identifying the files with high similarity. future work will consist of quantifying our losses in the form of storage space and finding out if our gain  in the form of better bandwidth utilization and throughput  outweighs this loss.
1. acknowledgments
　the authors would like to thank vinay deolalikar of hewlett packard labs  palo alto for contributing the lemma in section 1. the authors would also like to thank jaap suermondt and mark lillibridge of hewlett packard labs  palo alto for their comments.
