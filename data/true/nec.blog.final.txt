spam blogs  splogs  have become a major problem in the increasingly popular blogosphere. splogs are detrimental in that they corrupt the quality of information retrieved and they waste tremendous network and storage resources. we study several research issues in splog detection. first  in comparison to web spam and email spam  we identify some unique characteristics of splog. second  we propose a new online task that captures the unique characteristics of splog  in addition to tasks based on the traditional ir evaluation framework. the new task introduces a novel time-sensitive detection evaluation to indicate how quickly a detector can identify splogs. third  we propose a splog detection algorithm that combines traditional content features with temporal and link regularity features that are unique to blogs. finally  we develop an annotation tool to generate ground truth on a sampled subset of the trec-blog dataset. we conducted experiments on both offline  traditional splog detection  and our proposed online splog detection task. experiments based on the annotated ground truth set show excellent results on both offline and online splog detection tasks. 
1. introduction 
the blogosphere is growing extremely fast and provides new business opportunities in areas such as advertisement  opinion extraction  and marketing. however  spam blogs  splogs  have become a major problem in the blogosphere-they reduce the quality of information retrieval results and waste network and storage resources  1 . therefore  detecting splogs in the blogosphere has great importance. 
in this paper  we propose our solution to detect splogs in the blogosphere. the main contributions of our work are as follows: 
1. modeling the splog problem:  unlike web or email spam  a splog is dynamic since it continuously generates fresh content to drive traffic. to solve the splog problem  we need to take advantage of the unique splog properties. 
1. evaluation: splogs are characterized by temporal content dynamics and hence need to be identified as quickly as possible before they waste network and storage resources. we propose a time-sensitive evaluation framework to measure splog detection performance based on how fast the detection is made. 
1. regularity based detection: our detection algorithm identifies unique features such as temporal and link properties useful for detecting splogs. we identify temporal content regularity  self-similarity of content  and temporal structural regularity  regular post times  as well as regularity in the linking structure  frequent links to non-authoritative websites .  
we have evaluated our approach using the traditional offline task  as well as our proposed online metrics. the results are excellent indicating the combined feature set works well in both offline and online splog detection tasks. the online task reveals the sensitivity of the detection to the amount of evidence  posts  as well as the complimentary roles played by content and splog regularity features.  
most of previous work in spam detection comes from web spam detection. prior work to detect web spams can be further categorized into content analysis  1  and link analysis  1 . our work combines traditional features with temporal and link features that are unique to blogs. 
the rest of this paper is organized as follows. in the next section we provide a high-level definition of splogs; we shall also discuss splog characteristics and how splog differ from web sites. in section 1  we provide the online task definition and also provide a baseline offline splog detection task. in section 1  we present out splog detection framework and we discuss our proposed regularity  temporal and link  based features. in section 1  we discuss data pre-processing and our annotation tool to label data. in section 1  we present out experimental results and we present our conclusions in section 1.   
1. what are splogs  
in this section  we provide a high-level definition of splogs and the splog problem we face today  section 1   the typical splog characteristics  section 1   and the differences between splog and other types of spam  section 1 . 
1 working definition of splogs 
spam blogs  which are called splogs  are undesirable weblogs that the creators use solely for promoting affiliated sites . as blogs became increasingly mainstream  the presence of splogs has a detrimental effect in the blogosphere. according to multiple reports  the following are alarming statistics. 
* 1% of blogs are splogs. for the week of oct. 1  1  1 million blogs out of 1 million are splogs . 
* an average of 1 of the top 1 blogs search results in the three popular blog search engines came from splogs . 
* 1% of new pings came from splogs; more than 1% of claimed blogs pinging weblogs.com are splogs 
. 
the statistics exhibit serious problems caused by splogs  including  1  the degradation of information retrieval quality and  1  the tremendous waste of network and storage resources.   
 
 
figure 1 illustrates the overall scheme taken by splog creators. their motive is to drive visitors to affiliated sites  including the splog itself  that have some profitable mechanisms. by profitable mechanism  we refer to webbased business methods  such as search engine advertising programs  e.g. google adsense  or pay-per-click  ppc  affiliate programs. there are several schemes used by spammers to increase the visibility of splogs by getting indexed with high ranks on popular search engines. to deceive the search engine  the spammer may boost  1  relevancy  e.g. via keyword stuffing    1  popularity  e.g. via link farm   or  1  recency  e.g. via frequent posts   based on some ranking criteria used by search engines.  the increased visibility is unjustifiable since the content in splogs is often nonsense or stolen from other sites . the spammer also attacks regular blogs through comments and trackbacks to boost the splog ranking.  
1 typical splog characteristics 
in a typical splog  content is usually generated by machines in order to attract visitors through their appearance in either search engines or individual blogs.  by splog  we refer to a blog created by an author who has the intention of spamming. note that a blog that may contain spam in the form of comment spam or trackback spam is not considered a splog. 
there are typical characteristics observed in splogs: 
1. machine-generated content: splog entries are generated automatically  usually nonsense  gibberish  repetitive or copied from other blogs or websites. 
1. no value-addition: splogs provide useless or no unique information to their readers. there are blogs using automatic content aggregating techniques to provide useful service such as podcasting-these are legitimate blogs because of their value addition. 
1. hidden agenda  usually an economic goal: splogs have commercial intention that can be revealed if we observe any affiliate ads or out-going links to affiliate sites. 
some of these characteristics  such as no value-addition or hidden agenda  can also be found in other types of spams  e.g. web spam . however  splogs have unique properties that will be highlighted in the next section. 
1 uniqueness of splogs 
splogs are different from web spams in the following aspects. 
1. dynamic content: blog readers are mostly interested in recent entries.  unlike web spams where the content is static  a splog continuously generates fresh content to drive traffic. 
1. non-endorsement link: a hyperlink is often interpreted as an endorsement of other pages. it is less likely that a web spam gets endorsements from normal sites. however  since spammers can create hyperlinks  comment links or trackbacks  in normal blogs  links in blogs cannot be simply treated as endorsements. 
because of these two significant differences  the splog problem is different from that of traditional web spam as discussed next. 
1. task definition 
in this section we propose our evaluation methodology for comparing splog detection techniques on trec blog dataset. we first describe the detection task framework in section 1.  next  two detection tasks used in traditional information retrieval are given in section 1. in section 1 we propose an online detection task with novel assessment method.  
1 framework for detection task 
the objective of a splog detector is to remove unwanted blogs.  blog search engines need splog detectors to improve the quality of their search results. blog search engines differ from general web search engines in their growing contents - namely feeds. the detection decision is performed on a blog that consists of a growing list of entries. because entries become available gradually  there can be time delay to gather enough evidences  i.e.  entries  for detection. since a splog will persist in the index until it is detected  earlier detection with few evidences is crucial for the overall search quality. we refer a detector that can make a decision with less evidence fast. 
an illustration of how early splog detection is beneficial is shown in figure 1.  the grid represents how the amount of entries  x-axis  increases over time for each blog  y-axis .  for a specific time  the gray area denoted by  downloaded in the storage  shows the number of blogs discovered with the corresponding amount of entries.  as time passes  more blogs are indexed as well as growing amounts of entries  as shown by the dashed border and arrows.  

 
figure 1:  blogs are discovered and downloaded over time. similarly  the amount of entries downloaded grows over time.  the gray area represents blog data that have been downloaded  and the dashed border and arrows show the downloading process continuing over time. 
the target objective for blog search engines is to detect splogs as early as possible.  as a result  we need to measure the speed of splog detection. traditional detectors are evaluated offline  where a batch of data is inputted into the detector and some performance metrics are calculated on the detection results.  because we want to also evaluate the speed of splog detection  we propose an online detection evaluation. another aspect of evaluation depends on the availability of ground truth information.  both offline and online detection can be evaluated with or without ground truth. accordingly  there are four tasks as identified in table 1. 
table 1: four detection tasks are identified based on offline and online detections. 
dataset   task type ¡¡offline  traditional  ¡¡¡¡online  time-sensitive  with ground truth task 1 task 1 without ground truth task 1 task 1 1 traditional ir-based detection  
to compare different detection methods  there are two evaluation frameworks used in traditional information retrieval research and also widely applied in many trec tracks. 
1.1 evaluation with ground truth 
evaluation is designed to compare detectors for an input set of blogs. given a set of input blogs b with labels  the detectors can be evaluated by k-fold cross-validation  where the performance can be measured by metrics such as precision/recall  auc  or roc plot. 
1.1 evaluation without ground truth 
to evaluate detector performances on a large dataset  there will be limited amount of labeled ground truth. each detector makes its decision on the large dataset  and returns the detection results as a ranked list. the detector performance is evaluated by measuring the precision at top n  precision n  of the ranked list based on pooling of multiple detection lists. 
based on the availability of ground truth  splog detectors can be compared using one of the above offline evaluations.  however to measure the speed of detection efficiency  we propose an online detection framework. 
1 online detection  
as discussed above  the benefit of early splog detection is to quickly remove entries by splogs from the search index. hence  we propose a new framework to evaluate time-sensitive detection performance. 
we want to measure the detection performance on newly discovered blogs and observe how the decisions on these blogs can improve as more entries are available. first  blogs in the dataset are partitioned based on the time of discovery  i.e.  the first appearance in the dataset . we assume the splog detector evaluates the blog contents at uniform frequency  i.e. t1 = t  t1 = t+ t  ...  tk=t+k t.  b ti  is defined as a partition that consists of blogs discovered after time ti-1 and before ti. b t1  is the initial training set  usually given with labels  splog or nonsplog . 

figure 1: online time-sensitive evaluation performance. 
for each partition b tk   k   1   the detector gives a decision at time tj  j  = k   for which the performance pjk is measured. pjk is the detection performance at time tj on the partition at tk  b tk  . in order to measure the speed of detection  we are interested in how the detector performance pjk improves as j increases. then  we introduce an overall performance measure of all decisions made with a specific delay. more specifically  for each delay i = j - k  the overall performance pi is given as an average  where pi=e pjk | i=j-k . the performance is plotted with i on the x-axis as shown in figure 1  to demonstrate how quickly the detector can make a good decision.  note that each performance pjk is measured based on the same evaluation metrics as the traditional offline evaluations. we expect the proposed online evaluation to provide significant insights on early detection of splogs. 
1. our detection method 
we have developed new techniques for splog detection based on temporal and linking patterns  which are unique features that distinguish blogs from regular web pages. 
due to the special characteristics of splogs  traditional content-based or link-based spam detection techniques are not sufficient. it is difficult to detect spams for individual pages  i.e.  entries  by content-based techniques  since a splog can steal  copy  content from normal blogs. link-based techniques based on propagation of trust from legitimate sites will work poorly for blogs since spammers can create links  comments and trackbacks  from normal blogs to splogs. 
our observation is that a blog is a growing sequence of entries rather than individual pages. we expect that splogs can be recognized by their abnormal temporal and link patterns observed in entry sequences  since their motivation is different from normal  human-generated blogs. in a splog  the content and link structures are typically machine-generated  possibly copied from other blogs / websites . the link structure is focused on driving traffic to a specific set of affiliate websites. to capture such differences  we introduce new features  namely  temporal regularity and link regularity  which are described in the following subsection. 
1 baseline features 
we shall now discuss the content based features used in this work - these will serve as the baseline feature set as they are widely used in splog detection. we use a subset of the content features presented in . these features are used to distinguish between two classes of blogs - normal and splogs  based on the statistical properties of the content.  
in this work we extract features from five different parts of a blog:  1  tokenized urls   1  blog and post titles   1  anchor text   1  blog homepage content and  1  post content. for each category we extract the following features: word count  wc   average word length  wl  and a vector containing the word frequency distribution  wf . in this work  each content category is analyzed separately from the rest for computational efficiency.   
1.1 feature selection using fisher linear discriminant analysis  lda  
we need to reduce the length of the vector wf as the total number of unique terms  excluding words containing digits  is greater than 1  this varies per category  and includes non-traditional usage such as  helloooo  . this can easily lead to over fitting the data. secondly  the distribution of the words is long-tailed - i.e. most of the words are rarely used.  
we expect good feature subsets contain features highly correlated with  predictive of  the class  but uncorrelated with each other. the objective of fisher lda is to enable us to determine discriminative features while preserving as much of the class discrimination as possible. the solution is to compute the optimal transformation of the feature space based on a criterion that minimizes the within-class scatter  of the data set  and maximizes the between-class scatter simultaneously. this criterion can also be used as a separability measure for feature selection. we use the trace criteria  j = tr sw-1sb  where sw denotes the within-class scatter and sb denotes the between-class scatter matrix. this criterion computes the ratio of between-class variance to the within-class variance in terms of the trace of the product  the trace is just the sum of eigenvalues of sw-1sb . we select the top k eigenvalues to determine the key dimensions of the wf vector. 
1 temporal regularity 
temporal regularity captures consistency in timing of content creation  structural regularity   and similarity between contents  content regularity . content regularity is given by the autocorrelation of the content  derived from computing a similarity measure on the baseline content feature vectors. we define a similarity measure based on the histogram intersection distance. structural regularity is given by the entropy of the post time difference distribution. a splog will have low entropy  indicating machine generated content.   
1.1 temporal content regularity  tcr :  
we use the autocorrelation of the content to estimate the tcr value. intuitively  the autocorrelation function  conventionally depicted as r ¦Ó   of a time series is an estimate of how a future sample is dependent on a current sample. a noise like signal will have a sharp auto-correlation function  while a highly coherent signal's autocorrelation function will fall off gradually. since splogs are usually finally motivated  we conjecture that their content will be highly similar over time. however human bloggers will tend to post over a diverse set of topics  leading to a sharper autocorrelation function. we define tcr as a self-similarity measure of content and compute it by auto-correlation.  
		 
figure 1: the figure shows the difference in the autocorrelation function between a splog and a normal blog. notice that auto-correlation function for a splog is very high and nearly constant  while the values for a normal blog are relatively low and fluctuate. these graphs have been derived from a splog and a normal blog from the trec dataset.  
we compute the discrete time autocorrelation function r k  for the posts. the posts are time difference normalized - i.e. we are only interested in the similarity between the current post and a future post in terms of the number of posts in between  e.g. will the post after next be related to the current post   ignoring time. this is a simplifying assumption  but is useful when many posts do not have the time meta data associated with them. the autocorrelation function is defined as follows:  
	r k    =  1	d p l       p l  + k   
   wf    l ¡É wf  l + k     1  d p l       p l  + k   1  e    wf    l ¡È wf  l + k      
where e is the expectation operator  r k  is the expected value of the autocorrelation between the current lth post and the  l+k th post; d is the dissimilarity measure  | | is the cardinality operator  and ¡È  ¡É refer to the familiar union and intersection operators. we use the autocorrelation vector r k  as a feature to discriminate between splogs and normal blogs.   
1.1 temporal structural regularity  tsr :  
we estimate tsr of a blog by computing the entropy of the post time difference distribution. in order to estimate the distribution  we use hierarchical clustering on the post time difference values from a blog.  


 
figure 1: the figure shows the differences in the temporal regularity between a splog and a normal blog. a splog posts with a post time of 1 minutes  while a normal blog has post time interval that is highly varied and ranges to several hours to nearly a week. 
the temporal structure of post time interval can be discovered by clustering close post intervals. we use hierarchical clustering method with single link merge criteria on the post interval difference values. the original dataset is initialized into n clusters for n data points. two clusters are merged into one if the distance  linkage  between the two is the smallest amongst all pair wise cluster distances. we use the average variance stopping criteria for clustering. once the clusters are determined  we compute cluster entropy as a measure of tsr: 
	= ¡Æm pi log pi  	pi = ni  
be
	i=1	n
 	 	 1  
	tsr =  1	be  
bmax
where be is the blog entropy  bmax is the maximum observed entropy  n is the total number of posts  ni and pi are the number of posts and the probability of the ith cluster respectively  and m is the number of clusters. note that for some blogs including normal or splogs  post time is not available as part of the post metadata. we treat such cases as missing data. and if a blog does not have post time information  we do not use tsr as a feature. 
1 link regularity estimation 
link regularity  lr  measures consistency in target websites pointed by a blog. we expect that a splog will exhibit more consistent behavior since the main intent of such splogs is to drive traffic to affiliate websites. secondly we conjecture that there will be a significant portion of links that will be targeted to affiliated websites rather than normal blogs / websites. importantly these affiliate websites will not be authoritative and we do not expect normal bloggers to link to such websites. 
we analyze the splog linking behavior using the hits algorithm .  the intuition is that splogs target focused set of websites  while normal blogs usually have more diverse targeting websites. we use hits with out-link normalization to compute hub scores. the normalized hub score for a blog is a useful indicator of the blog being a splog.  

 
figure 1: normal blogs tend to link to authoritative websites while splogs frequently link to affiliate websites that are not authorities. the thickness of the arrow from the splog indicates the frequency with which the splog links to an non-authoritative  affiliate website.  
we put blogs and their linking websites on two sides of a bi-partite graph to construct an adjacency matrix a  where aij=1 indicates there is a hyperlink from blog bi to website wj. in the original hits algorithm  good hubs and good authorities are identified by the mutually reinforcing relationship: a=ath  h=aa  where a is the authority score  h is the hub score and a is the adjacency matrix. a blog with divergent out-links to authoritative websites will obtain a higher hub score. to suppress this effect and on the other side reinforce the influence of blogs with focused targets  we normalize a by out-degrees of blogs and then compute hub scores for blogs as lr.  
our splog detector combines these new features  tcr  tsr  lr  with traditional content features into a large feature vector. we then use standard machine learning techniques  svm classifier with a radial basis function kernel  to classify each blog into two classes: splog or normal blog.  
1. data-preprocessing and ground truth definition 
we have made significant efforts to pre-process the trec-blog dataset and to establish ground truth for training and testing. our major contributions are summarized as follows: 
1. pre-processing: the trec-blog 1 dataset is a crawl of 1 feeds collected over 1 weeks  from dec. 1  1 to feb. 1  1  totaling 1 days. after removing duplicate feeds and feeds without homepage or permalinks  we have about 1k unique blogs. we focus our analysis on this subset of blogs having homepage and at least one entry.  
1. annotation tool: we have developed a user-friendly interface  figure 1  for annotators to label the trecblog dataset. the detailed description of the tool is available at our webpage1. essentially  in the interface  the content of the blogs and their contents are fetched from the database and presented to the annotator.  

 
figure 1: splog annotation tool to view and label blogs. 
through the interface as shown in figure 1  an annotator can browse the blog homepage and entries that have been downloaded in the trec-blog dataset  or visit the blog site directly online  in order to assign one of the following five labels:  n  normal   s  splog   b  borderline   u  undecided  and  f  foreign language.  
1. disagreement among annotators: we performed a pilot study to investigate how different annotators identify splogs. we presented a set of 1 blogs to a group of 1 annotators  asking them to assign each blog to one of the five labels. one interesting result is that the annotators have agreement on normal blogs but have varying opinions on splogs  s/b/u   which suggests that splog detection is not trivial even for humans. we plan to conduct further intensive user studies.  
1. ground truth: as of august 1  1  we have labeled 1 blogs by using our annotation tool. the 1 blogs are selected using random sampling as well as stratified sampling methods.  among these 1 blogs  1 are labeled as normal blogs  1 are labeled as splogs  and the rest are borderline/undecided/foreign.  the annotated splog percentage is lower than what has been reported because  1  some known splogs are prefiltered from the trec dataset  and  1  we have selected to examine the 1k subset of blogs that have both homepages and entries downloaded.  
using the annotation tool to generate ground truth  we built a baseline splog detector and our detector. 
1. experimental results 
in this section  we present the annotation results. we manually labeled 1 normal blogs and 1 splogs. we decided to create a symmetric set for evaluation containing 1 splogs and 1 normal blogs. 
1 offline  traditional  
in the traditional offline task  we used all the 1 samples for evaluation. we used a five fold cross-validation technique to evaluate the performance of the splog detector. the results show that the proposed classifier and the new temporal and structural features work well together. in table 1  we summarize the results of the offline detection. the table shows the comparison between content features of different dimensionality against the combination of the same feature with the regularity features  tcr  tsr  lr . we use four measures - auc  area under the roc curve  also ref. figure 1   accuracy  precision and recall. the results indicate that the proposed feature set combines well with the traditional content based features  however the largest gains occur when the dimensionality of the content features is low.   
table 1: the table shows a comparison of the baseline content scheme against the combination of baseline  designated as base-n  where n is the dimension of the baseline feature  with temporal and link-structure features  designated as r . the table indicates that the improvement due to the non-baseline features is smaller with increase in the number of dimensions to the baseline features.  
feature auc accuracy precision recall base-1 1 1 1 1 r+base-1 1 1 1 1 base-1 1 1 1 1 r+base-1 1 1 1 1 base-1 1 1 1 1 r+base-1 1 1 1 1 base-1 1 1 1 1 r+base-1 1 1 1 1 r 1 1 1 1 roc curve

 
figure 1: the plot of the roc curves for different values of the baseline feature size  base-n + r as well as the roc curve due to the new features alone. 
1 online  proposed   
in the online evaluation framework  we are interested in the rate understanding the temporal effects in the splog classifier performance. in order to do this we create a training set b1 and testing sets b1 - b1. in the trec dataset the crawler discovers new blogs every day  but refreshes the feed only every week. due to this refresh anomaly  we test the data  weekly  as there is no intermediate download available for the blogs. the training sets b1 - b1 refer to the blogs that were discovered on day i where 1 ¡Üi ¡Ü1. we use 1 blogs for training  b1   and 1 blogs for testing  b1-b1 . the remaining 1 blogs were discovered after the 1st week and are not part of the testing set. we now introduce some notation for clarity: 
* t1  t1  ...  tn: testing period  week 1  1  ...  1. 
* tr t  denotes the training set blog b1 data downloaded until time t. tr 1  would denote the data for the blogs corresponding the end of week 1. 
* te t : denotes the training set blog  b1  b1  ...  b1 which are discovered in week 1  data downloaded until time t. note that tr¡Éte= ¦Õ. 
* c tr t   or ct: a classifier trained on tr t . ct f denotes the classifier is trained using feature set f. for example c1  base1+r denotes the classifier c1 using feature set base1+r and where r =  tcr  tsr  lr . 
* p tr t1   te t1   or p t1  t1 : the performance of classifier trained on tr t1   i.e. c1 and tested on te t1   or p t1  t1 . for example p 1  1  denotes the performance of classifier c1 trained on the 1st week training set and tested on the 1rd week testing set. 
 

figure 1: the figure illustrates the online testing framework. the training set b1 is partitioned weekly  as are the testing sets b1-b1. at the end of each week  the splog detector is re-trained to include the latest week's labeled data and is then tested on blogs b1-b1. the test blogs have additional downloaded entries for the latest week as well.  the symbols pi refer to testing at the end of the ith week. 

 
figure 1: the figures for the online experiments show impact of adding the structural features in the online evaluation. in the absence of content data  the regularity features provide a significant boost to the both the auc and the accuracy results. 
the results for the online evaluation scheme are shown in figure 1. they show the plot of p i i  against the weekly index i  with the metrics auc  area under the roc curve  and the accuracy metrics. the plot shows the result of testing the classifier on the data  testing sets b1-b1  collected after the ith week  with the classifier being retrained on b1  with additional data for the set b1. they indicate that the utility of adding the structural regularity features in on-line detection. in the absence of enough content  these features play a critical role in discriminating between splogs and normal blogs.  
it is striking to compare the results as shown in figure 1 against the results for offline testing as shown in  table 1 and figure 1. they indicate that the information provided by the structural information is complementary to the information in the content - this is evidenced by the jump in the auc and the accuracy values for the corresponding week. importantly the contribution to the results in the online case due to the regularity features is significant. not only is there a clear improvement for classifiers ci  base-n+r over the corresponding classifiers ci  base-n for all weeks  but also the difference is high for the low dimensional features.  
the explanation for the significant difference is as follows. in online tests when in the first week there is not enough content to train the classifier based on content analysis alone  and hence the regularity features become very important. over time  the training data available to the classifier increases  i.e. the blogs in the training set b1 have more entries over time  hence making the decision surface more stable. additionally  we note that the content features that we have extracted are statistical in nature. hence the feature vector corresponding to the content of both the training data and test data begin to stabilize only after a sufficient number of posts in each blog. note also that over time the combination of both baseline and regularity features shows less fluctuation than the baseline features alone  ref. figure 1 . 
1. concluding remarks 
in this paper we analyze the splog detection problem as an important open task for trec-blog track. a splog is significantly different from web spam  and thus new online detection tasks are identified. the new task measures how quickly a detector can identify splogs - this is important as temporal dynamics are key distinguishing features of a blog from traditional web pages. we identify new features based on temporal content and structural regularity as well as link regularity. we also provide a set of ground truth labeled through our annotation tool. our experimental results on both the offline and the online tasks are excellent and validate the importance of the both the proposed online task as well as the addition of regularity based features to traditional content features in such tasks. 
