
gene dictionary  fragment   derived 	derived by analyzing statistical cofrom locuslink	occurrence of verbs with genes in 
training data  plus manual curation
figure 1 bioteks processing steps and dictionaries 
to recognize gene mentions and function words  we used a dictionary-based named entity recognizer implemented as a uima text analysis engine.  the dictionary contains an entry for each named entity  which in turn includes all known synonyms for the entity  a  canonical  or preferred name for the entity  and additional optional meta-data associated with the entity.  a synonym may be a single token or a multi-token phrase.  the entity recognizer tae scans the input text and at each token searches for the longest matching synonym in the dictionary.  when a matching synonym is found an annotation is created in the text that spans the matching tokens.  the annotation includes the canonical form for the entity and all other meta-data specified in the dictionary entry for the entity.  the tae will optionally perform stemming and case folding when attempting to match the text against the dictionary of synonyms  and the set of characters used to separate tokens is configurable. 
the dictionary for finding gene mentions was automatically derived from the full locuslink database  and included 1 genes with a total of 1 synonyms.  the preferred gene symbol was used for the canonical form and the synonyms were extracted from the locuslink entry fields that contain the known gene or protein aliases used for the gene.  during dictionary matching we did not use stemming  but we did case fold all tokens that contained at least one numeric character  and the set of characters used to separate tokens included white space  punctuation characters  and in particular hyphen  forward and backward slash  and parentheses.  tokenizing on these characters and eliminating them from the tokens improved the recall of our gene identifier and addressed some of the variability found in gene names associated with inconsistent use of space  hyphen  slashes  and parentheses. 
the dictionary of function words was derived in a semi-automatic fashion.  using the training data for task 1  we identified verbs that frequently occur in sentences with genes as the subject.  we sorted this list based on a scoring function of the significance of this co-occurrence  and then manually curated the list to select important gene function words  yielding a rather small list of 1 function words.  we used 
source topic

generated query
figure 1 task 1 automatic query query generation. 
stemming and case folding during matching  allowing the function word finder to match noun forms as well as verb forms.  samples of our dictionaries are shown in figure 1. 
for the task 1 queries  we explored using the gene canon  the species name  human  mice / mouse  rat  or drosophila   the function word canon  and all given gene aliases as tokens or phrases.  we automatically generated queries for juruxml based on the provided query source topics.  our query generation process is summarized in figure 1.   
task 1 
for task 1  automatically extract and summarize a gene's function given a document known to describe the gene's function   we decided to chunk the document into whole sentences  score each sentence  and return the best scoring sentence as our answer.  a sentence's score is based on whether or not it contains the target gene  how many gene function words it contains  what structural role the sentence plays  i.e.  is it the title   and where in the document the sentence occurs.  to identify genes and function words in the documents we applied the text analysis processing steps shown in figure 1  excluding the final step of indexing with juruxml. 
given that we had committed to extracting the single best scoring sentence as the summary  we performed a simple analysis to determine if it was worthwhile to analyze the full article versus just the medline abstract.  for each document we scored every sentence in the document against the gold standard  the generif for the given gene and article  using the classic dice coefficient  as implemented in the scoring code provided by the track  and identified the best scoring sentence.  we then returned this sentence as our answer and calculated the average performance over the set of documents.  this essentially produces an upper bound the best possible score that could be obtained assuming a strategy of returning the single best sentence.  
task 1 test set performance
1
1s-idx1 cs-idx1 sf-idx1 csfl-idx1 csl-idx1 csfllc1-idx1 s-idx1 csfl-idx1keyquery generation option  query always includes canonical gene name sspecies name included in querycfor gene name  x  ambiguous w/ common words    x  goes to  x gene  and  x protein fgene function annotation term used in queryllong form: all topic fields used  multi-word fields in quotes  phrases   all tokens & phrases uniquellsame as long form  but multi-word fields are not in quotescncanonical gene name  official or preferred name  repeated n timestext analysis / indexing optionidx1gene matching done with case-folding of names with 1+ digits  hyphens strippedidx1heuristic expansion of hyphen/space combinationsfigure 1 task 1 test set performance. 
for the set of full-length articles  the optimal classic dice score is 1%.  for the set of medline abstracts  the optimal classic dice score is 1%.  this result is somewhat surprising given that the abstract should be a proper subset of the full-length article.  this anomaly is due to the following: most generifs are extracted directly from the medline abstracts.  the full-length article contains sgml entities that must be translated to ascii for the medline abstract  e.g.  '&agr;' -  'alpha'.  this translation is not done consistently  such that a fragment extracted from the full text may not exactly match the generif using the dice measures.  given this result  we chose to use the abstracts rather than the fulllength articles for our actual task 1 run. 
results 
task 1 
using the training queries for task 1 we explored a variety of query generation options and measured the performance of the system.  on the training queries we were able to obtain an 1pt average precision of 1.  based on these results  we submitted two runs on the test queries.  run ibmbt1 was generated using queries that comprise only the gene canonical form and the species name.  this run produced an 1pt average precision of 1  but found only 1 of 1 possible relevant documents. run ibmbt1 was generated using queries that comprise the gene canonical form  species name  function keyword  and all alias forms from the source query topic.  this run produced an 1pt average precision of 1 while returning 1 of 1 possible relevant documents.  adding more terms to the query improved recall but resulted in poorer overall ranking.   
with the relevance judgments for the test queries we performed a more detailed analysis of various query generation options on the test data.  these results are shown in figure 1.  from the plot we see that the relatively simple query s-idx1  species name and gene canonical form  produces better precision at low recall  while the queries with additional terms produce worse precision at low recall but better precision at higher recall levels. 
task 1 
although we explored a variety of parameter settings for our sentence scoring function  we were not able to obtain a scoring function that performed better than simply returning the title.  we are currently exploring a number of ways to improve our scoring function  such as incorporating a shallow parse in the analysis to more accurately connect the target gene with the function words in the sentence. 
conclusion 
based on our results  we conclude that using a comprehensive gene dictionary with appropriate normalization during matching is an effective way to annotate gene mentions in biomedical text.  the normalization and matching heuristics are very important  however  given the considerable variability found in gene names  especially in the use of capitalization  spaces  hyphens  slashes  and parenthesis.  unfortunately  identifying gene  function words  is not necessarily useful in a bag-of-words query context.  we suspect  however  that they might be more effective when identified in syntactic relationships with genes.  this will require the addition of parsing  e.g.  shallow parsing  to the analysis phase.   
the significant difference in our training and test results for task 1  a phenomenon observed by many of the task 1 participants  suggests that the overall test set is not stable.  there may be too few relevant documents for some of the test queries  or the relevance judgments may be too incomplete.  this latter issue is particularly important and was raised by a number of the track participants. 
given the exploratory nature of task 1 and the relatively late decision by the track to collect official runs for the task  we did not invest as much time in this task.  in the process of developing our sentence scoring function  we observed a number of cases where our extracted sentence appeared to convey the same meaning as the gold standard  but due to the wording the sentence scored poorly using the various dice measures.  based on our experience and the experience of others on this task  we are not convinced that this particular evaluation accurately measures a system's ability to perform what is arguably an important real world task. 
given the overall constraints under which this inaugural genomics track was run  we feel the track was very successful and accomplished its goals for the first year.  in particular  it brought this important area of research to the attention of the information retrieval community and made a positive step in the direction of building useful test sets in this domain  which currently suffers from a severe lack of well constructed test sets.  we look forward to next year's track and the development of more realistic tasks supported by more thorough evaluation. 
