we propose to demonstrate easedb  the first cache-oblivious query processor for in-memory relational query processing. the cacheoblivious notion from the theory community refers to the property that no parameters in an algorithm or a data structure need to be tuned for a specific memory hierarchy for optimality. as a result  easedb automatically optimizes the cache performance as well as the overall performance of query processing on any memory hierarchy. we have developed a visualization interface to show the detailed performance of easedb in comparison with its cacheconscious counterpart  with both the parameter values in the cacheconscious algorithms and the hardware platforms varied.
categories and subject descriptors
h.1  database management : systems-query processing  relational databases
general terms
algorithms  measurement  performance
keywords
cache-oblivious  in-memory query processing
1. introduction
　as the gap between the processor speed and the memory speed increases  the memory performance has become an important factor for the overall performance of relational query processing. however  it is a challenging task to optimize the memory performance for relational query processing  due to the diversity  complexity and runtime dynamics of database systems as well as memory hierarchies. thus  it is imperative to investigate self-optimizing query processing techniques for the memory hierarchy.
　easedb  is a new cache-oblivious in-memory relational query processor that can automatically optimize the query processing performance on any multi-level memory hierarchy. in easedb  data structures and algorithms for query processing are cache-oblivious  since they do not depend on any cache parameters of a specific memory hierarchy  e.g.  the cache capacity and block size. they automatically achieve a high performance comparable to the finetuned cache-conscious algorithms on various platforms. in contrast  cache-conscious algorithms  see ailamaki's survey   ex-
copyright is held by the author/owner s .
sigmod'1  june 1  1  beijing  china. acm 1-1-1/1.
plicitly take cache parameters as input and have a high performance with suitable parameter values.
　easedb automatically optimizes the performance of relational query processing on all levels of a memory hierarchy. this automaticity is especially desirable for the levels above the main memory  because caches at these levels  e.g.  l1 and l1 caches  are managed by the hardware. as a result  the accurate state information of these caches are difficult to obtain due to the system runtime dynamics and the hardware complexity. thus  we consider cacheoblivious algorithms that can automatically improve the in-memory performance of query processing.
　the system demonstration exposes the cache behavior of cacheoblivious query processing on a multi-level memory hierarchy in comparison with cache-conscious query processing  and also provides an intuitive way of visualizing the cache performance as well as the overall performance of the query processor. through our visualization tool  we can examine the cache performance together with the status of the query execution at runtime. we organize our demo into two parts:
  visualizing the cache behavior of a cache-conscious algorithm with different parameter values.this part is to simulate the performance tuning process for cache-conscious algorithms. initially  the parameter value is set to be a small one. subsequently  it doubles the one used in the previous execution. the execution stops when the parameter value is larger than the l1 cache capacity. through comparing these executions  we determine the suitable parameter value for the cache-conscious algorithm.
  visualizing the cache behavior of the cache-oblivious algorithm in comparison with its cache-conscious counterpart. the cache-conscious algorithm under comparison uses the suitable parameter value obtained in the first part.
　through the demonstration  we show that  1  cache-conscious algorithms typically optimize only the target level of the memory hierarchy  and  1  cache-oblivious algorithms in easedb have a comparable cache performance as well as overall performance to their fine-tuned cache-conscious counterparts.
1. system overview
we first give a brief overview of easedb in this demonstration.
next  we describe our visualization tool for the cache performance.
1 easedb
　figure 1 shows the system architecture of easedb. there are three major components  namely the sql parser  the query optimizer  and the plan executor. the query optimizer in turn consists


figure 1: the main execution window
library   to periodically obtain the cache performance from the lower-level hardware counters. in addition  pcl allows user-level code to access the performance counters.
　figure 1 shows the main execution window when a simple query is running. there are four panels on the left of the window  namely processors  queries  threads and options. on the right of the window  there are a number of panels visualizing the cache performance dynamically. the information shown in the processors panel is automatically obtained from the calibrator . we define the cache configuration as a three-element tuple  c  b  a   where c is the cache capacity in bytes  b the cache line size infigure 1: the system architecture of easedb
of a query plan generator and a cache-oblivious cost estimator. the execution engine is divided into three layers  including the storage  the access methods and the query operators . all these components and algorithms are designed to be cache-oblivious.
　we use two main methodologies  divide-and-conquer and amortization  to develop a cache-oblivious algorithm in easedb. for example  the cache-oblivious non-indexed nested-loop join  co nlj   applies recursive partitioning on both relations. the algorithm first divides each of the inner and outer relations into two equalsized sub-relations. next  it performs joins on the pairs of inner and outer sub-relations. this partitioning and joining process goes on recursively. at some point of the recursion  the join on two partitions fits into the l1 data cache. as the recursion goes on  the join fits into the l1 data cache. the base case is evaluated using the tuple-based nested-loop join algorithm. more details about the design and implementation of easedb can be found in our system overview paper .
1 visualizing the cache performance
　the visualization tool is a graphical user interface  gui  that dynamically displays the cache performance and the state of all queries in the system. the gui is implemented in java swt  standard widget toolkit   since java swt is widely applicable on various systems. the performance on cpu caches including the numbers of cache hits and misses are typically measured using a profiling tool. in our demonstration  we use pcl  performance counter bytes and a the set associativity.
　in the queries panel  the user can submit custom queries on the in-memory data. the user can choose cache-conscious or cacheoblivious algorithms to execute the query. when the cache-conscious algorithm is chosen  its parameters can be individually configured. more specifically  when the cc run button is clicked  a popup window is shown for the user to input the parameter value for the cache-conscious algorithm. the default parameter value for the cache-conscious algorithm is l1 cache capacity or cache line size according to the algorithmic characteristics  since the l1 cache is typically a major bottleneck for memory accesses . the user can also click on the view plan button and view the query plans generated from both the cache-conscious optimizer used in traditional relational databases and the cache-oblivious one used in easedb.
　in the threads panel  we display the basic information of all threads that are running or ran previously in the system. the state of a thread can be running  the thread is running   stop  the user clicks the pause button in the panel  and stops the execution  and done  the execution ends .
　in the options panel  the user can specify the time period of reading the cache performance metrics from hardware counters. the main performance metrics shown in our demo include the number of l1 and l1 data cache misses  l1 dcm and l1 dcm respectively  and the number of translation lookaside buffer  tlb  misses  tlb dm . these performance metrics can be shown on a per thread or per processor basis. the default setting is per thread.

 a  cc nlj with the block size varied	 b  cc nlj  best 	 c  co nlj
figure 1: screen shots: co nlj and cc nlj on p1　in each panel on the right of the main execution window  we display the main performance metrics graphically  from top down: l1 dcm  l1 dcm and tlb dm   query status and totals. the query status includes the relation regions that are accessed in the last period and the query progress. based on this information  we can determine the hot region during the process of evaluating the query.
1. demonstration
　we use the visual tool to study cache-oblivious algorithms in easedb in comparison with cache-conscious algorithms.
1 demo setup
　we will run our demo on two different platforms  namely p1 and amd. some features of these machines are listed in table 1. table 1: machine characteristics
namep1amdoslinux 1.1linux 1.1processorintel p1.1ghzamd opteron 1ghzl1 d-cache 1k  1  1  1k  1  1 l1 cache 1k  1  1  1m  1  1 dtlb1memory  bytes 1g1g　in our demonstration  we will submit custom queries to our synthetic data sets. an example custom query shown in figure 1 is a join  select r.a1 from r  s where r.a1 s.a1 and r.a1 s.a1... and r.an s.an . each of relations r and s consists of n four-byte integer attributes  a1  a1  ...  and an. all fields of each table are involved in the non-equijoin predicate so that an entire tuple is brought into the cache for the evaluation of the predicate. this query is evaluated with either the blocked nested-loop join  cc nlj   or the cache-oblivious nested-loop join  co nlj  .
　figure 1 shows the screen shot of evaluating the exapmle query with co nlj when the query progress was 1%. each relation has 1 attributes. the tuple size is 1 bytes  the l1 cache line size of p1 . the size of each relation is 1m bytes  which is larger than the l1 data cache capacity. we have varied the relation size and the tuple size  and obtained similar results .
1 runtime performance results
　as an example  figure 1 shows some screen shots of the runtime performance results running our demonstration system on p1.
figure 1  a  shows the screen shot of evaluating the query with
cc nlj with a changing block size of the inner relation. the block size is ranged from 1k to 1k bytes. the performance variance of cc nlj with different block sizes is large. this large performance variance quantifies the potential performance loss with ineffective tuning or without any tuning. moreover  the three kinds of cache misses reach their minimum at different block sizes. this is evidence of a disadvantage of cache-conscious algorithms  i.e.  they often optimize the performance for a specific level in the memory hierarchy  but do not optimize for all levels of the memory hierarchy. note  there are a very small number of outliers in the measurements. a possible reason is the casual error of the profiling tool . nevertheless  the accumulated results are stable in our experiments.
　figures 1  b  c  show the screen shots of evaluating the query with the best cc nlj and co nlj  respectively. the best cc nlj has a block size of 1k bytes. compared with the best cc nlj  co nlj has a consistently good performance on the l1  the l1 and tlb. this performance advantage shows the power of automatic optimization for all levels of the memory hierarchy achieved by cache-oblivious techniques. the execution time of co nlj is similar to that of the best cc nlj.
　in addition to the runtime performance results  we will demonstrate the working mechanisms of our cache-oblivious algorithms.
