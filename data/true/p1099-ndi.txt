as opposed to representing a document as a  bag of words  in most information retrieval applications  we propose a model of representing a web page as sets of named entities of multiple types. specifically  four types of named entities are extracted  namely person  geographic location  organization  and time. moreover  the relations among these entities are also extracted  weighted  classified and marked by labels. on top of this model  some interesting applications are demonstrated. in particular  we introduce a notion of person-activity  which contains four different elements: person  location  time and activity. with this notion and based on a reasonably large set of web pages  we are able to show how one person's activities can be attributed by time and location  which gives a good idea of the mobility of the person under question. 
categories and subject descriptors 
h.1  models and principles : systems and information theory 
general terms 
algorithms  measurement 
keywords 
web content mining  web page model  named entity  
1. introduction 
with the explosive growth of the web  it has become increasingly necessary for users to utilize automated applications in finding the desired information from a large number of web pages. web content mining can be broadly defined as the discovery and analysis of desirable information from the page content of the web. the prevailing representation of the web page content is the bag-of-words model  whereas we think that named entities in the content are more important and informative for in-depth mining. we propose a novel named-entitybased model for page content  which consists of multiple types of named entities along with relations between them. specifically  we utilize four types of named entities  person  location  organization and time  with the relations between them to represent the web page. furthermore  we weight  classify and label the relations. with this model  we can construct a series of interesting applications  such as a system tracking the entity's activities by time line and geographical space. in the following of this article  we will illustrate the details of this model  along with the related key techniques and two interesting applications. 
1. an overview of the model and a preliminary application 
1 named entity discovery 
as for the complexity and diversity of the web  traditional named entity  ne  discovery methods  such as rule-based method and model-based method  do not always work due to the lack of scalability. in our research  we combine these two types of methods to make the extraction more scalable. taking person entity as an example  we combine a rule-based method  a model-based method  and a bayesian method to make the ne extraction more scalable. for the rule-based method  we use three types of information as rules. for the model-based method  we utilize the hmm model. as for the bayesian method  we assume the first name and the last name of a candidate person name are independent  and use naive bayesian method to assess a confidence to the candidate person name. our method not only fits on person entity but also other types of name entities. readers can refer to  for more details. 
1 time discovery 
we consider two kinds of time that are important for a web page: one is the page-born time  which indicates when the page is available on the web; the other is page-content time  which indicates when the event described in this page happened. although we can use the lmt  last modified time  to measure the former  we think it's not desirable for two reasons: first  a great number of pages don't have lmts or their lmts are randomly set; second  the time we are interested in is when the page can be accessed on the web rather than when it's born. therefore  we choose to use the time when our crawler finds this page as the page-born time. comparing to page-born time  page-content time is more valuable and more difficult to obtain. we try to uncover it from both the url and the page text. a page's url may contain date information. we choose a set of urls manually from the pages crawled and learn the time patterns from these urls. then we can obtain the time information from url by applying these patterns. we also observe that many news web pages contains the page-content times  which are often located just right after the title. based on this observation  we divide one page into a sequence of text quarks by vips  and extract the candidate time from small quarks. we compare the time from both url and text  and choose the earlier one as the page-content time. 
1 relation discovery 
after the extraction of the four types of entities  we utilize the unsupervised method to explore the relations among these entities. 

copyright is held by the author/owner s .  
www 1  april 1--1  1  beijing  china. 

given the redundancy of web pages  we employ entity cooccurence to locate the entity pairs which might own one relation. previous relation 

acm 1-1-1/1. 
1
www 1 / poster paper	april 1  1 ¡¤ beijing  china

analysis researches only use the context over the cooccurence as the representation of this pair. it works well in a small corpus  whereas in the case of web content mining its performance is not acceptable. thus  we use search engine to extend the representation: we choose some key terms from the cooccurence context using term distance as the selection criterion  then construct a query using these terms and send it to the search engine. we use the retrieved pages' content as the representative text. to the relation classification  we use the label propagation algorithm based on graph. 
1 entity-based page model 
we then introduce the entity-based page model. this model represents each page using the persons  locations  organizations  relations and time which are extracted from the page: p={ p1 ... pi    l1 ... lj    o1 ... ok    r1 ... ru   t}  where pi is a person entity  lj is a location entity  ok is a organization entity  ru is a relation pair and t is the page time. by combining all the page models  we can generate a global entity model of a set of web pages. it contains entity list from the page set  the entity relations based on cooccurence  the entity relations based on links between pages where the entities are found. this global entity model is denoted by g={entitylist  corelist  linkrelist}  where entitylist is the entity list  corelist is the cooccurence relation list  and linkrelist is the link relation list. further analysis on this global model can answer some interesting questions such as: how many web pages are there that describe events happened at location l  what is the activity track of person p in the past year  former researches can only get some specious answers from the bag-ofwords model  whereas our new entity-based model pays more attention to the entities and relations  this effort can help us to dig more knowledge from the pages' content. 
 
figure 1. page-location mapping. 
1 a proof of concept application 
we select the top 1 chinese news sites in http://www.alexa.com as the seed sites and crawl each site down to four levels depth. this crawling process continues for 1 days  from october 1  1. we obtain 1k pages each day  and a total of 1m pages are crawled. after the crawling  we extract the persons  locations and organizations from them. the page-born time of each page is set as the crawled time  whereas the pagecontent time is extracted as described previously. to extract the entity relations among entities  we choose the top 1 persons  from the totally 1 persons  sorted by document frequency as the candidate entities. and 1 relation pairs are found among these persons. the relation's weight is calculated and the relation pairs are classified into four categories: politics  culture  sports and entertainment. based on the former process  our system provides two basic services now: page-location mapping and person friend searching. in page-location mapping we use google map api to show the number of pages that contains a particular location. in person friend searching  user can explore the relation set extracted from the top 1 persons. the weight and type of each relation pair are available. we also show the change of weight during a period of time which usually implies the occurrence of some events at the inflexion. 
 
figure 1. person friend search. 
1. conclusion and future works 
in this paper  we briefly describe a new page model for web content mining. instead of using all the terms in the text  our model pays more attention to various kinds of named entities in a page  such as person  location  organization and time. we develop a series of entity extraction methods to obtain these entities and their attributes. we explore the relations among these entities  calculate the weight  classify and label these relation pairs. by applying the methods to a set of pages crawled over 1 days  we implement a demonstration system which is able to show pagelocation mapping and be used for person friend search. 
for future works  we have two research interests. one is to explore the evolution of entities and relations over time. a sudden change in the count of the entity appearance or in the relation weight may imply some important events on this entity or entity pair. another area is to focus on person activity tracking which combines person  time  location and action together. and some advance issue such as conflicting relations  malicious information should also be considered. 
acknowledgements. this work is supported by nsfc  1  and 1 project 1aa1  hksar cerg  cityu 
1h  and city university of hong kong srg  1 . 
