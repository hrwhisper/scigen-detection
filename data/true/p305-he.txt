query processing over graph-structured data is enjoying a growing number of applications. a top-k keyword search query on a graph finds the top k answers according to some ranking criteria  where each answer is a substructure of the graph containing all query keywords. current techniques for supporting such queries on general graphs suffer from several drawbacks  e.g.  poor worst-case performance  not taking full advantage of indexes  and high memory requirements. to address these problems  we propose blinks  a bi-level indexing and query processing scheme for top-k keyword search on graphs. blinks follows a search strategy with provable performance bounds  while additionally exploiting a bi-level index for pruning and accelerating the search. to reduce the index space  blinks partitions a data graph into blocks: the bilevel index stores summary information at the block level to initiate and guide search among blocks  and more detailed information for each block to accelerate search within blocks. our experiments show that blinks offers orders-of-magnitude performance improvement over existing approaches.
categories and subject descriptors: h.1  information search and retrieval : search process; h.1  content analysis and indexing : indexing methods.
general terms: algorithms  design.
keywords: keyword search  graphs  ranking  indexing.
1 introduction
query processing over graph-structured data has attracted much attention recently  as applications from a variety of areas continue to produce large volumes of graph-structured data. for instance  xml  a popular data representation and exchange format  can be regarded as graphs when considering idref/id links. in semantic web  two major w1c standards  rdf and owl  conform to node-labeled and edge-labeled graph models. in bioinformatics  many well-known projects  e.g.  biocyc  http://biocyc.org   build graph-structured databases. in other applications  raw data might

 the first and third authors are supported by nsf career award iis-1  an ibm ph.d. fellowship  and an ibm faculty award.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee.
sigmod'1  june 1  1  beijing  china.
copyright 1 acm 1-1-1/1 ...$1.
not be graph-structured at the first glance  but there are many implicit connections among data items; restoring these connections often allows more effective and intuitive querying. for example  a number of projects  1  1  1  1  1  enable keyword search over relational databases  where tuples are treated as graph nodes connected via foreign-key relationships. in personal information management  pim  systems  1  1   objects such as emails  documents  and photos are interwoven into a graph using manually or automatically established connections among them. the list of examples of graph-structured data goes on.
﹛ranked keyword search over tree- and graph-structured data  1  1  1  1  1  1  1  1  1  1  1  1  has attracted much attention recently for two reasons. first  this simple  user-friendly query interface does not require users to master a complex query language or understand the underlying data schema. second  many graphstructured data have no obvious  well-structured schema  so many query languages are not applicable.
﹛in this paper  we focus on implementing efficient ranked keyword searches on schemaless node-labeled graphs. on a large data graph  many substructures may contain the query keywords. following the standard approach taken by other systems  we restrict answers to those connected substructures that are  minimal   and further provide scoring functions that rank answers in decreasing relevance to help users focus on the most interesting answers.
challenges ranked keyword searches on schemaless graphs pose many unique challenges. techniques developed for xml  1  1  1   which take advantage of the hierarchical property of trees  no longer apply. also  lack of schema precludes many optimization opportunities  such as in  1  1   at compile-time and makes efficient runtime search much more critical. previous work in this area suffers from several drawbacks. first  many existing keyword search algorithms employ heuristic graph exploration strategies that lack strong performance guarantees and may lead to poor performance on certain graphs. second  existing algorithms for general graphs do not take full advantage of indexing. they only use indexes for identifying the set of nodes containing query keywords; finding substructures connecting these nodes relies on graph traversal. for a system supporting a large  ongoing workload of keyword queries  we argue that it is natural and critical to exploit indexes that provide graph connectivity information to speed up searches. lack of this feature can be attributed in part to the difficulty in indexing connectivity for general graphs  because a naive index would have an unacceptably high  quadratic  storage requirement. we discuss these issues in detail in sections 1 and 1.
contributions to overcome these difficulties  we propose blinks  bi-level indexing for keyword search   an indexing and query processing scheme for ranked keyword search over node-labeled directed graphs. our main contributions are the following:
  better search strategy. blinks is based on cost-balanced expansion  a new policy for the backward search strategy  which explores the graph starting from nodes containing query keywords . we show that this policy is optimal within a factor of m  the number of query keywords  of an  oracle  backward search strategy that magically knows how to determine the top k answers with minimum cost. this new strategy alleviates many problems of the original backward search proposed in .
  combining indexing with search. blinks augments search with an index  which selectively precomputes and materializes some shortest-path information. this index significantly reduces the runtime cost of implementing the optimal backward search strategy. at the same time  this index enables forward search as well  effectively making the search bidirectional. compared with the heuristic prioritization policy for bidirectional search proposed in   blinks is able to make longer and more directed forward jumps in search. to the best of our knowledge  blinks is the first scheme that exploits indexing extensively in accelerating keyword searches on general graphs.
  partitioning-based indexing. a naive realization of an index that keeps all shortest-path information would be too large to store and too expensive to maintain for large graphs. instead  blinks partitions a data graph into multiple subgraphs  or blocks: the bi-level index stores summary information at the block level to initiate and guide search among blocks  and more detailed information for each block to accelerate search within the block. this bi-level design allows effective trade-off between space and search efficiency through control of the blocking factor. blinks also addresses the problem of finding a graph partitioning that results in an effective bi-level index.
﹛experiments on real datasets show that blinks offers ordersof-magnitude performance improvement over existing algorithms. we also note that blinks supports sophisticated  realistic scoring functions based on both graph structure  e.g.  node scores reflecting pagerank and edge scores reflecting connection strengths  and content  e.g.  ir-style scores for nodes matching keywords .
﹛the rest of the paper is organized as follows. we formally define the problem and describe our scoring function in section 1. we review existing graph search strategies and propose the new cost-balanced expansion policy in section 1. to help illustrate how indexing helps search  we present a conceptually simple  but practically infeasible  single-level index and the associated search algorithm in section 1. in sections 1 and 1  we introduce our full bi-level index and search algorithm. we discuss optimizations in section 1 and present results of experiments in section 1. finally  we survey the related work in section 1 and conclude in section 1.
1 problem definition
data and query similar to  1  1   we are concerned with querying a directed graph g =  v e   where each node v ﹋ v is labeled with some text. for example  in the graph shown in figure 1 a   node 1 contains two keywords {b g}. a keyword search query q consists of a list of query keywords  w1 ... wm . we formally define an answer to q as follows:
﹛definition 1. given a query q =  w1 ... wm  and a directed graph g  an answer to q is a pair  where r and ni's are nodes  not necessarily distinct  in g satisfying the following properties:
 coverage  for every i  node ni contains keyword wi.
 connectivity  for every i  there exists a directed path in g from r to ni.

        a   the graph g  c   answer trees figure 1: example of query and answers.
﹛we call r the root of the answer and ni's the matches of the answer. the connectivity property requires that an answer must be a subtree whose root reaches all keywords. in figures 1  for graph g and query q =  c d   we find two answers t1 and t1 shown in
figure 1 c .
top-k query in this paper  we are concerned with finding the topranked answers to a query. answer goodness is measured by a scoring function  which maps an answer to a numeric score; the higher the score  the  better  the answer. we now give the semantics of a top-k query.
﹛definition 1. given a query and a scoring function s  the  best  score of a node r is the maximum s t  over all answers t rooted at r  or 1 if there are no such answers . an answer rooted at r with the best score is called a best answer rooted at r. a top-k query returns the k nodes in the graph with the highest best scores  and  for each node returned  the best score and a best answer rooted at the node.
﹛note that in the definition above  the k best answers have distinct roots. we have several reasons for choosing this distinct-root semantics. first  this semantics guards against the case where a  hub  node pointing to many nodes containing query keywords becomes the root for a huge number of answers. these answers overlap and each carries very little additional information from the rest. as a concrete example  suppose we search for  privacy    mining   and  sensor  in a publication data graph with the intention of finding authors who publish in all three areas. say an author has published n1 papers with titles containing  privacy   n1 papers containing  mining   and n1 papers containing  sensor.  this author would be the root of n1 ℅n1℅n1 answers; if n1℅n1℅n1 is close to k  the top k answers would not be very informative. granted  there might be times when we are actually interested more in the combination of three papers than in the author  but accommodating such cases is not difficult: given an answer  which is the best  or one of the best  at its root   users can always choose to further examine other answers with this root.
﹛a second reason for the distinct-root semantics is more technical: it enables more effective indexing. we defer more discussion of this point to section 1.
scoring function many scoring functions have been proposed in the literature  e.g.   1  1  1  1  1  1  1  1  . since our primary focus is indexing and query processing  we will not delve into the specifics here. instead  we provide a general definition for our scoring function  and discuss the features and properties relevant to efficient search and indexing.
﹛our scoring function considers both graph structure and content  and incorporates several state-of-the-art measures developed by database and ir communities. formally  we define the score of an answer for query  w1 ... wm  as
  where s‘p r ni  denotes the shortest-path distance from root r to match ni
{e}
figure 1: answers with different tree shapes.
based on some non-negative graph distance measure. the input to f ﹞  is the sum of three score components  which respectively capture the contribution to the score from  1  the answer root   1  the matches  and  1  the paths from the answer root to the matches. the component score functions s‘r  s‘n  and s‘p incorporate measures based on both graph structure  e.g.  node scores reflecting pagerank and edge distances reflecting connection strengths  and content  e.g.  ir-style tf/idf scores for matches .
our scoring function has two properties worth mentioning:
  match-distributive semantics. in the definition of s t  above  the net contribution of matches and root-match paths to the final score can be computed in a distributive manner by summing over all matches. consequently  all root-match paths contribute independently to the final score  even if these paths may share some common edges. our semantics agrees with  but contrasts with some of other systems  e.g.   1  1  1 . those systems score an answer by the total edge weight of the answer tree spanning all matches; therefore  each edge weight is counted only once  even if the edge participates in multiple rootmatch paths. for example  these systems would rank the two answers in figure 1 equally  assuming identical distances along all edges   whereas our scoring function would prefer the answer on the right  as the connection between its root and matches is intuitively tighter. these two semantics also have very different implications on the complexity of search and indexing  which we discuss further in section 1.
  graph-distance semantics. in the definition of s t  above  the score contribution of a root-match path  s‘p r ni   is defined to be shortest-path distance from the root to the match in the data graph  where edges have non-negative distances. this semantics  also used by   for example  is intuitive and clean  and allows us to reduce part of the keyword search problem to the classic shortest-path problem. most of our algorithms and data structures assume this semantics; we point out some exceptions in section 1  where this assumption is not required.
an assumption for convenience for simplicity of presentation  we ignore for now the root and match components of the score  and focus only on  the contribution from the rootmatch paths. given non-negative distance assignments for edges in the data graph  our problem now reduces to that of finding k nodes  where each node can reach all query keywords and the sum of its graph distances to these keywords-which we call the combined distance  of the node to query keywords -is as small as possible.
﹛this assumption is for convenience only and does not affect the generality of our results. we discuss how incorporate the root and match components back into the scoring function in section 1.
1 towards optimal graph search strategies
in this section  we discuss the search strategy of blinks on a high level and compare it qualitatively with previous approaches.
backward search in the absence of any index that can provide graph connectivity information beyond a single hop  we can answer the query by exploring the graph starting from the nodes containing at least one query keyword-such nodes can be identified easily through an inverted-list index. this approach naturally leads to a backward search algorithm  which works as follows.

figure 1: an example where distance-balanced expansion across clusters performs poorly.
1. at any point during the backward search  let ei denote the set of nodes that we know can reach query keyword ki; we call ei the cluster for ki.
1. initially  ei starts out as the set of nodes oi that directly contain ki; we call this initial set the cluster origin and its member nodes keyword nodes.
1. in each search step  we choose an incoming edge to one of previously visited nodes  say v   and then follow that edge backward to visit its source node  say u ; any ei containing v now expands to include u as well. once a node is visited  all its incoming edges become known to the search and available for choice by a future step.
1. we have discovered an answer root x if  for each cluster ei  either x ﹋ ei or x has an edge to some node in ei.
the first backward keyword search algorithm was proposed by bhalotia et al. . their algorithm uses the following two strategies for choosing what to visit next. for convenience  we define the distance from a node n to a set of nodes n as the shortest distance from n to any node in n.
  equi-distance expansion in each cluster: this strategy decides which node to visit for expanding a keyword. intuitively  the algorithm expands a cluster by visiting nodes in order of increasing distance from the cluster origin. formally  the node u to visit next for cluster ei  by following edge u ↙ v backward  for some v ﹋ ei  is the node with the shortest distance  among all nodes not in ei  to oi.
  distance-balanced expansion across clusters: this strategy decides the frontier of which keyword will be expanded. intuitively  the algorithm attempts to balance the distance between each cluster's origin to its frontier across all clusters. specifically  let  u ei  be the node-cluster pair such thatand the distance from u to oi is the shortest possible. the cluster to expand next is ei.
bhalotia et al.  did not discuss the optimality of the above two strategies. here  we offer  to the best of our knowledge  the first rigorous investigation of their optimality. first  we establish the optimality of equi-distance expansion within each cluster  the proof can be found in  .
﹛theorem 1. an optimal backward search algorithm must follow the strategy of equi-distance expansion in each cluster.
﹛on the other hand  the second strategy employed in   distancebalanced expansion across clusters  may lead to poor performance on certain graphs. figure 1 shows one such example. suppose that {k1} and {k1} are the two cluster origins. there are many nodes that can reach k1 with short paths  but only one edge into k1 with a large weight  1 . withdistance-balanced expansion across clusters  we would not expand the k1 cluster along this edge until we have visited all nodes within distance 1 to k1. it would have been unnecessary to visit many of these nodes had the algorithm chosen to expand the k1 cluster earlier.
bidirectional search to address the above problem  kacholia et al.  proposed a bidirectional search algorithm  which has the option of exploring the graph by following forward edges as well.
the rationale is that  for example  in figure 1  if the algorithm is allowed to explore forward from node u towards k1  we can identify u as an answer root much faster. to control the expansion order  kacholia et al. prioritize nodes by heuristic activation factors  which intuitively estimate how likely nodes can be answer roots. while this strategy is shown to perform well in multiple scenarios  it is difficult to provide any worst-case performance guarantee. the reason is that activation factors are heuristic measures derived from general graph topology and parts of the graph already visited; they may not accurately reflect the likelihood of reaching keyword nodes through an unexplored region of the graph within a reasonable distance. without additional connectivity information  forward expansion may be just as aimless as backward expansion.
our approach is there any hope of having a simple search strategy with good performance guarantees  we answer in the affirmative with a novel approach based on two central ideas: first  we propose a new  cost-balanced strategy for controlling expansion across clusters  with a provable bound on its worst-case performance. second  we use indexing to support forward jumps in search. indexing allows us to determine whether a node can reach a keyword and what the shortest distance is  thereby eliminating the uncertainty and inefficiency of step-by-step forward expansion. the use of indexing will be discussed in detail in following sections; here  we describe our new cost-balanced expansion strategy and prove its optimality.
  cost-balanced expansion across clusters: intuitively  the algorithm attempts to balance the number of accessed nodes  i.e.  the search cost  for expanding each cluster. formally  the cluster ei to expand next is the cluster with the smallest cardinality.
this strategy is intended to be combined with the equi-distance strategy for expansion within clusters: once we choose the smallest cluster to expand  we then choose the node with the shortest distance to this cluster's origin.
﹛to establish the optimality of an algorithm a employing these two expansion strategies  we consider an optimal  oracle  backward search algorithm p. as shown in theorem 1  p must also do equi-distance expansion within each cluster. however  in addition  we assume that p  magically  knows the right amount of expansion for each cluster such that the total number of nodes visited by p is minimized. obviously  p is better than the best practical backward search algorithm we can hope for. although a does not have the advantage of the oracle algorithm  we show in the following theorem that a is m-optimal  where m is the number of query keywords  the complete proof can be found in  . since most queries in practice contain very few keywords  the cost of a is usually within a constant factor of the optimal algorithm.
﹛theorem 1. the number of nodes accessed by a is no more than m times the number of nodes accessed by p  where m is the number of query keywords.
﹛in following sections  we describe the top-k keyword search algorithms that leverage the new search strategy  equi-distance plus cost-balanced expansions  as well as indexing to achieve good query performance.
1 searching with a single-level index
before presenting the full blinks  we first describe a conceptually simple scheme to help illustrate benefits of our search strategy and indexing. this scheme works well for small graphs  but is not practical on large graphs. the full blinks  presented in sections 1 and 1  is designed to scale on large graphs.

figure 1: keyword-node lists and node-keyword map.
1 a single-level index
motivation and index structure for each cluster ei  the standard way of implementing equi-distance backward expansion is to maintain a priority queue of nodes ordered by their distances from keyword ki. the queue represents a  frontier  in exploring ki  which may grow exponentially in size even for sparse graphs. the time complexity is also high  as it takes o logn  time to find the highest-priority node  where n is the size of the queue. our goal is to reduce the space and time complexity of search.
﹛a common approach to enhance online performance is to perform some offline computation. we pre-compute  for each keyword  the shortest distances from every node to the keyword  or  more precisely  to any node containing this keyword  in the data graph. the result is a collection of keyword-node lists. for a keyword w  lkn w  denotes the list of nodes that can reach keyword w  and these nodes are ordered by their distances to w. each entry in the list has four fields  dist node first knode   where dist is the shortest distance between node and a node containing w; knode is a node containing w for which this shortest distance is realized; first is the first node on the shortest path from node to knode.1 in figure 1  we show some parts of the keyword-node lists built for the graph in figure 1  assuming all edges have weight 1 . as an example  in the list for keyword b  the first entry is  1 v1 v1 v1   which reflects the fact that v1 can reach the keyword b with distance 1 and first and knode happen to be v1 itself. the last entry
 1 v1 v1 v1  reflects the fact that the shortest path from v1 to b is v1 ↙ v1 ↙ v1 with distance 1.
﹛furthermore  as motivated in section 1  we would like to augment backward search with forward expansion  so that we can find answers faster. in previous approaches  forward expansion follows node-by-node graph exploration with little guidance. can forward expansion be made faster and more informed 
﹛we pre-compute  for each node u  the shortest graph distance from u to every keyword  and organize this information in a hash table called node-keyword map  denoted mnk. given a node u and a keyword w  mnk u w  returns the shortest distance from u to w  or ﹢ if u cannot reach any node that contains w. the hash entry for  u w  can contain  in addition to dist  the shortest distance   first and knode  which are defined identically as in lkn and used for the same purposes. figure 1 also shows the node-keyword map. in fact  the information in mnk u w  can be derived from lkn w . however  it takes linear time to search lkn w  for the shortest distance between u and w  while with mnk u w   the operation can be completed in practically o 1  time.
﹛we call the duo of keyword-node lists and node-keyword map a single-level index because the index is defined over the entire

data graph  as opposed to the bi-level index to be introduced in section 1 . it is easy to see that both the keyword-node lists and the node-keyword map contain as many as n ﹞k entries  where n is the number of nodes  and k is the number of distinct keywords in the graph. in many applications  k is on the same scale as the number of nodes  so the space complexity of the index comes to o n1   which is clearly infeasible for large graphs. the bi-level index we propose in section 1 addresses this issue.
index construction the single-level index can be populated by backward expanding searches starting from keywords. to compute the distances between nodes and keywords  we concurrently run n copies of dijkstra's single source shortest path algorithm in a backward expanding fashion  one for each of the n nodes in the graph. this process is similar to the keyword query algorithm given by banks   except that we are creating an index instead of answering online queries. we omit the detailed algorithm here. note that the time complexity of this algorithm is o n1   which is high for large graphs. our results in section 1 also reduce this complexity.
﹛the single-level index can be used for any scoring function with distinct-root and match-distributive semantics. however  the index construction algorithm outlined above additionally assumes the graph-distance semantics  cf. section 1 .
1 search algorithm with single-level index
we present searchslinks  the algorithm for searching with singlelevel index  in algorithm 1. this algorithm assumes a scoring function with distinct-root and match-distributive semantics; it does not assume the graph-distance semantics  cf. section 1 .
expanding backward given a query  w1 ﹞﹞﹞  wm   we use a cursor to traverse each keyword-node list lkn wi . cursor ci advances on list lkn wi  by calling next  line 1   which returns the next node in the list  together with its shortest distance to keyword wi. by construction  the list gives the equi-distance expansion order in each cluster. across clusters  we pick a cursor to expand next in a round-robin manner  line 1   which implements cost-balanced expansion among clusters. these two together ensure optimal backward search.
expanding forward in addition  we use the node-keyword map mnk for forward expansion in a direct fashion. as soon as we visit a node  we look up its distance to the other keywords  line 1 . using this information we can immediately determine if we have found the root of an answer. more specifically  for each node we visit we maintain a structure  where root is the node visited  and disti is the distance from the node to keyword wi. if any disti is ﹢  then root cannot possibly be the root of an answer  because it cannot reach wi. on the other hand  if none of dist1 ﹞﹞﹞  distm is ﹢  we know we have an answer  line 1  where sumdist u  is the combined distance from u to keywords computed as pmi disti .
stopping how do we know we have found all top k answers  we maintain a pruning threshold 而prune  which is the current k-th shortest combined distance among all known answer roots  provided that there are at least k answers . for a new answer to be in the top k  its root must have combined distance no greater than 而prune. meanwhile  due to equi-distance expansion in each cluster  we know that any unvisited node will have combined distance of at least .peekdist    where peekdist   is the next distance to be returned by a cursor. if this lower bound exceeds 而prune  we can stop the search  line 1 .

algorithm 1: searching with the single-level index.

variables: r: nodes visited; initially  . a: answers found; initially  .
而prune: pruning threshold; initially ﹢.
1 searchslinks w1 ... wm  begin
1 foreach i ﹋  1 m  do
1 ci ↘ new cursor lkn wi  1 ;
1 while  j ﹋  1 m  : cj.peekdist   do
1 i ↘ pick from  1 m  in a round-robin fashion;
1 ;
1 then visitnode i u d ;
1.peekdist     而prune then
1 exit and output the top k answers in a;
1 output up to top k answers in a;
1 end
1 visitnode i u d  begin
1 if r.contains u  then return;	// already visited
1;
1
1	foreach j ﹋  1 i  ﹍  i m  do	// expand forward 1	r u .disti ↘ mnk u wi ;
1 if sumdist u    ﹢ then	// answer found
1 a.add r u  ;
1 if |a| ≡ k then
而prune ↘ the k-th largest of {sumdist v  | v ﹋ a}
1 end

discussion compared with previous work that does not use index  searchslinks finds the top k answers in a time- and spaceefficient manner:  1  the current state of graph exploration is managed by m cursors instead of m priority queues.  1  finding the next node to explore is much faster from a cursor than from a priority queue.  1  forward expansion using the node-keyword map allows the search to converge on answers faster  which also translates to earlier stopping.
connection to the threshold algorithm keen readers might have noticed a resemblance between searchslinks and the threshold algorithm  ta  proposed by fagin et al. . ta arises in the context of finding objects with top overall scores  which are computed over m scores  one for each of m attributes. ta assumes that for each attribute  there is a list of objects and their scores under that attribute  sorted in descending score order. ta finds the top k objects by visiting the m sorted lists in parallel  and performing random accesses on the lists to find scores for other attributes. ta has been proven optimal in terms of number of objects visited  assuming the aggregate function that combines the m scores is monotone .
﹛with the single-level index  the keyword search problem can be framed as one addressed by ta. here  each object corresponds to a node in the graph  and an object's score under an attribute corresponds to the shortest distance between the node and a keyword. algorithm searchslinks conducts  1  equi-distance expansion for each keyword  and  1  cost-balanced expansion across keywords. clearly   1  is embodied by the problem definition of ta  where lists are sorted  and  1  is embodied by the fact that ta visits the lists in parallel. according to our analysis in section 1  a keyword search algorithm is optimal if it follows  1  and  1 . although we had arrived at this optimality result for general keyword search without assuming indexing  our conclusion coincides with the optimality of the ta algorithm when a single-level index is used.

figure 1: example of portals and blocks.
1 bi-level indexing in blinks
as motivated in section 1  a naive realization of the single-level index  which includes the keyword-node lists and the node-keyword map  is impractical for large graphs: the index is too large to store and too expensive to construct. to address this problem  blinks uses a divide-and-conquer approach to create a bi-level index.
﹛blinks partitions a data graph into multiple subgraphs  or blocks. a bi-level index consists of a top-level block index  which stores the mapping between keywords and nodes to blocks  and an intrablock index for each block  which stores more detailed information within a block. we show that the total size of the bi-level index is a fraction of that of a single-level index.
﹛we discuss the intra-block index in section 1  and the block index in section 1. to create the bi-level index  we need to first decide how to partition the graph into blocks; the partitioning strategy is presented in section 1. before we proceed  however  we need to introduce the concept of portal nodes in order to clarify what we mean by partitioning of graph into blocks.
partitioning by portal nodes graph partitioning has been studied for decades in many fields. one can partition a graph by edge separators or node separators. in either case  we need to maintain the set of separators in order to handle the case where an answer in general may span multiple partitions. we choose node-based partitioning for two reasons.  1  the total number of separators is much smaller for node-based partitioning than edge-based partitioning. therefore  there is less information to store for separators  and during search  we need to cross fewer separators  which is more efficient.  1  our keyword search strategy considers nodes as the basic unit of expansion  so using node-based partitioning makes the implementation easier.
﹛definition 1. in a node-based partitioning of a graph  we call the node separators portal nodes  or portals for short . a block consists of all nodes in a partition as well as all portals incident to the partition. for a block  a portal can be either  in-portal  or  out-portal  or both.
  in-portal: it has at least one incoming edge from another block and at least one outgoing edge in this block.   out-portal: it has at least one outgoing edge to another block and at least one incoming edge from this block.
﹛this definition can be illustrated by an example in figure 1. the dotted line represents the boundary of blocks. node v1  v1 and v1 are hence portal nodes  and they appear in the intra-block index of all blocks they belong to. for block b1  v1 is an out-portal. imagine we are doing backward expansion across blocks. through v1  we can only expand search from other blocks back into block b1. however  v1 is both in-portal and out-portal for both blocks b1 and b1; the expansion can go both ways.
1 intra-block index
in this section  we describe the intra-block index  ib-index   which indexes information inside a block. for each block b  the ib-index consists of the following data structures:
  intra-block keyword-node lists: for each keyword w  lkn b w  denotes the list of nodes in b that can reach w without leaving b  sorted according to their shortest distances  within b  to w  or more precisely  any node in b containing w .
  intra-block node-keyword map: looking up a node u ﹋ b together with a keyword w in this hash map returns mnk b u w   the shortest distance  within b  from u to w  ﹢ if u cannot reach w in b .
  intra-block portal-node lists: for each out-portal p of b  lpn b p  denotes the list of nodes in b that can reach p without leaving b  sorted according to shortest distances  within b  to p.
  intra-block node-portal distance map: looking up a node u ﹋ b in this hash map returns dnp b u   the shortest distance  in b  from a node u to the closest out-portal of b  ﹢ if u cannot reach any out-portal of b .
we next describe these data structures in more detail.
keyword-node lists and node-keyword map structures lkn and mnk are identical to those introduced in section 1  with the only difference that they are restricted to a block. partitioning implies that the shortest distances stored in lkn and mnk are not necessarily globally the shortest. for example  mnk b u w  = ﹢ means there is no path local to block b from u to a node in b containing w; however  it is still possible for u to reach some keyword node outside b  or even for u to reach some keyword node inside b through some path that leaves b and then comes back. clearly  the local information about shortest paths cannot be used directly for finding top-k answers.
﹛we can use the same procedure for building the single-level index in section 1 to build the intra-block keyword-node lists and the node-keyword map. instead of the entire graph  the procedure simply operates on each block. for block b  the data structures are of size o nb ﹞ kb   where nb is the number of nodes in the block  and kb is the number of keywords that appear in the block. with the assumption kb = o nb   the index size comes to o nb1 . in practice  the number of entries is likely to be much smaller than nb1  as not every node and every keyword are connected.
portal-node lists and node-portal distance map the lpn lists are similar to the lkn lists. the difference is that lpn stores the shortest path information between nodes and out-portal nodes  instead of between nodes and keywords. for an out-portal p ﹋ b  each entry in lpn b p  consists of fields  dist node first   where dist is the shortest distance from node to p  and first is the first node on the shortest path. for example  in figure 1  v1 is an outportal and can reach another portal v1 through the shortest path v1 ↙ v1 ↙ v1 with the corresponding entry  1 v1 v1 .
﹛the primary purpose of lpn is to support cross-block backward expansion in an efficient manner  as an answer may span multiple blocks through portals. since we search mainly in the backward direction  we do not index connectivity between in-portals and nodes. the dnp map gives the shortest distance between a node and its closest out-portal within a block. this distance is used by the search algorithm  to be discussed in section 1  in lower bounding node-keyword distances  which are useful in pruning.
﹛lpn can be constructed simply by running a standard singlesource shortest-path algorithm from each out-portal of a block. information in dnp can be easily computed with the results of the shortest-path algorithms. the lpn lists for a block b have a total
dist  node  first
lpn b1 v1 
lpn b1 v1 
	...	...
figure 1: the portal-node lists of b1.
size of o nb ﹞ pb   where nb is the block size and pb is the number of out-portal nodes in a block. since pb is usually much smaller than nb  these lists are smaller than keyword-node lists. the size of dnp is only o nb .
1 block index
the block index is a simple data structure consisting of:
  keyword-block lists: for each keyword w  lkb w  denotes the list of blocks containing keyword w  i.e.  at least one node in the block is labeled with w. in the example of figure 1  if block b1 does not contain the keyword a  we have lkb a  = {b1}; keyword d appears in both blocks  so lkb d  = {b1 b1}; the portal v1 between b1 and b1 contains b  so lkb b  = {b1 b1}.
  portal-block lists: for each portal p  lpb p  denotes the list of blocks with p as an out-portal. in figure 1  v1 resides in both b1 and b1 as an out-portal  so lpb v1  = {b1 b1}. but v1 is only an out-portal of b1  so lpb v1  = {b1}.
﹛the keyword-block lists are used by the search algorithm to start backward expansion in relevant blocks. the portal-block lists are used by the search algorithm to guide backward expansion across blocks. note that with the portal-block lists  it is not necessary for each node to remember which block it belongs to; during backward expansion it should always be clear what the current block is.
﹛construction of the block index is straightforward and we omit it for brevity. let n‘b be the average block size and k‘b be the average number of keywords in a block. since each block will appear in k‘b linked lists  the space requirement for the lkb lists is o  n/n‘b k‘b . if we assume k‘b = o n‘b   this requirement comes to o n . let p be the total number of portals. the space requirement for the lpb lists is o  n/n‘b ﹞p   though in practice the space should be much lower because a portal is usually shared by only a handful of blocks.
1 graph partitioning
before creating indexes  we first partition the graph into blocks. as we will see in section 1  the partitioning strategy has an impact on both index size and search performance. in this section  we first discuss guidelines for good partitioning  and then describe two partitioning methods.
﹛effect of partitioning on index size is captured by the theorem below  which follows directly from the analysis in section 1:
﹛theorem 1. suppose a graph with n nodes is partitioned into b blocks. let nb denote the size of block b  and assume that the number of keywords in b is o nb . the overall size of the two-level index is o pb nb1 + bp .
on the other hand  exact effect of partitioning on search performance is rather difficult to quantify  because it is heavily influenced by a number of factors such as the graph structure  keyword distribution  query characteristics  etc. nonetheless  two guidelines generally apply:
  first  we want to keep the number of portals  p  low. in terms of space  according to theorem 1  p appears as the one of the terms in the space complexity of our index  and nb also increased with p  since blocks include portals . in terms of search performance  intuitively  the more portals we have  the more

algorithm 1: node-based partitioning algorithm.

1 partition g  begin
1 find an edge-based partitioning of g;
1 s ↘ edge separators of the edge-based partitioning;
1 p ↘  ;
1 foreach  u v  ﹋ s do
1w ↘ chooseportal u v ;
1p ↘ p ﹍ {w};	// mark as portal
s ↘ s    edges incident to w in s ;
1 return p;
1 end

often we have to cross block boundaries during search  which hurts performance.
  second  we want to keep blocks roughly balanced in size  because a more balanced partitioning tends to make index smaller. in theorem 1  the term pb nb1 is minimized when nb's are equal  given that pb nb is fixed.
﹛to complicate matters further  finding an optimal graph partitioning is np-complete . thus  we instead use a heuristic approach to partitioning based on the two guidelines above. as discussed earlier  we use node-based partitioning. however  the only heuristic partitioning algorithm for node-separators  has complexity as high as o n1 . thus  we propose two algorithms that first partition a graph using edge-separators and then convert edgeseparators into node-separators  i.e.  portals .
bfs-based partitioning we first propose a simple and fast partitioning method based on breadth-first search  bfs . to identify a new block  we start from an unassigned node and perform bfs; we add to this block any nodes that we visit but have not been previously assigned to any block  until the given block size is reached. in case that bfs ends but the block size is still too small  we pick another unassigned node and repeat the above procedure. at the end  we obtain an edge-based partitioning.
﹛to convert this partitioning into a node-based one  for each edge separator  u1 u1   which currently connects two different blocks b1 and b1  we shift the block boundary so that one of u1 and u1 is on the boundary  which makes this node a portal. the choice of portal is controlled by the following chooseportal logic:
  let s1 and s1 be the numbers of edge separators  in the edgebased partitioning  incident to u1 and u1  respectively.
  choose ui with the bigger si + 汛|bi| as a portal  where 汛 is tunable constant. chooseportal seeks to balance the block sizes and minimize the number of portals  in light of the two partitioning guidelines. once we make a node portal  it will belong to all blocks in which its neighboring nodes reside  allowing us to remove all of its incident edges separators from consideration. hence  choosing a node with more incident edge separators heuristically reduces the number of portals we need to choose later. at the same time  we prefer to choose the node in the larger block  which allows the smaller block to grow   in order to balance block sizes. parameter 汛 attempts to balance these two sometimes conflicting goals.
the complete partitioning algorithm is presented in algorithm 1.
metis-based partitioning the problem with the bfs-based partitioning is that it may start with a large and poor set of edge separators in the first place. hence  we instead try the metis algorithm   which aims to minimize the total weight of edge separators. the overall procedure is still given by algorithm 1  except that on line 1 we use metis instead of bfs for edge partitioning.
before feeding the graph into metis  we apply some heuristics to adjust edge weights1 to encourage subtrees to stay within the same blocks. in experiments  we will show that each method has respective advantage on different graphs.
1 searching with the bi-level index
we now present searchblinks  the algorithm for searching with the bi-level index  in algorithm 1. at a high level  searchblinks is quite similar to searchslinks in section 1: we generally follow our optimal backward search strategy  and expand in the forward direction when possible.
﹛however  the bi-level nature of our index introduces an obvious complication: since the graph has been partitioned  we no longer have the global distance information as with the single-level index. therefore:  1  a single cursor is no longer sufficient to implement backward expansion from a keyword cluster. multiple blocks may contain the same keyword  and simultaneous backward expansion is needed in multiple blocks.  1  backward expansion needs to continue across block boundaries  whenever in-portals are encountered  into possibly many blocks.  1  distance information in intra-block node-keyword maps can no longer be used as actual node-keyword distances  as shorter paths across blocks may exist.
﹛fortunately  the bi-level index has been carefully designed with these challenges in mind  and we show how to address these challenges in the remainder of this section.
backward expansion with queues of cursors to support backward expansion in multiple blocks while still taking advantage of the intra-block keyword-node lists  we use a queue qi of cursors for each query keyword wi. initially  for each keyword wi  we use the keyword-block list to find blocks containing wi  line 1 . a cursor is used to scan each intra-block keyword-node list for wi; these cursors are all put in queue qi  line 1 .
﹛when we reach an in-portal u of the current block  we need to continue backward expansion in all blocks that have u as their outportal. we can easily identify such blocks by the portal-block list  line 1 . for each such block b  we continue expansion from u using a new cursor  this time to go over the portal-node list in block b for out-portal u  line 1 . note that we initialize the cursor with a starting distance equal to the shortest distance from u to wi. the cursor will automatically add this starting distance to the distances that it returns. thus  the distances returned by the cursor will be the correct node-to-keyword distance instead of the node-to-portal distances in the portal-node list.
﹛it is possible for searchblinks to encounter the same portal node u multiple times. there are two possible cases:  1  u can be reached  backwards  by nodes containing the same keyword in different blocks;  1  u can be reached  backwards  by nodes containing different keywords. interestingly  we note that in case  1   we only need to expand across u when it is visited for the first time; subsequent visits from the same keyword can be  short-circuited.  the rationale behind this optimization is the optimal equi-distance expansion: the first visit to u from keyword wi must yield the global shortest distance from u to wi; therefore  any subsequent expansion through u from wi will always have longer starting distances. we implement this optimization using a bitmap crossed to keep track of whether u has ever been crossed starting from a query keyword  lines 1 and 1 . an immediate consequence of this optimization is the following lemma:
lemma 1. the number of cursors opened by searchblinks

1
 note that these weights are relevant to graph partitioning only  and are not the same as those used in the scoring function.

algorithm 1: search using bi-level indexes.

variables: r: potential and completed answers  initially  .
a: completed answers; initially  . 而prune: pruning threshold; initially ﹢. qi: a queue of cursors  prioritized by peekdist    lower peekdist   means higher priority . crossed i u : a bitmap indicating whether backward expansion of wi has ever crossed portal u  initially all false .
1 searchblinks w1 ... wm  begin
1 foreach i ﹋  1 m  do
1 qi ↘ new queue  ;
1 foreach b ﹋ lkb wi  do
1 qi.add new cursor lkn b wi  1  ;
1 while	do
1 i ↘ pickkeyword q1 ... qm ; 1 c ↘ qi.pop  ;
1 ;
1 visitnode i u d ;
1 if  crossed	then
1 foreach b ﹋ lpb u  do	// cross portal
1 qi.add new cursor lpn b u  d  ;
1 crossed i u  ↘ true;
1 if c.peekdist  	then qi.add c ;
1 if |a| ≡ k and pj qj.top  .peekdist     而prune and
 v ﹋ r   a : sumlbdist v    而prune then
1 exit and output the top k answers in a;
1 output up to top k answers in a;
1 end
1 visitnode i u d  begin
1 if r u  = ﹠ then	// not yet visited
1;
1 r u .disti ↘ d; 1 b ↘ the block containing u;
1 foreach j ﹋  1 i  ﹍  i m  do // expand forward
1 if dnp b u  ≡ mnk b u wi  then 1 r u .disti ↘ mnk b u wi ;
1 else if sumlbdist u    而prune then // can be pruned
1 return;
1 else if r u .disti = ﹠ then // previously visited 1 r u .disti ↘ d;
1 if sumdist u    ﹢ then	// answer found
1 a.add r u  ;
1 if |a| ≡ k then
而prune ↘ the k-th largest of {sumdist v  | v ﹋ a}
1 end

for each query keyword is o p   where p is the number of portals in the partitioning of the data graph.
﹛therefore  even though searchblinks can no longer use one cursor per keyword  it only has to use one priority queue of o |p|  cursors for each keyword  still far better than algorithms that do not use indexes and therefore must use a priority queue of the entire search frontier.
implementing optimal backward search strategy we implement the cost-balanced expansion strategy across clusters by the function pickkeyword  line 1   which selects the keyword with the least number of explored nodes.
﹛for each keyword  the prioritization used by the queue of cursor reflects the optimal equi-distance expansion strategy within clusters: the cursor with the highest priority in the queue is the one whose next distance is the smallest.
expandingforward even though the distance information in intrablock node-keyword maps is not always valid globally  sometimes we can still infer its validity  enabling direct forward expansion from a node u to a keyword wi. in particular  lines 1 and 1   we consult the intra-block node-portal distance map for the shortest distance from u to any out-portal in its block. if this distance turns out to be longer than the intra-block distance from u to wi  we conclude that the shortest path between u to wi indeed lies within the block.
pruning and stopping before describing the stopping and pruning conditions  we first discuss how to lower bound a node's combined distance to the keywords  using the information available to us in the bi-level index and implied by our search strategy. for a node u that has been visited but not yet determined as an answer root  we compute this lower bound sumlbdist u  as the sum of lower bounds for distances to individual keywords  i.e. 
 lbdistj u . recall from section 1 that for each node u visited we maintain a structure  where disti is the distance from the node to keyword wi. without the single-level index  we may not know every distj. however  we can still derive a lower bound as follows. let b be the block containing u. lbdistj u  = max{d1 d1}  where:
   bound from search  d1 = qj.top  .peekdist    or ﹢ if qj is empty. intuitively  because of equi-distance expansion  if we have not yet visited u from keyword wj  then u's distance to wj must be at least as far as the next node we intend to expand to in the cluster.
   bound from index  d1 = min{mnk b u wj  dnp b u }  where mnk b u wj  is the distance in b from u to wj  ﹢ means u cannot reach wj in b   and dnp b u  is u's distance to the closest out-portal of b  ﹢ means u has no path to any out-portal of b . intuitively  if the true shortest path from u to wi is within the block  the distance is simply mnk b u wj ; otherwise  the path has to go out through an out-portal  which makes the distance at least dnp b u .
﹛we maintain a pruning threshold 而prune just as in searchslinks. if the lower bound on a node's combined distance is already greater than 而prune  the node cannot be in the top k  lines 1 and 1 . the condition for stopping the search  line 1  is slightly more complicated: we stop if every unvisited node must have combined distance greater than 而prune  same condition as in searchslinks   and every visited non-answer node can be pruned.
1 optimizations and other issues
evaluating pruning and stopping conditions calculating the lower bound sumlbdist u  used in pruning and stopping conditions is expensive  because the quantity qj.top  .peekdist    which constantly changes during the search  can increase the lower bound for many nodes at the same time. since a weaker lowerbound does not affect the correctness of our algorithm  we can exploit the trade-off between the cost and accuracy of this calculation. weaker lower bounds can make pruning and stopping less effective  but they avoid expensive calculations and updates that slow down search generally. our approach is to lazily compute sumlbdist u  only when visiting u. we also maintain a priority queue to keep track of the smallest lower bound among all candidate answers  to facilitate checking of the pruning condition. it would be interesting to use more sophisticated data structures tailored toward maintaining such lower bounds  but it is beyond the scope of this paper. experiments show that our simple approach above provides a reasonable practical solution.
batch expansion one performance issue that arises in a direct implementation of searchblinks is that it switches a lot among cursors  and the code exhibits poor locality of access. hence  we relax the equi-distance expansion strategy by allowing a small  and tunable  number of nodes to be expanded from a cursor as a batch. this optimization slightly complicates the pruning and stopping conditions of the algorithm  and may result in some unnecessary node accesses. however  we found such overhead to be generally small compared with the benefit of improved locality.
recovering answer trees for clarity of presentation  the algorithms return only the roots of top k answers and their distances to each query keyword. in practice  users might want to see the matches and/or root-match paths of an answer. it is straightforward to extend the algorithms to return this additional information. the knode fields in keyword-node lists and node-keyword maps allow our algorithms to produce matches for answers with simple extensions  omitted  and without affecting space and time complexity. the first fields in keyword-node lists  node-keyword maps  and portal-node lists allow root-match paths to be reconstructed. doing so requires extra time linear in the total length of these paths; in addition  searchblinks needs to be extended to record the list of portals crossed to reach an answer root.
handling the full scoring function again  for clarity of presentation  our search algorithm has so far focused only on the component of the scoring function that deals with root-match paths. we now briefly discuss how the other score components  namely root and matches  recall section 1   can be incorporated. assume that the overall scoring function is 
  where 汐  汕  and 污 are tunable weighting parameters. first  when constructing keyword-node lists and nodekeyword maps  we treat each node v containing keyword w as being distance 汕污 s‘n v w  away from w. second  during the search  when an answer root r is identified  we add to its combined distance. the pruning and stopping conditions still work correctly because this quantity is non-negative.
effect of ranking semantics here  we briefly discuss the effect of ranking semantics on the complexity of search and indexing. first  we note that if the score function is a black-box function defined on a substructure of the graph  there is no feasible method of precomputation and materialization that can avoid exhaustive search. therefore  we must look for properties of the ranking that can be used to turn the problem tractable. in this paper  we have identified three such properties  cf. section 1 :
  distinct-root semantics. with this semantics  we can devise an index that precomputes and materializes  for each node  some amount of information whose size is independent of k  to support top-k queries. the reason is that this semantics effectively requires us to produce at most one answer rooted at each node. without this semantics  more information must be materialized or computed on the fly.
  match-distributive semantics. section 1 cited an example of a scoring function that is not match-distributive: some systems score an answer by the total edge weight of the answer tree spanning all matches; each edge has its weight counted exactly only once  no matter how many matches it leads to. multiplekeyword search in this setting is equivalent to the group steiner tree problem  1  1   which is np-hard. in contrast  with the match-distributive semantics  we can efficiently support multikeyword queries by an index that precomputes  independently for each node and for each keyword  the best path between the node and any occurrence of the keyword. without this semantics  it would be impossible to score an answer given such an index  because we cannot combine score components for any overlapping paths.
  graph-distance semantics. intuitively  with this semantics  we can take a root-to-match path  break it into components  precompute and materialize the component scores independently  and still be able to obtain the overall score by combining the component scores. taking advantage of this semantics  our bilevel index breaks the graph into more manageable blocks to reduce index size; distance information across blocks can be assembled together for paths spanning multiple blocks. without the graph-distance semantics  we would have to precompute scores for all possible root-to-match paths. our single-level index offers this option  but its size disadvantage is obvious compared with our bi-level index.
1 experimental results
we implemented blinks  and for the purpose of comparison  the bidirectional search algorithm   in java with the jgrapht library  http://jgrapht.sourceforge.net/ . the experiments are conducted on a smp machine with four 1ghz intel xeon processors and 1gb memory. here we present experimental results and discuss factors affecting the performance of the blinks algorithm.
1 dblp dataset
graph generation wefirst generate a node-labeled directed graph from the dblp xml data  http://dblp.uni-trier.de/xml/ . the original xml data is a tree in which each paper is a small subtree. to make it a graph  we add two types of non-tree edges. first  we connect papers through citations. second  we make the same author under different papers share a common node. the graph is huge  but mostly it is still a tree and not very interesting for graph search. to highlight the purpose of graph search  we make it more graphlike by  1  removing elements in each paper that are not interesting to keyword search  such as url  ee  etc.;  1  removing most papers not referencing other papers  or not being referenced by other papers. finally  we get a graph containing 1k papers  1k nodes  1k edges  and 1k distinct lower-cased keywords.
search performance we perform ranked keyword search using blinks and the bidirectional algorithms on the dblp graph. the query workload has various characteristics. table 1 lists 1 typical queries  and figure 1 shows the time it takes to find the top 1 answers using bidirectional and four configurations of blinks- with two possible  average  block sizes  |b| = 1  1  and two possible partitioning algorithms  bfs- and metis-based . each bar in figure 1 shows two values: the time it takes to find any 1 answers1  as the height of the lower portion1   and the time it takes to find the top 1 answers  as the full height of the bar . the first value exposes how fast a search algorithm can respond without considering answer quality. note that we do not use the measurement described in  as their measurement requires knowing the k-th final answer in advance  which is impossible in practice before a query is executed. to avoid a query taking too much time  we return whatever we have after 1 seconds. due to the wide range of response times  we plot the vertical axis logarithmically.

1
 or all answer if there are fewer than 1. 1
the values for q1 and q1 are too small to show.
queries# keyword nodesq1algorithm 1 1  1 q1michael database 1 q1kevin statistical 1 q1jagadish optimization 1 q1carrie carrier 1 q1cachera cached 1 q1jeff dynamic optimal 1 1 q1abiteboul adaptive algorithm 1 1 q1hector jagadish performance improving 1 1 q1kazutsugu johanna software performance 1 1 table 1: query examples
﹛as shown in figure 1  blinks outperforms the bidirectional search by at least an order of magnitude in most cases  which demonstrates the effectiveness of the bi-level index. it also shows that the number of keyword nodes  see table 1  is not the single most important factor affecting response time. for instance  although the two keywords in q1 appear in few nodes  the bidirectional search uses more time on q1 than q1-q1. there are actually two more fundamental factors  but they cannot be statically quantified by the number of keyword nodes. first is the size of the frontier expanded during the search. the number of keyword nodes only determines the initial frontier. once a frontier reaches nodes with large indegrees  the size of the priority queue increases dramatically. q1 belongs to this case. second is when we can safely stop search. it highly depends on pruning effectiveness  which depends on the quality of the answers obtained so far. for example  q1 has only one answer  the root element dblp   so no pruning bound  the score of the k-th answer  can be established to terminate search early.
﹛the other observation is that although the exact search space of a query depends on many factors  queries containing more keywords tend to have larger search spaces as each keyword has its own frontier. in the experiment  q1-q1 each contain two keywords  q1-q1 three  and q1-q1 four. the results of blinks show longer response time for queries with more keywords. we also compare blinks using different partitioning algorithms. in most cases  bfs-based partitioning shows better performance than metis-based one. however  it is not always true  shown in the next experiment on the imdb dataset. we also observe the impact of block size. generally speaking  with larger blocks  searches will involve fewer cursors. however  for the same query  the query time of larger block partitioning does not always outperform that of smaller one. actually  the query time is affected by many other factors  such as the loading of block indexes  the way the search space spans blocks  etc.
index performance now we examine the impact of block size the indexing performance of blinks  in terms of indexing time  number of portals  and index size  which are shown in figure 1 a    b   and  c   respectively. each figure displays results under five different configurations. the first four vary in their average block sizes  |b| = 1  1  1  and 1  and all use metis-based partitioning. the last one has |b| = 1 and uses the simpler bfs-based partitioning.

1 bidirect 1bfs 1bfs 1bfs  a  building time  b  portal number  c  number of index entries figure 1: performance on imdb figure 1: impact on indexing the imdb graph with various parameters.﹛figure 1 a  shows partitioning time and indexing time for each configuration. the first four configurations have similar partitioning time  which is dominated by the metis algorithm  while indexing time increases consistently when blocks become larger. this increasing trend is also observed in figure 1 c   where larger blocks lead to more index entries. the last configuration  1bfs  applies the simple bfs-based partitioning  so it needs much less partitioning time. but interestingly  it also takes much less indexing time than the fourth configuration  1   which uses metis and has the same average block size. this result can be explained by the dblp graph topology. as we mentioned earlier  dblp consists of a very flat and broad tree plus a number of cross-links. thus  the bfs-based algorithm is likely to produce flat and broad blocks in which paths are usually quite short. the time for building an intrablock index is mostly spent on traversing paths in the block  which is faster on shorter paths. accordingly  as shown in figure 1 c   intra-block indexes of such blocks have fewer entries. note that the bfs-based algorithm does not alway lead to faster indexing and smaller index size; experiments on the imdb dataset below offer an counter-example. finally  figure 1 b  shows that metis-based partitioning achieves a significant reduction in the number of portal nodes compared with bfs-based partitioning.
1 imdb dataset
graph generation we also generate a graph from the popular imdb database  http://www.imdb.com . in this experiment  we are interested in highly-connected graphs with few tree components. we generate the graph from the movie-link table using movie titles as nodes and links between movies as edges. the graph contains 1k nodes  1k edges  and 1k distinct keywords.
search performance as different queries may have very different running times  we run a set of queries using bidirectional and six configurations of blinks  with three block sizes |b| = 1  1  and 1  each using bfs-based or metis-based partitioning . figure 1 shows the average response time  where each bar contains two readings with the same interpretation as figure 1. comparing neighboring bars with the same block size but different partitioning algorithms  we observe that bfs-based partitioning usually leads to worse query performance than metis-based partitioning. comparing bars with different block sizes but same partitioning algorithm  we see larger blocks usually lead to better performance.
index performance now we discuss the index performance of blinks on highly-connected graphs. figure 1 again reports three measurements: indexing time  number of portals  and index size under the same configurations as figure 1. since the imdb graph is relatively small  partitioning is fast. however  indexing time on this graph is comparable to the much larger dblp graph. the reason lies in the imdb graph topology  where the structure of each block is usually more complex than in the dblp graph. therefore  it takes more time to create index for each block  and each intrablock index tends to have more entries  as shown in figure 1 c . another issue is that the indexing time and size with the bfs-based algorithm are usually worse than those of the metis-based algorithm. comparing figures 1 and 1  we note that the graph topology plays an important role on blinks: bfs works fine on simpler graphs  but experiences difficulty on highly-connected graphs. as future work  it would be interesting to study how to use the characteristics of a graph to automate the choice of the partitioning strategy.
1 related work
the most related work  banks  1  1   has been discussed extensively in section 1. we outline other related work here. some papers  1  1  1  1  1  aim to support keyword search on xml data  which is a similar but simpler problem. they are basically constrained to tree structures  where each node only has a single incoming path. this property provides great optimization opportunities . connectivity information can also be efficiently encoded and indexed. for example  in xrank   the dewey inverted list is used to index paths so that a keyword query can be evaluated without tree traversal. however  in general graphs  tricks on trees cannot be easily applied.
﹛keyword search on relational databases  1  1  1  1  1  has attracted much interest. conceptually  a database is viewed as a labeled graph where tuples in different tables are treated as nodes connected via foreign-key relationships. note that a graph constructed this way usually has a regular structure because schema restricts node connections. different from the graph-search approach in banks  dbxplorer  and discover  construct join expressions and evaluate them  relying heavily on the database schema and query processing techniques in rdbms.
﹛because keyword search on graphs takes both node labels and graph structure into account  there are many possible strategies for ranking answers. different ranking strategies reflect designers' respective concerns. focusing on search effectiveness  that is  how well the ranking function satisfies users' intention  several papers  1  1  1  1  adopt respective ir-style answer-tree ranking strategies to enhance semantics of answers. different from our paper  search efficiency is often not the basic concern in their designs. in ir-styled ranking  edge weights are usually query-dependent  which makes it hard to build index in advance.
﹛to improve search efficiency  many systems  such as banks  propose ways to reduce the search space. some of them define the score of an answer as the sum of edge weights. in this case  finding the top-ranked answer is equivalent to the group steiner tree problem   which is np-hard. thus  finding the exact top k answers is inherently difficult. recently   shows that the answers under this scoring definition can be enumerated in ranked order with polynomial delay under data complexity.  proposes a method based on dynamic programming that targets the case where the number of keywords in the query is small. blinks avoids the inherent difficulty of the group steiner tree problem by proposing an alternative scoring mechanism  which lowers complexity and enables effective indexing and pruning.
﹛in the sense that distance can be indexed by partitioning a graph  our portal concept is similar to hub nodes in . hub nodes were devised for calculating the distance between any two given nodes  and a global hub index is built to store the shortest distance for all of hub node pairs. in blinks  we do not precompute such global information  and we search for the best answers by navigation through portals.
1 conclusion
in this paper  we focus on efficiently implementing ranked keyword searches on graph-structured data. since it is difficult to directly build indexes for general schemaless graphs  the existing approaches rely heavily on graph traversal at runtime. lack of more knowledge about the graph structure also leads to less effective pruning during search. to address these problems  we introduce an alternative scoring function that makes the problem more amenable to indexing  and propose a novel bi-level index that uses blocking to control the indexing complexity. we also propose the cost-balanced expansion policy for backward search  which provides good theoretical guarantees on search cost. our search algorithm implements this policy efficiently with the bi-level index  and further integrates forward expansion and more effective pruning. results on experiments show that blinks improves the query performance by more than an order of magnitude.
﹛index maintenance is an interesting direction for future work. it includes two aspects. first  when the graph is updated  we need to maintain the indexes. in general  adding or deleting an edge has global impact on shortest distances between nodes. a huge number of distances may need to be updated for a single edge change  which makes storing distances for all pairs infeasible. blinks localizes index maintenance to blocks  and we believe this approach will help lower the index maintenance cost. second  by monitoring performance at runtime  we may dynamically change graph partitions and indexes in order to adapt to changing data and workloads.
