   ten groups participated in the trec-1 cross-language information retrieval track  which focussed on retrieving arabic language documents based on 1 queries that were originally prepared in english. french and arabic translations of the queries were also available. this was the first year in which a large arabic test collection was available  so a variety of approaches were tried and a rich set of experiments performed using resources such as machine translation  parallel corpora  several approaches to stemming and/or morphology  and both pre-translation and post-translation blind relevance feedback. on average  forty percent of the relevant documents discovered by a participating team were found by no other team  a higher rate than normally observed at trec. this raises some concern that the relevance judgment pools may be less complete than has historically been the case.
1 introduction
for the 1 text retrieval conference  trec-1   the cross-language information retrieval  clir  task was to utilize english  or french  queries against arabic documents. monolingual arabic experiment designs in which both the queries and the documents were in arabic were also supported. this was the eighth year in which non-english document retrieval has been evaluated at trec  and the fifth year in which cross-language information retrieval has been the principal focus of that work. in trec-1  retrieval of 1 topics against a mexican newspaper corpus was tested by four groups. spanish language retrieval was evaluated in trec-1  trec-1  another 1 topics for the same mexican corpus   and trec-1  where an european spanish corpus was used . in trec-1  a chinese language track was introduced using both newspaper  people's daily  and newswire  xinhua  sources from people's republic of china  and 1 chinese topics with an english translation supplied. the trec-1 corpus was represented with the gb character set of simplified chinese. the chinese monolingual experiments on this collection that were done in trec-1 and trec-1 sparked research into the application of chinese text segmentation to information retrieval using dictionary-based methods and statistical techniques  and simpler overlapping bigram segmentation methods were also found to be effective. trec-1  trec-1 and trec-1 had the first cross language tracks  which focussed upon european languages  english 
1
french  german  and later italian . following trec-1  the venue for european-language retrieval evaluation moved to europe with the creation of the cross-language evaluation forum  clef   first held in lisbon in september 1 . for trec-1  the clir task used chinese documents from hong kong. in distinction from the earlier trec-1 chinese corpus  these sources were written in the traditional chinese character set and encoded in big1. following trec-1 the evaluation of english-chinese retrieval moved to the ntcir evaluation that is coordinated by the national institute of informatics in japan  http://research.nii.ac.jp/ntcir/workshop/work-en.html .
1 task description
as in past trec clir evaluations  the principal task for each group was to match topics in one language  english or french  in this case  with documents in another language  arabic  and return a ranked list of the top 1 documents associated with each topic. participating groups were allowed to submit as many as five runs  with at least one using only the title and description field of the topic description. evaluation then proceeded by pooling ranks and manual examination of the pools by human judges to decide binary  yes/no  relevance for each document in the pool with respect to each topic. a suite of statistics were then calculated  with the mean  over 1 topics  uninterpolated average being the most commonly reported.
1 topics
twenty-five topic descriptions  numbered ar1-ar1  were created in english in a collaborative process between the ldc and nist. an example of a topic description is:
top
	num	number: ar1
title	local newspapers and the new press law in jordan desc	description:
has the jordanian government closed down any local newspapers due to the new press law  narr	narrative:
any articles about the press law in jordan and its effect on the local newspapers and the reaction of the public and journalists toward the new press law are relevant. the articles that deal with the personal suffering of the journalists are irrelevant.
/top
   through the efforts of edouard geoffrois of the french ministry of defense  the english topics were translated into french and made available to participants which wished to test french to arabic retrieval. the french version of the topic shown above is:
top
	num	number: ar1
title	les journaux locaux et la nouvelle loi sur la presse en jordanie desc	description:
le gouvernement jordanien a-t-il interdit un journal local a` cause de la nouvelle loi sur la

figure 1: example arabic document.
presse  narr	narrative:
tout article concernant la loi sur la presse en jordanie et ses effets sur les journaux locaux ainsi que la re¡äaction du public et des journalistes a` la nouvelle loi sur la presse est pertinent. les articles traitant des souffrances personnelles des journalistes ne sont pas pertinents. /top
   the linguistic data consortium also prepared an arabic translation of the topics  so participating teams also had the option of doing monolingual  arabic-arabic  retrieval.
1 documents
the document collection used in the trec-1 clir track consisted of 1 newswire stories that appeared on the agence france press  afp  arabic newswire between 1 and 1. the documents were represented in unicode and encoded in utf-1  resulting in a 1 mb collection. a typical document is shown in figure 1.
1 relevance judgments
the ten participating research teams shown in table 1 together produced 1 automatic cross-language runs with english queries  1 automatic cross-language runs with french queries  1 automatic monolingual runs with arabic queries  and 1 manual runs  one with english queries and one with arabic queries . from these  1 runs were selected from each team in a preference order recommended by the participants for use in forming assessment pools. the resulting pools were formed from 1 cross-language runs with english queries  1 cross-language run with french queries  and 1 monolingual runs with arabic queries. the top-ranked 1 documents for a topic in each of the 1 ranked lists were added to the judgment pool for that topic  duplicates were removed  and the documents then sorted in a canonical order designed to prevent the human judge from inferring the rank assigned to a document by any system. each document

figure 1: effect on 1 judged runs of removing  uniques  contributed by that run.
in the pool was then judged for topical relevance  usually by the person that had originally written the topic statement. the mean number of relevant documents that were found for a topic was 1.
   most documents remain unjudged when pooled relevance assessments are used  and the usual procedure is to treat unjudged documents as if they are not relevant. voorhees has shown that the preference order between automatic runs in the trec ad hoc retrieval task would rarely be reversed by the addition of missing judgments  and that the relative reduction in mean uninterpolated average precision that would result from removing  uniques   relevant documents found by only a single system  from the judgment pools was typically less than 1% . as figure 1 shows  this effect is substantially larger in the trec1 arabic collection  with 1 of the 1 judged automatic runs experiencing a relative reduction in mean uninterpolated average precision of over 1% relative when the  uniques  contributed by that run were removed from the judgment pool.
   figure 1 helps to explain this unexpected condition  illustrating that many relevant documents were found by only a single participating research team. for 1 of the 1 topics  more than half of the known relevant documents were ranked in the top-1 in runs submitted by only a single research team. for another 1 of the 1 topics  between 1 and 1 percent of their relevant documents were ranked in the top-1 by only one team.
   these results show a substantial contribution to the relevance pool from each site  with far less overlap than has been typical in previous trec evaluations. this limited degree of overlap could result from the following factors:
a preponderance of fairly broad topics for which many relevant documents might be found in the collection. the average of 1 relevant documents per topic is somewhat greater than the value typically seen at trec  1 or so .
the limitation of the depth of the relevance judgment pools to 1 documents  1 documents per run have typically been judged in prior trec evaluations .
the diversity of techniques tried by the participating teams in this first year of arabic retrieval experiments at trec  which could produce richer relevance pools.
a relatively small number of participating research teams  which could interact with the diversity

figure 1: unique relevant documents  by research team.
of the techniques to make it less likely that another team would have tried a technique that would find a similar set of documents.
the first two factors have occasionally been seen in information retrieval evaluations based on pooled assessment methodologies  trec  clef  and ntcir  without the high  uniques  effect observed on this collection. we therefore suspect that the dominant factors in this case may be the last two. but until this cause of the high  uniques  effect is determined  relative differences of less than 1% or so in unjudged and post hoc runs using this collection should be regarded as suggestive rather than conclusive. there is  of course  no similar concern for comparisons among judged runs since judgments for their  uniques  are available.
   as has been seen in prior evaluations in other languages  manual and monolingual runs provided a disproportionate fraction of the known relevant documents. for example  1% of the relevant documents that were found by only one team were found only by monolingual runs  while 1% were found only by cross-language runs.
1 results
table 1 summarizes the alternative indexing terms  the query languages  and  for cross-language runs  the sources of translation knowledge that were explored by the ten participating teams. all ten participating teams adopted a  bag-of-terms  technique based on indexing statistics about the occurrence of terms in each document. a wide variety of specific techniques were used  including language models  hidden markov models  vector space models  inference networks  and the pircs connectionist network. four basic types of indexing terms were explored  sometimes separately and sometimes in combination:
words. indexing word surface forms found by tokenizing at white space and punctuation requires no language-specific processing  except  perhaps  for stopword removal   but potentially desirable matches between morphological variants of the same word  e.g.  plural and singular forms  are
teamarabic terms indexedquery
langtranslation resources usedwordstemroot-grammtlexiconcorpustranslitbbnxa exxxhummingbirdxaiitxxxa exxjhu-aplxxa e fxnmsuxxa exqueensxxa exuc berkeleyxa exxu marylandxxxxa exxu massxxa exxu sheffieldxa e fx
table 1: configurations tested by participating teams.
precluded. as a result  word indexing yielded suboptimal retrieval effectiveness  by the mean uninterpolated average precision measure . many participating research teams reported results for word-only indexing  making that condition useful as a baseline.
stems. in contrast to english  where stems are normally obtained from the surface form of words by automatically removing common suffixes  both prefixes and suffixes are normally removed to obtain arabic stems. participating teams experimented with stemming software developed at three participating sites  iit  nmsu  and u maryland  and from two other sources  tim buckwalter and shereen khoja .
roots. arabic stems can be generated from a relatively small set of root forms by expanding the root using standard patterns  some of which involve introduction of infixes. stems generated from the same root typically have related meanings  so indexing roots might improve recall  possibly at the expense of precision  though . although humans are typically able to reliably identify the root form of an arabic word by exploiting context to choose between alternatives that would be ambiguous in isolation  automatic analysis is a challenging task. two participating teams reported results based on automatically determined roots.
character -grams. as with other languages  overlapping character -grams offer a useful alternative to techniques based on language-specific stemming or morphological analysis. three teams explored -grams  with values of ranging from 1.
term formation was typically augmented by one or more of the following additional processing steps:
character deletion. some unicode characters  particularly diacritic marks  are optional in arabic writing. this is typically accommodated by removing the characters when they are present  since their presence in the query but not the document  or vice-versa  might prevent a desired match.
character normalization. some arabic letters have more than one unicode representation because their written form varies according to morphological and morphotactic rules  and in some cases authors can use two characters interchangeably. these issues are typically accommodated by mapping the alternatives to a single normalized form.

figure 1: cross-language retrieval effectiveness  english queries formed from title+description fields  automatic runs.
stop-term removal. extremely frequent terms and other terms that system developers judge to be of little use for retrieval are often removed in order to reduce the size of the index. stop-term removal is most commonly done after stemming or morphological analysis in arabic because the highly productive morphology would otherwise result in impractically large stopword lists.
   nine of the ten participating research teams submitted cross-language retrieval runs  with all nine using a query-translation architecture. both of the teams that tried french queries used english as a pivot language for french-to-arabic query translation  so english-to-arabic resources were key components in every case. each team explored some combination of the following four types of translation resources:
machine translation systems. two machine translation systems were used:  1  a system developed by sakhr  available at http://tarjim.ajeeb.com  and often referred to simply as  ajeeb  or  tarjim    a system produced by ata software technology limited  available at http://almisbar.com  and sometimes referred to as  almisbar  or by the prior name  al-mutarjim  . at the time of the experiments  both offered only english-to-arabic translation. some teams used a machine translation system to directly perform query translation  others used translations obtained from one or both of these systems as one source of evidence from which a translated query was constructed. a mark in the  mt  column of table 1 indicates that one or more existing machine translation systems were used in some way  not that they were necessarily used to directly perform query translation.
translation lexicons. three commercial machine readable bilingual dictionaries were used: one marketed by sakhr  sometimes referred to as  ajeeb    one marketed by ectaco inc.   typically referred to as  ectaco    and one marketed by dar el ilm lilmalayin  typically referred to as  al mawrid  . in addition  one team  nmsu  used a locally produced translation lexicon.

figure 1: cross-language topic difficulty  uninterpolated average precision  base of each bar: median over 1 runs  top of each bar: best of the 1 runs .
parallel corpora. one team  bbn  obtained a collection of documents from the united nations that included translation-equivalent document pairs in english and arabic. word-level alignments were created using statistical techniques and then used as a basis for determining frequently observed translation pairs.
transliteration. one team  maryland  used pronunciation-based transliteration to produce plausible arabic representations for english terms that could not otherwise be translated.
   when multiple alternative translations were known for a term  a number of techniques were used to guide the combination of evidence  including:  1  translation probabilities obtained from parallel corpora   1  relative term frequency for each alternative in the collection being searched  and  1  structured queries. pre-translation and/or post-translation query expansion using blind relevance feedback techniques and pretranslation stop-term removal were also explored by several teams.
   to facilitate cross-site comparison  teams submitting automatic cross-language runs were asked to submit at least one run in which the query was based solely on the title and description fields of the topic descriptions. figure 1 shows the best recall-precision curve for this condition by team. all of the top-performing cross-language runs used english queries.
   as is common in information retrieval evaluations  substantial variation was observed in retrieval effectiveness on a topic-by-topic basis. figure 1 illustrates this phenomenon over the full set of crosslanguage runs  i.e.  not limited to title+description queries . for example  half of the runs did poorly on topic 1  which included specialized medical terminology  but at least one run achieved a perfect score on that topic. topic 1  by contrast  turned out to be problematic for all systems.
   no standard condition was required for monolingual runs  so figure 1 shows the best monolingual run by team regardless of the experiment conditions. several teams observed surprisingly small differences between monolingual and cross-language retrieval effectiveness. one site  jhu-apl  submitted runs under similar conditions for all three topic languages  and figure 1 a  shows the resulting recall-precision graphs by topic language. in that case  there is practically no difference between english-topic and arabic-topic results. there are two possible explanations for this widely observed effect:

figure 1: monolingual retrieval effectiveness  arabic queries formed from title+description fields  except jhu-apl and uc berkeley  which also used the narrative field   automatic runs  except u maryland  which was a manual run .
no large arabic information retrieval test collection was widely available before this evaluation  so the monolingual arabic baseline systems created by participating teams might be improved substantially in subsequent years.
the 1 topics used in this year's evaluation might represent a biased sample of the potential topic space. for example  relatively few topic descriptions this year included names of persons.
   several teams also observed that longer queries did not yield the improvements in retrieval effectiveness that would normally be expected. one site  hummingbird  submitted runs under similar conditions for three topic lengths  and figure 1 b  shows the resulting recall-precision graphs. in this case  longer queries showed no discernible benefit; indeed  it appears that the best results were achieved using the shortest queries! the reasons for this effect are not yet clear  but one possibility is that the way in which the topic descriptions were created may have resulted in a greater concentration of useful search terms in the title field. for example  the title fields contains an average of about 1 words  which is about twice as long as is typical for trec.
1 summary and outlook
the trec-1 clir track focussed this year on searching arabic documents using english  french or arabic queries. in addition to the specific results reported by each research team  the evaluation produced the first large arabic information retrieval test collection. a wide range of index terms were tried  some useful language-specific processing techniques were demonstrated  and many potentially useful translation resources were identified. in this paper we have provided an overview of that work in a way that will help readers recognize similarities and differences in the approaches taken by the

 a  topic language effect  title+description+narrative.	 b  query length effect  arabic queries.
figure 1: comparing runs under comparable conditions  t=title  d=description  n=narrative .
participating teams. we have also sought to explore the utility of the test collection itself  providing aggregate information about topic difficulty that individual teams may find useful when interpreting their results  identifying a potential concern regarding the completeness of the pools of documents that were judged for relevance  and illustrating a surprising insensitivity of retrieval effectiveness to query length.
   the trec-1 clir track will continue to focus on searching arabic. we plan to use 1 new topics  in the same languages  and to ask participating teams to also rerun the 1 topics from this year with their improved systems as a way of further enriching the existing pools of documents that have been judged for relevance. we expect that the result with be a test collection with enduring value for post hoc experiments  and a community of researchers that possess the knowledge and resources needed to address this important challenge.
acknowledgments
we are grateful to ellen voorhees for coordinating this track at nist and for her extensive assistance with our preliminary analysis  to the participating research teams for their advice and insights along the way  and to kareem darwish for his comments on an earlier version of this paper.
