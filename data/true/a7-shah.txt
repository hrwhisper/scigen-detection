viola-jones approach to object detection is by far the most widely used object detection technique because of speed of detection in images with clutter. svm-based object detection techniques have the disadvantage of slow detection speeds because of exhaustive window search. appearancebased detection techniques do not generalize well in the presence of pose variations. in this paper  we propose a feature-based technique which classifies salient-points as belonging to object or background classes and performs object detection based on classified key points. since keypoints are sparse  the technique is very fast. the use of sift descriptor provides invariance to scale and pose changes.
1. introduction
모object detection is an important problem in computer vision and has plethora of applications like image search. photo tagging is currently the mainstream technique for searching. the number of consumer digital photographs is increasing at an enormous rate and object detection will be essential for making consumer image search scalable.
모faces appear in more than 1% of consumer photographs and hence face detection is an important problem. face detection has been studied over years and there have been some recent breakthroughs. boosting and svm have been applied to face detection and have provided comparable results. detection of faces in cluttered background is compute-intensive because of repetitive window search operations. the technique due to viola and jones uses several ideas to speedup window search. svms have desirable properties like speed of training  generalization on smaller samples  etc. in this paper  we outline our attempts to use svms for object detection. we use salient point detection and description to generate feature vectors and use svms as classifiers. the number of svm evaluations is significantly less in our technique.
모this paper is organized as follows. section 1 provides an overview of relevant research in object detection. section 1
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee.
mdm'1 august 1  1  san jose  california  usa copyright 1 acm 1-1-1/1 ...$1. {shs subhajit} yahoo-inc.com
describes our approach. section 1 provides details of the experiments and performance. section 1 closes the paper with a critical discussion.
1. related work
모reference  contains a survey of research on face detection till early 1. two important recent approaches to face detection are the papers based on boosting  and svms . to detect faces in images with clutter  windows of all possible sizes and scales have to be classified. so the number of classifier evaluations are very large. the complexity of a classifier evaluation consists of two parts: complexity of feature computation and complexity of classifier evaluation. in   the classifier itself is very simple: a decision stump. the feature computations are speeded up using an elegant notion called integral image.  also uses the notion of cascades to further speed up the calculations.
모in svm-based approaches  the pixel values are usually used as features. so feature computation costs are zero. hence the complexity of svm-evaluation depends on the number of support vectors. in   a cascade of svms are used. initial svms work on downsized images and use small  1 뫄 1  windows. the classifiers earlier in the cascade are used to reject windows which are highly unlikely to be faces. svms downstream work on bigger window sizes  up to 1뫄 1  and these svms are evaluated only on those windows which are more likely to be faces. in a sense   is directly inspired by .
모some techniques directly try to speed up svm calculations.  replaces the number of original support vectors by a smaller set of synthesized input points. the notion of separability is used to arrive at the reduced set in . there has been lot of research on speeding up svm training. though this is not directly related to the main flow of the paper  we mention this since the following technique is used in our experiments for svm training. core vector machines  map the svm learning problem to minimum enclosing ball problem and use approximation algorithms for minimum enclosing ball problem to speed up svm training.
모the boosting approach has two drawbacks: training times are large and large number of training examples are required. on the other hand  svms have faster training times. see  for results on the spam classification problem. svms also generalize well on smaller training sets. while svms have these desirable properties  their main drawback is window search. instead of searching all windows in the image  if the most likely windows are searched for  then the search complexity reduces. unlike  which uses a cascade of svms

figure 1: salient points and their neighborhoods. the neighborhood of the salient point pi is the ellipse. the axes of the ellipse define local scale and orientation.
to reduce the search complexity  we use concepts from computer vision for search complexity reduction.
모there is vast literature in computer vision on location of visually salient regions and obtaining descriptors for such regions. see  for a tutorial introduction to salient point detectors. the interest points are characterized by location  scales in x- and y -directions  and orientation  figure 1 . we denote the radii of the ellipse along the axes as 뷂i and 뷃i. the orientation is denoted 붿i. some interest point detectors do not provide some of these numbers.  the well-known harris corner detector  for example  does not provide scale or orientation information.  we use the harris-affine detector  which is based on the harris detector with the scale provided by laplacian-of-gaussian followed by affine adaptation.
모the detected points are described by a descriptor. several descriptors like shape context  moments invariants  etc. are evaluated in . the authors conclude that sift  performs best.
모since interest points are perceptually salient  it should be possible for an object to be described by the collection of interest points. this is the basis for recent work on  bag of words techniques .  is also based on the use of salient point detection  sift description  and clustering much like bag of visual words approach.
모in this paper we propose a simple technique for object detection based on training svms on sift descriptors of salient points located on objects. we show that  despite the simplicity  the technique has very good performance.
1. classification of local descriptors
모in this section  we propose two techniques for object detection based on classification of local descriptors: unigram and bigram models. the motivation behind this terminology will be made clear later in the section.
1 unigram model
모one simple way of using salient point detection and svms together is to train the svm on two types of descriptors: the positive class containing descriptors of keypoints belonging to the object class and the negative class containing descriptors belonging to the background class. the success of this approach is based on the following.
1. the set of all descriptors describing various regions of the object having some structure.
1. svms being able to capture this structure.
모the testing scenario is as follows. in a tightly-cropped test image  the salient points are detected and the descriptors of the salient object are classified using the trained svm. if the number of keypoints belonging to the object class exceeds a threshold  the image is classified as belonging to the object class. the map of salient points belonging to the positive class provides localization of the object in cluttered scenes.
1 bigram model
모the above model does not include any information on spatial relations between salient points. in the bigram model  we concatenate the descriptors of nearby salient points. the notion of  nearness  is scale-dependent. for a keypoint pi with scales  뷂i 뷃i  and orientation 붿i  all keypoints qj which are inside an ellipse with axes  뷂i 뷃i  and orientation 붿i are considered near-neighbors. if d p  denotes the descriptor of p  then the pairs  d pi  d qj   are called  bigrams . the svm is trained to discriminate bigrams belonging to the object class and the background class.
모the term  bigram is inspired by text processing. we use the term bigram even though the descriptors are not vector quantized. we are not aware of any work in computer vision which uses bigrams - with or without vector quantization.
1. experimental results
모the techniques outlined above have been tested on feret and caltech datasets. the classes of objects detected are: face  car  bike  airplane  bottle  camel  guitar  and house. for face detection  we used the feret database1 and the caltech database1. for other objects  we used the caltech database.
모in all our experiments  we used harris-affine for salient point detection and sift for salient point description. the detector and descriptor implementations were obtained from  and used with the default parameters.
모we first describe the experiments with the unigram model. experiments with the bigram model are described in section 1.
모training phase: depending on the size of the training image  the harris-affine detector detects several salient points. the sift description for each of these keypoints yields a 1 dimensional vector. this descriptor along with the scale information of the respective keypoint forms a 1 dimensional pattern. each of these 1 dimensional feature patterns was assigned an appropriate label and used for training.
모for training these patterns we used the core vector machine implementation   a recently proposed flavor of svms. again we used the default parameters for the cvm implementation  that included gaussian being the choice of kernel.
모testing: for a test image  all the salient keypoints were classified. if the number of keypoints belonging to a par-


figure 1: face detection performance as a function of image size. the unigram model was trained on 1뫄1 face and background images. the test image sizes are varied from 1 뫄 1 to 1 뫄 1.
ticular class exceeded 1% of the total number of keypoints then the image was classified as belonging to the class.
모for testing the performance of the proposed approach we performed four sets of experiments.
1. identification of faces of the feret face dataset fromnon-faces.
1. caltech cars  rear end  from caltech cars  rear  background of road scenes.
1. caltech motorbikes  side  from background of roadscenes.
1. a multiclass classification between eight classes  namelyairplanes  background scenes  bottles  camels  rear end cars  human faces  guitars and houses - all from the caltech dataset.
we now describe each of the above in detail.
1 feret face dataset vs. background
모the training set comprised of a random selection of 1 face images from the feret dataset and 1 assorted

figure 1: roc for identification of faces from the feret dataset from background scenes
background images collected from the web. the test set comprised of 1 face images from the feret dataset and 1 background images. it was ensured that the subjects whose faces were used for training were distinct from the subjects whose faces were used for testing. the feret images are images of people from above the head region till about the chest region. therefore some of the salient points could be detected on the background of the image as well as shoulders etc. to avoid manually labeling the individual salient keypoints as belonging to faces or non-faces  we extracted the faces from the feret images using the voila jones face detector. all the keypoints that arose in the cropped face images were labeled as face points.
모all training images  faces as well as non-faces  were resized to 1 뫄 1. during testing  if more than 1% of the keypoints were classified as belonging to a face then the image was classified as a face  else background. the roc curve in figure 1 depicts the accuracy vs. false positive rate obtained when testing was performed after resizing all the test images to 1 뫄 1.
모next  we tested the sensitivity of the classifiier to the size of the test images. we used the classifier trained on 1뫄1 images and varied the size of the test images from 1뫄1 to 1 뫄 1. figure 1 shows the accuracy and false detection rate obtained on varying the size of the face and background test images respectively. from figure 1  we note that the accuracy in detecting faces is above 1% for the test images over a wide range of scale  but drastically falls down for images sized 1 뫄 1. we noticed that this was because for many of the small sized images very few keypoints were detected  leaving many undetected important keypoints.
1 caltech rear end car dataset
모in this experiment the task was to classify the cars from the background images of road scenes. the training set and test set of 1 car and non-car images each were exactly the same as those of . we tightly cropped the training images of the rear end cars so as to remove most of visible portions of road from them. for training  the images of cars and road background dataset were resized to 1 뫄 1. in this dataset  there is a lot of variation in the scale of the cars.
predicted carpredicted roadtarget car1target road1table 1: confusion matrix for the caltech rear end cars
predicted bikepredicted roadtarget bike1target road1table 1: confusion matrix for the caltech motorbike  side  vs. background road images
the size of a car varies from 1 뫄 1 to approximately 1 뫄 1. we tested the model obtained after training on 1뫄1 images on these test image without either cropping or resizing them. table 1 summarizes the results obtained. table 1 reflects the fact that the model was invariant to scale changes and was able to identify cars of variable sizes.
1 caltech motorbike  side  data set vs. road
모in this experiment the task was to identify the motorbikes in images. we used 1 images of bikes and 1 images of road for training. the test set and training set are the same as . the caltech motorbikes  side  dataset has many images in which along with the bike there is a significant amount of background. the background is also visible behind the side views of bikes. therefore it was not possible to crop out the background from the bikes. again  we performed training on 1 뫄 1 sized images but the test images were tested as they are. the results obtained have been summed up in table 1. though there is lot of variation in the appearances of bikes in the test set  perfect detection score implies that the classifier was able to generalize well.
모a possible reason for high false detections is that in the motorbike images  a lot of background is present. since all the keypoints arising on the bike image are labeled as keypoints  a number of keypoints arising on the background also get mislabeled as bike images.
1 multiclass
모in this experiment we performed a multiclass detection task between eight caltech datasets namely  airplanes  side   background scenes  bottles  camel  cars  rear end   faces  guitar  and houses. we used the default split of images between the training and testing sets. however we resized the training and testing images down to 1 뫄 1. table 1 summarizes the results obtained for each class. most of the classes yielded good accuracy and low false positive rate  however there is a high false positive rate between some of the classes for example  houses and airplanes. this is because of the common presence of sky in both during training stage which leads to some keypoints on the sky to be labelled as both house and airplane and causes ambiguity in classification. as seen in the table  for test sets like faces and background  where there are no common keypoints  there is perfect classification accuracy. therefore  we believe that the proposed scheme of using svms over detected keypoints  described by sift descriptor can lead to very powerful classifiers for object detection in clutter..

figure 1: face localization by bigram model. the images are from the cmu face test set. the top image contains rotated faces and the bottom one has faces at several cases.
1 bigram experiments
모we tested the bigram model for two tasks: object localization and object detection. the bigram model was trained on the training set described in section 1. the test set was the cmu face test set. figure 1 shows plot of bigrams which are classified as belonging to the object class on two test images. it can be seen that the localization is accurate despite scale changes and image rotation.
모figure 1 shows the roc curve for the bigram model on caltech car database. the cropped car images were used for training and the uncropped ones for testing as in 1. as seen in the roc  the bigram approach leads to very high detection accuracy with a very low false positive rate.
1. discussion
모in this paper  we have proposed a technique for object detection which is based on classifying local descriptors. we

airplanesbackgroundbottlescamelcarsfacesguitarhousesairplanes1111background1111bottles1111camel1111cars1111faces1111guitar1111houses1111the eight classes dataset has been downlaoded from http://www.robots.ox.ac.uk/~vgg/data1.html. the training and testing sets are also available at the same site.
table 1: confusion matrix for the eight classes.figure 1: roc of the bigram model for caltech car dataset.
have shown that the technique has high precision and recall for a variety of detection tasks. the technique is also able to localize objects in cluttered scenes.
모we now demonstrate the computational advantages of the proposed technique. let the number of keypoints in a 1뫄 1 image be n.  the value of n is typically 1.  in the unigram model we need n svm evaluations with the feature vector having dimension around 1. in the bigram model  the number of svm evaluation in the worst case is n1. the feature vector size for the bigram model is twice that of the unigram model. in conventional approaches for object detection  the training images are 1뫄1 or greater in size. so the feature vector sizes are greater than 1. the number of windows is of the order of million . the number of windows increases if object rotations are taken into account. hence the approach proposed in this paper results in great computational savings.
모the proposed technique depends on the salient point detector and the behavior of the detectors change with change in image size. with robust salient point detectors  the proposed method is expected to work well even for small images.
