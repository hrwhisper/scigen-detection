hidden variables  evolving over time  appear in multiple settings  where it is valuable to recover them  typically from observed sums. our driving application is 'network tomography'  where we need to estimate the origin-destination  od  traffic flows to determine  e.g.  who is communicating with whom in a local area network. this information allows network engineers and managers to solve problems in design  routing  configuration debugging  monitoring and pricing. unfortunately the direct measurement of the od traffic is usually difficult  or even impossible; instead  we can easily measure the loads on every link  that is  sums of desirable od flows.
﹛in this paper we propose i-filter  a method to solve this problem  which improves the state-of-the-art by  a  introducing explicit time dependence  and by  b  using realistic  non-gaussian marginals in the statistical models for the traffic flows  as never attempted before. we give experiments on real data  where i-filter scales linearly with new observations and out-performs the best existing solutions  in a wide variety of settings. specifically  on real network traffic measured at cmu  and at at&t  i-filter reduced the estimation errors between 1% and 1% in all cases.

 this author thanks the data privacy laboratory and the center for automated learning and discovery  cald  at carnegie mellon university for their support.
 this author thanks the support by the national science foundation under grants no. iis-1  iis-1  iis-1  iis-1  int-1  sensor-1  ef-1  iis-1 and by the pennsylvania infrastructure technology alliance  pita  grant no. 1. additional funding was provided by donations from intel  and by a gift from northrop-grumman corporation. any opinions  findings  and conclusions or recommendations expressed in this material are those of the author s  and do not necessarily reflect the views of the national science foundation  or other funding parties.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee.
kdd'1  august 1  1  seattle  washington  usa.
copyright 1 acm 1-1/1 ...$1.
categories and subject descriptors: i.1  artificial
inteligence : learning
general terms: algorithms
keywords: origin-destination traffic flows  link loads  self-organizing bayesian dynamical system  mcmc  particle filter  informative priors  empirical bayes
1. introduction
﹛knowledge about the origin-destination  od  traffic matrix allows network engineers and managers to solve problems in design  routing  configuration debugging  monitoring and pricing; in fact the od traffic matrix provides valuable information about who is communicating with whom in a network  at any given time. unfortunately the direct measurement of the od traffic is usually difficult  or even infeasible  in real networks. the direction of current research is to develop methods to infer the od traffic flows from observed traffic loads on the links of the network  however the methods that have been proposed so far seem not to fully take advantage of two of the main empirically observed features of network traffic; namely its very skewed marginal distribution  and its time dependent nature.

figure 1: estimation error in `1 distance.
﹛in this paper we present i-filter  an intelligent filtering method which improves the models present in the literature by introducing two realistic assumptions:
  the successful log-normal distribution provides a realistic model for the marginal od traffic flows 
  time dependence between successive flows on a same od route narrows the variability of the estimates. i-filter uses a two-stage estimation procedure: estimates the pattern of time-dependencies  and eventually uses it to gain in precision.
  the learning algorithm is linear in the number of epochs times the number of od flows that need be recovered 
  the learning algorithm  particle filter  estimates the parameters of our bayesian dynamical system and the od traffic flows with one pass over the data  using few high-quality particles.
﹛in our experiments  using the best log-normal model reduced the estimation error of previously proposed methods by 1%  and the introduction of explicit stochastic dynamical behavior reduced the estimation error up to 1%. the magnitude of the improvements entailed by the simple ideas we propose goes far beyond that of state-of-the-art re-sampling schemes that could be used to refine any given set of estimates. further a stochastic dynamical behavior played an essential role in our models; it served as the right channel where to introduce prior information about the od flows  gained in stage-one of our procedure.
﹛the rest of the paper is organized as follows: section 1 describes the problem and the relevant issues in more detail. section 1 surveys the relevant literature. section 1 describes our proposed methodology. section 1 reports the results of our experiments on real data. section 1 discusses our main findings and their relevance towards our solution to the problem  and section 1 concludes with some final remarks and future research directions.
1. problem - background
﹛in this paper we write m for matrices  v t  for column vectors at time t  and v i t  for their generic component i.
tnumber of time points.`number of observable link loads.百number of non-observable od flows.a ` ℅ 百  fixed routing matrix.y ` ℅ t  matrix of link loads.x 百 ℅ t  matrix of od flows.托 百 ℅ t  matrix of means of x|托 耳.耳 1℅ t  vector of scale factors for x|托 耳.牟generic vector of hyper-parameters.羽 牟 generic prior distribution.table 1: summary of symbols.
﹛we begin by defining the problem  introducing the relevant issues  and discussing related works.
1 the problem and its facets
﹛in a formulation of the problem we want to solve there are several time series which we would like to estimate  but which we cannot observe  say  a vector of traffic flows x t  over times t = 1 ... t. however  we are able to observe linear combinations of these traffic flows  the vector of link loads y t  over times t = 1 ... t  and we know which components of x t  mix into each of the components y i t  at each time t trough the routing matrix a  that does not change over time. this problem can be decomposed in three subproblems  which we now define.
﹛problem 1.  network tomography  given the matrix of link loads y `℅t  and a routing matrix a `℅百   we want to find the matrix of non-observable od traffic flows x 百℅t  such that y = a ﹞ x. always 百   `.
﹛for example  the linear equations that correspond to the routing scheme of the star network in figure 1 below are: 1 y 1 t  1 1	1 1
x 1 t  x 1 t  1 x 1 t 
y 1 t  = 1 1  1  y 1 t  1 1 1 1
x 1 t 
y 1 t  measures the traffic load on the link from node 1 to the router and captures both the od flow from node 1 to node 1  x 1 t   and the od flow from node 1 to itself  x 1 t . y 1 t  measures the traffic load on the link from the router to node 1 and captures both the od flow from node 1 to node 1  x 1 t   and the od flow from node 1 to itself  x 1 t .

figure 1: two subnetworks connect to a router in a small star network. we observe the link loads  solid blue arrows   and want to infer the hidden od flows  dashed red arrows .
﹛in the example above we want to estimate four  百  unobservable quantities starting from three  `  independent observations1. the system is under-specified  百   `  hence some extra information is needed in order to identify one single solution.
﹛problem 1.  prejudices  choose a set of additional constraints to be imposed on x 百℅t  in order to make the  network tomography  problem exactly determined.
﹛the likelihood of the data entailed by a statistical model provides us with a natural criterion to discern  likely  solutions from unreasonable ones. following this idea we model the unobservable quantities x t  with a joint probability distribution; this induces a probabilistic mapping on the space of the observations y t  via equation 1  so that we can compute the likelihood of the observations  and look for traffic flows that maximize the probability of particular data observations. unfortunately in time-independent models the likelihood of y t  is not necessarily unimodal  even as we assume independent components in x t   and even as we use well-behaved functional forms for their distributions. more information is needed to identify a solution.
﹛at this point there are two main ways to introduce the extra information we need. in a purely data-driven approach we would augment the data in some way  whereas in a knowledge-driven approach we would make use of informative priors in a bayesian setting  with the complication


figure 1: graphical representations: previous works assume no explicit time dependance  left   whereas the linear ssm introduces an explicit dynamical behavior  center . our proposed i-filter moves the explicit time dependence one layer up in the graphical model  thus allowing for the od flows to be more diverse  right .1 we assume that routers neither generate nor absorb traffic. in this latter case of defining what we mean by  informative . data augmentation can be realized  for example  by raising the likelihood of the data to a power  as in simulated annealing  or by borrowing observations from epochs close in time to the current one to obtain a smoothed average solution. alternatively  we can build  informative  priors based on partial knowledge about the magnitude of the od flows  and update using bayes rule and a  more accurate  data model.
﹛problem 1.  speed  solve efficiently the  network tomography  problem  under the  prejudices  of problem 1.
﹛we offer a novel solution to the  prejudices  problem  which satisfies the efficiency requirement of the  speed  problem. the two-stage estimation procedure at the core of ifilter corresponds to a non-parametric empirical bayes learning strategy  where the observations are used to first calibrate informative priors  and then to filter the posterior distributions of the od flows given the data. our solution:  1  uses realistic models for the od flows;  1  takes advantage of the time dependence of the data while using the whole history of observations {y 1  ... y t } to estimate x t  in a proper bayesian fashion.
1 state-space models
﹛to the best of our knowledge dynamical systems have never been used to solve the  network tomography  problem1. previous works assume independent od flows across different epochs. we use dynamical systems  which naturally extend previous approaches by assuming time dependence explicitly.
﹛definition 1. gaussian linear state-space models are defined by the set of equations 
	x t 	= f ﹞ x t   1  + e t 
 1 
	y t 	= a `℅百  ﹞ x t  	t ≡ 1
where {e t } is an i.i.d. gaussian process with variancecovariance matrix q  and f is a known matrix. further x 1  ‵ normal m v   and independent of e t  for t ≡ 1.

1
 wei et al.  1  and others use hmms to approach a different problem  also called  network tomography .
﹛in figure 1 above we show the graphical representations for the  network tomography  problem at subsequent time points in a static setting  and its natural extension to a dynamic setting  by means of various state-space models  ssm henceforth . classical state-space modeling strategies a la box and jenkins would look for the additional constraints needed to solve problem 1 in a known dynamical behavior suggested by some physical law underlying the specific problem at hand and from known seasonal patterns in the traffic  for example the laws of motion in tracking the trajectories of moving objects  or from the presence of strong cross-correlations among the od flows. this knowledge would translate into constraints on f  and q in the system 1 above  and would serve the critical role of driving the inferences towards one particular solution.
1. related work
1 classical literature
﹛as we discussed above the  network tomography  problem is under-specified  and allows for infinite valid solutions. fienberg  1  1  studied the geometry of the underlying mathematical problem and identified the  百 ` dimensional space of solutions. by assuming specific marginal probability distributions for the od flows we induce a probability map on the the space of measurements. vanderbei and iannone  1  show that assuming poisson od traffic does not yield a necessarily convex probability map  and vardi  1  further shows that solving the likelihood equations may yield local maximum whereas the actual global maximum is on the boundary  assuming poisson traffic. both these works assume a fixed vector of parameters for all epochs. tebaldi and west  1  propose a fully bayesian framework with non-informative priors based on poisson traffic and acknowledge the need for informative priors  but they do not specify how to obtain them. in fact  using the measurements at time t in order to estimate the od flows at the same epoch  flat priors over the possible amount of traffic yield uniform or multi-modal posteriors. their work is important in that they explore the extent to which it is possible to find a solution at each epoch without using the information entailed by past or future measurements.

figure 1: a summary of the models present in the literature in terms of their ability to model relevant features of real traffic data.
1 recent approaches
﹛solutions to the problem in the non-statistical literature consider a fixed vector of parameters across all epochs as the favorite solution to overcome the lack of information entailed by the measurements. for example  a typical solution would assume traffic flows at different epochs as independent for each od route and estimate a fixed vector of parameters by composing the constraints given by the measurements via generalized least squares. similar solutions differ in the way they compose the constraints given by the measurements at different epochs; the alternatives include the assumptions of multivariate gaussian or multinomial measurements and the composition is carried out via maximum likelihood or via bayes theorem  or else using maximum entropy arguments  and so on. economic approaches that explicitly deal with congestion had also been tried with success. as we noted above  these solutions all assume an underlying fixed vector of parameters which governs the od traffic at all epochs  and we can express them as solutions of a common minimization problem  airoldi 1  zhang et al. 1 .
﹛several of these time-independent solutions have been applied locally in order to get a time-varying solution for the od flows  otherwise constant across time. a drawback of such approaches is that they cannot obtain estimates for the od flows corresponding to several measurements. for example  a window of 1 observations would not inform about the first and last 1 od flows  ＞ 1 mins . a recent approach due to cao et al.  1  assumes multivariate gaussian od flows  i.i.d. across time. however  they propose a clever parametrization with several desirable properties which yields reliable estimates. further cao et al.  1  show how to estimate od traffic flows in bigger networks by solving sub-problems and then composing their solutions. medina et al.  1  compare several methods and survey the literature. zhang et al.  1  propose a gravity model for the od traffic  and use stein's shrinkage estimator to refine their estimates.
1 skewed and bursty traffic
﹛the log-normal distribution has never been used to model the od traffic flows  however several works support this distribution for traffic in communication networks and over the internet. empirical studies and theoretical models that recreate realistic traffic flows from underlying processes consistently come to the conclusion that network traffic flows are skewed and bursty  see mandelbrot  1   leland et al.  1   coutin and carmona  1   sarvotham et al.  1   wang et al.  1   and cao et al.  1 . most of the skewed distributions follow the characterization given by zipf  1   and its generalizations given by mandelbrot  1  and bi et al.  1 . in particular bi et al. show that the truncated log-normal distribution is flexible enough to fit a wide variety of such observed behaviors. we show the log-log plots for the two data sets we used in figure 1 below.
1 learning state-space models
﹛ghahramani and hinton  1  show how to learn all the parameters in the system 1  in our case f  q  m  and v   by means of the em algorithm. higuchi  1  shows how a self-organizing system can be built from non-linear non-gaussian systems  so that all the relevant parameters are learned during the filtering process. gilks and berzuini  1  propose a particle filter that keeps particles diverse.
1. proposed method: i-filter
﹛briefly  i-filter uses a two-stage approach to the filtering problem. in the first stage we find preliminary  smooth estimates for the od flows  which make a good guess for the averages of the od traffic  and in the second stage we refine these smooth estimates by looking for spikes and bursty periods with one single pass over the data. we model the od flows as bayesian dynamical systems  and we use a em and particle filter as learning algorithms1.

figure 1: a non-parametric empirical bayes approach to the filtering problem is at the core of i-filter.
﹛more specifically  we use the linear gaussian ssm and related em steps proposed in airoldi and faloutsos  1   which includes the model in cao et al.  1  as a special case  to obtain smooth estimates of the od traffic  and we then use these estimates to calibrate informative priors for the parameters underlying the dynamic of a non-gaussian system  in non-parametric empirical bayes fashion. eventually the particle filter makes good use of these priors and of the skewed models  and finds a sequence of better posterior distributions for the traffic flow on each od route; we pick their means as point estimates. our experiments show i-filter achieves an error 1% to 1% smaller than that of state-of-the-art methods in all cases.
1 models for od traffic
﹛in our experiments on carnegie mellon origin-destination traffic we noticed that assuming a fixed relationship between x i t  and x i t + 1  is an unrealistic constraint. our solution is to assume a relationship between the means of the od flows 竹 i t  and 竹 i t+1  instead  and to allow for some error. the ssm yields smooth estimates that capture information about this relationship  which we pass to the next estimation stage. in fact  we introduce soft constraints on the average process {竹 t t ≡ 1} in the form of informative priors for the parameters underlying its dynamical behavior.

1
 an implementation of i-filter described in this paper is available for the open source r environment  on request.
we reduce the number of parameters by merging dynamic and error terms into a stochastic dynamical behavior. the marginal models for the od traffic flows are independent log-normals1. the main objects of interest are then the posterior distributions p x t |y 1  ... y t  . in particular the point estimate for the od traffic vector at time t is given by the mean x  t  = e x t |y 1  ... y t  .
1.1 i-filter static
﹛the static version of i-filter considers independent problems at each epoch. briefly  we are interested in estimating x  t  = e x t |y t   = e x|y  . to specify the full models at each time t we write: `	∩	 1 
x竹 耳	‵	p 竹 耳  y = a ﹞ x 
where p is log-normal  parametrized so that e x i |竹 耳  = 竹 i   v  x i |竹 耳  = 耳 ﹞ 竹 i 而  cov x i  x j |竹 耳  = 1 for i = 1 ... 百 and i 1= j. notice that 耳 is common across od flows at each epoch  and that 而 is a known scalar  which we obtain by inspection of y . the priors for the 竹 i  are log-normal 牟1 i  牟1 i  1  for i = 1 ... 百 and independent for i 1= j. the prior for 耳 is proportional to a constant  to 1/耳 or to 1/耳1.
1.1 i-filter dynamic
﹛this dynamic version of i-filter  which yields the best results  implements the following bayesian dynamical system:
 ... 百  1 
	: x t   竹 t  耳 t 	‵	p`竹 t  耳 t ∩	 1 
	 	y t 	= a ﹞ x t  	t ≡ 1 	 1 
where p is log-normal  parametrized so that for i = 1 ... 百 e x i t |竹 t  耳 t   = 竹 i t   v  x i t |竹 t  耳 t   = 耳 ﹞ 竹 i t 而  and cov x i t  x j t |竹 耳  = 1 for i 1= j. notice that 耳 t  is common across od flows at time t  and that 而 is a known scalar  which we obtain by inspection of y . the priors for 竹 i 1  are log-normal 牟 i 1  考 1  for i = 1 ... 百 and independent for i 1= j  and for a big number 考 that accounts for the uncertainty of the means of od flows at time zero. the prior for 耳 t  is proportional to a constant  to 1/耳 t  or to 1/耳 t 1. the priors for  i t  are log-normal 牟1 i t  牟1 i t  1 for i = 1 ... 百  and independent for i 1= j.
1.1 informative priors for 竹 t 
﹛the crucial question at this point is: how do we calibrate the hyper-parameters underlying the prior distributions of 竹 t   first we obtain a preliminary set of estimates x  t  with the gaussian linear ssm. then  in the case of ifilter static   牟1 牟1  at each time are set so that mean and variance of 竹 correspond to those of x  t . variances can be made much larger without significant loss of precision. the intuition is that the preliminary estimates indicate us where od flows are on average. in the case of i-filter dynamic the intuition is the same  however it is not possible to set priors for 竹 t  as the sequence {竹 1  ... 竹 t } is going to be determined by 竹 1  alone. the solution is then

1 airoldi  1  also considers gamma models. 1
 airoldi  1  also considers gamma  uniform  and truncated gaussian priors.
to extract from {x  1  ... x  t } information about their local dynamical behavior and use it to calibrate informative priors for . technically  we set  i t  as independent log-normals; we use the facts that product convolution of log-normals is log-normal  equation 1   and that log-normal 牟1 i t  牟1 i t   = exp{n 牟1 i t  牟1 i t  } to solve the convolution problem exactly for  牟1 i t  牟1 i t    for i = 1 ... 百. in other words  values for  牟1 t  牟1 t   are computed from  x  t  x  t   1   at each time  and these parameters need not be learned. 牟 i 1  is set to be the average of corresponding od flow {x i t   t ≡ 1}.
﹛notice that every two-stage method that finds preliminary estimates and refines them uses {x  1  ... x  t } in the second stage  in some way. we prefer to translate this information into information about the means of the od flows {竹 1  ... 竹 t }  according to the intuition that preliminary estimates can identify a smooth version of the od flows we are looking for  which make reasonable guesses for their underlying average processes.
1 parameter estimation
﹛in order to filter the posterior distributions of the origindestination flows and estimate the parameters of the models  i-filter implements a slight variation of the sampleresample-move algorithm of gilks and berzuini  1   which we briefly outline below. for simplicity define v t  to be the vector of all parameters in the model at time t  v t  := x t  竹 t   t  耳 t ∩  and v 1  := `竹 1 ∩.
algorithm 1. enhanced particle filter:
at t = 1 generate n particles {竹  i  1 }ni=1 using 牟 1  考.
1. set t = t + 1. move each particle like so:  a  generate
 i  t  using  牟1  i  t  牟1  i  t    and 耳 i  t ;  b  compute 竹 i  t  using the equation 1;  c  generate x i  t  by sampling from equation 1.
1. resample n new particles from {v  i  t }ni=1 according to the likelihood  p y t |v  i  t    they entail.
1. move the new set of particles according to a mcmcfor  several steps  to improve their diversity. go to 1.
for details about the mcmc see airoldi  1 .
1 scalability and irreducibility
﹛a recent result in network tomography  see cao et al. 1  is that it is possible to reformulate filtering problems corresponding to complex networks as a sequence of problems corresponding to small  simple networks.
lemma 1. the complexity of i-filter is o 百 ﹞ t  .
﹛proof. we use results by cao et al.  1  which imply that a tomography problem corresponding to a network with 百 origin-destination flows is equivalent to o 百  tomography problems  which correspond to disjoint sub-sets of  say  one to four od traffic flows in the original problem. this fact along with the fact that our solution is linear in the number of time points for which the od traffic need be filtered  yields a total complexity of o 百 ﹞ t   for i-filter. 
﹛lemma 1 implies if we solve the  network tomography  problem for small size networks  we immediately solve it for arbitrary size networks with comparable estimation errors. further the following result holds:
	carnegie mellon traffic	at&t traffic

1	1	1	1	1	1	1	1	1 log traffic	log traffic
figure 1: left: a log-log plot of the 1 traffic flows measured at carnegie-mellon university suggests that skewed distributions are appropriate. right: a log-log plot of the 1 traffic flows measured at at&t  which we use as a test bench for our models. i-filter yields the best performance when based on the successful log-normal distribution.lemma 1. i-filter is based on an irreducible mcmc. proof. see airoldi  1  
﹛lemma 1 implies that i-filter is able to explore the support of the whole joint posterior distribution of the od flows. a proof of this fact is needed since the mcmc uses a gibbs sampler with metropolis steps.
1. experiments
1 experiment setup
1.1 data sets description
﹛we had two data sets available. both of them included validation data.
  carnegie mellon traffic: the first data set  which we used to choose the appropriate model  contained about 1 origin-destination traffic flows measured every 1 minutes over slightly less than two days at carnegiemellon university  cmu . we measured an average traffic of 1gb every 1 minutes.
  at&t traffic: the second data set  which we used to test and compare the filtered traffic obtained with different methodologies  contained 1 origin-destination flows measured every 1 minutes over a one-day period at at&t  courtesy of dr. jin cao at bell labs.
the analysis of carnegie mellon origin-destination traffic flows supports the hypothesis of a very skewed distribution. in figure 1 we plotted the logarithms of the observed flows versus the logarithms of the number of times measurements of such a size appear  aka. log-log plot   after discarding the measurements smaller than a standard packet  1 bytes = 1 bytes . the log-log plot indicates a log-normal distribution may be appropriate. a histogram of the logarithms of the flows indicated that a logarithmic transformation is actually too mild to remove all the skewness  and a double logarithmic transformation would be more appropriate. the at&t data set is much smaller  and contains traffic flows generated on a smaller network; they are less skewed overall  and a logarithmic transformation is enough to yield a symmetric histogram for the truncated flows.
1.1 performance and robustness
﹛we used the cmu data set to drive our modeling choices  on star network topologies. in order to test both the performance of i-filter and the robustness of its underlying log-normal model we eventually set the cmu data aside  and used the at&t data set as an independent validation data set.
﹛recall  as we noted in section ∫1 above  that it is possible to break down a big filtering problem on a complex network into a sequence of smaller problems on  disjoint  simple star networks. hence  it was enough to test the performance of our methods on the simple star network in figure 1  composed by one router and two nodes connected to it. we used subsets of non-observable origin-destination flows from the at&t data set  to generate the link loads corresponding to the simple star network topology above  and then compared the estimation errors of the competing methods in the task of reconstructing the non-observable od flows.
1 results
﹛combining realistic models and time dependence into ifilter reduced the error obtained with local likelihood between 1% and 1%. we performed experiments to answer the following questions:
1. skewed marginals: what is the impact of skewed model on the accuracy of the estimates  and what is the best model for the od traffic 
1. time dependence: what is the impact of explicit time dependence on the accuracy of the estimates 
1. informative priors: what constraints should we impose to solve the  prejudice  problem  how do they impact the accuracy of our estimates 
1. scalability: does our algorithm scale well with the problem size 
we were most interested in assessing the differential impact on the estimation error of our novel ideas  as opposed to the methods present in the literature. that is  we measured the goodness of the competing methods by computing the corresponding estimation errors  as given by the `1 distances between the true od flows in the validation set and the estimates. the best results were obtained with log-normal distribution for the flows and gaussian vague priors.

figure 1: the bars represent the average estimation error in a validation set. specifically we plot the `1 distance between the true od flows and the corresponding estimates obtained with the local likelihood approach and i-filter in its various flavors. i-filter based on the bayesian dynamical system is a clear winner! in both panels we include the estimates obtained with our gaussian linear ssm. left: error bars corresponding to i-filter based on gamma models. right: error bars corresponding to i-filter based on log-normal models.

figure 1: example posterior distributions for the od flow x 1 . the traffic on the x axes is measured in kbytes  and the figures show the posterior distribution we obtained with i-filter static  left panel  versus the one we obtained with i-filter dynamic  right panel   which encodes time dependence of the od flows. the solid triangles represent the true hidden od flow  whereas the empty triangles are our point estimates  which correspond to the means of the posterior distributions. time dependence entails that the posterior distribution of x 1  depends on all observations {y 1  ... y 1 } and has a lower variability - notice the different ranges - thus improving the inference.1.1 effect of skewed marginals
﹛to isolate the effect of realistic distributions for the od flows  we compared the estimates obtained with i-filter where no time dependence was assumed  for gamma and log-normal models  and a variety of non-conjugate priors  uniform  gaussian  gamma l log-normal  and different parametrizations  with the estimates obtained by local likelihood. introducing realistic model reduced the error between 1% and 1%. see figure 1.
1.1 effect of time dependence
﹛to isolate the effect of explicit time dependence  we compared the estimates we obtained with the gaussian linear ssm in airoldi  1  that uses independent ar 1  processes for the od flows  with the estimates obtained with local likelihood. introducing time dependence reduced the error by 1% on average; the reduction ranged between 1% and 1%. see figures 1 and 1.
1.1 informative priors
﹛in 1% of the time points uninformative priors yielded flat or multi-modal posteriors  whereas in the remaining 1% of the time points uninformative priors yielded wide uni-modal posteriors. in the static case  the effect of one data point  y t   on the posterior  p x t |y t    is on its range; impossible configurations receive zero posterior probability. on the other hand  informative priors with wide variance all yielded uni-modal distributions. further  they have the advantage of requiring fewer particles than uninformative priors; knowing where to sample may introduce bias  but the thick tails of the log-normal distribution of both x t |竹 t  耳 t  and 竹 t |牟1 t  牟1 t  mitigate the problem  and allow us to capture several of the hidden spikes. see figures 1 and 1.
 1.1 scalability i-filter reconstructs the od flows with one single pass over the data; the first stage of the procedure and the calibration of the priors are also linear in the problem size  as we compute the posterior distributions using the gaussian linear ssm on a large sliding windows  for example. figure 1 below shows that in less than one hour i-filter calibrates the informative priors and recovers the flows corresponding to one-day worth of data for the small network in figure 1  on a powerbook g1.1ghz.

figure 1: i-filter scales linearly with the problem size  number of time ticks .
1. discussion
﹛in this paper we propose i-filter  a two-stage procedure which naturally fits in a non-parametric empirical bayes framework. i-filter reduced the estimation error1 in all cases  and on average between 1% and 1%  when compared to state-of-the-art methods on real traffic data. such improvements  see figure 1  are due to three factors:
1. realistic log-normal distributions for the od flows 
1. dynamical systems as a natural way to deal with datawith a temporal dimension 
1. informative priors calibrated via empirical bayes 
further  i-filter scales linearly with the size of the problem. briefly  we recover a smooth version of the od flows  we use it to calibrate informative priors for some crucial parameters  and eventually we use a bayesian dynamical system to refine the estimates and capture bursty traffic. this methodology allows us to combine the three simple ideas above: a realistic model for the data  the use of a filtering scheme which takes advantage of time  probabilistic constraints to overcome the under-determinacy of the problem.
﹛more in detail  in the first stage we use the gaussian linear ssm proposed in airoldi and faloutsos  1  to estimate a smooth version of the od traffic  and we calibrate informative priors for 竹 t  using these estimates. these priors incorporate information about the magnitude and the dynamical behavior of the od traffic flows on average  and softly constrain the location of the average processes {竹 t   t ≡ 1}. other methods proposed in the literature make use of preliminary estimates  but they only retain the information about the magnitude of the od flows given by the such estimates in the refining stage - see for example zhang et al.  1  who use shrinkage to improve the solutions given by a gravity model. in our method  the fact that we retain also the information about the local dynamical behavior yields a significant jump in the final accuracy. another channel

1
measured in `1 distance from the true od flows.
through which informative priors help achieve a better accuracy is by reducing the bias entailed by multiple modes in the posterior distributions. making the posteriors more unimodal improves the precision of the point estimates of the od flows  the posterior means  as we show in figure 1 below. informative priors do drive the inferences about the od flows towards the preliminary guesses  however the two layers of our model and the use of soft probabilistic constraints entail enough flexibility to capture several of the spikes in many cases  for an example see figure 1 below. further our first-stage estimates are safely based on a model which entails a one-to-one relationship between od flows and measurements  as it includes the model by cao et al.  1  as a special case.
﹛in the second stage the primary object of interest becomes the sequence of posterior distributions p x t |y 1  ... y t  . we use their means x  t  = e x t |y 1  ... y t   as point estimates for the od flows at time t. the bayesian dynamical system brings further improvements  as we show in figure 1 above  due to the fact that we make use of all the observations up to time t in computing the posterior distributions p x t |y 1  ... y t  ; conditioning on more observations yields a narrower variability. local methods use fewer observations in a short window around t  instead. the improvement i-filter achieves goes beyond the contribution of state-of-the-art methods even when combined with recent resampling schemes which improve any given set of estimates.
1. conclusions
﹛in this paper we described i-filter  a two-stage estimation method that combines three simple ideas:
1. log-normal models to account for skewed  and burstyunobservable od traffic flows 
1. a novel bayesian dynamical systems to take advantageof the time dependence of the data and narrow the
variability of the estimates 
1. informative priors as soft constraints to overcome theunder-determinacy of the problem.
﹛we offer simple heuristics to understand our modeling choices; first-stage estimates capture smooth average processes  second-stage estimates capture the spikes. we tested our methodology on star topologies using real traffic measured at carnegie mellon  1 od flows  and at&t  1 flows  and reduced by 1% to 1% the estimation error obtained with state-of-the-art methods  in all cases. finally  we provided a solution to the problem of how to calibrate informative priors in our bayesian dynamical systems  where no clear guidance about the dynamic of the hidden od flows is available. in the future we plan to explore whether periodic traffic patterns may also be discovered successfully.
1. acknowledgments
﹛the authors thank dr. stephen e. fienberg for engaging discussions  dr. jin cao  dr. srinivasan seshan  dr. russel yount and dr. frank kietzke for providing the traffic data measured at at&t and at carnegie mellon university  which made this work possible  dr. irina rish and dr. alina beygelzimer at ibm t.j. watson for helpful comments.

figure 1: example posterior distributions for the od flows x 1  and x 1 . the traffic on the x axes is measured in kbytes  and the figures show the posterior distributions we obtained with non-informative priors  top panel  and with informative priors  bottom panel  calibrated using our gaussian linear ssm. the solid triangles represent the true hidden od flows  whereas our point estimates would be the means of the posterior distributions. making the posteriors more unimodal improves the estimates by reducing the bias entailed by extra modes.

