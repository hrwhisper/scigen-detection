this paper provides a novel algorithm for automatically extracting social hierarchy data from electronic communication behavior. the algorithm is based on data mining user behaviors to automatically analyze and catalog patterns of communications between entities in a email collection to extract social standing. the advantage to such automatic methods is that they extract relevancy between hierarchy levels and are dynamic over time.
　we illustrate the algorithms over real world data using the enron corporation's email archive. the results show great promise when compared to the corporations work chart and judicial proceeding analyzing the major players.
general terms
social network  enron  behavior profile  link mining  data mining
1.	introduction
　there is a vast quantity of untapped information in any collection of electronic communication records. the recent bankruptcy scandals in publicly held us companies such as enron and worldcom  and the subsequent sarbanes-oxley act have increased the need to analyze these vast stores of electronic information in order to define risk and identify any conflict of interest among the entities of a corporate household. corporate household is 'a group of business units united or regarded united within the corporation  such as suppliers and customers whose relationships with the cor-
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee.
joint 1th webkdd and 1st sna-kdd workshop '1 august 1  1  san
jose  california   usa
copyright 1 acm 1-1 ...$1.
poration must be captured  managed  and applied for various purposes' . the problem can be broken into three distinct phases; entity identification  entity aggregation  and transparency of inter-entity relationships .
　identifying individual entities is straightforward process  but the relationships between entities  or corporate hierarchy is not a straightforward task. corporate entity charts sometimes exist on paper  but they do not reflect the day to day reality of a large and dynamic corporation. corporate insiders are aware of these private relationships  but can be hard to come by  especially after an investigation. this information can be automatically extracted by analyzing the email communication data from within a corporation.
　link mining is a set of techniques that uses different types of networks and their indicators to forecast or to model a linked domain. link mining has been applied to many different areas  such as money laundering   telephone fraud detection   crime detection   and surveillance of the nasdaq and other markets  1  1 . perlich and huang  show that customer modeling is a special case of link mining or relational learning  which is based on probabilistic relational models such as those presented by  1  1  1 . a recent survey of the literature can be found in . in general models classify each entity independently according to its attributes. probabilistic relational models classify entities taking into account the joint probability among them. the application of link mining to corporate communication is of course limited by restrictions to disseminate internal corporate data. thus testing algorithms against real world data is hard to come by. an exception to this situation is the publicly available enron email dataset.
　the enron corporation's email collection described in section 1  is a publicly available set of private corporate data released during the judicial proceedings against the enron corporation. several researchers have explored it mostly from a natural language processing  nlp  perspective  1  1  1 . social network analysis  sna  examining structural features  has also been applied to extract properties of the enron network and attempts to detect the key players around the time of enron's crisis;  studied the patterns of communication of enron employees differentiated by their hierarchical level;  interestingly enough found that word use changed according to the functional position  while  conducted a thread analysis to find out employees' responsiveness.  used an entropy model to identify the most relevant people   presents a method for identity resolution in the enron email dataset  and  applied a cluster ranking algorithm based on the strength of the clusters to this dataset.
　the work presented in this paper differs in two major ways. first  the relationship between any two users are calculated based on behavior patterns of each specific user not just links. this allows the algorithm to judge the strength of communication links between users based on their overall communication pattern. second  we assume a corporate householding perspective and propose a methodology to solve the problem of transparency of inter-entity relationships in an automatic fashion. our approach determines link mining metrics which can reproduce approximate social hierarchy within an organization or a corporate household  and rank its members. we use our metric to analyze email flows within an organization to extract social hierarchy. we analyze the behavior of the communication patterns without having to take into account the actual contents of the email messages.
　by performing behavior analysis and determining the communication patterns we are able to automatically:
  rank the major officers of an organization.
  group similarly ranked and connected users in order to accurately reproduce the organizational structure in question.
  understand relationship strengths between specific sets of users.
　this work is a natural extension of previous work on the email mining toolkit project  emt   1  1 . new functionality has been introduced into the emt system for the purposes of automatically extracting social hierarchy information from any email collection.
　the rest of the paper is organized as follows: section 1 describes the enron email corpus  section 1 presents the methods used to rank the enron's officers; section 1 presents the results; section 1 discusses the results  and section 1 presents the conclusions.
1.	enron antecedents and data
　the enron email data set is a rich source of information showcasing the internal working of a real corporation over a period between 1. there seems to be multiple versions of the  official  enron email data set in the literature  1  1  1  1 . in the midst of enron's legal troubles in 1  the federal energy regulatory commission  ferc  made a dataset of 1 emails from 1 enron employees available to the public removing all attachment data. cohen first put up the raw email files for researchers in 1  the format was mbox style with each message in its own text file . following this  a number of research groups around the country obtained and manipulated the dataset in a variety of ways in attempts to correct inconsistencies and integrity issues within the dataset. like   the version of the dataset we use to conduct our own research was treated and provided by shetty and adibi from isi . the isi treatment of the enron corpus consisted of deleting extraneous  unneeded emails and fixing some anomalies in the collection data having to do with empty or illegal user email names and bounced emails messages. in addition duplicates and blank emails were removed.
　it should be noted that  has found that there is indication that a significant number of emails were lost either in converting the enron data set or through specific deletion of key emails. so although we are working with most of the emails  we will make the assumption that the algorithm is robust although some emails are not part of the analysis. in addition the ferc dataset only covers about 1% of enron employess at the time.
1.	sna algorithm
the social network analysis algorithm works as follows:
　for each email user in the dataset analyze and calculate several statistics for each feature of each user. the individual features are normalized and used in a probabilistic framework with which users can be measured against one another for the purposes of ranking and grouping. it should be noted that the list of email users in the dataset represents a wide array of employee positions within the organization or across organizational departments.
　two sets of statistics are involved in making the decision about a given user's  importance.  first  we collect information pertaining to the flow of information  both volumetric and temporal. here we count the number of emails a user has sent and received in addition to calculating what we call the average response time for emails. this is  in essence  the time elapsed between a user sending an email and later receiving an email from that same user. an exchange of this nature is only considered a  response  if a received message succeeds a sent message within three business days. this restriction has been implemented to avoid inappropriately long response times caused by a user sending an email  never receiving a response  but then receiving an unrelated email from that same user after a long delay  say a week or two. these elapsed time calculations are then averaged across all
 responses  received to make up the average response time. second  we gather information about the nature of the connections formed in the communication network. here we rank the users by analyzing cliques  maximal complete subgraphs  and other graph theoretical qualities of an email network graph built from the dataset. using all emails in the dataset  one can construct an undirected graph  where vertices represent accounts and edges represent communication between two accounts. we build such a graph in order to find all cliques  calculate degree and centrality measures and analyze the social structure of the network. when all the cliques in the graph have been found  we can determine which users are in more cliques  which users are in larger cliques  and which users are in more important cliques. we base it on the assumption that users associated with a larger set and frequency of cliques will then be ranked higher. finally all of the calculated statistics are normalized and combined  each with an individual contribution to an overall social score with which the users are ultimately ranked.
1	information flows
　first and foremost  we consider the volume of information exchanged  i.e. the number of emails sent and received  to be at least a limited indicator of importance. it is fair to hypothesize that users who communicate more  should  on average  maintain more important placement in the social hierarchy of the organization. this statistic is computed by simply tallying the total number of emails sent and received by each user.
　furthermore  in order to rate the importance of user i using the amount of time user j takes to respond to emails from user i  we must first hypothesize that a faster response implies that user i is more important to user j. addition-
ally  when we iterate and average over all j  we will assume that the overall importance of user i will be reflected in this overall average of his or her importance to each of the other people in the organization. in other words  if people generally respond  relatively  quickly to a specific user  we can consider that user to be  relatively  important. to compute
the average response time for each account x  we collect a list of all emails sent and received to and from accounts y1 through yn  organize and group the emails by account y1 through yn  and compute the amount of time elapsed between every email sent from account x to account yj and the next email received by account x from account yj. as previously mentioned  communication of this kind contributes to this value only if the next incoming email was received within three business days of the original outgoing email.
1	communication networks
　the first step is to construct an undirected graph and find all cliques. to build this graph  an email threshold n is first decided on. next  using all emails in the dataset  we create a vertex for each account. an undirected edge is then drawn between each pair of accounts which have exchanged at least n emails. we then employ a clique finding algorithm  algorithm 1  first proposed by bron and kerbosch . this recursively finds all maximal complete subgraphs  cliques .
a. number of cliques: the number of cliques that the account is contained within.
b. raw clique score: a score computed using the size of a given account's clique set. bigger cliques are worth more than smaller ones  importance increases exponentially with size.
c. weighted clique score: a score computed using the
 importance  of the people in each clique. this preliminary  importance  is computed strictly from the number of emails and the average response time. each account in a clique is given a weight proportional to its computed preliminary. the weighted clique score is then computed by adding each weighed user contribution within the clique. here the 'importance' of the accounts in the clique raises the score of the clique.
　more specifically  the raw clique score r is computed with the following formula:
r = 1n 1
where n is the number of users in the clique. the weighted clique score w is computed with the following formula:
w = t ， 1n 1
where t is the time score for the given user.
　finally  the following indicators are calculated for the graph g v e  where v = v1 v1 ... vn is the set of vertices  e is the set of edges  and eij is the edge between vertices vi and vj:
.
  degree centrality or degree of a vertex vi: deg vi  = where aij is an element of the adjacent matrix
.
  clustering coefficient:		  where cci =
 : vj （ ni  eij （ e. each vertex vi has a neighborhood n defined by its immediately connected neighbors: ni = {vj} : eij （ e.
  mean of shortest path length from a specific vertex to all vertices in the graph p   where dij （ d  d is the geodesic distance matrix  matrix of all shortest path between every pair of vertices  of g  and n is the number of vertices in g.
  betweenness centrality pp kij . this is the proportion of all geodesic distances of all other vertices that include vertex vi where gkij is the number of geodesic paths between vertices k and j that include vertex i  and gkj is the number of geodesic paths between k and j .
   hubs-and-authorities  importance:  hub  refers to the vertex vi that points to many authorities  and  authority  is a vertex vj that points to many hubs. we used the recursive algorithm proposed by  that calculates the  hubs-and-authorities  importance of each vertex of a graph g v e .
1	the social score
　we introduce the social score s  a normalized  scaled number between 1 and 1 which is computed for each user as a weighted combination of the number of emails  response score  average response time  clique scores  and the degree and centrality measures introduced above. the breakdown of social scores is then used to:
i. rank users from most important to least important
ii. group users which have similar social scores and cliqueconnectivity
iii. determine n different levels  or echelons  of social hierarchy within which to place all the users. this is a clustering step  and n can be bounded.
　the rankings  groups and echelons are used to reconstruct an organization chart as accurately as possible. to compute s   we must first scale and normalize each of the previous statistics which we have gathered. the contribution  c   of each metric is individually mapped to a  1  1  scale and weighted with the following formula:

where x is the metric in question  wx is the respective weight for that metric  the supx and inf x are computed across all i users and xi is the value for the ith user. this normalization is applied to each of the following metrics:
1. number of emails
1. average response time
1. response score
1. number of cliques
1. raw clique score
1. weighted clique score
1. degree centrality
1. clustering coefficient
1. mean of shortest path length from a specific vertex toall vertices in the graph
1. betweenness centrality
1.  hubs-and-authorities  importance
　finally  these weighted contributions are then normalized over the chosen weights wx to compute the social score as follows:
pall x wx ， cx
s =
pall x wx
　this gives us a score between 1 and 1 with which to rank every user into an overall ranked list. our assumption is that although the number of emails  average response time  number and quality of cliques  and the degree and centrality measures are all perfectly reasonable variables in an equation for  importance   the appropriate contribution  i.e. weight  of each will vary by situation and organization  and therefore can be adjusted to achieve more accurate results in a variety of cases.
1	visualization
　as part of this research  we developed a graphical interface for emt  using the jung library  to visualize the results of social hierarchy detection by means of email flow.
　after the results have been computed  the statistics calculated and the users ranked  the option to view the network is available. when this option is invoked  a hierarchical  organized version of the undirected clique graph is displayed. nodes represent users  while edges are drawn if those two users have exchanged at least m emails. information is provided to the user in two distinct ways  the qualities of a user are reflected in the look of each node  where the relative importance of a user is reflected in the placement of each node within the simulated organization chart.
　although every node is colored red  its relative size represents its social score. the largest node representing the highest ranked individual  the smallest representing the lowest. the transparency of a given node is a reflection of the user's time score. a user boasting a time score near to 1 will render itself almost completely opaque where a user with a very low time score will render almost entirely transparent. the users are divided into one of n echelons using a grouping algorithm  we use n = 1 in this paper. currently  the only grouping algorithm which has been implemented is a straight scale level division. users with social scores from 1 are placed on the top level  users with social scores from 1 are placed on the next level down  etc. if the weights are chosen with this scale division in mind  only a small percentage of the users will maintain high enough social scores to inhabit the upper levels  so a tree-like organizational structure will be manifested. different  more sophisticated  ranking and grouping algorithms have been considered and will be implemented  and will be discussed in the following section on future work.
　when a node is selected with the mouse  all users connected to the selected user through cliques are highlighted and the user  time score and social score populate a small table at the bottom of the interface for inspection. nodes can be individually picked or picked as groups and rearranged at the user's discretion. if the organization is not accurate or has misrepresented the structure of the actual social hierarchy in question  the user can return to the analysis window and adjust the weights in order to emphasize importance in the correct individuals and then can recreate the visualization.
　if the user would prefer to analyze the network graphically with a non-hierarchical structure  a more traditional graph/network visualization is available by means of the fruchterman-reingold node placement algorithm. this node placement algorithm will emphasize the clique structure and the connectedness of nodes in the graph rather than the hierarchical ranking scheme in the first visual layout.
1.	results and discussion
　we have performed the data processing and analysis using emt . emt is a java based email analysis engine built on a database back-end. the java universal network/graph framework  jung  library  is used extensively in emt for the degree and centrality measures  and for visualization purposes  see section 1 .
　in order to showcase the accuracy of our algorithm we present the analysis of the north american west power traders division of enron corporation.
　as one can see in table 1 and figure 1  when running the code on the 1 users contained with the north american west power traders division we can reproduce the very top of the hierarchy with great accuracy. the transparency of the vertices in the graph visualization  figure 1  denotes the response score of the user  a combination of the number of responses and the average response time. by our assumptions made in section three  we have determined that lower average response times infer higher importance  and appropriately  tim belden and debra davidson have fast average response times  causing more opaque colored node representations.

figure 1: enron north american west power traders extracted social network　once we turn to the lower ranked individuals  differences in our computed hierarchy and the official hierarchy are quite noticeable in figure 1. as we move down the corporate ladder  the conversational flows of dissimilar employees can in fact be quite similar. despite the discrepancies of our selections with the lower ranked officers  we find that consistently we are able to pick out the most important 1 or 1 individuals in any given subset  affording us the power to build a hierarchy from small groups up. not only does the head of enrons western trading operation  tim belden  appear on the top of our list  both his administrative assistants appear with him. additionally  in the first fourteen positions we are also able to identify the majority of directors  and an important number of managers and specialists. figure 1 highlights these positions and their key role in the organizational structure.1
　the placement of accounts other than the top two or three is in fact giving us insight into the true social hierarchy of this particular enron business unit over the course of time from which the emails were gathered. this differs noticeably from the official corporate hierarchy  which can be expected as the data reflects the reality of the corporate communication structure.
　with this sort of technique  it may be possible to view a snapshot of a corporate community  or any number of sub-communities  and effectively determine the real relationships and connections between individuals  a set of insights an official corporate organization chart simply could not offer.
1.	conclusions and future work
　although real world data is hard to come by  the enron dataset provides an excellent starting point for these tools. when we analyzed the algorithm on our own email data the social hierarchy of our lab was very apparent. figure 1 clearly shows professor  phd  lab students  and outsiders.
　the next immediate concern is to apply these tools to the enron dataset in a comprehensive and formal manner over time based data sets. the dataset contains enough email volume and generality to provide us with very useful results if we are interested in knowing how social structure changes over time. by varying the feature weights it is possible to use the mentioned parameters to:
a. pick out the most important individual s  in an orga-nization 
b. group individuals with similar social/email qualities and
c. graphically draw an organization chart which approx-imately simulates the real social hierarchy in question
　in order to more completely answer our question  as previously mentioned  a number of additions and alterations to the current algorithms exist and can be tested. first  the concept of average response time can be reworked or augmented by considering the order of responses  rather than the time between responses  like in . for example  if user a receives an email from user b before receiving an email from user c  but then promptly responds to user c before responding to user b  it should be clear that user c carries more importance  at least in the eyes of user a . either replacing the average response time statistic with this  or introducing it as its own metric may prove quite useful.
　another approach is to consider common email usage times for each user and to adjust the received time of email to the beginning of the next common email usage time. for example  if user a typically only accesses her email from 1am and from 1pm  then an email received by user a at 1pm can be assumed to have been received at 1am the next morning. we hypothesize that this might correct errors currently introduced in the average response time calculations due to different people maintaining different work schedules.

figure 1: analysis of our own emails　in addition to the continued work on the average response time algorithms  new grouping and division algorithms are being considered. rather than implementing the straight scale division algorithm  a more statistically sophisticated formula can be used to group users by percentile or standard deviations of common distributions. furthermore  rather than ignoring the clique connections between users at this step  the graph edges could very well prove important in how to arrange users into five different levels of social ranking  by grouping users with respect to their connections to others.
1.	additional authors
