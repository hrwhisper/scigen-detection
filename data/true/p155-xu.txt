as a social service in web 1  folksonomy provides the users the ability to save and organize their bookmarks online with  social annotations  or  tags . social annotations are high quality descriptors of the web pages' topics as well as good indicators of web users' interests. we propose a personalized search framework to utilize folksonomy for personalized search. specifically  three properties of folksonomy  namely the categorization  keyword  and structure property  are explored. in the framework  the rank of a web page is decided not only by the term matching between the query and the web page's content but also by the topic matching between the user's interests and the web page's topics. in the evaluation  we propose an automatic evaluation framework based on folksonomy data  which is able to help lighten the common high cost in personalized search evaluations. a series of experiments are conducted using two heterogeneous data sets  one crawled from del.icio.us and the other from dogear. extensive experimental results show that our personalized search approach can significantly improve the search quality.
categories and subject descriptors
h.1  information search and retrieval : information search and retrieval-search process
general terms
algorithms  measurement  experimentation  performance
keywords
folksonomy  personalized search  topic space  web 1  automatic evaluation framework

 part of this work was done while shengliang xu and shenghua bao were interns at ibm china research lab.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee.
sigir'1  july 1  1  singapore.
copyright 1 acm 1-1-1/1 ...$1.
1. introduction
¡¡in today's search market  the most popular search paradigm is keyword search. despite simplicity and efficiency  keyword queries can not accurately describe what the users really want. people engaged in different areas may have different understandings of the same literal keywords. authors of   concluded that people differ significantly in the search results they considered to be relevant for the same query.
¡¡one solution to this problem is personalized search. by considering user-specific information   search engines can to some extent distinguish the exact meaning the users want to express by the short queries. along with the evolution of the world wide web  many kinds of personal data have been studied for personalized search  including user manually selected interests  1  1   web browser bookmarks   users' personal document corpus   search engine click-through history  1  1  1   etc. in all  search personalization is one of the most promising directions for the traditional search paradigm to go further.
¡¡in recent years  there raises a growing concern in the new web 1 environment. one feature of web 1 that distinguishes it from the classical world wide web is the social data generation mode. the service providers only provide platforms for the users to collaborate and share their data online. such services include folksonomy  blog  wiki and so on. since the data are generated and owned by the users  they form a new set of personal data. in this paper  we focus on exploring folksonomy for personalized search.
the term  folksonomy  is a combination of  folk  and
 taxonomy to describe the social classification phenomenon . online folksonomy services  such as del.icio.us   flickr and dogear    enable users to save and organize their bookmarks  including any accessible resources  online with freely chosen short text descriptors  i.e.  social annotations  or  tags   in flat structure. the users are able to collaborate during bookmarking and tagging explicitly or implicitly. the low barrier and facility of this service have successfully attracted a large number of users to participate.
¡¡the folksonomy creates a social association between the users and the web pages through social annotations. more specifically  a user who has a given annotation may be interested in the web pages that have the same annotation. inspired by this  we propose to model the associations between the users and the web pages using a topic space. the interests of each user and the topics of each web page can be mapped to vectors in the topic space. the personalized search is conducted by ranking the web pages in two guidelines  term matching and topic matching. when a user u issues a query q  a web page p is ranked not only by the term similarity between q and p but also by the topic similarity between u and p. the social annotations in folksonomy naturally form a social topic space. three properties of folksonomy are studied for the topic space estimation:
¡¡the categorization property. many of the social annotations are subject descriptor keywords at various levels of specificity . the selection of proper annotations for a web page is somewhat a classification of the web page to the categories represented by the annotations.
¡¡the keyword property. as discussed in  1  1  1   the annotations can be seen as good keywords for describing the respective web pages from various aspects.
¡¡the structure property. in folksonomy systems  users' bookmarking actions form a cross link structure between the users and the web pages. since all the folksonomy data are publicly available  the structure can be fully explored.
¡¡some of the prior studies show similar ideas. in  1  1  1  1  1   they use odp taxonomy structure to represent the topics of the web pages and the interests of the users. as a comparison  we also apply odp in our work to show whether or not the classical web page taxonomy still perform well enough for the web 1 search personalization.
¡¡as for evaluation  we propose a new evaluation framework for personalized search using folksonomy data. the framework is low cost. thus it is able to help lighten the common high barrier in personalized search evaluation. extensive experimental results show that our personalized search algorithm outperforms the baselines significantly.
¡¡the rest of this paper is organized as follows. section 1 lists some related work. in section 1  after a detailed analysis of folksonomy  the personalized search algorithms are discussed. section 1 presents the novel personalized search evaluation framework. in section 1  we report the experiment results. section 1 lists some discussions about our work. finally  we conclude our work and list some future work in section 1.
1. related work
¡¡this paper brings together two areas  personalized search and folksonomy  both of which already exist a lot of prior efforts. in this section we present a separate review on either of them.
1 personalized search
¡¡as early as in 1  lawrence  pointed out that nextgeneration search engines will increasingly use context information to improve search effectiveness. in 1  pitkow et al. further identified two primary strategies  query refinement and result processing  to personalize search in .
¡¡query refinement  also called query expansion  refers to the modification to the original query  including augmenting the query by other terms or changing the original weight of each query term. much work has been done in this area  like  1  1   etc. however  since our work focuses on result processing  these prior efforts are not relevant to us closely. we do not review them in detail here.
¡¡result processing includes result reranking according to each user's personal needs  result clustering for better presentation  etc. among these  result reranking is one of the most widely used. haveliwala in  proposed to calculate a set of pageranks for each web page biased on the top most 1 odp categories. the odp categories in his work is a little similar to the topic space we will propose in the personalized search framework. but our topic space is much more general than their odp categories. further in   qiu and cho proposed a sophisticated approach to build user models from user click history and combine it with haveliwala's work for personalized search. in some other studies  such as  1  1  1  the odp category structure is also accepted for modeling the web pages' topics and the users' interests. the odp categories in these studies is a little similar to the topic space we will propose in the personalized search framework but our topic space is more general. in a recent study   noll and meinel proposed to rerank the non-personalized search results by considering the user's social annotations and the search results' social annotations. their work is rather simple while effective. the success they achieved is a strong support for our work. recently  dou et al.  proposed an evaluation framework for personalized search using user click-through history  which needs a lot of user click through data from a real life search engine. though the technology sounds promising  it is unpractical for most of the researchers because the click through data of search engines are not publicly accessible.
¡¡except the above  there are still a lot of wonderful prior studies on result refinement for personalized search  such as  1  1   etc. since they are not very relevant to our work  we don't present the detailed reviews here.
1 folksonomy
¡¡existing research on folksonomy can be mainly divided into two directions. the first is the survey and analysis of the general characteristics of folksonomy systems. the second is the exploring of folksonomy for various applications.
¡¡the semantic values of folksonomy. in    the authors investigated two of the most famous folksonomy service providers del.icio.us and flickr and gave the strengths and weaknesses of annotation data. golder & huberman gave a deep investigation of the del.icio.us tag data in . al-khalifa & davis analyzed the semantic value of social annotations and got the conclusion that the folksonomy tags are semantically richer than keywords extracted using a major search engine extraction service like yahoo te .
¡¡the collaborative link structure. several prior efforts propose to model the underlying link structure of folksonomy by graphs. in   the authors viewed the tagging system as a tripartite network with users  tags and urls as three kinds of nodes. catutto et al. investigated the underlying tripartite graph of the tagging systems in . they concluded that folksonomies exhibit a small world structure. applications. many applications of social annotations have been carried out in recent years  most of which focus on exploring the semantic value of annotations.  and  both exploited the latent semantics under the tag literature. bao et al. in  proposed to measure the similarity and popularity of web pages from web users' perspective by calculating socialsimrank and socialpagerank  respectively.
1. using folksonomy for personalized search
in this section  we first give a short analysis of folksonomy  and then discuss in detail the approach we propose for personalized search.
1 analysis of folksonomy
¡¡what folksonomy can bring us in personalized search  the best way to answer this question is to analyze it.
¡¡social annotations as category names. in the folksonomy systems  the users are free to choose any social annotations to classify and organize their bookmarks. though there may be some noise  each social annotation represents a topic that is related to its semantic meaning . based on this  the social annotations owned by the web pages and the users reflect their topics and interests respectively.
¡¡social annotations as keywords. as discussed in  1  1  1  the annotations are very close to human generated keywords. thus  the social annotations usually can well describe or even complement the content of the web pages.
¡¡collaborative link structure. one of the most important benefits that online folksonomy systems bring is the collaborative link structure created by the users unconsciously. the underlying link structure of the tagging systems has been explored in many prior efforts  1  1  1 . the whole underlying structures of folksonomy systems are rather complex. different researchers may reduce the complexity of modeling the structure by various simplified model  e.g. in   the structure is modeled through a latent semantic layer while in  the relations between the annotations and the web pages are modeled using a bipartite graph. in our work  since the relations between the users and the web pages are very important  we model the structure using a user-web page bipartite graph as shown in figure 1.

figure 1: user-web page bipartite structure
where ui  i = 1 ¡¤¡¤¡¤  n denote n users  pj  j = 1 ¡¤¡¤¡¤  m
denote m web pages  wk  k = 1 ¡¤¡¤¡¤  l are the weights of the links  i.e. the bookmarking actions of the users. one of the simplest implementation of the weights is the number of annotations a user assigned to a web page.
1 a personalized search framework
¡¡in the classical non-personalized search engines  the relevance between a query and a document is assumed to be only decided by the similarity of term matching. however  as pointed in   relevance is actually relative for each user. thus  only query term matching is not enough to generate satisfactory search results for various users.
¡¡in the widely used vector space model vsm   all the queries and the documents are mapped to be vectors in a universal term space. the similarity between a query and a document is calculated through the cosine similarity between the query term vector and the document term vector. though simple  the model shows amazing effectiveness and efficiency.
¡¡inspired by the vsm model  we propose to model the associations between the users and the web pages using a topic space. each dimension of the topic space represents a topic. the topics of the web pages and the interests of the users are represented as vectors in this space. further we define a topic similarity measurement using the cosine function. let p~ti =  w1 i w1 i ¡¤¡¤¡¤  w¦Á i  be the topic vector of the web page pi where ¦Á is the dimension of the topic space and wk i is the weight of the kth dimension. similarly  let u~tj =  w1 j w1 j ¡¤¡¤¡¤  w¦Á j  be the interest vector of the user uj. the topic similarity between pi and uj is calculated as equation 1.
		 1 
¡¡based on the topic space  we make a fundamental personalized search assumption  i.e. assumption 1.
¡¡assumption 1. the rank of a web page p in the result list when a user u issues a query q is decided by two aspects  a term matching between q and p and a topic matching between u and p.
¡¡when a user u issues a query q  we assume two search processes  a term matching process and a topic matching process. the term matching process calculates the similarity between q and each web page to generate a user unrelated ranked document list. the topic matching process calculates the topic similarity between u and each web page to generate a user related ranked document list. then a merge operation is conducted to generate a final ranked document list based on the two sub ranked document lists. we adopt ranking aggregation to implement the merge operation.
¡¡ranking aggregation is to compute a consensus ranking of several sub rankings . there are a lot of rank aggregation algorithms that can be applied in our work. here we choose one of the simplest  weighted borda-fuse  wbf . equation 1 shows our idea.
	r u q p  = ¦Ã ¡¤ rterm q p  +  1   ¦Ã  ¡¤ rtopic u p 	 1 
¡¡where rterm q p  is the rank of the web page p in the ranked document list generated by query term matching  rtopic u p  is the rank of p in the ranked document list generated by topic matching and ¦Ã is the weight that satisfies
1 ¡Ü ¦Ã ¡Ü 1.
¡¡obviously  how to select a proper topic space and how to accurately estimate the user interest vectors and the web page topic vectors are two key points in this framework. the next two subsections discuss these problems.
1 topic space selection
¡¡in web page classification  the web pages are classified to several predefined categories. intuitively  the categories of web page classification are very similar to the topics of the topic space. in today's world wide web  there are two classification systems  the traditional taxonomy such as odp and the new folksonomy. the two classification systems can be both applied in our framework. since our work focuses on exploring the folksonomy for personalized search  we set the odp topic space as a baseline.
1.1 folksonomy: social annotations as topics
¡¡based on the categorization feature  we set the social annotations to be the dimensions of the topic space. thus  the topic vector of a web page can be simply estimated by its social annotations directly. in the same way  the interest vector of a user can be also simply estimated by her social annotations.
¡¡obviously  if we treat the users and the web pages as documents  the social annotations as terms  the above setting is right the vsm. since the vsm has developed for a long time  there have been a large number of mature technologies to improve the vsm search effectiveness. all these can be easily applied here. one of the most important in vsm is the weighting for document terms. similarly  the topic weighting here is also very important. the simplest while widely used one is tfidf.
	 	 1 
 where tf denotes the term frequency  n denotes the total number of documents in the whole collection and ni denotes the number of documents in which the term appears. beside this  bm1 weighting scheme is a more sophisticated alternative  which represents state-of-the-art retrieval functions used in document retrieval

where k1 and b are free parameters  dl denotes the document length and avgdl denotes the average document length of all the documents in the collection.
1.1 taxonomy: odp categories as topics
¡¡in web page taxonomy  the dmoz open directory project  odp  is the largest  most comprehensive human-edited directory of the web. this high quality and free web taxonomy resource has been used in rather a number of prior researches like  1  1  1  1  1 . some of these studies show similar idea as ours  especially  and . they use the odp categories as topics to calculate a set of topic biased pageranks  which are used in personalized search. following their steps  we can also choose odp's 1 top categories as the dimensions of the topic space. however  1 categories may be too few for our personalized search task comparing to the folksonomy categories. thus  we make another choice of totally 1 categories  including all the second level categories of odp and the third level categories of top/computers. the choice is based on the consideration that the data corpus we will use in experiments are mostly about computer science.
¡¡now the question is how to estimate the topic vectors and interest vectors. odp releases all the data in rdf format. in the rdf file  each of the web pages included in odp attaches a short description. all the descriptions of the web pages under a category can be merged to create a term vector of the corresponding category. then the topic vector of a web page can be calculated by cosine similarity of the category's term vector and the social annotations of the web page. similarly  the interest vector of a user can be calculated by cosine similarity of the category's term vector and the social annotations owned by the user.
1 interest and topic adjusting via bipartite collaborative link structure
¡¡in section 1  we have modeled the underlying collaborative structure of a folksonomy system as a bipartite graph. the bipartite structure is the result of user collaboration which is one of the main advantages that online folksonomy service over offline desktop bookmarks. intuitively  the topics of the web pages that a user saved in social tagging systems exhibit the user's interests. in return  the interests of the users who saved a given web page also imply the topics of the web page to some extent. furthermore  it's not difficult to infer that this process is actually iterative. we propose to fully explore this bipartite structure for adjusting the initial estimation of users' interest vectors and the web pages' topic vectors using an iterative algorithm.
¡¡formally  let g =  v e  be the graph  where the nodes in v represent users and web pages  and the edges e represent the bookmarking actions. the nodes in v are divided into two subsets u = {u1 u1 ¡¤¡¤¡¤  un} representing the users and p = {p1 p1 ¡¤¡¤¡¤  pm} representing the web pages. in table 1  we list all the symbols we will use in the algorithm. table 1: symbols used in the topic adjusting algorithm
symbolmeaningwthe adjacency matrix  in which the rows represent the users and the columns represent the web pages. wi j is set to the number of annotations that ui gives to pj.wrnthe row normalized version of w.the column normalized version ofthe jth normalized interest of the	userthe	normalized topic of the ith web pagethe row normalized interest matrix of all the users  in which the rows represent the users and the columns represent the interests. ri j is the jth interest value of uitthe row normalized topic matrix of all the web pages  in which the rows represent the web pages and the columns represent the topics. ti j is the jth topic value of pi¦Áthe weight of the initial estimated user interest¦Âthe weight of the initial estimated web page topiceach iteration of this algorithm is performed in two steps. 1  user interest adjusting by related web pages.
		 1 
where ri j1 is the initial value of ri j.
1  web page topic adjusting by related users.
		 1 
where ti j1 is the initial value of ti j.
¡¡as we can see from the above two equations  we reserve in each iteration an ¦Á and a ¦Â weight of the initial interest value and the initial topic value respectively. the reason is that  since ri j1 and ti j1 are estimated directly from the social annotations' literal contents while  
and   n w are from the link structure  they are two heterogeneous parts. the two weights  ¦Á and ¦Â  are to reserve the influence of the social annotations' literal contents in the final adjusted vectors.
¡¡besides  though the forms of the above two equations seem to be complicated  the operations are actually linear combination. thus the topic vectors of the web pages and the interest vectors of the users must be in the same scale. thus  before the running of the algorithm we normalize all the vectors.
¡¡finally  the above two equations can be rewritten in the form of matrices as following:
rt+1=¦Ár1 +  1   ¦Á wrntt 1 tt+1=¦Ât1 +  1   ¦Â wcnt rt+1 1  we claim that this iterative algorithm converges to a fixed point finally. in the following we give a short proof. we don't list the detailed analysis of this algorithm because of page limitation. the interested readers can refer to some prior studies such as    inspired from which we have the idea of this algorithm.
¡¡proof. without loss of generality  we only prove ri can converge to a fixed point. let w¦Á be  1   ¦Á wrn and w¦Â be  1   ¦Â wcnt   we can expand equation 1 as following:
ri+1=¦Á{e + w¦Áw¦Â +  w¦Áw¦Â 1 + ¡¤¡¤¡¤ +  w¦Áw¦Â i+1}r1thus +¦Âw¦Á{e + w¦Âw¦Á +  w¦Âw¦Á 1 + ... w¦Âw¦Á i}t1 lim kri+1   rik i¡ú+¡Þ= lim k¦Á w¦Áw¦Â i+1 + ¦Âw¦Á w¦Âw¦Á it1k i¡ú+¡Þ=+ on the one hand  consider that wrn and wcnt are both row normalized  they are actually two markov matrices  thus
wrnwcnt   wcnt wrn   wrnwcnt  i+1 and  wcnt wrn i are also markov matrices. on the other hand  because that 1   ¦Á   1 and 1   ¦Â   1  we can derive:
	lim {¦Á 1   ¦Á i+1   ¦Â i+1}	=	1
i¡ú+¡Þ lim {¦Â 1   ¦Á i+1   ¦Â i}	=	1
i¡ú+¡Þ
 thus  we can finally derive that limi¡ú+¡Þ kri+1  rik = 1  i.e. ri is convergent. 
¡¡for convenience  we refer to this algorithm as topic adjusting algorithm in the rest of the paper.
1. an evaluation framework for personalized search using social annotations
¡¡in the community of personalized search  evaluation is not an easy task. generally speaking  the evaluation methods used in prior personalized search studies fall into two categories  user experience study  1  1  1  1  1  and search engine query logs  1  1 .
¡¡the user study approach  though widely accepted in most of the prior efforts  needs many users to involve in the experiments  which is a rather high cost. in addition  since the users who take part in the experiments know that they are being tested  they may bias the experiment results. the search engine query logs approach needs a large portion of real life search logs. this is not possible for most of the researchers  including us. the search engine service providers are not willing to release their query logs because they include privacy of the users. in addition  the relevance assumption based on user clicks is strongly biased by the search engines.
¡¡under this condition  we propose a new evaluation framework for personalized search based on social annotations. the main obstacle that raises the difficulty of evaluation for personalized search is that we must have enough userspecific relevance judgement data. in the user experience study  these data are collected from the experiment participants directly. in the search log approach  the researchers make an assumption that the user clicks reflect their relevance judgement. thus they can collect a lot of experiment data without any extra user efforts. as for our evaluation framework  we make an assumption similar to the search log approach  i.e.
¡¡assumption 1. the users' bookmarking and tagging actions reflect their personal relevance judgement.
¡¡for example  if a user assigned an annotation java to the apache lucene homepage  http://lucene.apache.org  we assume that the user will consider this web page as relevant if she issues  java  as a query. of course  it's also the truth that a lack of an annotation doesn't necessarily mean irrelevance. however  to the best of our knowledge  this is a common problem for all the prior evaluation approaches for personalized search within the web scale.
this assumption is based on three considerations.
¡¡1  in today's search technology  keyword query is the most popular query representation. according to the keyword feature of folksonomy  most of the social annotations are keywords of their owner web pages. thus  the annotations can be considered as queries to some extent.
¡¡1  as discussed in section 1  a web page may contain multiple topics. different users may be interested in different topics of the same web pages. most likely the users may choose their favorite topics of the web pages to assign some related annotations. in other words  if the social annotations are issued as queries  different users may consider a web page to be relevant to different queries.
¡¡1  different users may choose various terms as social annotations for the same web page. the annotations reflect their personal preference of daily life vocabulary. in other words  the data don't bias for our experiments.
¡¡the above three considerations have been analyzed and explored in several prior efforts  1  1  1  1  1  1  1  1  1   because of page limitation  we don't list the detailed analysis here. in all  we expect this new evaluation framework to lighten the high barrier of personalized search evaluation.
1. experiments
1 experiment setup
1.1 data set
¡¡to fully evaluate our personalized search model  we use two heterogeneous data sets. one is crawled from del.icio.us during may 1  consisting of 1 web pages  1 distinct annotations and 1 users. since this data set is from the web  it reflects the web users' social bookmarking and tagging patterns. the other one is the tagging records of the dogear tagging system  up to july 1th 1. the data set consists of 1 web pages  1 distinct annotations and 1 users. this data set reflects the enterprise users' social bookmarking and tagging patterns.
¡¡from each data set  we build three test beds according to the number of bookmarks owned by the users  resulting in totally 1 test beds. the 1 test beds built from the del.icio.us data set are: 1  1 randomly selected users who own 1 ¡« 1 bookmarks and their tagging records  denoted as del.1; 1  1 random users who own 1 ¡« 1 bookmarks and their tagging records  denoted as del.1; 1  all the 1 users who own more than 1 bookmarks and their tagging records  denoted as del.gt1. the 1 test beds from the dogear data set are built in the same way as del.icio.us  denoted as dog.1  dog.1 and dog.gt1 respectively. the purpose of building the 1 test beds is not only to evaluate the model in the two different environments  i.e. web and enterprise  but also to evaluate it in the situations of different amount of data.
¡¡before the experiments we perform two data preprocessing processes. 1 several of the annotations are too personal or meaningless  such as  toread    importedie fa-vorites    system:imported   etc. we remove some of them manually. 1  some users may concatenate several words to form an annotation   e.g. javaprogramming  java/programming  etc. we split this kind of annotations with the help of a dictionary. table 1 presents the statistics of the two data sets and the 1 test beds after data preprocessing where  num.users  denotes the number of users   max.tags  denotes the maximum number of distinct tags owned by each user  the rest columns have the similar meanings as  max.tags . as for
table 1: statistics of the user owned tags and web pages of the experiment data
data setnum.
usersmax.
tagsmin.
tagsavg.
tagsmax.
pagesmin.
pagesavg.
pagesdelicious11.11.1dogear11.11.1del.gt11111del.111.11.1del.111.11.1dog.gt11111dog.111.11.1dog.111.11.1
1
each test bed  we randomly split them into 1 parts  a 1% training part and a 1% test part. the training parts are used to estimate the models while the test parts are used for evaluating. all the preprocessed data sets are used in the experiments. no other filtering is conducted.
1.1 personalized search framework implementation
¡¡our personalized search framework needs two separated ranked lists of web pages. in practice  instead of generating two full ranked lists of all the web pages  an alternative approach that costs less is to rerank only the top ranked results fetched by the text matching model. in the experiments  we conduct such reranking based on two state-of-the-art text retrieval model  bm1 and language model for ir  lmir . firstly  a ranked list by a text retrieval model is generated. then top 1 web pages in the ranked list are reranked by our personalized search model.
1.1 parameter setting
¡¡before the experiments  there are three sets of parameters that must be set. the first two parameters are the ¦Á and ¦Â in the topic adjusting algorithm in section 1. we simply set them both 1 to keep the same influence for the initial social annotations' literal contents and the link structure. the second set of parameters are the set of ¦Ãs in the ranking aggregation when using various search models under various test beds  i.e. equation 1. we conduct a simple training process to estimate the ¦Ãs as shown in procedure 1. the concrete values of ¦Ã under each search model and test bed

procedure 1. ranking aggregation parameter training process

foreach test bed tb ¡Ê 1 test beds do
split the training part of tb into 1 parts tni  1 ¡Ü i ¡Ü 1 foreach tn ¡Ê tni do
training the interest vectors and the topic vectors
using other 1 training parts
1 run the evaluation 1 times using tn with ¦Ã set to
1  1  ¡¤¡¤¡¤  1 respectively
1 record the ¦Ã that leads to the optimal performance 1	set the average of the 1 ¦Ãs as the final parameter

is listed in table 1. in addition  we set the three parameters k1  k1 and b in bm1.1  1 and 1 respectively  which are the default parameter scheme in the lemur toolkit1. for the
lmir we accept jelinek-mercer smoothing  with ¦Á set to 1.
1.1 baseline models
¡¡in the experiments we select 1 baseline models  one is the non-personalized text matching model using no extra information except for contents  the second is the model using the top 1 odp categories as topic space which is denoted as  odp1   the third is the model using 1 odp categories as topics which is denoted as  odp1   and the last is the model proposed in   which is actually a simplified case of our personalized search framework when the topic space is set to be folksonomy and the topic matching function is set to simply counting the number of matched annotations. we refer to it as the  ac  model.
1.1 evaluation metric
¡¡the main evaluation metric we used in our work is mean average precision  map   which is a widely used evaluation metric in the ir community. more specifically  in our work  we calculate map for each user and then calculate the mean of all the map values. we refer it as mean map or mmap.

 where mapi represents the map value of the ith user and nu is the number of users.
¡¡in addition  we perform t-tests on average precisions over all the queries issued by all the users in each experimental data set to show whether the experimental improvements are statistical significant or not.
1 performance
table 1 lists all the 1 experimental results. the columns
 text    odp1    odp1    ac    f.tfidf  and  f.bm1  denote the non-personalized text model  the 1 top most odp topic space personalized model  the 1 odp topic space personalized model  the ac model  the folksonomy topic space personalized model using tfidf weighting scheme and the folksonomy topic space personalized model using bm1 weighting scheme. the sub columns b. a. and a. a. denote before adjusting by link structure and after adjusting by link structure   respectively. the * s in the mmap  row stand for four significance levels of the t-test  satisfying
1 ¡Ý *   1 ¡Ý **   1 ¡Ý ***.
¡¡as we can see from the table  the 1 personalized search models all outperform the simple text retrieval models sig-

1 http://www.lemurproject.org/
table 1: the ¦Ã settings  mmaps and the improvements imp.  comparing to the non-personalized text retrieval model using various personalized search models under various data sets
  bm1 textodp1odp1acf.tfidff.bm1   b. a.a. a.b. aa. a. b. a.a. a.b. a.a. a.dog.1¦Ã 1111 1111mmap11**1**1*1***1***1***1***1***1***imp. 1%1%1%1%1%1%1%1%1%dog.1¦Ã 1111 1111mmap111*111***1***1***1***1***imp. 1%1%1%1%1%1%1%1%1%dog.gt1¦Ã 1111 1111mmap11**1***11***1***1*1***1***1***imp. 1%1%1%1%1%1%1%1%1%del.1¦Ã 1111 1111mmap11***1***11**1***1***1***1**1***imp. 1%1%1%1%1%1%1%1%1%del.1¦Ã 1111 1111mmap11***1***1***1***1***1***1***1***1***imp. 1%1%1%1%1%1%1%1%1%del.gt1¦Ã 1111 1111mmap11**1***1**1***1***1***1***1***1***imp. 1%1%1%1%1%1%1%1%1%  lmir textodp1odp1acf.tfidff.bm1   b. a.a. a.b. aa. a. b. a.a. a.b. a.a. a.dog.1¦Ã 1111 1111mmap11*1**1**1***1***1***1***1**1***imp. 1%1%1%1%1%1%1%1%1%dog.1¦Ã 1111 1111mmap111**111***1***1***1***1***imp. 1%1%1%1%1%1%1%1%1%dog.gt1¦Ã 1111 1111mmap11***1***111***1***1***1***1***imp. 1%1%1%1%1%1%1%1%1%del.1¦Ã 1111 1111mmap11*1*1*1**1***1***1***1**1***imp. 1%1%1%1%1%1%1%1%1%del.1¦Ã 1111 1111mmap11***1***1***1***1***1***1***1***1***imp. 1%1%1%1%1%1%1%1%1%del.gt1¦Ã 1111 1111mmap11***1***1***1***1***1***1***1***1***imp. 1%1%1%1%1%1%1%1%1%nificantly. though the two odp topic space search models have rather great improvements over the simple text search models  it is not well enough to fully utilize the folksonomy. the odp1 model outperforms the odp1 model in nearly all the experiments while the improvements are not so great. in contrast  even the simplest folksonomy topic space model  i.e. the ac model can beat the odp models with great improvements. a reason for this is that the interests of the users and the topics of the web pages are actually boundless  thus a predefined static topic space such as odp is not enough. however  the social annotations in folksonomy are dynamic. they can describe the topics and the interests more precisely.
¡¡as for the topic adjusting algorithm  comparing the experimental results of the two columns  b. a.  and  a. a.   it is clear that the algorithm is very effective. all the models with the adjusted vectors beat the corresponding models with non-adjusted vectors.
¡¡besides  among the three folksonomy topic space models  as we have expected  f.bm1 and f.tfidf outperform the ac model significantly. notice that the adjusted f.bm1 reaches the optimal performance in all the experiments.
¡¡as we can see  all the experiments under various amount of data all output promising results. that means our model can handle all the situations of different amount of data. however one strange phenomenon is the search effectiveness seems to reduce when the amount of data increase. we expected the personalized models to increase performance when the amount of data increase. as to this problem  we manually analyzed the tagging data in the two data sets and find a main cause. generally the social annotations owned by the users who own a small amount of total social annotations are much semantically richer than the social annotations owned by the users who own a relatively large amount of total social annotations. because most of the users who own many bookmarks  especially those who have more than 1 bookmarks  directly export their desktop bookmarks into the folksonomy systems. the annotations of these bookmarks are not user manually generated and many of them are obviously noise  such as  importedie favorites    imported1/1    system:imported    imported   etc.
1. discussions
¡¡integrating folksonomy systems with search engines. one problem in implementing our personalized search algorithm in real life is how to access the folksonomy data of a user when she is searching. this won't be a problem if the search engines and the folksonomy systems are owned by the same company or organization. yahoo! has given us a solution to this problem not long ago. the two most well known web 1 social tagging websites  del.icio.us and flickr  have been purchased by yahoo!. furthermore  many folksonomy websites provide simple search engines themselves. the personalization can be implemented on these search engines.
¡¡sparseness of social annotations. since the social annotations require the users to create explicitly  many users may be reluctant to maintain such personal data. though more and more users are now engaged in folksonomy  it's still a small portion of all the search engine users. how to expand the benefit of our personalized search algorithm to all the search engine users   and  give us two potential solutions. in   the authors collected tagging data automatically from user click through histories by treating queries as annotations and all the clicked web pages as bookmarks.  proposed to automatically generate personalized annotations based on users' personal document corpus. both the above approaches can be incorporated in our personalized framework easily. thus the sparseness of social bookmarks can be lightened to a certain extent.
¡¡folksonomy topic dimension reduction. similar to the document terms  the synonymy and polysemy problem also exist in social annotations. dimension reduction is a technology to tackle this problem  including lsi  plsi  etc. however  these algorithms are rather time and space consuming. in our future work  we will study how to reduce folksonomy dimension efficiently and evaluate the effectiveness using reduced dimensions.
1. conclusions and future work
¡¡how to effectively use folksonomy for personalized search in web 1 environment is quite a new problem. the main contributions of this paper can be summarized as following: 1  the proposal of a personalized search framework  in which the users and the web pages are associated by a topic space. 1  the proposal of using the social annotations to modeling the topic space. specifically  three properties of folksonomy  namely the categorization  the keyword and the structure property  are studied. 1  the proposal of an automatic evaluation framework for personalized search using folksonomy data. the evaluation framework is able to lighten the common high cost problem in personalized search evaluations. 1  the evaluations of our personalized search approach using a del.icio.us corpus and a dogear corpus show that our approach outperforms the baselines significantly.
¡¡this is just our first trial of leveraging folksonomy for personalized search. there are several possible future extensions as listed in the following. 1  we set text retrieval models as our baselines. the purpose of this choice is to show the pure ability of folksonomy for personalized search. however  today's web search engines already account for much meta information such as link structure  anchor text  etc. in addition to the similarity of a query to a document when ranking. we'll explore some approaches to incorporate these information into our framework. 1  the personalized search framework uses weighted borda-fuse as the rank aggregation approach. this simple method is essentially a linear combination. we'll try more sophisticated rank aggregation methods to test the personalized search framework. 1  as for the evaluation framework  we'll test it in some other contexts to show its detailed pros and cons.
1. acknowledgement
¡¡the authors would like to thank ibm china research lab for its continuous support to and cooperation with shanghai jiao tong university. we would also like to express our gratitude to d.r. millen and j. feinberg from ibm watson research center for providing us the dogear social tagging data corpus . besides  we also appreciate the valuable suggestions of feng yun  mianwei zhou  and jinwen guo. in the end  we would like to thank the anonymous reviewers for their elaborate and helpful comments.
