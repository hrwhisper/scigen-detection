steganography is the art to transmit secret messages through seemingly innocuous files  while steganalysis is to detect or extract hidden messages from such files. heuristic and feature based methods were proposed for hidden information detection  but their methods seem to be too specific. in this paper we propose a general framework of applying machine learning to steganalysis for lsb  least significant bit steganography  hidden information detection. we have investigated the performance of our method on different classification methods  different complexities of images and different embed rates. feature based classifiers are trained for sequential and non-sequential lsb hidden information detection. the results show that chi-square feature based decision tree can get almost 1 percentage higher accuracy than the simple threshold based chi-square techniques for sequential lsb detection. in the non-sequential case  just 1-d rs steganalysis features based decision trees can achieve an accuracy of 1% in mixed embed rate case.
categories and subject descriptors
i.1  artificial intelligence : learning; i.1.m  image processing and computer vision : miscellaneous-steganalysis
general terms
experimentation  performance
keywords
machine learning  information hiding  lsb steganography  lsb steganalysis
1. introduction
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee.
1 acm sigkdd workshop on domain driven data mining  dddm1   august 1  1  san jose  california  usa.
copyright 1 acm 1-1-1/1...$1.
r.wang massey.ac.nz
the research of machine learning and data mining on multimedia data is challenging because multimedia data are essentially non-structured. previous works of multimedia data mining includes content-based information retrieval  cbir     discovering relationships between data items or segments within images/videos   extracting patterns from images and videos   etc.. information hiding techniques have recently received a lot of attention  but there are few works on applying learning/mining approaches to it. information hiding techniques include steganography and steganalysis. steganography is the art of transmitting secret messages through seemingly innocuous files   and the goal of steganography is not only to ensure secret messages transferred secretly  but also to make the transferred secret messages undetectable. it is the art of invisible communication  and provide a plausible deniability to secret communication . since steganography can be easily misused for planning and coordinating criminal activities  methods for hidden information detection known as steganalysis methods are proposed. the goal of steganalysis is to detect the existence of steganography  to estimate its message length  or to extract the hidden information . the steganalysis algorithms achieve their goals by exploiting the differences between the media files before and after embedding.
lsb is quite a simple method on which most steganography algorithms are based. lsb replace the lowest bits in images with secret message bits  and the stego images  embedded images  are difficult to be found embedded by people's eyes. there are three main methods in the literature to detect lsb embedding  1 1 : the до1 method  the rs  regularsingular  steganalysis and the spa  sample pair analysis  method. these three methods are proposed to estimate the length of embedded message in images  but we can use them for just detection in this paper. the conventional до1 steganalysis splits the image into segments  calculate the до1 coefficients for every segment  and then use these coefficients to decide whether there are hidden messages. but we found that до1 steganalysis is sensitive to the randomness of lsbs  the results depend strongly on the threshold we choose and thus not stable. and до1 is only suitable for sequential lsb embedding  it performs badly for the non-sequential case. this is because for sequential case  the bits are successively embedded  so we can find clusters of bits embedded  resulting in abrupt changes in the bits statistics  and this makes the detection easier. for non-sequential case  there are no such clusters because the embedded bits are scattered randomly in the data  so we cannot expect the detection process as effective as the one for the sequential case. the rs and spa methods are better methods for all situations  but if we use thresholds  we are faced with the same problem of choosing the right threshold.
in order to overcome these difficulties in hidden information detection  ml  machine learning  techniques  such like decision tree  bp back propagation  neural network and svm etc.  are applied. previous works  1 1  on machine learning based hidden information detection seem to be specific  we propose a general framework for lsb steganalysis and use features to construct different types of classifiers. since we focus on lsb hidden information detection  we use features derived from conventional lsb steganalysis and wrap them by classification scheme. we show that our methods performs better than threshold based ones in sequential and non-sequential lsb case. in section 1  conventional steganography and steganalysis methods are reviewed  and до1  rs steganalysis and spa method are described in detail. in section 1  we will discuss the hidden information detection problem from a viewpoint of ml-based classification. the features which we use are introduced  and the framework of our ml-based methods are also illustrated. in section 1  our experiments are described and the analysis of the results are given. finally  in section 1  we provide our conclusions and indicate future work.
1. steganography and steganalysis
1 conventional methods
by the source format  steganography methods can be generally divided into two groups  one group operates in bitmaps  the other embeds in transformed domain images  such like jpeg images . lsb operates in spatial domain and embed in bitmaps. since jpeg is becoming more and more popular  algorithms are proposed to perform jpeg embedding. jsteg  simply use the lsbs of dct coefficients stored in jpeg. outguess  preserves some statistics  and is immune to some statistical attacks. f1  preserves the histogram of dct coefficients  using hashing and matrix coding to improve the overall performance. recent techniques include model based embedding  and perturbed quantization embedding .
we classify steganalysis technique as whether they use instances to construct classifiers. so the steganalysis approaches can be grouped into two types  one uses instances of training images  the other does not use instances  instead  a parametric model is built and its statistics are computed for steganalysis detection.
non-instance based techniques exploit the statistics of the image by an implicated parametric model  and classification is done by rules. most conventional steganalysis are of this type. the до1 steganalysis proposed by pfitzmann and westfeld   the rs steganalysis proposed by fridrich et al.  and sample pair analysis  are described in detail later  some improvements on rs and spa see  . fridrich et al.  proposed a steganalysis based on jpeg compatibility. their method can potentially detect message as short as one bit. we draw a comparison between them as table
1.
instance based methods use training sets  and involve a classifier construction process. avcibas et al. proposed a method using image quality metrics . they select a subset of iqms  then use regression to train a classifier  and then use it to classify. lyu and farid proposed a method to use higher-order dwt  discrete wavelet transform  coefficients based svm-based classifier  1 . fridrich  proposed to use calibrated feature to estimate the original nonembedded image  then use 1 first and second order features to construct a classifier. recent work includes blind steganalysis  1 1  and some theoretical frameworks  1 .
1 the chi-square steganalysis
as we mentioned above  lsb utilizes the lowest bit plane for embedding  and replaces every suitable bit with message bit. if the embedded message bit is different from the original one  then a bit flip must have been performed.
let the pixel value be j  j А╩  1 . if j = 1i then after flip j will be 1i + 1  and if j = 1i + 1 then after flip j will be 1i. pfitzmann and westfeld  introduced the concept of pov pairs of values   which combines two pixel values 1i and 1i + 1 together as a pair  and the two values in the pair only differ in the lowest bit. we can easily observe that if a pixel value is in a pair  then after embedding the value is still in the same pair. let the frequencies of pixel value 1i  1i+1 be h1i  h1i+1. usually messages are compressed or encrypted before embedding  so the message bits now can be treated as random  and subsequently the frequencies of 1 and 1 will be nearly. so that is to say  the frequencies of the two pixel values in the same pov will be nearly the same after embedding. in order to determine whether there exist significant differences between h1i and h1i+1  до1 test can be used. we need to calculate до1 statistics as  after embedding the expectation of
		 1 
then we use can calculate the probability of images being embedded using density function of до1 distribution as p  k is the total number of all possible i in equation 1 :
		 1 
if p is close to 1  the image is classified as an embedded stego.
originally до1 steganalysis is used to estimate the hidden message length  but it can also be used to detect the existence of hidden messages. we can simply use the piecewise до1 coefficients and manually choose a threshold. if there are coefficients which are higher than the threshold  then we classify the image as embedded. we call this approach the simple до1 method. it is easy to implement  but the results are not so good  so we apply machine learning to this method  and hope we can get better results.
table 1: comparison between conventional lsb stagenalysis for detection
methodprinciplefeatureclassifiers for detectionusing
mlдо1split images into segments and use до1-test for every
segmentдо1 coefficientsthreshold-basednorsuse mask and flip to identify r s u groups and draw rs-diagram to
estimatethe frequency of
r s u groups in different masksthreshold-basednospacalculate the frequency of sample pairs and solve equations to estimatethe frequency of every specific sample pairthreshold-basedno1 the rs steganalysis
fridrich et al.  proposed rs steganalysis. rs method exploits the spatial correlations in stego-images. let us assume that we have mА┴n images  and set p stands for all pixel values. we define discrimination function f on group 
 i = 1 ... n .the discriminate function f can be treated as a smoothness measure of g. there are three types of flipping function defined. f1 is defined as 1   1   1 ... 1   1  f 1 as  1   1   1 ... 1   1. f1 is defined as identity permutation f1 x  = x. so lsb embedding can be expressed as follow: when the embed bit and corresponding cover bit are the same  f1 is applied  else f1 is applied. lsb embedding will cause an increase of the f value. every group is applying flipping functions using mask m and the result flipped group is f g  =  fm 1  x1  fm 1  x1  ... fm n  xn   which m i  А╩ { 1 1}.
three types of pixel groups r  s  u are defined as regular groups: gА╩r   f f g     f g   singular groups: gА╩s   f f g     f g  and unusable groups: gА╩u   f f g   = f g . we denote the relative number of r groups of non-negative mask m А╩ {1} as rm  s groups as sm. similarly  the relative number of r groups of nonpositive mask  m А╩ { 1} can be denoted as r m  s groups as s m. here fridrich et al. present the zerohypothesis that for typical cover images  that is rm is approximately equal to r m  and the same should be true for sm and s m:
	rmАФ=r m	and	smАФ=s m	 1 
they justify their hypothesis by inspecting group relations and experimental results.
the lsb embedding forces the difference between rm and sm to zero as embedding length increases. if 1% of pixels are flipped  when every pixel is embedded   we obtain rmАФ=sm. but the effect on r m and s m is opposite.
fridrich et al. fit straight lines through the points rm p/1  
rm 1   p/1  and s m p/1   s m 1   p/1 . the points rm p/1   rm 1   rm 1   p/1   and sm p/1   sm 1   sm 1 p/1  are considered to be two parabolas. the arithmetic average of the x coordinates of both intersections is the estimation of the message length p. there are two more assumptions proposed by fridrich et al.:  1  the point of intersection of rm and r m has the same x coordinate as the intersection point of sm and s m and  1 
these two assumptions make it possible to derive a simple formula for p. they re-scale the x axis so that p/1 becomes 1 and 1   p/1 becomes 1  the x-coordinate of the intersection point in re-scaled axis  represented as xp  is a root of the following equation: 1 
1 xp+d1 d 1 = 1 where d1 = rm p/1  sm p/1   d1 = rm 1   p/1    sm 1   p/1   d 1 = r m p/1    s m p/1  and d 1 = r m 1   p/1    s m 1   p/1   and finally we get the message length p by p = xp/ xp   1 .
1 the sample pair analysis
dumitrescu et al.  proposed sample pair analysis. the spa method traces the multisets of sample pairs before and after lsb embedding  and use relationships between multisets to solve the length of embedded messages p.
assume the digital images are represented by successive samples s1 s1 ... sn  n is the total number of the sample . a sample pair is a tuple  si sj  1 i j 1 n  and let p be the set of all sample pairs drawn from the digital image. we define dn to be the submultiset of p which contains sample pairs like  u u + n  or  u + n u  where 1 n 1b   1  b is the total bit number . for 1 m 1b 1   1  we define cm as the sample pairs whose values differ by m in the first  b   1  bits i.e. by right shifting one bit and then measure the difference . we define x1m+1 = d1m+1 А╔ cm+1 and y1m+1 = d1m+1А╔cm  for 1 m 1b 1 and x1b 1 =    y1b 1 = d1b 1. so if the sample pairs of p are uniformly scattered  then for  m 1 m 1b 1   1  we have
                 e|x1m+1| = e|y1m+1| which is the key observation of spa method.
obviously the sample pairs in the set x1m+1 have a form of  1k   1m   1k  or  1k 1k   1m   1   and the sample pairs in the set y1m+1 have the form of  1k  1m 1k +1  or  1k + 1k   1m . if we consider the flip operation to the sample pairs in lsb embedding  we have four modification patterns дл : 1 1 where 1 indicating which sample s  of a pair has have  the lsb reversed  1 indicating intact sample s . so for each m  1 m 1b 1  the submultiset cm is partitioned into x1m 1 d1m and y1m+1. it is clear that cm is closed under embedding  but x1m 1 d1m and
y1m+1 are not. so we split d1m into x1m and y1m  where x1m contains sample pairs whose values have the form of  1k   1m 1k  or  1k + 1k   1m + 1   and y1m contains sample pairs whose values have the form of  1k 1m+1k+ 1  or  1k 1k   1m . and by doing this  multiset cm with
1 m 1b 1  1 is partitioned into x1m 1  x1m  y1m and y1m+1  called the trace submultisets of cm. so a finite-state machine can be obtained to describe the transitions between trace submultisets after lsb embedding.
dumitrescu et al. derived several equations  we just use below to calculate the embed length p :

we let j = 1b 1   1  so the embedding length p can be estimated at last. a. ker  1  has made some improvements on conventional lsb steganalysis and extends spa to use triples of sample points.
1. the machine learning based steganalysis
we described three typical lsb steganalysis techniques in detail  it is easy to see that none of the three steganalysis techniques uses machine learning techniques. they just use some hypotheses observed heuristically  and assume the distribution of the embedded images to follow. although their models about the stegos are carefully adjusted to be very close to the real world model  if there are differences between their fixed models and the real world one  they will fail. so we can use machine learning to construct adaptive models  so as to reduce the errors brought by fixed models.
1 the machine learning point of view
in fact  the hidden information detection problem itself can be treated as a standard classification problem. we give some classified instances  then a classifier is properly constructed using the training set  and then we can use the classifier to classify unknown test set.
in conventional steganalysis  classifiers are not playing a very important role. conventional steganalysis does not focus on detection  so for the hidden information detection problem  just simple classifiers are used  many of which are threshold based classifiers. because classifiers are inevitable in hidden information detection process  if machine learning methods are applied  the quality of classifiers will be improved and successively more stable performance can be acquired.
for the hidden information detection problem we cannot do classification without preprocess because the training sets are images and there exist a lot of noises. because no prior knowledge is given  using ml methods to do information extraction adaptively is a more suitable approach here. when used in practice  machine learning wrapped methods are sometimes more flexible then the original ones. they can dynamically change the the models build while traditional methods just use heuristic fixed models.
as we concern about the data set property  there is a problem that the space of the original images is too large for us to handle. we can reduce the space by means of feature extraction  and this process is viewed as a linear or non-linear mapping. after the data reduced  the classifiers are easier to construct. but here another problem arises  that is whether the reduced space can represent the properties of original space. so we have to choose features properly so as to get well constructed classifiers.
1 machine learning based lsb steganography detection
we treat the hidden information detecting problem as a classification process  the inputs are the images  the outputs are their class labels. we are using the feature extraction scheme. feature extraction is often used in blind steganalysis  1 1  which intends to build a universal classifier to detect all steganography without knowing the actual methods used. here we use features in a different way. first  features in blind steganalysis is not intuitively proposed  the reason they use one feature is always because the feature can lead to good results  but we use conventional based features for lsb hidden information detection. second  we use classifiers to wrap the feature extracted by conventional style staganalysis. since we focus on a specific class of steganography approaches  no doubt we can get better performance than a universal classifier.
we tested directly using original bitmap pixel data for classifier construction  but the result is not better than a random guess. therefore we are building our dataset based on the values in до1  rs or spa methods. many classical algorithms can be used  such like c1  svm etc. we compare our method and conventional instance-based methods as in table 1.
for illustration  we draw our framework as fig. 1 and compare it with simple до1 methods as fig. 1. in our approach 

figure 1: the framework of general machine learning based steganalysis.
a variety of classification methods can be used and different classification algorithms will lead to different results  so we did a benchmark on commonly used learning methods and compare the performances of different algorithms in the next section.
1. experiment results and analysis

table 1: comparison between ml-based framework and conventional approaches
methodclassifiers usedfeaturedetect file
formatadvantage/ disadvantageiqmmultivariate regressionimage
quality
metricsbitmapsanova selects most useful features  but must have corresponding
unembedded images to
decidedwtsvmhigh-order
dwt
coefficientsjpeg 
gif 
tiffcan potentially detect any steganography 
performs not good when embedding rate is lowcalibrated featurefisher linear discriminant1 first and second order featurejpegcan detect several jpeg steganographyour methodany
classification
methodдо1  rs or
spa features or combinedbitmapscan get very good performance by selecting proper classifiersfigure 1: the framework of simple and machine learning based chi-square steganalysis.
we collect 1-bit color images from public domains  the only difference from gray scale bitmap embedding is that the embed capacity is 1-times larger. we embedded different length of messages into the images. we extract features using different methods for sequential and non-sequential case which are described later. after preprocessing  every image will result an instance represented by a set of features in the dataset. we build our experiment platform on weka   and test the results on different machine learning methods. we choose naАД ve bayes  bayes net  the j1 decision tree  knn  svm  smo algorithm with rbf kernel  and bp  back propagation  neural network  here we use the default parameter indicated by weka  to build classifiers. we also test threshold based-до1 with threshold of 1% and 1% to compare with our 1-fold cross validation results. we use the entropy of h value of hsv color as the measure of image internal complexity  and divide the image set to five complexity levels and use four different embed rates as 1%  1%  1% and 1%. we make data gathering by internal complexity and embed rate to simulate the real situation. although precision maybe not the best measurement to asses classifier accuracy  for its simplicity  we use it for the comparison between different methods. we leave the research of using other measures to future work.
1 sequential lsb case
we apply ml-based classifier on pov1  algorithm. in this method the lsb bit-plane is treated as sequential pixel samples and is split into 1 segments  and for every segment  the до1 probability for all the pixels from the first segment to current one is calculated according to equation 1. now we get 1 coefficients  simple до1 then make a decision according to a threshold  but our method use these as features and construct classifiers. we use a total of 1 images for experimentation.
due to the page limit  we show part of the final results as table 1  the rms root mean square  error of 1-fold cross validation is also listed .
we show the results of different image complexity levels with all embed rate mixed and results of different embed rates with all image complexities mixed as fig. 1 and fig. 1.

figure 1: results of different image complexity levels  all embed rate mixed .

table 1: part of the sequential lsb experiment results: the accuracies and the root mean squares.
 threshold based до1 rms is omitted because cross validation cannot be performed. 
naАД ve bayeslevel 1level 1level 1level 1level 1all mixedembed 11% 1 1% 1 1% 1 1% 1 1% 1 1% 1 embed 11% 1 1% 1 1% 1 1% 1 1% 1 1% 1 embed 11% 1 1% 1 1% 1 1% 1 1% 1 1% 1 embed 11% 1 1% 1 1% 1 1% 1 1% 1 1% 1 all mixed1% 1 1% 1 1% 1 1% 1 1% 1 1% 1 knnlevel 1level 1level 1level 1level 1all mixedembed 11% 1 1% 1 1% 1 1% 1 1% 1 1% 1 embed 11% 1 1% 1 1% 1 1% 1 1% 1 1% 1 embed 11% 1 1% 1 1% 1 1% 1 1% 1 1% 1 embed 11% 1 1% 1 1% 1 1% 1 1% 1 1% 1 all mixed1% 1 1% 1 1% 1 1% 1 1% 1 1% 1 j1level 1level 1level 1level 1level 1all mixedembed 11% 1 1% 1 1% 1 1% 1 1% 1 1% 1 embed 11% 1 1% 1 1% 1 1% 1 1% 1 1% 1 embed 11% 1 1% 1 1% 1 1% 1 1% 1 1% 1 embed 11% 1 1% 1 1% 1 1% 1 1% 1 1% 1 all mixed1% 1 1% 1 1% 1 1% 1 1% 1 1% 1 smolevel 1level 1level 1level 1level 1all mixedembed 11% 1 1% 1 1% 1 1% 1 1% 1 1% 1 embed 11% 1 1% 1 1% 1 1% 1 1% 1 1% 1 embed 11% 1 1% 1 1% 1 1% 1 1% 1 1% 1 embed 11% 1 1% 1 1% 1 1% 1 1% 1 1% 1 all mixed1% 1 1% 1 1% 1 1% 1 1% 1 1% 1 до1%level 1level 1level 1level 1level 1all mixedembed 11%1%1%1%1%1%embed 11%1%1%1%1%1%embed 11%1%1%1%1%1%embed 11%1%1%1%1%1%all mixed1%1%1%1%1%1%до1%level 1level 1level 1level 1level 1all mixedembed 11%1%1%1%1%1%embed 11%1%1%1%1%1%embed 11%1%1%1%1%1%embed 11%1%1%1%1%1%all mixed1%1%1%1%1%1%

figure 1: results of different embed rates  all image complexities mixed .
the results show that the precision decreases when the image complexity increases and increases when the embed rate increases. this is because the intrinsic randomness have the same effects as the randomness brought by embedding. if the internal randomness of cover image is high  the coefficients will be high  and the algorithm tends to have a wrong result remember that if there exists coefficients higher than the threshold  the images is classified as embedded . when the internal complexities are the same  we can see that if the embed rate is high  the result complexity will be high  and thus the accuracy will be high.
from fig. 1 and fig. 1  we can see that except for naАД ve bayes and bayes net  other traditional methods like knn  j1 and svm can get a same or better accuracy than simple до1 method. and we illustrate the differences of results between ml results and simple chi-square results as fig. 1. from fig. 1 we can see that when the internal com-

figure 1: the differences of results between machine learning results and simple chi-square results.
plexity is higher  our methods performs better than simple до1. because most of the pictures are in high complexity level 1  so ml-based methods are generally performs better than simple до1. when the randomness level and embed rate change  we can see that traditional machine learning methods like knn  j1  smo and bp can still get quite good results which seems like these methods are immune to conditional changes. we can make conclusion that applying machine learning to до1 can effectively improve the accuracy  and the classifier wrapped conventional steganalysis maybe a good solution to detect sequential lsb steganography.
1 non sequential lsb case
since the ml-based chi-square methods seems quite successful in the sequential lsb case  we would like to investigate if it is useful in the non-sequential case. because nonsequential lsb embedding is used  we cannot still base our method on pov1. we use до1 coefficients of extended до1 test  with sample size set to 1%. we test naАД ve bayes and j1 method  but the results is not good as expected. the precision for of all mixed embed rates is less than 1%  the most surprising thing is at 1% embed rate level  the performance of j1 is worse than a random guess.
to choose the right feature is an important issue in doing classification  in our rs wrapped approach  rs features are not directly used. we observe that in rs steganalysis the differences between rА└m p/1  and sА└m p/1  increase when message length p increases. thus  using the difference between them sounds a good idea  and our features are calculated as:
 
 1 
the reason for not using the differences directly is to reduce the bias between different images and keep feature as monotonic as possible. the actual differences are divided by the smaller value of the r and s values. we test this feature based methods with naАД ve bayes  bayes net  the j1 decision tree  knn  svm  smo algorithm with rbf kernel  and bp neural networks still with default parameter in weka . here we mainly focus on the change of embed rate  or message length   the differences between different intrinsic complexities  or randomness  of cover images are ignored. we list the precisions in table 1  the rms root mean square  error of 1-fold results is also listed .
from table 1  we can see that j1 performs best in mixed embed rate case  and can get nearly 1% accuracy at all embed levels. although threshold rs performs better in some separate embed levels  we treat the mixed embed rate as the most important case because in real-life task all the embed rates are actually mixed. we use only two features  this result is comparable to до1 case in sequential embedding and is better than threshold based rs can do.
some previous works  1 1  on steganalysis focuses on feature selection  but we think that the most important question is to produce a initial feature set to be selected at first. unlike blind steganalysis  we use some intuitively reasonable features based on conventional steganalysis. although we can not detect all hidden information regardless of the original steganography used  we can get high accuracy in lsb embedded images. so our work can be viewed as semi-blind steganalysis because the wrapper classifier gives us generalization ability.
precision  rms embed 1embed 1embed 1embed 1embed all mixednaАД ve bayes1% 1 1% 1 1% 1 1% 1 1% 1 bayes net1% 1 1% 1 1% 1 1% 1 1% 1 knn1% 1 1% 1 1% 1 1% 1 1% 1 j1.1% 1 1% 1 1% 1 1% 1 1% 1 smo1% 1 1% 1 1% 1 1% 1 1% 1 bp1% 1 1% 1 1% 1 1% 1 1% 1 threshold rs1%1%1%1%1%table 1: the results of rs feature based method.on the success of applying machine learning to до1 and rs steganalysis. we test j1 decision tree on spa steganalysis  using mixed data of sequential and non-sequential embedded images. the features used here is the number of multiset xk and yk  k А╩  1  . the best precision of threshold based spa methods is 1%  and the precision of our j1-based method is 1%. it seems like in mixed embedding case  the applying of machine learning is still effective. so we believe our ml-based methods is quite a good solution for lsb steganography detection.
1. conclusion and future work
in this paper  we have developed a novel general framework of applying machine learning to steganalysis for lsb hidden information detection. unlike conventional steganalysis  we introduce features derived from conventional methods and use classifier methods based on them. previous works on feature based steganalysis often focus on a single type of classification scheme  here we evaluate the performance of our framework on different classification methods. with the more effective classifier methods  our framework can be applied for more effective steganalysis.
in sequential lsb case  we split the images data into subsets with different internal complexities and different embed rates. we applied naАД ve bayes  bayes net  the j1 decision tree  knn  svm and bp neural network to conventional до1 steganalysis and build classifiers. the results show that the j1 decision tree performs best  and it is much better than original до1. we believe the reason for this is because decision trees can fit the structure extracted from the embedded images by conventional до1.
in non-sequential lsb case  the performance on до1 features are not as effective as expected. based on rs steganalysis  we proposed just 1-d features  and results show that the feature based decision tree can achieve a better accuracy than conventional rs. given the extremely low dimension of our features  the results we can get is quite impressive. we also did a primarily test on spa using the numbers of multisets generated by spa  our framework can get higher accuracy than conventional spa on the mixed dataset of sequential and non-sequential lsb embedded images.
in the future  we are seeking more theoretical explanation for the effectiveness of our framework. we plan to use feature selection and non-linear mapping to construct more effective features. we will try to extend our framework to non-lsb steganalysis especially for jpeg steganalysis . furthermore  more effective learning techniques like costsensitive learning and class-imbalance learning will be incorporated in our framework for more effective classifiers. anyway  applying machine learning to steganalysis needs further discussion and more research.
acknowledgment
this work is supported by the natural science foundation of china  no.1   the national outstanding youth foundation of china  no.1  and the national grand fundamental research 1 program of china under grant no.1cb1. a special thanks to ruyi zhou for his boundless support. we would also like to thank the anonymous reviewers for their insightful comments.
