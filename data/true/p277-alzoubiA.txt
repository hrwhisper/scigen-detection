because it is an integral part of the internet routing apparatus  and because it allows multiple instances of the same service to be  naturally  discovered  ip anycast has many attractive features for any service that involve the replication of multiple instances across the internet. while briefly considered as an enabler when content distribution networks  cdns  first emerged  the use of ip anycast was deemed infeasible in that environment. the main reasons for this decision were the lack of load awareness of ip anycast and unwanted side effects of internet routing changes on the ip anycast mechanism. prompted by recent developments in route control technology  as well as a better understanding of the behavior of ip anycast in operational settings  we revisit this decision and propose a load-aware ip anycast cdn architecture that addresses these concerns while benefiting from inherent ip anycast features. our architecture makes use of route control mechanisms to take server and network load into account to realize load-aware anycast. we show that the resulting redirection requirements can be formulated as a generalized assignment problem and present practical algorithms that address these requirements while at the same time limiting session disruptions that plague regular ip anycast. we evaluate our algorithms through trace based simulation using traces obtained from a production cdn network.
categories and subject descriptors
h.1.m  information systems : miscellaneous; d.1  software : software engineering; d.1  software engineering : metrics-complexity measures  performance measures
general terms
performance  algorithms
keywords
cdn  autonomous system  anycast  routing  load balancing
1.	introduction
　the use of the internet to distribute media content continues to grow. the media content in question runs the gambit from operating system patches and gaming software  to more copyright is held by the international world wide web conference committee  iw1 . distribution of these papers is limited to classroom use  and personal use by others.
www 1  april 1  1  beijing  china.
acm 1-1-1/1.
traditional web objects and streaming events and more recently user generated video content . because of the often bursty nature of demand for such content   and because content owners require their content to be highly available and be delivered in timely manner without impacting presentation quality   content distribution networks  cdns  have emerged over the last decade as a means to efficiently and cost effectively distribute media content on behalf of content owners.
　the basic architecture of most cdns is simple enough  consisting of a set of cdn nodes distributed across the internet . these cdn nodes serve as proxies where users  or  eyeballs  as they are commonly called  retrieve content from the cdn nodes  using a number of standard protocols. the challenge to the effective operation of any cdn is to send eyeballs to the  best  node from which to retrieve the content  a process normally referred to as  redirection  . redirection is challenging  because not all content is available from all nodes  not all nodes are operational at all times  nodes can become overloaded and  perhaps most importantly  an eyeball should be directed to a node that is in close proximity to it to ensure satisfactory user experience.
　because virtually all internet interactions start with a domain name system  dns  query to resolve a hostname into an ip address  the dns system provides a convenient mechanism to perform the redirection function . indeed most commercial cdns make use of dns to perform redirection. dns based redirection is not a panacea  however. in dnsbased redirection the actual eyeball request is not redirected  rather the local-dns server of the eyeball is redirected . this has several implications. first  not all eyeballs are in close proximity to their local-dns servers  1  1   and what might be a good cdn node for a local-dns server is not necessarily good for all of its eyeballs. second  the dns system was not designed for very dynamic changes in the mapping between hostnames and ip addresses. this problem can be mitigated significantly by having the dns system make use of very short time-to-live  ttl  values. however  caching of dns queries by local-dns servers and especially certain browsers beyond specified ttl means that this remains an issue . finally  despite significant research in this area  1  1  1   the complexity of knowing the distance between any two ip addresses on the internet  needed to find the closest cdn node  remains a difficult problem.
　in this work we revisit ip anycast as redirection technique  which  although examined early in the cdn evolution process   was considered infeasible at the time. ip anycast refers to the ability of the ip routing and forwarding architecture to allow the same ip address to be assigned to multiple different endpoints  and to rely on internet routing to select between these different endpoints. endpoints with the same ip address are then typically configured to provide the same service. for example  ip anycast is commonly used to provide redundancy in the dns root-server deployment . similarly  in the case of a cdn all endpoints with the same ip anycast address can be configured to be capable of serving the same content.
　because it fits seamlessly into the existing internet routing mechanisms  ip anycast packets are routed  optimally  from a ip forwarding perspective. that is  for a set of anycast destinations within a particular network  packets are routed along the shortest path and thus follow a proximally optimal path from a network perspective. packets traveling towards a network advertising an ip anycast prefix  will similarly follow the most optimal path towards that destination within the constraints of the inter-provider peering agreements along the way.
　from a cdn point of view  however  there are a number of problems with ip anycast. first  because it is tightly coupled with the ip routing apparatus  any routing change that causes anycast traffic to be re-routed to an alternative anycast endpoint may cause a session reset to any session-based traffic such as tcp. second  because the ip routing infrastructure only deals with connectivity  and not the quality of service achieved along those routes  ip anycast likewise is unaware of and can not react to network conditions. third  ip anycast is similarly not aware of any server  cdn node  load  and therefore cannot react to node overload conditions. for these reasons  ip anycast was originally not considered a viable approach as a cdn redirection mechanism.
　in this paper we present our work on a load-aware ip anycast cdn architecture. our revisiting of ip anycast as a redirection mechanism for cdns was prompted by two recent developments. first  route control mechanisms have recently been developed that allow route selection to be informed by external intelligence  1  1  1 . second  recent anycast based measurement work  shed light on the behavior of ip anycast  as well as the appropriate way to deploy ip anycast to facilitate proximal routing.
　when selecting between multiple hosts with the same anycast ip address  route control mechanisms allow both cdn node load and network conditions to be taken into account  which addresses two of the concerns listed above  i.e.  quality of service and load-awareness . route control also partially deals with the concern about resetting sessions because of route changes. we note that in practice there are two variants of this problem:  i  route changes within a network that deploys ip anycast addresses and  ii  route changes outside of the network which deploys anycast ip addresses. route control mechanisms can easily deal with the first of these problems preventing unnecessary switching between anycast addresses within the network. as for route changes outside of the ip anycast network  recent anycast measurement work  has shown that most ip prefixes exhibit very good affinity  i.e.  would be routed along the same path towards the anycast enabled network.
the main contributions of our work are as follows:
  we present a practical anycast cdn architecture that utilizes server and network load feedback to drive route control mechanisms to realize cdn redirection  section 1 .

figure 1: load-aware anycast cdn architecture
  we formulate the required load balancing algorithm as a generalized assignment problem and present practical algorithms for this np-hard problem that take into consideration the practical constraints of a cdn  section 1 .
  using server logs from an operational production cdn  section 1   we evaluate our algorithms by trace driven simulation and illustrate their benefit by comparing with native ip anycast and an idealized load-balancing algorithm  section 1 .
1.	architecture
　in this section we first describe the workings of a loadaware anycast cdn and briefly discuss the pros and cons of this approach vis-a-vis more conventional cdn architectures. we also give an informal description of the load balancing algorithm required for our approach before describing it more formally in later sections.
1	load-aware anycast cdn
　figure 1 shows a simplified view of a load-aware anycast cdn. we assume a single autonomous system  as  in which ip anycast is used to reach a set of cdn nodes distributed within the as. for simplicity we show two such cdn nodes  a and b in figure 1. in the rest of the paper  we use the terms cdn node and content server interchangeably. we further assume that the as in question has a large footprint in the country or region in which it will be providing cdn service; for example  in the us  tier-1 isps have this kind of footprint1. our paper investigates synergistic benefits of having control over the pes of a cdn. we note that these assumptions are both practical  and  more importantly  a recent study of ip anycast  has shown this to be the ideal type of deployment to ensure good proximity properties1.
　figure 1 also shows the route controller function that is central to our approach  1  1 . the route controller exchanges routes with provider edge  pe  routers in the cdn

1
 http://www.business.att.com  http://www.level1.com 1
 note that while our focus in this work is on anycast cdns  we recognize that these conditions can not always be met in all regions where a cdn provider might provide services  which suggests that a combination of redirection approaches might be appropriate.
provider network. as such  the route controller can influence the routes selected by these pes. for our purposes  the route controller takes two other inputs  namely  ingress load from the pes at the edge of the network  and server load from the cdn nodes for which it is performing redirection. the load-aware anycast cdn then functions as follows  with reference to figure 1 : all cdn nodes that are configured to serve the same content  a and b   advertise the same ip anycast address into the network via bgp  respectively through pe1 and pe1 . pe1 and pe1 in turn advertise the anycast address to the route controller who is responsible to advertise the  appropriate  route to all other pes in the network  pe1 to pe1 . these pes in turn advertise the route via ebgp sessions with peering routers  pea to ped  in neighboring networks so that the anycast addresses become reachable via the whole internet  in the figure represented by access networks i and ii .
　request traffic for content on a cdn node will follow the reverse path. thus  a request will come from an access network  and enter the cdn provider network via one of the ingress routers pe1 to pe1. in the simple setup depicted in figure 1 such request traffic will then be forwarded to either pe1 or pe1 en-route to one of the cdn nodes.
　based on the two load feeds  ingress pe load and server load  provided to the route controller it can decide which ingress pe  pe1 to pe1  to direct to which egress pe  pe1 or pe1 . the route controller can manipulate ingress load s  worth of request traffic in order to effect server response load. in other words  there is an implicit assumption in our approach that there is a direct correlation between the request  ingress  traffic and the resulting response server traffic. fortunately  as we will show in section 1  this assumption holds because cdn providers typically group like content together  e.g.  large or small objects  so that in the aggregate each request  weighs  more or less the same.
1	objectives and benefits
　given the architecture described above  the goals of the redirection algorithm driving the route controller are as follows:  i  to utilize the  natural  ip anycast proximity properties to reduce the distance traffic is carried in the network.  ii  to react to overload conditions on cdn servers by steering traffic to alternative cdn servers.  iii  to minimize the disruption of traffic that results when ongoing sessions are being re-mapped to alternative cdn servers. note that this means that  load-balancing  per server is not a specific goal of the algorithm: while cdn servers are operating within acceptable engineering loads  the algorithm should not attempt to balance the load. on the other hand  when overload conditions are reached  the system should react to deal with that  while not compromising proximity.
　a major advantage of our approach over dns-based redirection systems is that the actual eyeball request is being redirected  as opposed to the local-dns request in the case of dns-based redirection. further  with load-aware anycast  any redirection changes take effect very quickly  because pes immediately start to route packets based on their updated routing table. in contrast  dns caching by clients  despite short ttls  typically results in some delay before redirection changes have an effect.
　the redirection granularity offered by our route control approach is at the pe level. for large tier-1 isps the number of pes typically count in the high hundreds to low thou-

figure 1: application level redirection for long-lived sessions
sands. a possible concern for our approach is whether pe granularity will be sufficiently fine grained to adjust load in cases of congestion. our results in section 1 indicate that even with pe-level granularity we can achieve significant benefit in practice.
　before we describe and evaluate redirection algorithms that fulfill these goals  we briefly describe two other cdnrelated functions enabled by our architecture that are not further elaborated upon in this paper.
1	additional functions
dealing with long lived sessions: despite increased distribution of rich media content via the internet  the average web object size remains relatively small . this means that download sessions for such web objects will be relatively short lived with little chance of being impacted by any anycast re-mappings in our architecture. the same is  however  not true for long-lived sessions  e.g.  streaming or large file download .  both of these expectations are validated with our analysis in section 1.  in our architecture we deal with this by making use of an additional application level redirection mechanisms after a particular cdn node has been selected via our load-aware ip anycast redirection. this interaction is depicted in figure 1. as before an eyeball will perform a dns request which will be resolved to an ip anycast address  i and ii . the eyeball will attempt to request the content using this address  iii   however  the cdn node will respond with an application level redirect  iv   containing a unicast ip address associated with this cdn node  which the eyeball will use to retrieve the content  v . this unicast address is associated only with this cdn node  and the eyeball will therefore continue to be serviced by the same node regardless of routing changes along the way. while the additional overhead associated with application level redirection is clearly unacceptable when downloading small web objects  it is less of a concern for long lived sessions such as large file download. this is why we use http redirection only for large file downloads so that the startup overhead is amortized.
dealing with network congestion: as described above  the load-aware cdn architecture only takes server load into account in terms of being  load-aware .  in other words  the approach uses network load information in order to effect the server load  but does not attempt to steer traffic away from network hotspots.  the route control architecture  however  does allow for such traffic steering . for example  outgoing congested peering links can be avoided by redirecting response traffic on the pe connecting to the cdn node  e.g.  pe1 in figure 1   while incoming congested peering links can be avoided by exchanging bgp multi-exit discriminator  med  attributes with appropriate peers . we leave the full development of these mechanisms for future work.
1.	redirection algorithm
　as described above  our redirection algorithm has two main objectives. first  we want to minimize the service disruption due to load balancing. second  we want to minimize the network cost of serving requests without violating server capacity constraints. in this section  after presenting an algorithm that minimizes the network cost  we describe how we use the algorithm to minimize service disruption.
1	problem formulation
　our system has m servers  where each server i can serve up to si requests per time unit. a request enters the system through one of n ingress pes  and each ingress pe j contributes rj amount of requests per time unit. we consider a cost matrix cij for serving pe j at server i. since cij is typically proportional to the distance between server i and pe j as well as the traffic volume rj  the cost of serving pe j typically varies with different servers.
　the first objective we consider is to minimize the overall cost without violating the capacity constraint at each server. the problem is called generalized assignment problem  gap  and can be formulated as the following integer linear program .
minimizexxcijxij
i=1 j=1	m	n
x
m
subject toxij = 1   j
i=1 x（{rjxij ＋}si    i
	xij	1  	i j
where indicator variable xij=1 iff server i serves pe j  and xij=1 otherwise. when xij is an integer  finding an optimal solution to gap is np-hard  and even when si is the same for all servers  no polynomial algorithm can achieve an approximation ratio better than 1 unless p=np . recall that an α-approximation algorithm always finds a solution that is guaranteed to be at most a times the optimum.
　shmoys and tardos  present an approximation algorithm  called st-algorithm in this paper  for gap  which involves a relaxation of the integrality constraint and a rounding based on a fractional solution to the lp relaxation. specifically  given total cost c  their algorithm decides if there exists a solution with total cost at most c. if so  it also finds a solution whose total cost is at most c and the load on each server is at most si + maxrj.
1	minimizing cost
　note that st-algorithm can lead to server overload  although the overload amount is bounded by maxrj. in practice  the overload volume can be significant since a single pe can contribute a large request load  e.g.  1% of server capacity . in our system  we use the following post-processing on the solution of st-algorithm to off-load overloaded servers and find a feasible solution without violating the constraint. we first identify most overloaded server i  and then among all the pes served by i  find out the set of pes f  starting from the smallest in load  where server i's load becomes below the capacity si after off-loading f. then  starting with the largest in size among f  we off-load each pe j to a server with enough residual capacity  as long as the load on server i is above si.  if there are multiple such servers for j  we choose the minimum-cost one in our simulation although we can employ different strategies such as best-fit.  we repeat this if there is an overloaded server. if there is no server with enough capacity  we find server t with the highest residual capacity and see if the load on t after acquiring j is lower than the current load on i. if so  we off-load pe j to server t even when the load on t goes beyond st  which will be fixed in a later iteration. note that the load comparison between i and t ensures the maximum overload in the system decreases over time  which avoids cycles.
1	minimizing connection disruption
　while the above algorithm attempts to minimize the cost  it does not take the current mapping into account and can potentially lead to a large number of connection disruptions. to address this issue  we present another algorithm in which we attempt to reassign pes to different servers only when we need to off-load one or more overloaded servers. specifically  we only consider overloaded servers and pes assigned to them when calculating a re-assignment  while keeping the current mapping for pes whose server is not overloaded. even for the pes assigned to overloaded servers  we set priority such that the pes prefer to stay assigned to their current server as much as possible. then  we find a set of pes that  1  are sufficient to reduce the server load below maximum capacity and  1  minimize the disruption penalty due to the reassignment. we can easily find such a set of pes and their new server by fixing some of input parameters to st-algorithm and applying our post-processing algorithm on the solution.
　since this algorithm reassigns pes to different servers only in overloaded scenarios  it can lead to sub-optimal operation even when the request volume has gone down significantly and a simple proximity-based routing yields a feasible solution with lower cost. one way to address this is to exploit the typical diurnal pattern and reassign the whole set of pes at a certain time of day  e.g.  1am every day . another possibility is to compare the current mapping and the best possible mapping at that point  and initiate the reassignment if the difference is beyond a certain threshold  e.g.  1% . in our experiments  we use employ the latter approach.
　to summarize  in our system  we mainly use the algorithm in section 1 to minimize the connection disruption  while we infrequently use the algorithm in section 1 to find an  approximate  minimum-cost solution for particular operational scenarios.
1.	methodology
1	data set
　we obtained server logs for a weekday in july  1 from a production cdn which we utilized in a trace driven simulation of our algorithms. for our analysis we use two sets of content groups based on the characteristics of objects the servers serve: one set for small web objects  and the other for large file download. each log entry we use has detailed information about an http request and response such as client ip  web server ip  request url  request size  response size  etc. depending on the logging software  some servers provide service response time for each request in the log  while others do not. in our experiments  we first obtain sample distributions for different response size groups based on the actual data. for log entries without response time  we choose an appropriate sample distribution  based on the response size  and use a randomly generated value following the distribution.
　one set of inputs required by our algorithm is the request load arriving from each ingress pe. we use the number of ongoing requests  being served by a server  that have arrived from each ingress pe j as request load rj. to determine the number of request counts arriving from each pe  we look at the client and server ip pair for each log entry and use netflow data to determine where the request has entered the system. then  we use the service response time to determine whether a flow is currently being served.
　one of our objectives is to minimize the network bandwidth usage by service requests and responses. to reflect this  we first obtain the distance matrix dij between server i and ingress pe j in terms of air miles  which is known to be highly correlated with link usage within an autonomous system . then  we use the product rjdij as the cost cij of serving requests from pe j at server i. to determine the server capacity in our experiments  we first analyze the log to determine the maximum load during the entire time period in the log. then  we use a value slightly larger than the maximum load and divide it by the number of servers. this leads to a high-load scenario for peak time  while we have sufficient server capacity to handle all the requests. another interesting aspect is to understand how each scheme performs in scenarios with different loads  e.g.  light or medium load   which we plan to investigate in our future work.
1	simulation environment
　we used csim  http://www.mesquite.com  to perform our trace driven simulation. csim creates process-oriented  discrete-event simulation models. we implemented our cdn servers as a set of facilities that provide services to ingress pe flows  which are implemented as csim processes. for each flow that arrives we determine the ingress pe j  the response time t  and the response size l. we assume that the server responds at a constant rate calculated as the response size divided by the response time. in other words  each flow causes a server to serve data at the constant rate of l/t for t seconds. multiple flows from the same pe j can be active simultaneously on server s. furthermore  multiple pes can be served by the same facility at the same time.
　our servers  facilities  are configured to have infinite capacity and very large bandwidth. this means that our servers in the simulation can handle any size of load. the redirection algorithm decides whether or not servers are overloaded  depending on the number of active connections monitored at the time the algorithm starts. we keep track of the number of active connections at the server side and ingress pes side to calculate the current server load and pe load rj.

figure 1: correlation between server load and incoming traffic volume. the straight line is the average value for server 1.
1	schemes and metrics for comparison
　we experiment with the following schemes and compare the performance:
  simple anycast  sac : this is native anycast  which represents an idealized proximity routing scheme  where each request is served at the geographically closest server.
  simple load balancing  slb : this scheme minimizes the difference in load among all servers without considering the cost.
  advanced load balancing  always  alb-a : this scheme always attempts to find a minimum cost mapping as described in section 1.
  alb  on-overload  alb-o : this scheme only reassigns pes currently mapped to overloaded servers to minimize connection disruptions as described in section 1.
in sac  each pe is statically mapped to a server  and there is no change in mapping. slb and alb-a recalculate the mapping every two minutes based on the current load. while alb-o also analyzes the current load and mapping every two minutes  it re-calculates the mapping  usually only for a subset of pes  only if an overloaded server exists.
　for performance comparison  we first use the number of ongoing connections and service data rate at each server. a desirable scheme should keep the number below the capacity limit all the time. we also examine the average miles a request traverses within the cdn provider network before reaching a server. a small value for this metric denotes small network link usage in practice. we finally use the number of connection disruptions due to re-mapping. sac uses a static mapping and does not experience disconnections due to remapping. however  since it is not load-aware  the number of connections for one server can go over the maximum limit. in this case  we count the number of dropped connections. with our redirection scheme  a request may use a server different from the one used in the trace  and its response time may change  for example  depending on the server load or capacity. in our experiments  we assume that the response time of each request is the same as the one in the trace no matter which server processes it as a result of our algorithms.
　
figure 1: number of concurrent connections for each scheme  large file download 
　
1.	experiment results
　in this section  we present our simulation results. we first investigate the validity of our correlation assumption between request load and response load in section 1. we present the evaluation of our redirection algorithms in section 1.
1	request load vs. response load
　as explained in section 1  our approach relies on redirecting traffic from ingress pes to effect the load on cdn servers. as such it relies on the assumption that there exists a linear correlation between request load and the resulting response load on the cdn server. the request packet stream takes the form of requests and tcp ack packets flowing towards the cdn node.1 since there is regularity in the number of tcp ack packets relative to the number of response  data  packets that are sent  we can expect correlation. in this subsection  we investigate data from an operational cdn to understand whether this key assumption holds.
　we study a cdn content group for large file downloads and obtain per-server load data from the cdn nodes in

1
 a  sac b  slb 1	 1	 1	 1	 1
time  hours in gmt 
 c  alb-a 1	 1	 1	 1	 1	 1	 1
time  hours in gmt 
 d  alb-o 1 1we limit our discussion here to tcp based downloads.
question. for the network ingress load data  we obtained netflow records to count the number of packets from each ingress pe to content servers for the corresponding period of time.  due to incomplete server logs  we use 1+ hours of results in this subsection. 
　consider the following value γ = αs/r  where s is the maximum capacity of the cdn node  specified as the maximum bytes throughput in the configuration files of the cdn   α is node's utilization in  1   as reported by the cdn's load monitoring apparatus and referred to as server load below   and r is the aggregate per-second request count from ingress pes coming to the server. note that a constant value of γ signifies a perfect linear correlation between server load α and incoming traffic volume r.

 a  sac b  slb
 1	 1	 1	 1	 1
time  hours in gmt 
 c  alb-a 1	 1	 1	 1	 1	 1	 1
time  hours in gmt 
 d  alb-o 1 1figure 1: number of concurrent connections for each scheme  small web object 　in figure 1  we plot γ for multiple servers in the content group. we observe that γ is quite stable across time  although it shows minor fluctuation depending on the time of day. we further note that server 1 has 1% higher capacity than the other two servers  and the server load ranges between 1 and 1 over time. this result shows that the maximum server capacity is an important parameter to determine γ. although server 1 exhibits a slight deviation after 1 seconds due to constant overload  i.e.  α = 1   γ stays stable before that period even when α is often well above 1. the data therefore indicates that our assumption of linear correlation holds.
1	redirection evaluation
　in our evaluation we consider in turn the server load  the number of miles traffic were carried and the number of session disruptions that resulted for each of the redirection schemes presented in section 1.
server load: we first present the number of connections at each server using the results for large file downloads. in figure 1  we plot the number of concurrent flows at each server over time. for the clarity of presentation  we use the points sampled every minute. since sac does not take load into account  but always maps pes to a closest server  we observe from figure 1 a  that the load at only a few servers grows significantly  while other servers get very few flows. for example  at 1am  server 1 serves more than 1% of total requests  1 out of 1   while server 1 only receives fewer than 1. unless server 1 is provisioned with enough capacity to serve significant share of total load  it will end up dropping many requests. in figure 1 b   we observe that slb evenly distributes the load across servers. however  slb does not take cost into account and can potentially lead to high connection cost.
　in figure 1 c   we present the performance of alb-a. based on the maximum total number of concurrent requests  we set the capacity of each server to 1. unlike slb  alb-a  as well as alb-o  does not balance the load among servers. this is expected because the main objective of alb-a is to find a mapping that minimizes the cost as long as the resulting mapping does not violate the server capacity constraint. as a result  in the morning  around 1am   a few servers receive only relatively few requests  while other better located servers run close to their capacity. as the traffic load increases  e.g.  at 1pm   the load on each server becomes similar in order to serve the requests without violating the capacity constraint. alb-o initially shows a similar pattern to alb-a  figure 1 d    while the change in connection count is in general more graceful. however  the difference becomes clear after the traffic peak is over  at around 1pm . this is because alb-o attempts to reassign the mapping only when there is an overloaded server. as a result  even when the peak is over and we can find a lower-cost mapping  all pes stay with their servers that were assigned based on the peak load  e.g.  at around 1pm . this property of alb-o leads to less traffic disruption at the expense of increased overall cost. we further elaborate on this aspect later in this section.

 a  sac b  slb 1	 1	 1	 1	 1
time  hours in gmt 
 c  alb-a 1	 1	 1	 1	 1	 1	 1
time  hours in gmt 
 d  alb-o 1 1figure 1: service data rate for each scheme  large file download 　in figure 1  we present the same set of results using the logs for small object downloads. we observe a similar trend for each scheme  although the server load changes more frequently. this is because their response size is small  and the average service time for this content group is much shorter than that of the previous group. we also present the service rate of each server in figure 1  and figure 1 for large file download . we observe that there is strong correlation between the number of connections  figures 1 and 1  and data rates  figures 1 and 1 .
connection disruption: slb  alb-a  and alb-o can disrupt active connections due to reassignment. in this subsection  we investigate the impact of each scheme on connection disruption. we also study the number of dropped connections in sac due to limited server capacity. in our experiments  we use sufficiently large server capacity for sac so that the aggregate capacity is enough to process the total offered load: 1 for large file download scenario  and 1 for small object scenario. then  we count the number of connections that arrive to a server and find the server is operating at its capacity  which would be dropped in practice. while using a smaller capacity value in our experiments will lead to more connection drops in sac  we illustrate that sac can drop a large number of connection requests even when servers are relatively well provisioned.
　in figure 1  we present the percentage of disrupted connections for each scheme. for large file downloads  the service response time is longer  and in case of slb  alb-a  and alb-o  a flow is more susceptible to re-mapping during its lifetime. this confirms our architectural assumption concerning the need for application level redirect for long lived sessions. from the figure  we observe that alb-o clearly outperforms the other two by more than an order of magnitude. however  the disruption penalty due to re-mapping is much smaller than the penalty of connection drops due to overload in sac. specifically  sac drops more than 1% of total requests in the large files scenario  which is 1 times higher than the number of disruptions by alb-o. for small object contents  the disruption is less frequent due to the smaller object size and thus shorter service time. alb-o again significantly outperforms the other schemes. average cost: we present the average cost  as the average number of air miles  of each scheme in figures 1 and 1. in sac  a pe is always mapped to the closest server  and the average mileage for a request is always the smallest  at the cost of high drop ratio as previously shown . slb balances the load among servers without taking cost into account and leads to the highest cost. we observe in figure 1 that alba is nearly optimal in cost when the load is low  e.g.  at 1am  because we can assign each pe to a closest server that
　
 a  sac b  slb1	 1	 1	 1
time  hours in gmt 
 c  alb-a1	 1	 1	 1	 1	 1
time  hours in gmt 
 d  alb-o 1 1figure 1: service data rate for each scheme  small web object 
　
has enough capacity. as the traffic load increases  however  not all pes can be served at their closest servers without violating the capacity constraint. then  the cost goes higher as some pes are re-mapped to different  farther  servers. alb-o also finds an optimal-cost mapping in the beginning when the load is low. as the load increases  alb-o behaves differently from alb-a because alb-o attempts to maintain the current pe-server assignment as much as possible  while alb-a attempts to minimize the cost even when the resulting mapping may disrupt many connections  figure 1 . this restricts the solution space for alb-o compared to alb-a  which subsequently increases the cost of alb-o solution.
1.	conclusion
　new route control mechanisms  as well as a better understanding of the behavior of ip anycast in operational settings  allowed us to revisit ip anycast as a cdn redirection mechanism. we presented a load-aware ip anycast cdn architecture and described algorithms which allow redirection to utilize ip anycast's inherent proximity properties  without suffering the negative consequences of using ip anycast with session based protocols. we evaluated our algorithms using trace data from an operational cdn and showed that they perform almost as well as native ip anycast in terms of proximity  manage to keep server load within capacity constraints and significantly outperform other approaches in terms of the number of session disruptions.
　in the near future we expect to gain operational experience with our approach in an operational deployment. we also plan to exploit the capabilities of our architecture to avoid network hotspots to further enhance our approach.
acknowledgment. we thank the reviewers for their valuable feedback. the work on this project by alzoubi and rabinovich is supported in part by the nsf grant cns-
1.
