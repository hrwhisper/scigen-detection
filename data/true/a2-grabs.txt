with enterprise-class database systems like microsoft sql server  changing mission-critical components such as the relational database engine pose significant challenges to the engineering teams involved.  this is because customers carefully configure  tune  and test applications and the underlying database system for their specific scenario to ensure they achieve desirable performance. this situation poses particular challenges for developing and extending existing database components of high complexity such as relational query processing where a change to a policy or heuristics may adversely affect performance of a customer workload . mitigating risk of regressions through a 
variety of testing and validation techniques during development is essential for the database system engineering team.  in this paper  we present a case study to demonstrate the challenges of testing an extension to the query processor in microsoft sql server 1 targeted at improved query performance for star join queries . we discuss the unique range of problem spaces which must be addressed  and present an overview of the variety of techniques that are used to provide a high level of quality.  our main contribution is an iterative process of interleaved development and performance test phases using customer workloads to quantify performance improvement and to limit regressions. we present our experiences with this approach and explore some future opportunities with the hope that they will encourage discussion and additional research in the area of query processor architecture and testing. 
1. introduction 
relational database systems are successfully deployed across the different tiers of an enterprise it landscape: they successfully power desktop applications as well as highly mission-critical transactional systems for large enterprises. many database applications in particular in the enterprise space  outlive a single database system release. as a consequence  database applications usually require database system upgrades during the lifetime of the application. an important implication from this observation is that customers with existing well-tuned applications expect at least similar performance of their applications with every new database system release that they deploy - in particular when they do not need or plan to use any of the new functionality available in a new database system release.  
this makes extending the database system and adding new functionality to database products a challenging effort for database vendors as one has to carefully balance the risk and opportunity of changes to the product. note that these challenges go far beyond simple code defects. database products use heuristics in various ways and any change in the policies underlying those heuristics can put existing customers at risk without introducing a code defect.  
a particularly challenging area in that respect is the query processor in commercial database systems. this is because  1  cost based query optimization is of statistical nature   1  query processing heavily relies on carefully tuned heuristics in the product. an obvious approach to tackle this problem would be to add a new configuration surface area for every change which would allow customers to carefully chose new functionality and then opt in on a case-by-case basis. the downside of this approach is that it puts a big burden on the customer and it makes the database system increasingly more difficult to use over time. 
the microsoft sql server team was facing these challenges when working on enterprise data warehouse support for sql server 1. in the context of this current paper  we take the development effort that improved star join query processing as our running example. the main innovations in query processing and query execution for the new star join functionality with microsoft sql server have already been discussed in . the main objective of this work is to provide significant performance improvements for the typically star-shaped decision support queries over dimensionally modeled star and snow flake schemas .  in contrast to   however  this paper focuses on the software testing challenges and solutions we faced and developed in the context of our star join feature development.  of particular relevance to these challenges is the fact that the feature was built to perform automatically within the query processor  without the need for user configuration  across a wide variety of workloads.   
our main contributions are as follows: 

 	
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  or republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee. 
dbtest'1  june 1  1  vancouver  bc  canada. 
copyright 1 acm 1-1-1/1...$1. 
 
we define the problem space and explain the challenges of extending an enterprise-class relational database query processor with new functionality that is completely automatic i.e.  it has no surface area or configuration options to opt in or out. 
 we describe in depth an iterative development methodology that allowed us to progress iteratively towards a wellperforming new feature. we explain how to balance risks for existing customers that do not want or need to leverage the new functionality vs. existing or new customers that want to benefit from the new functionality. 
the remainder of the paper is structured as follows: section 1 defines the problem space and introduces the necessary terminology. section 1 explores the solution space  discusses alternatives  and explains the customer-workload-driven process of iterative development and test that we have chosen for the star join development in microsoft sql server 1. section 1 presents results on how we tracked different performance metrics during development and explains how the iterative approach helped us achieve our performance goals. section 1 discusses related work. section 1 concludes the paper and presents an outlook on future work. 
1. problem space 
as sql server's query processor has evolved over years of research and development  the problem space which must be considered in order to validate  correctness  has grown exponentially  specifically in regard to extensibility and maintenance.    
the term  correctness  can hold a number of meanings when it comes to testing.  for the context of this paper  the correctness that we are validating revolves primarily around functionality and performance.  for any database system  the most essential type of validation is to ensure that the correct results are returned for all interactions.  while we focus most of our discussion towards performance evaluation  this tenet for correct results holds true throughout the entire problem space definition and within all of our testing solutions. 
many of the fundamental challenges of developing and testing this sophisticated system are outlined by giakoumakis and galindo-legaria .  they highlight three key issues which are particularly relevant to this case study: the practically infinite input space in which the query optimizer must operate; the inexact cost and cardinality estimation modeling; and the number of existing customers who come to rely on certain optimizer behavior for their workloads.  we now explore these three issues in the context of this case study and give some examples that we encountered in these domains. 
1 large input space of customer queries 
as an increasing number of customers develop mission-critical data warehouses with terabytes of data to support their operational decisions  the range and complexity of their query workloads increases dramatically.   
a common workload on a star schema generally includes a variable mix of ad-hoc and parameterized queries .  due to the inconsistent nature of many of these  especially the ad-hoc queries  it is very challenging to pinpoint a specific set of queries to make up a testing matrix which can be deemed representative of a large customer segment.   
in addition to traditional star schema queries  the possible workload input space for this case study also includes a segment of transactional workloads which lie close to the boundary between oltp and olap.  these types of workloads are found in many line-of-business applications and must coexist peacefully with the star join improvement. 
1 cost and cardinality estimation 
one of the primary goals of the star join improvement was to provide added value and performance without the extra overhead of requiring database administrators to configure the feature manually.  in order to achieve this  the feature was implemented using a cost and cardinality based solution within the query processor . 
inherent in this design is the testing challenge of validating the heuristics that are built on top of these estimates of the data.  from a testing perspective  we had to confirm that these heuristics are  correctly  determining when the expected benefit outweighs the expected cost of invoking the new star join optimizations.  defining and then validating  correctness  in this context is one of the most significant challenges encountered with all enhancements to the query processor. 
in the star join improvement  we had two main design decisions that had to be tested within the costing and cardinality estimation problem space.  one was to validate the ability of the query processor to detect star join queries by using information about the relational tree pattern along with the cardinality estimations on the fact and dimension tables.  the second was to validate that the estimated selectivity of the joins was then used to determine the correct order and method of processing the subtrees . 
1 existing customers 
with every enterprise software product  providing consistency between legacy and new versions is always a high priority.  many customers of microsoft sql server have spent a significant amount of time tuning their workloads and their database in order to find a synergy that provides them with optimal performance.  although enhancements and modifications to the query processor can generally provide substantial benefit to a large portion of our customers  we must remain sensitive to the fact that regressions  no matter how small  can turn out to be major hurdles for those customers who encounter them. 
while the star join optimizations can provide an order-ofmagnitude benefit to many scenarios   it was critical that we developed a large matrix of workloads and test scenarios to demonstrate both potential improvements and regressions in order to validate our tradeoffs and preserve the experience that legacy customers have come to expect from the query processor.   
another important aspect of this problem space which we encountered is that  from a customer's perspective  certain queries in their workload may be more  important  than others.  that is  they may see a big improvement in one particular query that they run once a week  but they may see a small regression in a query that they run nightly.  over time  this small regression may outweigh the benefit gained from the less frequently run query.  developing the semantics within the testing matrix to capture this  importance  metric is another dimension that must be considered when evaluating design choices and tradeoffs of extensions to the query processor. 
1. solutions 
in order to fully cover the problem space of extending the query processor for the star join improvement  our testing effort undertook a multi-dimensional solution that included a mix of model based testing  performance criteria testing  and real-world customer validation.  the testing methodologies were designed to mitigate the risks and regressions while also validating designed improvements.   
1 iterative development approach 
in the star join improvement  we employed an iterative software development and testing approach.  this was chosen to mitigate the risk of encountering a large number of performance problems at the end of development  once fundamental design decisions had been entrenched.  it was critical to begin testing early prototypes in order to validate the sensitive heuristic and cost-based designs in the query processor space.  for example  early performance experimentation was done to determine the effectiveness of various execution plans for a given set of queries across a range of dimensional selectivity .  over the course of the project  iterative execution of this experiment evolved it to a point where we were able to fine tune the query processor's detection of star schema queries and eliminate cases where we were not seeing benefit from the new enhancements. 
1 model based testing 
in order to cover the vast testing input space of possible schemas and queries  we developed a model which encapsulated the key components of the input space and allowed us to build programmatic tests on top of it.  the selection of parameters for our model evolved from an analysis of the variances within typical customer scenarios.  we looked at a number of these scenarios and identified the key variables which we wanted to model in order to emulate the customer's experience in our testing.  some additional parameters were deemed to be extraneous to our model and were left out  including things like data types and sizes for supplemental columns that were not involved in the star joins.  when developing this model  we applied the common practice of developing both the data model and the test  or query  generation model . 
1.1 schema modeling 
first  we developed a framework to model the various factors within the database schema itself that were important to our improvement.  since we wanted to have independent control over these factors  the schema model was developed in a way that we could adjust parameters to achieve a desired configuration.  the main characteristics of the schema model were as follows: 
number and classification of tables:  this allowed us to control the number of tables in our schema  as well as their classification as fact or dimension table. 
cardinality:  the ability to control how many rows were in each table  this feature was especially useful in allowing us to generate test scenarios that exercised the costing and cardinality aspects of the design.  we were able to easily model a wide range of table sizes for both dimension and fact tables. 
relationships:  star schemas can be modeled by defining relationship between fact and dimension tables. this was useful in covering areas of the problem space that had to do with multidimension selectivity on joins. a snowflake schema can also be modeled by additional relationships between fact tables or dimension tables. for example  a typical user scenario would normalize sales fact table into two tables of master and detail. this would be captured by relationships defined between facts. another example of a snowflake relationship is at the dimension level  where it is common to normalize complex dimensions like customer into two tables - customer contact info and customer location info. the relationship definition within our model was also able to cover more advanced scenarios like vertical partitioning of fact tables   a best practice on separating frequently versus non-frequently accessed columns  and surrogate keyed tables as observed in sap-bi . 
distribution of data:  in addition to the actual schema requirements  our model based testing approach provided the ability to control the distribution of data that the schemas were populated with.  this was necessary to cover test cases that focused on the performance and functionality in cases with data skew or other interesting data distributions.  skewed distributions tend to be very important in query processor testing in order to validate many of the algorithmic assumptions that are often made with respect to normalized or random data.  
one particularly interesting skew scenario that we covered with this aspect of the model was to create a fact table with an extremely uneven distribution on a surrogate key column.  with this type of distribution  the number of output rows from joins between the dimension and fact table using this key column is largely dependent on the individual values from the dimensional predicate.  certain predicates may result in a significantly higher or lower number of rows being returned  which can be difficult for the query processor to predict. 
1.1 query modeling 
along with our ability to programmatically develop a schema model  we also developed a query model which allowed us to generate star join queries on top of the schema model.  this query model encapsulated the following key characteristics that were able to be controlled by our test scenarios: 
number of fact tables involved - this was a particularly interesting characteristic which was used to cover the input space of workloads and queries.  this allowed us to control how many fact tables were involved in the star joins in order to simulate a range of ad-hoc and standardized queries from simple to very complex. 
number of dimension tables involved - similarly  this characteristic was useful in covering the input space of customer queries as we were able to model a variety of dimensions involved with a variety of fact tables. 
predicates on the dimension table - developed for testing the cardinality and costing estimation problem space  this feature of the query model enabled us to apply various filters and selection criteria to the rows returned from the fact and dimension tables.  this allowed us to test how well the query processor was able to perform the estimations and make decisions about which heuristics to apply based on those estimates.   
coupled with the data distribution feature on the schema modeling  this allowed us to test scenarios involving skewed surrogate keys. 
aggregation functions on fact tables - this was another feature of the model that we developed to test costing and cardinality estimation.  often  the application of aggregate functions on top of a fact table can cause problems for the query processor's estimation techniques.  we used this component of the model to validate that our techniques continued to be performant in light of this. 
nested subqueries - this aspect of the query model was used to simulate some typically complex analytic decision-support queries.  for example  this portion of the model was able to generate two star join queries which work over two independent fact tables  and then join their aggregated results together to create an even more complex query.  one typical real-world example that we modeled in this space would be to query the inventory items along with the sales data in order to figure out whether there was a stock or fulfillment problem for the top selling items.  
expected selectivities - the star join optimizations are designed to handle queries which have high selectivity very differently from queries that are non-selective.  for example  the query processor recognizes that very selective queries generally prefer to use a non-clustered index to seek into the fact table .  conversely  less selective queries will generally try to use a scan of the fact table  coupled with a bitmap filter .  our model was designed to produce queries that covered a broad range of selectivities in order to help us tune the heuristics and rules in the query processor. 
 
1 performance criteria testing 
in addition to the model based testing  we also developed a substantial set of performance criteria that we monitored throughout many iterations of testing over the course of the project.  this suite included both performance benchmark tests as well as real-world data warehouse customer workloads. 
1.1 benchmarks 
we used the decision support benchmark  tpc-ds  which is still currently under development from the tpc .  our experiments were focused primarily on the 1gb scale factor for this benchmark and we used a snapshot of the full benchmark for our testing workload.  in addition  we also considered a set of transactional benchmarks including tpc-h . 
1.1 workloads 
in addition to benchmarks  our other main source for performance criteria testing consisted of workloads - both internally developed sets as well as many derived from actual customer queries.  two of the primary customer workloads which were most representative are as follows: 
retail customer - this workload was based on a data warehousing scenario which uses microsoft sql server for online retail business.  this schema is characterized as a dimensionally modeled snowflake and the workload consists of a number of canonical star join queries.  the size of this database was around 1gb. 
microsoft sales organization data warehouse - this workload was based on an internal decision support from within microsoft's sales organization.  for our testing purposes  we used a representative sample of the data which was around 1gb  along with a set of queries that ranged from relatively simple  to extremely complex.   
 
1 customer validation 
once the feature development had stabilized  we entered a final stage of validation and began gathering usage data and feedback directly from customers.  this feedback came primarily from three sources. 
first  we were able to get cooperation from an internal customer within the microsoft sales organization to allow us to deploy our early builds on their test system.  this test system was a scaled down mirror of their actual production system which they use to track and measure performance trends for their users.  the typical workload of this test system was similar to the one mentioned in section 1.1  however this was running within their test center environment and was measured using a pre-defined set of metrics which they had developed to quantify overall quality for their workload.  the customer ran on a pre-release version of sql server 1 which contained our optimizations and reported back with detailed data which demonstrated considerable gains in overall query performance. 
secondly  we validated our design further through the use of our on-site sql server customer lab.  we hosted a customer whose data warehouse was relatively large  around 1tb.  this customer provided us with their application and workload and allowed us to test out our star query optimizations on some of their most difficult queries.   
finally  after these two customer validations were complete  we released the star join improvements in the public ctp-1 release of sql server 1 .  this gave us the chance to have almost a year of real-world feedback on the feature prior to sql server 1's rtm date. 
1. results 
during the development of the star join optimization  we tracked performance for  real-world  customer workloads and industry benchmarks over several iterations in the development process. reference  discusses our most important findings from this effort and focuses on the performance gains we eventually achieved at the end of development  i.e.  performance gains achieved after the last iteration in development. for this current paper instead  we focus on our iterative performance testing approach and how it has helped us to achieve our performance objectives. the following paragraphs revisit the customer workloads introduced in section 1. we report on our two main performance metrics that we tracked during the development cycle: 
query response time: we are using the geometric mean of wallclock query response times across all queries in a workload to quantify query performance.  we track gains and losses of the geometric mean using a baseline taken from the product without changes.  
regressions: the number and magnitude of regressions introduced by the changes is an important metric that approximates the customer experience for customers that are already using sql server and how they are going to be impacted when the upgrade from a previous release to the current one.  therefore  regressions are well-suited to quantify the risk of changes to the product.  we are using the geometric mean as opposed to the arithmetic mean because it gives short and long running queries the same weight. therefore  it is well-suited to indicate performance improvements with the new product irrespective of the size or complexity of the queries.  in addition  we track the number of regressions as a separate metric to quantify negative side effects of our changes to the product which we wanted to minimize to the extent possible. a metric for regressions also penalizes cases where sizable improvements on few queries over-compensate performance degradations on several other queries where a response time average would return an overall improvement. this could negatively affect customers that are not running any of the queries that improved and are stuck with the ones that regressed. we wanted to make sure that our metrics provide an incentive to avoid the latter. 
along with defining and tracking these aforementioned metrics  setting the actual criteria for success versus failure on these was another important aspect of our results.  this proved to be one of the most challenging parts  and one that also benefited from the iterative development and testing process.  in the early stages  we developed our criteria based primarily on customer feedback from sql server 1  along with some of our own internal performance measurements and theoretical expectations.  initially we strived to accept no regressions whatsoever.  as we implemented and further refined our design while starting to accurately track our metrics  we also refined our success criteria - realizing that some expectations were initially set too high  and some were set too low.  also  as we began to encounter more of the challenges inherent in extending the query processor   we realized that some regressions which were orthogonal to our technology changes would be inevitable.  however  we maintained strict criteria on the number of allowable regressions throughout the iterative process and ensured that our implementation itself was not to blame for any that appeared. 
following the iterative testing and development approach introduced in section 1  we have tracked both of these metrics across multiple iterations within the star join development process. the following paragraphs discuss detailed findings. 
decision support benchmark: this workload focuses on decision support queries over a dimensionally modeled snowflake schema with several fact tables. it was one of the first workloads that we considered within the star join development process.  figure 1 shows performance results across all nine iterations  runs  of performance testing within star join development. as the figure shows  the initial changes to the product for star join led to a significant number of regressions  around 1% of the total workload  with no significant performance improvement. based on these findings  we adjusted the implementation to better leverage some lost performance opportunities while avoiding unnecessary risks for regressions. with this workload  we made progress quickly and reached our goals for performance and regression rates after three iterations. 
 

figure 1: decision support workload results 
microsoft sales organization data warehouse: this workload tracks performance for a data warehouse that is used internally for decision support in microsoft's sales organization. it is more challenging than the previous workload for two reasons:  1  with 1gb  its raw data size is much larger than the 1gb of the decision support workload  and  1  its queries are highly complex with often more than 1 joins per query. as figure 1 shows  the initial changes from the previous workload already yield significant performance improvements. however  the number of regressions with the initial changes was unacceptable and it took us several iterations to reduce to an acceptable number such as two queries both with less than 1% regression in response time. through these iterations  we identified three problems which were causing a majority of these regressions:  poor plan choice  or  star joins not being recognized correctly   incorrect tuning of cost heuristics  and increased overhead in query compilation time due to our larger plan search space.  as it turned out  reducing the number of regressions from these three areas was challenging: it required careful analysis of the root cause from development on a query-by-query basis  the fix usually involved changes to the rule set of the query optimizer code  and we had to simultaneously anticipate the effect of such changes on the other workloads. 

     figure 1: microsoft sales data warehouse results retail workload: the retail workload is derived from data and queries associated with a major retail business. almost half way through the development effort  we decided to include this workload into the development process to track performance for workloads and databases with a complex physical design  i.e.  a variety of clustered and non-clustered indexes with materialized views and data partitioning. run 1 in figure 1 shows that the initial changes lead to no significant performance improvement.  

figure 1: retail workload results 
as run 1 and the subsequent runs in figure 1 show  we started experimenting with several different design approaches and verified their performance characteristics over several runs  the initial approaches lead to more regressions and we had to revert those changes. only after run 1  the product stabilizes with noticeable performance improvements and increasingly smaller number of regressions. 
1. related work 
query optimization for data warehousing and decision support has been an active field of database research and development for more than a decade. our earlier work  provides more details about the underlying technology that the sql server team built in the star join effort discussed in this paper and relates to other prior work in the field of data warehousing. 
recent work by giakoumakis and galindo-legaria  provides a comprehensive discussion of the testing challenges for database query optimizers. in particular  our testing for performance regressions relies heavily on baseline performance testing as  among others  suggested by . however  an iterative approach to performance testing and development as discussed in this paper is necessary to achieve satisfactory results. 
a significant amount of research and work has been done on model-based testing  both in the context of object-oriented components  as well as non-deterministic systems .  in addition  many techniques for applying model-based testing in practice have been analyzed . 
1. conclusion and future work 
changing a widely deployed relational database system such as the microsoft sql server query processor is a challenging task in particular when these changes are to be transparent  i.e.  not exposed through configuration surface area of the product to opt in or opt out. given the statistical nature of many heuristics in today's cost-based query optimizers  any development work needs to carefully balance the risk between performance improvement opportunity and regression risks by keeping in particular existing customers in mind. this poses a particular challenge for test and quality assurance of any such changes. 
as we have learned throughout development of new data warehousing functionality for microsoft sql server 1  mitigating those risks and finding the right balance requires significantly more effort from the test teams as compared to other feature work. having taken development of new star join query processing functionality as our running example for this paper  we discussed why a multi-dimensional testing approach is necessary. our approach combines aspects of model-based testing along with iterative development and testing cycles using benchmark workloads and real-world customer validation.  each of these parts of the testing brings unique value to the entire solution. 
in the future  enhancements to relational database system query processors will benefit from improved testing methodologies that make easier validation of code changes a priority. query processors in turn need to make it a design priority to support incremental improvements with bounded effort and predictable customer experience. 
1. acknowledgments 
our acknowledgments to the other members of the star join improvement team for microsoft sql server 1. 
