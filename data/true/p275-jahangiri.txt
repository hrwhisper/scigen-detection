the discrete wavelet transform is a proven tool for a wide range of database applications. however  despite broad acceptance  some of its properties have not been fully explored and thus not exploited  particularly for two common forms of multidimensional decomposition. we introduce two novel operations for wavelet transformed data  termed shift and split  based on the properties of wavelet trees  which work directly in the wavelet domain. we demonstrate their significance and usefulness by analytically proving six important results in four common data maintenance scenarios  i.e.  transformation of massive datasets  appending data  approximation of data streams and partial data reconstruction  leading to significant i/o cost reduction in all cases. furthermore  we show how these operations can be further improved in combination with the optimal coefficient-to-diskblock allocation strategy. our exhaustive set of empirical experiments with real-world datasets verifies our claims.
1. introduction
모the discrete wavelet transform is a well established tool  used extensively in signal processing applications for many years since its introduction. recently  it has proven useful for a number of database applications as well. the wavelet transformation has been used to provide approximate  progressive or even fast exact answers to olap range-aggregate queries  1  1  1  1  1  1  1   with its performance rivaling traditional histogram and sampling techniques. in the do-
 this research has been funded in part by nsf grants eec1  imsc erc  and iis-1  pecase   unrestricted cash gifts from microsoft  an on-going collaboration under nasa's genesis-ii reason project and partly funded by the center of excellence for research and academic training on interactive smart oilfield technologies  cisoft ; cisoft is a joint university of southern california - chevrontexaco initiative.
 this work was done while the author was a graduate student of infolab at the university of southern california.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee.
sigmod 1 june 1  1  baltimore  maryland  usa copyright 1 acm 1-1/1 ...$1.
main of time-series analysis and mining  wavelets are used to automate feature extraction and expedite pattern discovery and outlier detection  1  1 . the wavelet transformation is also used to provide compact synopses of data streams  1  1  in support of approximate query processing.
모however  despite its broad acceptance  the wavelet transformation has not been explored to its full potential for data intensive applications. namely  the compact support and the multi-scale properties of the wavelets  as illustrated by the wavelet tree of decomposition  lead to some overlooked but interesting properties. with the exception of   where traditional relational algebra operations are re-defined to work directly in the wavelet domain  most applications resort to reconstruction of many data values to support even the simplest operations in the original domain.
모we introduce two novel operations for wavelet decomposed data  named shift and split  that stem from the multiresolution properties of wavelets to provide general purpose functionality. they are designed to work directly in the wavelet domain and can be utilized in a wide range of data intensive applications  resulting in significant improvements in every case.
모furthermore  queries on wavelet-transformed data exhibit a particular access pattern. there is a strong dependency among wavelet coefficients  enforced by the multi-scale nesting property  so that we always know which coefficients must be retrieved alongside any coefficient to reconstruct a data point or a range. this observation leads to constructing multidimensional tiles containing wavelet coefficients that are related with each other under a particular access pattern. these tiles are then stored directly into the secondary storage  as their size is adjusted to fit a disk block. by using this tiling approach we can minimize the number of disk i/os needed to perform any operation in the wavelet domain  including the important reconstruction operation which results in significant query cost reductions. we designed the shift and split operations to work with multidimensional tiles  as these operations benefit significantly from their existence.
1 data maintenance scenarios
모to demonstrate the usefulness of our shift and split operations we look into four common data maintenance scenarios  and examine these operations in each context. the scenarios are diverse enough to cover most of the areas where wavelets are used  but not exhaustive  as we conjecture that the applications that can benefit from the shift and split operations are plenty. the scenarios examined here share the fact that the problem they deal with has a straightforward solution when dealing with untransformed data. therefore  one is compelled to first reconstruct the original data from the transformed data. however  we are interested in working entirely in the wavelet domain  and as we see  this becomes a complicating  but fruitful  factor. beside the shift and split operations  a major contribution of this paper includes the six analytically proven improvement results in these four applications by utilizing
shift and split:
  transformation of massive multidimensional datasets: in the simplest scenario  we are faced with the transformation of a multidimensional dataset into the wavelet domain in an i/o efficient manner  where available memory is limited. our approach is transformation by chunks  small enough to fit in memory. each transformed chunk is then shifted  to relocate its coefficients  and split  to update some of the already calculated coefficients. we show that our new transformation technique significantly outperforms the current state of the art methods  1  1  for transforming large multidimensional datasets.
  appending to wavelet decomposed transforms: to illustrate  suppose we have already accumulated and transformed data for 1 years of measurements to expedite query processing. now  what should we do in the case that new data for one more year arrive  should we throw the old transformed data and do the transformation from scratch  certainly  we cannot perform updates; there is nothing to update since the new data involve a part of the data we have not transformed yet. this scenario  seen in the untransformed domain  involves a number of inserts. however  in the transformed domain  each of these inserts require some dimensions to grow  and therefore not only do coefficients have to be updated  but new coefficients need to be created as well. in   the authors define the relational algebra operations in the wavelet domain  but do not propose a solution for insert operations. generally  expanding the transformed data to larger dimension sizes has a high asymptotic cost  even when using our shift and split operations; however  since these operations are faster than computing coefficients  our approach results in faster execution times.
  data stream approximation: gilbert et al.  demonstrated that a best k-term wavelet approximation of a single dimensional data stream of domain size n in the time series model is possible using space of o k + logn   by keeping the o logn  coefficients that can change  with per-item cost of o logn . we show that the shift-split operations can further reduce the per-item cost to at the expense of additional storage of b coefficients.
furthermore  we investigate the case of multidimensional data streams  decomposed under two different forms of wavelet transformation. we conclude that we can maintain a k-term approximation  under certain restrictions. to the best of our knowledge  this is the first work dealing with wavelet approximation of multidimensional data streams  as previous works  1  1  1  1  focused on the single dimensional case.
  partial reconstruction from wavelet transforms: consider the scenario in which we wish to extract a region of the original data from its wavelet transform. we are faced with the following dilemma: either decompose the entire data and then extract the desired region  which is reasonable if the region extend over large part of the data; or reconstruct point by point the desired region  which is preferable for small regions.
chakrabarti et al.  propose a solution to deal with relational algebra selection operations in the wavelet domain. their approach examines the wavelet coefficients to calculate their contribution to the selected range. our shift-split approach generalizes this notion and therefore can be applied to other forms of wavelet decomposition.
1 outline
모we begin our discussion  in section 1  with presenting an overview of discrete wavelet transform and the notion of wavelet trees. in section 1  we introduce the disk block allocation strategy which leads to the efficient tiling of wavelet coefficients and then we extend this strategy to the multidimensional case. the shift and split operations are presented in full details in section 1  with their most important applications appearing in section 1. we present our experimental studies in section 1 and we conclude our discussion in section 1.
1. preliminaries
모in this section  we define the preliminary concepts that we use throughout this paper. for a more detailed treatment of wavelet basics please refer to .
1 discrete wavelet transform
모the discrete wavelet transformation  dwt  provides a multi-scale decomposition of data by creating  rough  and  smooth  views of the data at different resolutions. in the case of haar wavelets that we use throughout this paper  the  smooth  view consists of averages or average coefficients  whereas the  rough  view consists of differences or detail coefficients. at each resolution  termed level of decomposition or scale  the averages and details are constructed by pairwise averaging and differencing of the averages of the previous level.
모let us consider a vector of 1 values {1 1} and let us apply dwt. we start by first taking the pairwise averages: {1} and the pairwise differences { 1}. for any two consecutive and non-overlapping pair of data values a b we get their average:  and their difference divided by 1:
. the result is 1 vectors each of half size containing a smoother version of the data  the averages  and a rougher version  the differences; these coefficients form the first level of decomposition. we continue by constructing the average and difference from the smooth version of the data: {1}. the new average is {1} and the difference is { 1}  forming the second and last level of decomposition. notice that 1 is the average of the entire vector as it is produced by iteratively averaging pairwise averages. similarly   1 represents the difference between the average of the first half of the vector and the average of the second half. the final average and the differences produced at all levels of decomposition form the haar transform: {1  1  1}. notice  that at each level of decomposition the averages and differences can be used to reconstruct the averages of the previous level.
모we denote by uj k and wj k the k-th average  a.k.a. scaling coefficient  and the k-th detail coefficient  a.k.a. wavelet coefficient   respectively  for the j-th level of decomposition. the averages at level j are decomposed into averages and details of level j+1. if we denote the set of scaling coefficients at the j-th level by uj and the set of wavelet coefficients at the j-th level by wj  we can formally write the previous statement as uj = uj+1  wj+1  where the direct-sum  notation refers to the decomposition process. the original data are the scaling coefficients of the 1-th level. see also appendix a.
모for example  the 1 level decomposition  shown in figure 1  is formally written as:
u1 = u1  w1
= u1  w1  w1
= u1  w1  w1  w1
모figure 1 also shows that for each level of decomposition j  there are 1n j wavelet coefficients wj k and 1n j scaling coefficients  for 1 뫞 k 뫞 1n j  1. the transformed vector a consists of the average  un 1  as its first element  followed by the details wj k sorted decreasing by level j and increasing by position k: un 1  wn 1  wn 1  wn 1  wn 1  ...  w1  ...  w1n 1. we denote that vector a is the discrete wavelet transform of a by a = dwt a . note that the untransformed vector a contains the scaling coefficients at the 1-th level of decomposition: a k  = u1 k  for 1 뫞 k 뫞 n.

figure 1: haar wavelet decomposition
모we now define the term  support interval  that we will use frequently in this paper.
모definition 1. the support interval of a  wavelet or scaling  coefficient is the part of the original data from which this coefficient is computed.
모figure 1 shows the support intervals of haar wavelets for a vector of size 1.
모definition 1. a  wavelet or scaling  coefficient covers another  wavelet or scaling  coefficient if the support interval of the latter is  completely  contained in the support interval of the former.
모for example  the first coefficient in the second level of decomposition w1 covers the first and second coefficients of the first level of decomposition  w1 and w1; see figure
1.
모definition 1. an interval i is a dyadic interval if i = k1j  k + 1j   1   for 1 뫞 j 뫞 n and 1 뫞 k 뫞 1n j 1.
모haar wavelet coefficients wj k and haar scaling coefficients uj k have the property that their support intervals are dyadic intervals.
모property 1. the support interval of a haar wavelet coefficient wj k  or scaling coefficient uj k  is the ij k dyadic interval k1j  k + 1j   1 .
u1u1u1u1u1u1u1u1a  j=1 
u1w1u1w1u1w1u1w1level 1  j=1 
u1w1u1w1level 1  j=1 
u1w1level 1  j=1 
figure 1: support intervals of haar wavelets
모multidimensional wavelet transformation there are two ways to perform a multidimensional wavelet decomposition  the standard and the non-standard. in short  the standard form is performed by applying a series of onedimensional decompositions along each dimension whereas the non-standard form does not decompose each dimension separately. in the non-standard form  after each level of decomposition only the averages corresponding to the same level are further decomposed. we refer the reader to appendix b for further discussion.
1 wavelet tree
모in this section  we review the notion of wavelet tree. our purpose is two-fold. this tree exploits the relationships between coefficients  and thus identifies the access patterns which lead to the block allocation strategy described in section 1. furthermore  the shift and split operations that we define in section 1 are easily understood in the context of wavelet trees  as they essentially are operations on trees.
모the multiresolution property of the haar wavelets induces a tree construct capturing and illustrating this property. a wavelet coefficient w is the parent of another coefficient w  when w is the coefficient with the smallest support that covers w. for haar wavelets  which is our case  this tree is a binary tree where each node wj k has exactly two children  wj 1k and wj 1k+1. the scaling coefficient un 1 is the root of the tree having only one child wn 1. this tree structure has been given several names in the wavelet bibliography  such as error tree  1  1   dependency graph   etc. figure 1 shows this tree for a vector of size 1; scaling coefficients are shown with squares  whereas wavelet coefficients are shown in circles. figure 1 also shows the original data as children of the leaf nodes of the tree  drawn with dotted line.
모the beautiful property of this tree is that it portrays the way haar wavelets partition the time-frequency plane; see figure 1. as j decreases we gain accuracy in the time domain  but simultaneously  we lose accuracy in the frequency domain and vice versa.
모the following lemma is a consequence of the time-frequency trade-off. a single point in time domain depends on those wavelet coefficients in the path to the root. as a result  a data value can be reconstructed in time proportional to the tree height and thus in time logarithmic to the vector size.

figure 1: haar wavelet tree
모lemma 1. let a be the wavelet transform of vector a of size n = 1n  a = dwt a . any value of a can be reconstructed using exactly n + 1 = logn + 1 coefficients from
a.
모proof. let a i  be the  i + 1 -th value of a. at each level of decomposition j  there is exactly one wavelet coefficient that covers a i   because of the fact that haar wavelets of the same level have non-overlapping support. this together with the parent-child relationship existent in the wavelet tree results in the covering wavelet coefficients
  and the scaling coefficient un 1 belonging to a  n + 1 -long path in the tree. 
모therefore  as lemma 1 suggests a point query can be answered using o logn  coefficients. however  the wavelet transformation is mainly used for its ability to answer rangesum queries also using o logn  coefficients  as the following lemma suggests.
모lemma 1. let a be the wavelet transform of vector a of size n = 1n  a = dwt a . a range-sum query can be answered using not more than 1n + 1 = 1logn + 1 coefficients from a.
모proof. this lemma holds because of the fact that haar wavelets have a 1-th vanishing moment. for more details refer to . 
1. disk block allocation of wavelet coefficients
모the purpose of this section is to assign wavelet coefficients to disk blocks in such a way that the number of blocks required for answering queries is minimized. we have already seen that the wavelet tree captures the dependency among coefficients. in particular  if a coefficient is required to be retrieved then all coefficients on the path to the root must also be retrieved. this property creates an access pattern of wavelets that must be exploited by the disk block allocation strategy.
모intuitively  a disk block should contain coefficients with overlapping support intervals  so that the utilization of the in-block coefficients is high. however  we must take under consideration the fact that the disk block allocation strategy should not allow redundancy  in that a wavelet coefficient should belong to one block only. under this restriction  in order to be fair across all coefficients  we partition the wavelet tree into binary subtree tiles and store each tile on a disk block. assuming that the disk block size b is a power of 1  b = 1b  we achieve logarithmic utilization of the blocks.
at least b coefficients inside the block  lying in a path  are to be utilized any time this disk block is needed. logarithmic utilization may seem low at first  but it is the best we can hope for under our restrictions  as proven in .
모one final issue is that the size of the binary subtree tiles is 1b  1  whereas the block size is 1b. we are wasting space of 1 coefficient in our block allocation strategy. therefore  we choose to store the scaling coefficient corresponding to the root of the subtree  along with the wavelet coefficients of the tile. the extra scaling coefficients that we store are useful for query answering  as they can dramatically reduce query costs. an example of the disk block allocation strategy for a wavelet tree of 1 coefficients is shown in figure 1.

figure 1: disk block allocation strategy
모we continue our discussion by generalizing the disk block allocation schema for both standard and non-standard multidimensional wavelet transformation in section 1; but first  we need to extend the wavelet tree notion to the multidimensional case.
1 multidimensional wavelet trees
모as mentioned before  there are two forms of multidimensional wavelet decomposition  the standard and non-standard. the non-standard form of decomposition involves fewer operation and thus is faster to compute but does not compress as efficiently as the standard form. particularly  range aggregate queries can be highly compressed using the standard form as shown in . in the database literature both transformation forms have been used: standard by  1  1  1  1  and non-standard by  1  1 . however  we are not aware of any study on the extension of the wavelet tree concept for either form of the multidimensional transformations. more details on the multidimensional transformation forms can be found in appendix b.
모in the standard multidimensional transformation each dimension is decomposed independently. therefore  there cannot be a single tree capturing the levels of decomposition. in case of 1-d  considering a 1-d wavelet tree for each of the decomposed dimensions  two 1-d wavelet trees are required. every coefficient in a transformed 1-d array has two indices  one for each dimension. each of these indices identifies a position in the 1-d tree  which as we have seen corresponds to a decomposition level and to a translation inside that level. figure 1 shows a coefficient in an 1 뫄 1-d array and the corresponding indices on the two wavelet trees.
모the two 1-d trees can be used to determine which coefficients need to be retrieved for reconstructing data values on the 1-d array. subsequently  they provide information about the access pattern of 1-d wavelets. a single data value on the untransformed  original  1-d array corresponds to a path in each of the 1-d wavelet trees  or better  a set of 1-d indices  as mentioned before. the cross product among all indices

figure 1: standard form wavelet trees
across these sets  construct the 1-d indices whose coefficients must be retrieved. for a n 뫄 n array  where n = 1n  each of the paths contains  n+1  1-d indices  therefore there are  n + 1 1-d indices. figure 1 shows the two paths on the 1-d wavelet trees  as well as the required coefficient resulting from the cross product between 1-d indices.

figure 1: standard form data point reconstruction
모in contrast to the standard multidimensional transformation  a single wavelet tree can capture the levels of decomposition and dependency among coefficients for the nonstandard transformation. the support intervals of the wavelet coefficients form a quad-tree  as each support interval is further decomposed in quadrants at the next level of decomposition. at the j-th level of d-dimensional decomposition we have  1d j nodes  each containing 1d  1 coefficients with support interval hypercubes with edge length 1j.
모in the 1-d case  the support intervals of the coefficients are squares with side length of power 1. there are 1 coefficients for each support interval  one for each of the wavelet subspaces: wd  wv and wh; thus  each quad tree node contains its 1 corresponding coefficients. figure 1 shows the wavelet tree for an 1뫄1 array and zooms in on a multidimensional tile  described in section 1. the support interval of the children nodes  which are the four quadrants of the support interval of the parent node  are shown in dark grey. to reconstruct a point in the original 1-d array  one has to traverse the quad tree bottom up and use all 1 coefficients in each node.
1 diskblockallocationofmultidimensional wavelets
모as in the single dimensional case  our main concern is to pack coefficients in disk blocks so that we achieve the highest possible block utilization on query time and thus decreasing retrieval cost. the solution is to assign as many coefficients with the same support to the same disk block as possible.

figure 1: non-standard form wavelet tree
this results in different disk block allocation strategies for the two multidimensional forms of decomposition. we assume d-dimensional dataset  where each dimension has size n = 1n. furthermore  disk block size is bd  where b = 1b.
모in the standard multidimensional decomposition  each dimension can be treated independently. therefore  for each dimension we construct tiles of size b containing the b coefficients of a subtree  similar to the single dimensional case. the cross product of these d sets of single dimensional bases construct bd multidimensional bases. the coefficients corresponding to these bd bases are stored in the same block and form a multidimensional tile.
모in the non-standard multidimensional decomposition  tiles are subtrees of the quad tree. the branching factor of a ddimensional quad tree is d = 1d and each node contains d   1 coefficients. therefore  a tile of height b contains
b	b
 nodes or equivalently d   1 coefficients. by also storing the scaling corresponding to the root node we create tiles of db =  1d b =  1b d = bd coefficients which fit in a disk block of size bd. figure 1 shows the tiling of a 1 뫄 1 array  for disk blocks of size 1.
1. shift-split
모in this section we describe our general purpose operations  shift and split  on wavelet transformed vectors. later  in section 1  we discuss the applications that can benefit from our operations.
모there is a relationship among the coefficients in the transform of a vector  a and in the transform of a dyadic region b of the vector. this relationship is captured by shifting  re-indexing  the wavelet coefficients  details  of b and by splitting  calculating contributions from the scaling coefficient  average .
모the shift-split operations are better understood in the context of wavelet trees. let a be a vector of size n = 1n and let b be the  k + 1 -th dyadic range of vector a with size m = 1m. the wavelet coefficients of a are denoted by wj la   whereas the wavelet coefficients of b are denoted by wj lb ; similarly for scaling coefficients  uaj l and ubj l. also  let
ta and tb denote the wavelet trees of a and b  respectively. figure 1 illustrates the above.
	the support of the wavelet coefficient wm ka	is the dyadic

figure 1: shift-split operations
range that b represents. therefore  covers wm b 1 and vice versa  since their support is the same range of a; see tb in figure 1. furthermore  all children of wm ka in ta have common support with the corresponding children of wm b 1 in tb. specifically  at the j-th level of decomposition  the i-th coefficient wj ib of tb has the same support with the k1m j + i -th coefficient wj ka 1m j+i. n
모definition of shift. let a be a vector of size n = 1 and let b be the  k + 1 -th dyadic range of vector a with size m = 1m. also  let   be a function that translates the indices i of b to indices f i  of a. the shift operation on the transformed vector b is defined as the re-indexing of the wavelet coefficients by function f. 
모the wavelet coefficients of a that cover the interval represented by b contain a portion of the energy of the average of vector b. to be exact  the value of the wavelet coefficients
   as well as the average uan 1
depend on the value of the average ubm 1; these coefficients lie in the path from wm ka to the root and are contained in
tc of figure 1. essentially the value of the average ubm 1 is split across these n   m + 1 coefficients  contributing either positively  or negatively.
모definition of split. let a be a vector of size n = 1n and let b be the  k + 1 -th dyadic range of vector a with size m = 1m. also  let g :  m + 1 n  뫸 r 
	 	if k	mod 1j m even
 odd
be the function that calculates the contribution of ubm k per level j. the split operation on the transformed vector b calculates the contribution of ubm k to the n   m wavelet coefficients:   and to the
average:.	
모to demonstrate the use of the shift-split operations  let us look at two examples.
모example 1. assume we are to transform a very large vector a of size n = 1n into the wavelet domain  where only the subregion  k1m  k + 1m   1  of the vector contains non-zero values. let b be that non-zero subregion of size m = 1m. because of the fact that b forms a dyadic interval  we can apply the shift-split operations to construct a as follows. first  we obtain the wavelet transform b in time o m . next  we apply the shift operation to place the wavelet coefficients of b in their corresponding position in a. finally  we apply the split operation on the average of b to obtain n m+1 contributions and construct the remaining n   m + 1 coefficients. we have completed the wavelet transformation of a in time   instead of o n . 
모example 1. assume we have already transformed vector a of size n = 1n into the wavelet domain. there are updates  stored in vector b  coming for a subregion   of a. the goal is to update the wavelet transform of a as efficiently as possible. each of |b| = m = 1m updates requires n + 1 values to be updated  leading to a total cost of o m logn . however  we can use the shift-split operations to batch updates and reduce cost  as follows. first  we obtain the wavelet transform b in time o m . next  we apply the shift operation to calculate the indices of the wavelet coefficients of a which need to be updated by the wavelet coefficients of b. finally  we apply the split operation on the average of b to obtain n   m + 1 contributions and update the corresponding coefficients in a. the total update cost using shift-split has been reduced to 
1 multidimensional shift-split
모the shift-split operations in the multidimensional decomposition exploit the relationship between the wavelet coefficients of the entire dateset and those in a multidimensional dyadic range. a multidimensional dyadic range is formed by the cross product of single dimensional dyadic intervals. for the non-standard decomposition we will only consider cubic multidimensional dyadic ranges resulting from dyadic intervals of equal length for all dimensions; arbitrary multidimensional dyadic ranges can always be seen as a collection of cubic intervals.
모to perform the shift-split operations for the standard multidimensional decomposition  one has to perform the operations for each dimension separately. any coefficient in the d-dimensional dyadic interval can only be shifted or split in each dimension  and thus can sustain d operations in total. consider as an example a d-dimensional dataset  where each dimension has size n = 1n  and a cubic dyadic range of edge m = 1m. the shift operation affects  m   1 d coefficients and the split operation calculates  m + n   m d    m   1 d contributions.
모with the non-standard multidimensional transformation  all the wavelet coefficients in the cubic dyadic range must be shifted similar to the standard transformation. however  only the scaling coefficient has to be split and the contributions for the coefficients inside nodes on the path to the root have to be calculated. therefore  in the non-standard transformation  the shift operation affects md  1 coefficients and the split operation calculates  1d   1  n   m  + 1 contributions.
1 shift-split of tiles
모in this section we assume that the coefficients are stored using the optimal block allocation strategy described in section 1. we will calculate the number of tiles affected by the operations for the single dimensional and extend to the two multidimensional wavelet transformations.
shiftsplitstandard
non-standardo	 b 	 		m 
table 1: shift-split of tiles모we start with the single dimensional case of a vector of size n = 1n and its k+1-th dyadic interval of size m = 1m  when the disk block size is b = 1b. the coefficients affected by the shift operation belong to a subtree of the wavelet tree  and that subtree contains exactly  tiles. on the other hand  the split operation calculates log contributions. because these contributions lie on a single path to the root inside every tile  there are logb coefficients affected per tile. this results in exactlytiles containing the contributions of the split operation. to summarize for the single dimensional case  the shift operation affects b times less tiles than coefficients  whereas the split operation affects logb times less tiles than coefficients.
모extending to d-dimensional tiles of size bd =  1b d and applying the observation for the single dimensional case  we derive the number of d-dimensional tiles affected by the operations in each multidimensional form. the results are summarized in table 1. for the remainder of this paper we will drop the ceiling operations to increase readability.
1. shift-split applications
모in this section  we describe some of the applications where the shift-split operations prove useful and draw comparisons to the existing alternatives.
1 transformation of massive multidimensional datasets
모one of the most important application of the shiftsplit operations is i/o efficient transformation of massive multidimensional datasets. in the following  we assume that the dataset is d-dimensional with each dimension having a domain of size n = 1n  so that the hypercube has nd cells. the available memory for performing the transformation is md  where m = 1m  measured in units of coefficients. therefore  at any point in time  there can only be coefficients in main memory. given these restrictions we need to construct an efficient  in terms of required i/o operations  algorithm for decomposing the dataset. we begin by assuming that one i/o operation involves a single data value  or coefficient. later  we measure i/o operations in units of disk blocks  as we consider the optimal disk block allocation strategy described in section 1.
모the intuition behind our approach is simple. we assume that the data are either organized and stored in multidimensional chunks of equal size and shape  or that the chunkorganization process has been performed  similar to  1  1 . we transform each chunk and use the shift operation to relocate the coefficients and the split operation to update the stored coefficients. the chunks are hypercubes of size md so that they fit in main memory. figure 1 shows a one dimensional example  for n = 1 and m = 1  where the current chunk is c. the transformation of c results in the wavelet coefficients inside the box needing to be shifted. the scaling coefficient of c must be split to calculate the contributions to the coefficients shown in grey. with black are shown the coefficients that have a finalized value; that is  coefficients that will not be affected by c or by chunks coming after c. with white are shown the coefficients that do not cover any of the chunks seen so far.

figure 1: transformation by chunks
모result 1. the i/o complexity for transforming a d-dimensional dataset with each dimension having domain size n = 1n into the standard form of decomposition using memory of md coefficients is  disk blocks of size bd.
모proof. as mentioned in section 1  the shift operation  for the standard decomposition  affects  m   1 d coefficients  whereas the split operation affects  m +n  m d    m   1 d coefficients. consequently  each chunk requires i/o operations.	summing for all	 chunks  we derive the i/o complexity for the standard multidimensional wavelet transformation measured in coefficients:  .
now  let us consider disk blocks of size bd  for b = 1b. in this case  the i/o cost per chunk in units of disk blocks is: o mb + logb mn d . summing for all chunks we derive the i/o complexity  measured in terms of disk blocks  for the standard multidimensional wavelet transformation:

모vitter et al.  1  1  use the standard form to decompose multidimensional datasets  without taking under consideration  however  our optimal block allocation strategy. they transform a dense d-dimensional dataset in o nzd logm n disk i/o operations; in the case of sparse data with nz non-zero values the i/o complexity is o nzd logm n . we can modify our shift-split approach to accommodate for sparseness similar to the latter case  where only nz non-zero values exist; the modified i/o complexity is o nz + nmz log mn d .
however  for comparison purposes we omit the effect of sparseness in the original data. the i/o complexities are summarized in table 1.
모result 1. the i/o complexity for transforming a d-dimensional dataset with each dimension having domain size n = 1n into the non-standard form of decomposition using memory of  coefficients is  disk blocks of size bd.
모proof. in the case of the non-standard multidimensional wavelet transformation  the shift operation affects md 1 coefficients  whereas the split operation affects  d 1  n  m +1coefficients  where d = 1d. the per chunk i/o cost is
d
 . summing for all		chunks  we
derive the i/o complexity  measured in terms of coefficients  for the non-standard multidimensional wavelet transformation:  . when tiling is used  the i/o cost per chunk in units of disk blocks becomes: o mb d +  d   1 logb mn . summing for all chunks we derive the i/o complexity  measured in terms of disk blocks  for the non-standard multidimensional wavelet transformation: o nb d +  d   1  mn d logb mn . however  if we enforce a particular access pattern on the chunks  namely a z-ordering  and allow some extra amount of memory  1d   1 log to store those coefficients that are affected by the splitting of the scaling coefficient of the chunks  we can reduce the cost to the optimal o nd   as seen in table 1. a similar approach has been suggested in   where a recursive procedure is used to ensure values come in the particular access pattern. 
1 appendingtowaveletdecomposedtransforms
모in this section we investigate the problem of appending new data to existing transformed data. appending is fundamentally different from updating in that it results in the increase of the domain of one or more dimensions. as a result  the wavelet decomposed dimensions also grow  new levels of transformation are introduced and therefore the transform itself changes. we would like to perform appending directly in the wavelet domain  preserving as much of the transformed data as possible and avoiding reconstruction of the original data. the shift-split operations helps us achieve this goal. to make complexity analysis easier  we omit the effect of the optimal disk block allocation strategy  or equivalently assume disk block size of 1 coefficient. also  we use the standard form of decomposition  as analysis for the non-standard form is similar.
모as a motivation  consider the scenario where a massive multidimensional dataset containing measurements over 1 years is decomposed into the wavelet domain to expedite query processing. a new set of data for the following year has become available  which results in appending to the time domain and possibly on other measure dimensions. let us assume that the 1-year decomposed d-dimensional dataset has size of nd  and that the available memory is md  for
n = 1n and m = 1m.
모our shift-split approach to the problem is the following  repeating for each md data values that we gather in memory. we start by performing the d-dimensional dwt on the gathered data. next  if required  we make the necessary space on the original transformed data  expand  to accommodate for the new data to be appended. the final step is to shift and split the gathered data to update the expanded data. the second step is the most important in the appending application. let us assume that we must expand on one of the dimensions to accommodate for the coefficients held in memory. the expansion means that the wavelet tree for that dimension has to increase its height by 1  and thus double its domain range. this expansion process is carried out by shifting and splitting the decomposed data in this dimension. figure 1 shows expansion in one dimension  where told becomes tnew and |tnew| = 1|told|. the expansion step creates the necessary space for the current chunk of md coefficients in memory  as well as for some of the next chunks. therefore  this step  although costly  is rather rare.

figure 1: wavelet tree expanding
모the i/o cost of expanding transformed data in one dimension is o nd  as all coefficients have to be shifted to construct the new data cube of size 1nd. note  that although the asymptotic cost is high  the required shift-split operations are very fast  which leads to fast execution times for expanding the domain of one dimension. this phenomenon is amplified by the use of tiling and is demonstrated in section 1. moreover  this operation  unlike reconstruction  does not require memory to process. the i/o cost of applying the shift-split operations on the memory chunk of size .
1 data stream approximation
모in this section  we revisit the appending problem  this time in the context of stream query processing: we wish to maintain a wavelet approximation of a multidimensional datastream in the time-series model  when dimension sizes are unbounded and new data are coming. the focus here is to construct a space and time efficient algorithm for maintaining the best k-term synopsis. we show that we cannot  in general  maintain a k-term synopsis for multidimensional datasets decomposed using the standard form under bounded space. however  if certain conditions are met we can maintain a k-term synopsis effectively.
모let us start with the simple one dimensional case. as shown in   we can maintain the best k-term approximation of a data of length n = 1n by using space k+logn+1. we always store the k highest coefficients encountered so far  plus those coefficients whose value can change by subsequent data arrivals. these coefficients  termed wavelet crest in   lie on the path from the current value to the root of the wavelet tree and therefore  they are exactly logn + 1 . equivalently  if we consider a range containing just the data values under consideration  the split operation results in contributions lying in the wavelet crest. therefore  at any time we have to keep the coefficients that can be affected by the split operation in memory.
모result 1. a k-term wavelet synopsis of a data stream of size n in the time series model can be maintained using
memory of  coefficients with per-item computational cost.
transformation methodi/o cost  in coefficients i/o cost  in blocks vitter et al.  standard 
shift-split  standard  shift-split  non-standard dtable 1: i/o complexities모proof. if we keep in memory a buffer of size b = 1b we can reduce per-item processing time at the expense of extra space. we collect b coefficients in the buffer  transform them and apply the shift operation to obtain the b 1 relocated wavelet coefficients. next  we compare these coefficients with the k highest  to obtain the new set of k highest coefficients. finally  we have to update the coefficients that can change by using the contributions derived from the split operation. the number of contributions for a buffer of size b is log and thus the space required for the coefficients on the crest is log. the total computational cost for the buffer  which includes the cost for transformation and the cost for updating the coefficients on the crest  is . as a result  the per-item computational cost is  reduced from o logn   at the expense of extra space of b. 
모the key for being able to maintain a wavelet approximation in the one dimensional case is the fact that only a single path to the root of the wavelet tree has to be maintained at any time. let us turn our attention to the multidimensional case. we assume that the data needs to be appended in only one dimension  usually the time dimension   which is the case for multidimensional data streams of the time series model. to separate the continuously increasing dimension  we let t denote its current size  whereas the other dimensions have a constant size of n. therefore  the ddimensional data stream has a size of nd 1t. the amount of space  besides the k terms  required to maintain a kterm approximation depends on the number of coefficient that can be affected by a split operation. we calculate the number of these coefficients for each of the multidimensional forms  assuming that we have extra storage to buffer md coefficients  where m = 1m. note that when m = 1  we achieve maximum efficiency in terms of space  in the expense of increasing the per-item processing time.
모result 1. a k-term standard wavelet synopsis of a ddimensional data stream growing in the t dimension can be maintained using memory of o k + md + nd 1 log mt coefficients.
모proof. in the standard form  there are d   1 wavelet trees of size n and a single wavelet tree of size t. since  the stream expands on the dimension of size t  we only have to keep a path to the root for the wavelet tree corresponding to that dimension. however  a new data value can arrive in any position on the other trees  which means that we have to keep all the paths to the root for the d   1 trees. to recap  we need to keep all n 1-d basis functions from the d 1 trees of size n and only log 1-d basis functions for the tree corresponding to the dimension which increases. the cross product between these sets of 1-d basis functions results in nd 1 log mt d-dimensional basis functions and thus that many coefficients have to be maintained  besides the k highest coefficients and the extra storage space of md coefficients used for buffering. therefore  the required space of coefficients is prohibitive  except in the case where the constant dimensions have very small domain size  so that nd 1 is small. 
모result 1. a k-term non-standard wavelet synopsis of a d-dimensional data stream growing in the t dimension can be maintained using memory of o k + md +  1d   1 log mn + log nt coefficients.
모proof. since the dimension with size t is constantly expanding  we have to deal with non equal dimension sizes  similar to . such a data stream can be seen as a  hypercubes of size nd  where each of these hypercubes can be decomposed with the non-standard form. each of these  hypercubes results in a wavelet tree capturing the nonstandard decomposition  where there exists a single average as the root of each of these trees. we apply the single dimensional transformation on the  data constructed by these averages. the final result consists of  non-standard multidimensional trees and a single one dimensional tree which has as leaf nodes the averages of the non-standard trees. we assume the z-ordered access pattern  described in section 1  and we allow for extra buffering space of md coefficients. under these restrictions  the coefficients we have to retain lie in a path to the root in the last tree of the hypercubes  and in the path to the root in the single dimensional wavelet tree. therefore we need to keep
 1d   1 log mn coefficients from the non-standard tree and coefficients from the 1-d tree  resulting in a total space cost of . 
1 partialreconstructionfromwavelettransforms
모in this section  we discuss the problem of reconstructing a set of values specified by a range on a multidimensional dataset. the problem is equivalent to translating the selection operation of relational algebra to the wavelet domain. chakrabarti et al.  have provided a solution for the non-standard form  in which they identify the coefficients who cover the range and calculate their contribution. here  we present a similar approach  based on the inverse of shift-split operations  which generalizes to both forms of decomposition. the inverse of shift is essentially the inverse index translation  whereas the inverse of split is lemma 1  which shows how to reconstruct a value from contributions on a path to the root. therefore  the cost of the inverses of these operations is the same.
모we focus our discussion here to multidimensional ranges that are dyadic ranges; an arbitrary selection range can be seen as a number of such dyadic ranges. therefore  our problem degenerates to the reconstruction of a d-dimensional dyadic range of size md  given the transformation of the entire data of size nd. the scaling coefficients of the dyadic range are calculated using the inverse shift  whereas the rest of the coefficients are simply calculated from the coefficients in the original dataset by re-indexing  using the inverse split.
모result 1. the time complexity for reconstructing a ddimensional dyadic range of size md from a wavelet transformed signal of size for the standard form and for the non-standard.
모proof. it follows from the complexity of the shiftsplit operations. 
1. experiments
모in this section  we study the performance of the shiftsplit operations in three real world scenarios. first  we use these operations to transform a large dataset into the wavelet domain. next  we show how shift-split operations are employed for the maintenance of transformed data in an appending scenario. finally  we show the significant improvement in the update cost for maintaining a wavelet synopsis in a data stream application by employing additional memory as buffer. we would like to emphasize that the experiments are accurate implementations of the operations on real disks with real disk blocks  see  for further information .

figure 1: effect of larger memory
1 transformation of massive multidimensional datasets
모in this set of experiments  we transform a large dataset  temperature  into the wavelet domain using limited available memory. the temperature dataset is a real-world dataset provided to us by jpl that measures the temperatures at points all over the globe at different altitudes for 1 months  sampled twice every day. we construct a 1-dimensional cube with latitude  longitude  altitude and time as dimension attributes  and temperature as the measure attribute  with the total size of the cube being 1gb.
모figure 1 shows that larger memory considerably reduces transformation cost of shift-split in the standard form but it does not noticeably affect shift-split in the nonstandard form. the reason behind this is that the cost of the split operation is considerably different for the two forms of multidimensional wavelet transformation. increasing memory size causes a significant decrease in split cost and consequently a major decrease of the standard form transformation as there are many coefficients affected by the contributions of the split operation. however  split cost is almost negligible in the non-standard form  see table 1 . finally  this figure also states that our shiftsplit approach outperforms the vitter et al.  algorithm for any memory size.

figure 1: effect of larger tiles
모as we have shown in section 1  not only tiling is the optimal wavelet coefficient blocking for query processing  but it is also a shift-split friendly schema which introduces significant cost improvements in the transformation process. figure 1 demonstrates this fact by using different tile sizes and thus illustrates the scalability of the shift-split algorithms.
1 appending to wavelet-transformed data
모we examine our proposed appending technique on the precipitation  dataset  where we incrementally receive new sets of data every month. precipitation is a real-life dataset that measures the daily precipitation for the pacific northwest for 1 years. we built a 1-dimensional cube with latitude  longitude and time as dimensional attributes  and precipitation as the measure attribute for every day. the sizes of these dimensions are 1  1 and 1 respectively for each month. figure 1 demonstrates the shiftsplit i/o cost as new sets of data are appended. the sudden jumps in the figure correspond to the expansion process  where all coefficients must be shifted to accommodate for new data values. one can observe that this expansion process is not such a dominating factor as described in section 1  especially for larger disk block sizes.

figure 1: shift-split in appending
1 data stream approximation
모in this scenario we only need to preserve the synopsis of the precipitation dataset  limited to a memory footprint of 1kb. figure 1 demonstrates the computational cost versus the extra storage trade-off described in section 1. as the figure suggests  the update cost can be improved by 1% by employing additional memory buffer of only 1% of the total synopsis size.

figure 1:	shift-split in multidimensional streaming
1. conclusions
모we have introduced two general purpose operations  termed shift and split  that work directly in the wavelet domain and can also be applied in combination with the optimal disk block allocation strategy. we analyze their costs for both the single dimensional case and the two forms of multidimensional transformation.
모there is a significant number of applications that can benefit from these operations. we have revisited some data maintenance scenarios  such as transforming massive multidimensional datasets and reconstructing large ranges from wavelet decomposed data  and utilized the shift-split operations to draw comparisons with the current state of the art techniques. furthermore  we have provided solutions to some previously un-explored maintenance scenarios  namely  appending data to an existing transformation and approximation of multidimensional data streams. we demonstrated the effectiveness of the proposed techniques both analytically and experimentally  and we conjecture that the introduced operations can prove useful in a plethora of other applications  as the shift-split operations stem from the general properties and behavior of wavelets.
