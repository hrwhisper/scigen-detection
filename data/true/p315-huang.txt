snippets are used by almost every text search engine to complement ranking scheme in order to effectively handle user searches  which are inherently ambiguous and whose relevance semantics are difficult to assess. despite the fact that xml is a standard representation format of web data  research on generating result snippets for xml search remains untouched.
모in this paper we present a system  extract  which addresses this important yet open problem. we identify that a good xml result snippet should be a self-contained meaningful information unit of a small size that effectively summarizes this query result and differentiates it from others  according to which users can quickly assess the relevance of the query result. we have designed and implemented a novel algorithm to satisfy these requirements and verified its efficiency and effectiveness through experiments.
categories and subject descriptors
h.1  information search and retrieval : search process
general terms
algorithms  design
keywords
xml  snippets  keyword search
1. introduction
모the semantics of searches issued by web or scientific users  especially when specified using keywords  are inherently ambiguous. various ranking schemes have been proposed to assess the relevance of query results so that users can focus on the ones that are deemed to be highly relevant. however  due to the ambiguity of search semantics  it is impossible to design a ranking scheme that always perfectly gauges query
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee.
sigmod'1  june 1  1  vancouver  bc  canada.
copyright 1 acm 1-1-1/1 ...$1.
result relevance with respect to users' intentions. to compensate the inaccuracy of ranking functions  result snippets are used by almost every text search engine. the principle of result snippets is orthogonal to that of ranking functions: let users quickly judge the relevance of query results by providing a brief quotable passage of each query result  so that users can choose and explore relevant ones among many results.
모despite the fact that xml is a standard representation format of web data  the problem of generating result snippets for xml search remains untouched. compared with result snippets for text document search  xml presents better opportunities for generating meaningful and helpful search result snippets. in document search  due to the lack of structure  a common strategy is to use document fragments that contain keywords along with the surrounding words as snippets in order to approximate a semantic summary of the document. on the other hand  xml data is semistructured with mark-ups providing meaningful annotations to data content  and therefore has a better hope to generate semantically meaningful snippets.
모in this paper we identify the specific goals that a semantically meaningful result snippet should meet. first  a result snippet should be self-contained so that the users can understand it. second  different result snippets should be distinguishable from each other  so that the users can differentiate the results from their snippets with little effort. third  a snippet should be representative to the query result  thus the users can grasp the essence of the result from its snippet. at last  a result snippet should be small so that the users can quickly browse several snippets. however  achieving these goals is highly challenging.
모to be self-contained  a result snippet should represent a semantic unit. suppose figure 1 shows the fragments of a result of query texas apparel. if we choose the fragment between keyword matches in the corresponding xml document as the snippet of this query result  just as what a text search engine does  the users will not be able to see that both matches are nested in the tag retailer  and thus not able to easily understand that this query result is about an apparel retailer in texas  rather than a book discussing the popular apparel styles in texas .

figure 1: part of a query result of query texas apparel retailer and statistics about value occurrences.모to illustrate other goals  let us look at a different query texas apparel retailer as the running example. as snippet generation  whose inputs are the user query and a query result  is independent of query result generation  we omit the description of source data and the query result generation techniques in this paper  and only show the fragments of a sample query result in figure 1. some statistics of the full query result are presented at the right portion in the figure  where for each distinct name-value pair  we record the number of its occurrences in the query result. for instance 
 city: houston: 1  indicates that there are 1 occurrences of houston as a value of node city in the query result. values with low occurrences are omitted.
모the second goal of snippets is to allow users to easily distinguish different query results from each other. to achieve this in text document search  result snippets often include the document titles. analogously  we propose to select the unique identifier  aka. key  of a query result into its snippet to identify this query result and highlight the fundamental differences among results. however  it is not clear how to identify the key of a query result. intuitively  a node in a query result is a key if the values of the nodes with the same name are all distinct in all the query results. a plausible solution would use such nodes as the key of a query result. according to this  the name of a store could be considered as a key of the results of query texas apparel retailer. nevertheless  using the names of the stores as the key of a query result is unlikely to be reasonable  as the user searches for retailer  which can have hundreds of stores.
모the third goal is to design snippets that provide a representative summary of the query result by including the most prominent features in the result. intuitively  a prominent feature is often reflected by a large number of occurrences of such a feature in the result. continuing our example  suppose brook brothers has 1 clothes of different styles  among which 1 are for men and 1 for children. therefore including clothes of style men instead of children in the snippet shows a prominent feature of this query result: this retailer targets clothes for men. however  the relationship between the prominence of a feature and the number of occurrences is not always reliable. in our example  the number of occurrences of houston: 1  is much less than that of children: 1. however  considering that the majority of brook brothers stores are in houston in the query result  houston should be considered as a prominent feature. the challenge is how to capture the prominent features from various data values in an xml query result tree.

figure 1: a snippet of the query result in figure 1
모the three goals discussed above address the requirements on the semantics of a result snippet. clearly the larger a snippet is  then the more information it has  the better it can meet these goals. a trivial solution to generate snippets that meet these goals could be using the query result itself as a snippet. nevertheless  this is obviously undesirable. the last goal specifies a conflicting requirement: a snippet should be small so that a user can quickly and efficiently browse and understand snippets of several query results. therefore the challenge is how to provide as much information as possible in a snippet to meet the first three goals within an upper bound of the snippet size.
모in this paper we present a system extract which addresses the important yet open problem of generating effective snippets for xml search results. we identify that a good xml result snippet should be a self-contained information unit of a bounded size that effectively summarizes the query result and differentiates itself from others. to achieve this  we first analyze the semantics of the query result. we discover entities in a query result  whose names can effectively describe the snippet and thus make it self-contained. we then identify the key and dominant features of a query result  based on which a snippet information list is generated  which contains the most significant information in the query result that should be selected into the snippet. finally  we need to select as many items in the information list as possible given an upper bound of the snippet size. however  we show that this problem is np-complete. finally a novel algorithm is proposed that efficiently generates semantic snippets with a given size bound for xml search.
모as an illustration  the snippet for the query result in figure 1 is shown in figure 1. it captures the heart of the query result in a small tree: the query result is about retailer brook brothers  which has many stores in houston and features casual clothing for men and women  especially suits and outwears.
the contributions of our work include:
  this is the first work that studies the problem of generating query result snippets for xml search.
  we identify four goals that a good query result snippet should meet in order to help users quickly get the essence of a query result and assess its relevance.
  to address the goals  we identify the significant information in a query result to be selected into the snippet.
  we prove that the decision problem of whether we can construct a snippet of a given size limit that contains all the significant information is np-complete.
  we design an efficient algorithm to generate snippets that capture the identified significant information given the snippet size limit.
  a system for generating snippet for xml search has been implemented and tested for its efficiency and effectiveness through experimental studies.
모the rest of paper is organized as follows: section 1 presents how to meet the first three goals in generating meaningful snippets. section 1 discusses the additional challenge for meeting the fourth goal. experimental studies are presented in section 1. section 1 discusses related work and section 1 concludes the paper.
1. identifying significant information in query results
모we have discussed the four goals in generating result snippets for xml search and the challenges to achieve them. in this section we discuss how to tackle the challenges to meet the first three goals  such that the most significant information in a query result to be selected in its snippet is identified. we start with preliminaries on some notations.
1 preliminaries
모we model xml data d as a rooted  labeled  unordered tree. every internal node in the tree is labeled with a name  and every leaf node is labeled with a data value. in figure 1  we use subscripts to distinguish nodes with the same label.
모a query result r q d  of a keyword query q on xml data d is an xml tree  whose nodes and edges are extracted from d.
a snippet s r q  of a query result r q d  is an xml
tree  whose nodes and edges are extracted from r.
모we define a snippet information list  denoted as ilist r q   which contains the most significant information in a query result that a snippet should include to meet the first three goals. we initialize this list with the keywords  as shown in the first step in figure 1  since their matches should be included in the snippet. in the next several subsections we discuss what other items should be added to the list in order to make the snippet self-contained  distinguishable  and representative.
1 self-contained snippets
모goal 1: a query result snippet should be self-contained so that the user can understand it.
모in text search  due to the inherent ambiguity  multi-meaning  of words  providing the context of the keyword matches helps users to judge the relevance of query results. users prefer result snippets that are one or more windows on the document containing the complete phrases/sentences where the keyword matches appear because they are self-contained and can be easily read .
모analogously  an xml result snippet should also be selfcontained. as discussed in section 1  windows on an xml document where the keyword matches appear are in general not self-contained. xml data may not contain complete phrases/sentences  but use a tree structure  i.e. nested mark-ups  to provide the context information. it is not obvious what is the counterpart in xml data for complete phrase/sentences in text document  which functions as basic semantic units.
모to identify basic semantic units  we analyze that an xml database contains information about real-world entities with associated attributes as well as their relationships. an entity represents a basic semantic information unit. we adopt the approach in  that leverages the xml data structure to classify xml nodes into three categories: entities  attributes  and connection nodes. other classification approaches can also be used.
definition 1: a node represents an entity if it corresponds to a *-node in dtd. if a node is not a *-node and only has one child which is a data value  then this node  together with its value child  represents an attribute 1. a node is a connection node if it represents neither an entity nor an attribute.
definition 1: an attribute is associated with an entity e  if e is the nearest ancestor entity of a.
모for example  in the query result in figure 1  retailer  store and clothes are considered as entities  assuming each is a *-node in the dtd of the xml data . fitting  situation and category  together with their values  are considered as attributes associated the clothes entity. merchandises is a connection node.
모a self-contained xml result snippet should contain the names of the entities involved in the query result as context information  even though names of such entities may not necessarily appear between two keyword matches in the xml document.
example 1: in our sample query result in figure 1  entity names retailer  store and clothes should therefore be added to the snippet information list ilist  as shown in step 1 in figure 1.

1 in the rest of the paper  attribute refers to the concept in an entity-relationship model  rather than the one defined in xml specification.
ilist:      texas  apparel  retailer  store  clothes  brook brothers  houston  outwear  men  casual  suit  women weight:       1           1           1          1          1                 1                         1 1 1 1 1 1
	|                        step 1                       | |             step 1            | |             step 1      	| |                                                  step 1                                                 |
	keywords	entity names 	key of query result 	dominant features
	goal 1	goal 1	goal 1
figure 1: ilist of the query result in figure 1.1 distinguishable snippets
모goal 1: a snippet should make the corresponding query result distinguishable from  the snippets of  other query results such that the users can differentiate them with little effort.
모as discussed in section 1  we propose to select the key of a query result into its snippet  reminiscent to the document title in result snippets in text document search  such that a query result can be identified and differentiated from other results.
모however  it is not obvious how to identify the key of a query result. if the values of the nodes with the same name are all distinct in all the query results  then such node name can be considered as a key. as we have discussed in section 1  a query result may contain several entities along with their attributes. therefore a key should be associated with an entity. then the question is which entities' keys should be considered as the key of the query result. to answer this question  we observe that different entities play different roles in a query result. intuitively  each query has a search goal. the search goal can be used to classify the entities in a query result into two categories.
1. return entities are what the users are looking for when issuing the query.
1. supporting entities are used to describe the return entities in a query result.
모for example  the goal of query texas apparel retailer is likely to be searching for the retailer of apparel in texas state. therefore retailer should be considered as the return entity of this query. on the other hand  store and clothes in the query result are likely to be supporting entities  which are used to describe the return entities.
모since return entities are the core of a query result  their keys can function as the key of the query result and can be used to differentiate this query result from others. indeed there are often too many differences between two query results. the differences among their return entities best reflect the fundamental differences among query results with respect to the users' search goal. the keys of the return entities identify the return entities  and thus can identify the corresponding query result and highlight the semantic differences among query results concisely. in our example query texas apparel retailer  it is reasonable and concise to use the key of the return entity: retailer's name rather than the keys of supporting entities  say store's name  or other attributes  to differentiate query results.
모now the remaining question is how to identify these two types of entities in a query result. there could be many heuristics  and we propose the one in definition 1.
definition 1: an entity in a query result is a return entity if its name matches a query keyword or its attribute name matches a keyword. if there is no such entity  that is  no keyword matches node names  then we use the highest entity  i.e. entities that do not have ancestor entities  in the query result as the default return entity.
모for example  for query casual outwear  there is no keyword matching a node name. assuming a result of this query is a smallest xml tree that contains both keywords  then entity clothes is considered as the return entity.
example 1: in our running example  for query texas apparel retailer  entity retailer matches a keyword  and therefore is considered as a return entity  corresponding to the user's search goal. the key attribute of retailer: name is considered the key of this query result  and is added to the snippet information list. the current ilist comprises the first three steps in figure 1.
모the key of xml nodes can be directly obtained from the schema of xml data  if available  specified as id or key node. otherwise  we find the most selective attribute of the return entity and use it as the key. specifically  for all query results  we find the attribute of the return entity that has the fewest duplicate values.
1 representative snippets
모goal 1: a snippet should be representative of the query result  so that the users can grasp the essence of the result from its snippet.
모similar to text document search  a snippet should provide a summary of the query result. since there can be a lot of information in a query result  a good summary should be concentrated on the most prominent ones referred as dominant features.
모we define a feature as a triplet  entity name e  attribute name a  attribute value v . for example  store  city  houston  is a feature. the pair  entity name e  attribute name a  is referred as the type of a feature  and attribute value v is referred as the value of a feature. note that the entity name is taken into account because different entities may share the same attribute names. for example  both retailer and store have attribute name. for presentation purpose  we refer a feature by its value when there is no ambiguity.
모as discussed in section 1  a dominant feature of a query result is often reflected by a large number of occurrences of the feature in the result. for example  the fact that there are more clothes for men than children in the query result indicates that brook brothers is specialized for men instead of children clothes.
모however  the relationship between the dominance of a feature and the number of occurrences is not reliable due to two reasons. first  different features have different domain sizes. the domain size of a feature type  e a  is defined as the number of distinct values  e a v  of this type  denoted as d e a . the smaller size a domain has  the more chances for a value to have more occurrences in the result.
for example  the number of occurrences of outwear: 1  is less than that of women: 1. however  considering the domain sizes of their corresponding feature types in the query result: d clothes  category  = 1  d clothes  fitting  = 1  outwear could be more dominant than women in their respective domains.
모second  due to the tree structure of xml data  different features have different total number of occurrences in the query result  denoted as n e a . the more occurrences of a feature type  the more chances that a value of this feature type to occur. for example  a value houston only occurs 1 times  while children occurs 1 times in the query result. however  considering the number of occurrences of their corresponding feature types: n store  city  = 1  n clothes  fitting  = 1  houston is likely to be more dominant than children.
모as observed from these examples  comparing the number of occurrences of values of different feature types may not make sense in determining dominant features. to quantify the above intuition  we propose to use normalized frequency  called dominance score  to measure the significance of a feature in a query result.
definition 1: we define dominance score of a feature f =  e a v  as follows:
n e a v 
	ds f r  =	n e a 	 1 

d e a 
모where r is a query result  n x  denotes the number of occurrences of x in r  d e a  denotes the domain size of  e a  in r.
모a feature is dominant if its dominance score is larger than 1  in other words  its number of occurrences is more than the average number of occurrences of the feature values of the same type: n e a /d e a . there is one exception: if the domain size is 1  d e a  = 1  then there is only one feature value of this type  which is trivially considered to be dominant even though its dominance score is 1.
definition 1: a feature f is dominant in a query result r if one of the following holds:  a  ds f r    1 if d e a    1; or  b  ds f r  = 1 if d e a  = 1.
모we include dominant features into the snippet information list in the decreasing order of their dominance scores.
example 1: continuing our example  we compute the dominance scores for features in the query results. in the following the corresponding feature types are omitted for conciseness.
ds houston  = 1 /  1 / 1  = 1
ds men  = 1 /  1 / 1  = 1
ds women  = 1 / 1 / 1  = 1 similarly  we get ds casual  = 1  ds outwear  = 1  and ds suit  = 1.
모we add the dominant features into the snippet information list  which now contains the items in all four steps in figure 1.
모since the dominant features of a query result provide a good summary of the result  together with the key of the result they can help user distinguish different query results.
1 algorithm for snippet information list construction
모as have been discussed  the snippet information list ilist contains the following four components in order. each item in the list is referred as an informative item.
1. keywords;
1. the names of the entities in the query result  contributing to self-contained snippets;
1. the key of the query result  reflected by the keys of thereturn entities  contributing to distinguishable snippets;
1. an ordered list of dominant features contributing torepresentative snippets.
모the snippet information list can be generated during a pre-order traversal of the query result  as shown in algorithm 1. we use e  a and v to denote the last entity name  attribute name and attribute value that have been encountered during the traversal  respectively. first  we add the keywords into ilist  line 1 . for each node n visited in the traversal  if n is an entity  we set e as n.name  line 1   and add it to ilist if it is not already in it  line 1 . we consider e as a return entity if e matches a keyword  line 1 . if n is an attribute name  we set a as n.name  line 1   and increase the number of occurrences of feature type  e a   line 1 . if a matches a keyword  entity e is considered as a return entity  line 1 . if n is an attribute value  we set v as n.value  line 1   increase the number of occurrences of feature  e a v   line 1  and increase the domain size of feature type  e a  if feature  e a v  has not appeared before  line 1 . then we add the key attribute values of the return entities as well as all dominant features into ilist  line 1 . at last  we sort the dominant features in ilist according to their dominance scores  line 1 .
모now we analyze the time complexity of algorithm 1. a hash index was built off-line on the xml data  which takes an input of a node id and returns the information about this node  such as node type  entity  attribute  or connection node  and key values  if exists . hash indexes are also built to access n e a   d e a  and n e a v  in o 1 . therefore the cost of traversing the query result  line 1  is bounded by the size of the query result  o |qr| . since the number of dominant features is bounded by |qr|  computing their dominance scores  line 1  also takes o |qr|  time. sorting ilist  line 1  takes o |l|log|l|   where |l| is the size of ilist. therefore  the complexity of algorithm 1 is o |qr| + |l|log|l| .
모in the following section  we discuss how to extract data nodes from the query result to capture the items in the list as much as possible.
1. generating small and meaningful result snippets
모we have discussed how to identify the snippet information list for a query result  which contributes to a self-contained  representative and distinguishable snippet. besides the requirements on the semantics  we also need to meet a conflicting goal on snippet size.
모goal 1: a query result snippet should be small so that the user can quickly browse several snippets.
algorithm 1 construction of snippet information list

constructilist  qr  q 
1: ilist =  
1: returnentity =  
1: ilist = ilist 뫋 q
1: for each node n in a pre-order traversal of qr do
1:	if n is an entity then
1:	e = n.name
1:	if e /뫍 ilist then
1:	ilist = ilist 뫋{e}
1:	if e matches a keyword then
1:	returnentity = returnentity 뫋{e}
1:	else if n is an attribute name then
1:if a matches a keyword then1:returnentity = returnentity 뫋{e}1:
1:
1:	else if	then
1:
1:	n e a v  + +
1:	if triplet  e a v  has not appeared before then
1:	d e a  + +
1: ilist	=	ilist 뫋 the set of key attribute values of returnentity
1: for each feature f =  e a v  do
1:	calculate ds f qr  using eq.  1  do
1: sort all features in ilist by dominance score
1: return ilist

 
figure 1: reduction from set cover
1 problem definition
모the challenge is given an upper bound on the size  how to include as many items in the snippet information list as possible into the snippet to make it maximally informative. recall that an informative item in the list  such as a keyword and a dominant feature value  can have multiple occurrences in the query result. although the instances of the same informative item are not distinguishable in terms of semantics  different instances have different impacts on the size of the snippet. to include an instance of an informative item in a tree-structured snippet  we need to add a path to the snippet from its nearest ancestor in the query result that is already in the snippet to this node. therefore we should carefully select instances such that they are close to each other in order to capture as many informative items as possible given the size limit of the snippet. for example  considering the instance of houston  to capture informative item outwear  choosing instance outwear1 results in a smaller snippet tree compared with outwear1.
모however  the problem of maximizing the number of informative items selected in a snippet given the snippet size upper bound is hard. we prove that its decision problem is np-complete as follows.
definition 1: for an xml tree t  let label u  be the label
of node u 뫍 t  and label t  = s label u  | u 뫍 t . the tree size |t| is the number of edges in t. we use a boolean cont t v  to denote whether tree t contains a label v.
모given an xml tree t  an integer c  and a set p of labels v  v 뫍 label t   the instance selection problem is to find t's subtree t뫣  such that |t뫣| 1 c  and  v 뫍 p  cont t v  = true.
모the problem can be illustrated as: given a tree t  a set of labels p and a size bound c  whether it is possible to find a subtree t뫣 of t  such that t뫣 contain every label in p and has a size no more than c.
theorem 1: instance selection problem is np-complete.
모proof. it is easy to see that this problem is in np. given a t's subtree t뫣  we can check in polynomial time whether |t뫣| 1 c  and  v 뫍 p  cont t v  = true.
모now we prove that it is np-complete by reducing the set cover problem to it  set cover 뫞p instance selection. recall the set cover is the following problem: given a universe u = {a1 a1 ... an}  a collection c of m subsets si   u 1 i 1 m  and an integer k  can we select a collection c뫣 of at most k subset in c  whose union is u  i.e.  s s | s 뫍 c뫣  = u 
모for any instance of set cover  we construct a tree as shown in figure 1. for each si 뫍 c  we construct a node ei  whose parent is root. let the j-th element in si be aij. for each aij  we create a node aij with value aij as a child of ei. except leaf nodes  no node label is the same as an element in u. for every ai 뫍 u  we have a corresponding label ai and let p denote the set of such labels. let c = k + 1|u|. this transformation takes polynomial time. next we show that this transformation is a reduction: the set cover problem can be answered if and only if this constructed instance selection problem can be answered.
모given an answer to set cover  we obtain t's subtree t뫣 as follows:  si 뫍 c뫣  we select ei and a subset of its children  such that every element ai 뫍 u has exactly one leaf node in t with value ai selected. such leaves along with their ancestors up to the root compose t뫣. now we have  a 뫍 p  cont t뫣 a  = true  and |t뫣| 1 k +1|u| = c. t뫣 is an answer to the instance selection problem.
모given an answer to the instance selection problem t뫣  |t뫣| 1 c and  a 뫍 p  cont t뫣 a  = true. let r denote the set of nodes ei in t뫣. 1|u| + |r| 1 |t뫣| 1 c  therefore |r| 1 c   1|u| = k. let c뫣 be the collection of set si  such that ei 뫍 r. the union of si is u and |c뫣| = |r| 1 k  therefore c뫣 is an answer to the set cover problem.
1 algorithm for instance selection
모as has been shown  the decision problem of instance selection is np-complete. however  snippet generation must be efficient as web users are often impatient. we propose a greedy algorithm that efficiently selects instances of informative items in generating a meaningful and informative snippet for each query result given an upper bound on size. there are several challenges in instance selection. first  xml nodes interact with each other. selecting each individual node in isolation can result in a large snippet. second  the cost associated with a node  measured by the number of edges to be added to the snippet if this node is selected  changes dynamically during the selection procedure. third  due to dynamic costs of node selection  we are not able to
determine the number of informative items that can be cov-
ered till the very end.
모next we discuss how to address these challenges  by effectively determining the data unit for selection  measuring the benefit and cost of each selection  and designing an efficient instance selection algorithm.
모since informative items in the information list have different priorities  we assign weights to these items. though we know that the items will be selected in the order of their appearance in the information list until the snippet size limit is reached  we are not able to determine the number of items to be selected beforehand. note that an item in the list should not be considered before all its precedents are chosen to be in the snippet  otherwise the dominance of different features of the query result can not be faithfully reflected in the snippet. based on this  we assign the weights to the items in the list to reflect the higher importance of the items that appear earlier in the list. specifically  the weight of an item is half of the weight of its previous one. for the first several items that are keywords or names of the entities involved in the query result  each is assigned a weight of 1. it is easy to see that such a weighting scheme satisfies the requirement: an item is more important to be selected than all the items after it in the list combined together  as an item must be included in the snippet before any of its successors is included.
example 1: the weight of each item in the snippet information list for the example is annotated below the items in figure 1. note that all keywords and entity names have the highest weight of 1.
entity path based selection. for an instance of an informative item to be selected into the snippet  we need to include the path from the closest ancestor of this node that is in the current snippet to the node. we thus make the selections based on paths instead of nodes  which makes the selection procedure more efficient as fewer data units need to be considered for selection. one solution would consider each root-to-leaf path in the query result tree as a data unit for selection in determining which one to be included in the snippet. however  each path often only contains an instance of a single informative item  as most of the informative items are feature values  which are leaf nodes. therefore each selection is still based on individual informative item covering without considering possible interaction among them.
모we consider entity-based paths as data units for selection. we use leaf entity to refer to the entities that do not have descendant entities. an entity path consists of a path from the closest ancestor of a leaf entity in the query result that is currently included in the snippet  to the leaf entity  along with all the attributes of the entities on the path. if a node instance of an informative item itself or its associated entity is on an entity path  then we say this informative item is covered by the path.
example 1: to concisely illustrate our algorithm  here we only present how to choose from the paths in the query result fragment shown in figure 1  although there are many paths in the query result  based on which the ilist in figure 1 is computed. there are five leaf entities in the figure  all of which are clothes entity. therefore there are five entity paths  each of which is from retailer to a clothes algorithm 1 instance selection of snippet information list

selectinstance  qr ilist sizelimit 
1: init qr 
1: snippet =  
1: sizelimitexceeded = false
1: currsize = 1: repeat1:v = the next item in ilist to be included in snippet1:if v is already covered then1:add the covered instance of v to snippet if it is not in snippet yet1:currsize += number of edges added to snippet1:else1:find the path p with the highest  benefit/cost  that covers v1:add the shortest prefix p뫣 of p to snippet  such that p뫣 covers v1:currsize += number of edges added to snippet1:if p뫣 = p then1:p.benefit = 1:for each path p뫣뫣 that share a prefix with p뫣 do1:p뫣뫣.cost -= length of common prefix of p뫣 and p뫣뫣1:for each item v뫣 in ilist covered by p뫣 do1:put a mark on v뫣 to denote that v뫣 has been covered1:for each path p뫣뫣 that covers v뫣 do1:p뫣뫣.benefit -= weight of v뫣 in ilist1:if currsize   sizelimit then1:remove all nodes added to snippet in this iteration1:	sizelimitexceeded = true
1: until all items in ilist are selected in snippet or sizelimitexceeded = true 1: return snippet init  qr 
1: qrroot.anccover = the informative items covered by the root of qr if it is an entity
1: for each entity n in the depth-first traversal of qr do
1: n뫣 = the nearest ancestor entity of n in qr  and if it does not exist  qrroot
1: n.anccover = n뫣.anccover뫋 the informative items covered by n
1:	if n is a leaf entity then
1:	p = the path from qrroot to n
1:	p.benefit = the sum of weights of the items in
n.anccover
1:	p.cost = number of edges on the path from qrroot to n

node. we use p1 - p1 to denote the path from retailer to clothes1 - clothes1 respectively.
benefit-cost of an entity path. to decide which path to select  we choose the one that has the maximal benefit-cost ratio. the cost of selecting a path p p.cost  is the number of edges to be added into the snippet tree when selecting p. initially  p.cost is the number of nodes on p.
모the benefit of selecting path p  p.benefit  is the summation of the weights of all the informative items covered by this path. p.benefit is initialized during a depth first traversal of the query result  as presented in procedure init in algorithm 1. for each node n in the query result  we use n.anccover to denote the set of the informative items covered if n is selected. note that if n is selected  then all its ancestors in path p will be included in the snippet  therefore n.anccover = n뫣.anccover 뫋 v   where n뫣 is the parent of n  and v is the set of informative items that are covered by n's label and its attributes  if exists . we set p.cover = n.anccover  where n is the leaf entity of p.
example 1: take the path p1 from retailer to clothes1 for example. p1 covers informative items texas  apparel  retailer  store  clothes  brook brothers  houston  men  casual  and suit  thus p1.benefit is the summation of their weights  1 + 1 + 1 + 1 +1 + 1 + 1 + 1 +
1 + 1 뫘 1. similarly  benefit of the paths p1  p1  p1 and p1 are initialized to be 1  1  1  1 respectively. the cost of all paths is 1 initially.
path selections and benefit-cost updates. the algorithm for selecting informative items is presented in procedure selectinstance in algorithm 1. for a query  each of its query results qr  an upper bound of the snippet size sizelimit and its information list ilist  we generate a snippet. initially  the snippet is empty. we process the items in ilist one by one in order  and select an entity path in the query result that can cover this item with maximal benefitcost into a snippet  till all the items are covered in the snippet or the upper bound of snippet size is reached.
모at each step  let v be the current item being considered. if an instance of v is already included in the snippet  nothing needs to be done. if its associated entity is included in the snippet  it can be easily added into the snippet by adding the path from the associated entity to itself to the snippet  line 1 . for example  if we want to include an instance of item outwear in the snippet  and entity clothes1 is already in the snippet  we simply add the path from clothes1 to outwear1 without choosing another entity path that covers outwear  and therefore has a minimal cost.
모otherwise  we need to choose a new entity path to cover the current informative item v. for all entity paths covering v  we choose the one p that has the best cost-benefit p.benefit/p.cost to the snippet  line 1 . notice that for a chosen entity path  we only need to add its shortest prefix p뫣 to cover the current informative item. if p뫣 is a proper prefix of p  then p will not be removed from the entity path lists  but has its cost adjusted  as to be discussed soon; otherwise p can be disregarded.
example 1: the running example is continued here. we start with the first informative item in the list texas. since all five entity paths cover it  we choose the one with the highest benefit/cost  which is p1. in fact  we only need to add a prefix of p1  from entity retailer to entity store1  together with their associated attributes into the snippet to cover texas.
모after an entity path p뫣 is added to the snippet  we need to update the information list  the cost and benefit of affected paths  according to the following.
모first  for each item in ilist that is covered by p뫣  we put a mark on it  denoting that it has been covered  line 1 . if one of these items is encountered in future  it has a node instance that can be added to the snippet with the low cost  i.e.  the number of nodes from this instance to its associated entity  or zero if it is already in the snippet   without the need of choosing another entity path.
모second  we update the costs of the affected entity paths. for each entity path p뫣뫣 that has a common prefix with p뫣  including p itself  its cost is decreased by the length of the common prefix.
모to efficiently calculate the length  we assign each xml node a dewey label  as a unique id. a dewey id is composed of integers concatenated by dots. the dewey id of a node contains in order the dewey id of its parent  a dot  and one more integer denoting the position of this node among its siblings. the dewey id of the root is 1. for example  the nodes on the path from retailer to texas1 in figure 1 should have dewey ids 1  1  1.1  1.1  respectively.
모the length of the common prefix of two entity paths can now be easily calculated as the length of the common prefix of the dewey ids of the leaf entities of p뫣 and p뫣뫣  line 1 . to efficiently identify these affected paths  we sort all entity paths by the dewey id of their leaf entities in a list. for the first node n in path p뫣  we find the first and the last path in the entity path list whose leaf entity is a descendant of n  using a binary search. each of the paths in the entity path list between them has a common prefix with p뫣.
모at last  we need to update the benefits of the affected entity paths. for each entity path p뫣뫣 that covers an item which is already covered by p뫣  its benefit p뫣뫣.benefit is decreased by the weight of the corresponding item  for all the commonly covered items of p뫣뫣 and p뫣  line 1 .
모after an instance of the current informative item v in ilist is included into the snippet  we need to check whether the snippet exceeds the size limit. if so  we must remove the nodes that were added into the snippet in this iteration  line 1   and set the flag that no more nodes need to be added into the snippet as its size limit is reached  line 1 .
example 1: continuing the running example  after selecting the highest benefit-cost entity path p1 to cover item texas  we include its prefix from retailer to store1 to the snippet  and perform the following updates. first  we annotate in the ilist that the informative items apparel  retailer  store  brook brothers and houston are covered. second  we update the costs of affected path. since paths p1  p1 and p1 have a common prefix with the path included in the snippet  their costs are decreased by the length of this common prefix. now the costs of the updated entity paths p1  p1  and p1 are all 1.
we also update the benefits of the affected paths. since
texas  apparel  retailer  store  brook brothers and houston are all considered to be covered by the first selected path  the benefits of the paths that cover these informative items need to be subtracted accordingly. specifically  since p1  p1 and p1 originally cover the above six items  each of their benefits is subtracted by the sum of these items' weights: 1. p1 and p1 cover the first five items in the above list  and each has its benefit subtracted by 1.
모now  the next uncovered item in ilist is clothes. we choose the path that covers it and has the highest benefitcost  hence p1  which is from merchandises1 to clothes1. now p1 is removed from the entity path list  as the entire path is included in the snippet. now besides clothes  item outwear  casual and women in ilist are also marked as covered. the cost of p1 and p1 is now reduced to 1. for each path that covers clothes  i.e.  p1  p1  p1 and p1  its benefit is reduced by the weight of clothes: 1. for the paths that cover outwear: p1  we subtract its benefit by 1. we also subtract the weight of casual from the benefits of p1 and p1  and subtract the weight of women from the benefit of p1. we cover the items in ilist one by one in this manner. suppose the size limit of the snippet allows us to include all the items in the ilist in figure 1 into the snippet  the final snippet is presented in figure 1.
to efficiently select the entity path to cover the current
filmqf1films  hitchcock  paramountqf1films  hitchcockqf1easyvirtue  1qf1lifeboat  1qf1dram  filmsqf1  gb  famousqf1hitchcock  paramountqf1m  filmsretailerqr1store  formal store
retailer  texas  men store  texas
retailer  california  sportswear
store  houston
store  texas  menqr1retailer  apparel  store  philadelphia  formalfigure 1: data and query sets
item in the snippet information list and to perform updates after a selection  we build a bitmap index for a query result during a traversal. the path dimension has all the paths sorted by the dewey id of their leaf entities. the value dimension has all the distinct informative items in the order of their appearance in the query result. each entry b p v  in the index records whether an item v is covered by p  and if so  which node on p covers it. for each path p  we also record its benefit p.benefit and cost p.cost.
모now we analyze the complexity of the algorithm. let qr be the query result  p the set of all entity paths in qr  d the document depth  and |l| the size of ilist. to include one item v in the information list ilist into the snippet  the algorithm searches for the path with the best benefit-cost that covers v  line 1 in selectinstance  by traversing all the entries b p v   which entails a cost o |p| . after selecting the entity path p뫣  we update the cost of all the paths that share a prefix with p뫣  line 1 . finding such a path using binary search on the path list has a cost o log|p| . each of such paths has the cost updated according to dewey label prefix computation  which is bounded by d. the complexity of performing cost updates is o |p|d   as in the worst case all paths need to be updated. we also update the benefits of the affected paths. for each item v뫣 covered by p뫣  we reduce the benefits of the paths that cover v뫣 by traversing all entries b p뫣뫣 v뫣   line 1 . the complexity of performing benefit updates is o |l||p| . the total number of iterations is bounded by |l|  and the cost of adding nodes into the snippet is o |p|d . therefore  the total time complexity for instance selection is max{|l||p|d  |l|1|p|}.
1. experiments
모we have developed an effective and efficient snippet generation system for xml search: extract  which is available online at http://extract.asu.edu.1 we have evaluated extract on three metrics: quality of the snippets  processing time of snippet generation and scalability over the increase of query result size  as well as the upper bound of snippet size in terms of the number of edges in a tree.
모the experiments were performed on a 1 ghz pentium 1 machine  running windows xp  with 1gb memory and 1 gb hard disk.

1
 the web site also shows the snippets generated by google desktop as a reference.

figure 1: average scores of google desktop  optimal algorithm and greedy algorithm over all queries
모we have tested two data sets. film is an xml data set about the movie and director information.1 retailer is a synthetic data set that has the same schema and similar domains for node values as the one in figure 1  while the value of a node is randomly selected from its corresponding domain. for each data set we have tested eight queries  as shown in figure 1. for each query  a snippet size limit is randomly selected ranging from 1 to 1. the query results are generated using one of the existing keyword search approaches .
모since there is no existing snippet generation system designed for xml search in the literature  we compared our system with a popular text document search engine  google desktop. to focus the comparison on snippet generation instead of query result generation  we store each keyword query result generated by  as an xml file. then we issue the test query using google desktop on the corresponding xml file to obtain its result snippet.
모to evaluate our approach  we also implemented an algorithm which generates result snippets that maximally cover the items in the information list within a upper bound of the snippet size  referred as optimal algorithm. the optimal algorithm enumerates all possible combinations of instances of each item in the list with some pruning of the search space in order to find the optimal solution. in contrast  our approach uses algorithm 1 for instance selection and is referred as greedy algorithm. both optimal algorithm and greedy algorithm use algorithm 1 to generate the snippet information list for a query result.
1 snippet quality
모as there is no benchmark for evaluating the snippet quality for xml keyword search  we performed a user study. the quality test involves two parts: scoring snippets generated using three different approaches by users  and measuring the precision and recall of snippets based on the ground truth set by users. ten graduate students majoring in computer science who were not involved in our project were invited to participate in the user study in assessing the snippet quality.
assessment of snippets by scoring them. for each query result of the sixteen queries in figure 1  we use three approaches  greedy algorithm  optimal algorithm and google desktop  to generate snippets. since a query result may be large  the users are given the statistical information of each query result  like the one shown in figure 1  together with


	 a precision measurement	 b recall measurement
figure 1: precision and recall measurements1 http://infolab.stanford.edu/pub/movies its snippet. each user is asked to give a score for each snippet generated by each approach  respectively  on a scale of 1. the snippets are arranged in a random order for each query result without the information about its generation system. the evaluation result is shown in figure 1. the score for each algorithm shown in the figure is the average score of all the queries provided by all the users. as we can see  the score of our approach is close to that of the optimal approach  and is much better than that of google desktop. for most queries  our approach either generates the same snippet as the optimal approach  or misses one or two items in the snippet information list compared with the optimal algorithm  thus their scores are close. google desktop is a search engine designed for text documents. it does not generate the snippets as tree structures  but simply concatenates the values in the xml document and outputs a fragment of it. since google desktop has a low score for snippet generation on xml documents  we do not further compare with it in the experiments.
assessment of snippets by comparing with ground truth. to make a deep analysis of our approach  we have conducted user surveys to define ground truth for the snippet of a given query result. we found that it is extremely difficult for users  who may not have experience or background in xml  to decide which subtree in the query result should be the desired snippet. therefore  we asked the users to focus on the content  instead of the tree structure  in a query result. for each query result  each user is asked to provide a set of top k most important items in the query result  which they think should be included in the snippet. since this part of the user study requires a lot of effort from the users  we randomly choose four queries in figure 1 to perform this study. after collecting the set of items provided by each user  in order to get the ordered snippet information list  we combine the top-k items from all the users together to form a universal set. then we rank the items according to the numbers of their occurrences in the universal set  i.e.  the number of users who think that the item should be selected in the snippet. the list obtained in this way is considered as the ground truth of the snippet information list. since the optimal algorithm guarantees to find the optimal snippet with respect to a given snippet information list  we invoked the instance selection part of the optimal algorithm on each ground truth information list  whose result is considered as the ground truth snippet for the corresponding query result. based on the ground truth of the snippets  we assess the relevance of the snippets generated by greedy algorithm and optimal algorithm  both of which invokes algorithm 1 to generate the same snippet information list  where the number of dominant features is set to be k.
모figure 1 shows the quality assessment of the snippets produced by each approach. precision measures the percentage of the informative items output by an algorithm that are in the ground truth snippet. recall measures the percentage of the informative items in the ground truth snippet that are output by an algorithm.
모the first observation is that both approaches have a good precision and recall  which confirms the intuition of our approach. this is because the snippet information list that our algorithm generates is similar as the one given by the user study  especially the items that appear earlier in our list. therefore the snippets generated according to our information list  by optimal algorithm or greedy algorithm  has a high quality.
모on the other hand  the precisions and recalls of both algorithms are not perfect  mainly because the information list that we generate are often not the same as the ground truth. the main reason of these differences is that the user may care about interesting features of an entity  instead of/besides dominant features. take qr1  store  formal  for example. this query looks for the information of the stores selling formal clothes. to summarize a query result  our approach selects the most dominant features  such as the  fitting:men of the clothes  which is an attribute of most of the clothes sold by this store. however  users sometimes prefer having attributes of their own interest to be included in the snippet  even though their values may not be a dominant feature. for example  users may choose  brand:adidas  as an interesting feature to be included in the snippet  which might only appear in a few of the clothes.
모finally  we compare the optimal algorithm with the greedy algorithm. for test queries qr1  qr1  qf1  the precisions and recalls of these two algorithms are the same. in fact  the snippets generated by both algorithms for these queries are the same. recall that the optimal algorithm maximizes the number of items in the information list to be selected in the snippet. when the snippet size is small  the greedy algorithm can cover the same set of informative items. indeed  the upper bounds of the snippet size for the results of the above three queries  are 1  1 and 1  respectively. on the other hand  for qf1  which has an upper bound of 1 of the snippet size  the optimal approach selects more items in the information list into snippets and therefore achieves a better recall. in practice  when the snippet size is small  the greedy algorithm can achieve similar quality as the optimal algorithm.
1 processing time
t i
m e

qr1qr1qr1qr1qr1qr1qr1qr1t i
m e

qf1 qf1 qf1 qf1 qf1 qf1 qf1 qf1	 a queries on retailer data set	 b queries on film data set
figure 1: processing time on retailer and film data sets
t i
m e
t i
m e
  a size of query result  kb   b number of edges in snippet figure 1: scalability test on size of query result and number of edges모to evaluate the efficiency of our approach for generating result snippets  we test the processing times of the queries listed in figure 1. the processing times  comprising the time of generating ilist and selecting instances  of the greedy algorithm and the optimal algorithm are shown in figure 1. the sizes of the query results vary from 1kb to 1kb  and the snippet size limits vary from 1 to 1 edges. as we can see  the greedy algorithm is much faster than the optimal algorithm.
모both algorithms need to traverse the query result and construct an ordered snippet information list  in the same way. the difference lies in the cost of selecting instances of informative items in the list. the optimal algorithm searches for the optimal solution by enumerating possible combinations of instances to each item in the snippet information list  which leads to a cost exponential to the size of the information list. when the query result size or the snippet size limit is small  e.g. qf1 whose query result size is 1kb and snippet size limit is 1  and qf1 whose result size is 1kb and snippet size limit is 1   the processing times of both algorithms are small. however  when the query result size is relatively large  indicating a potentially large number of instances of each informative item  the difference between the processing times of these two approaches becomes significant  e.g. qr1 whose result size is 1k and snippet size limit is 1  and qf1 whose result size is 1k and snippet size is 1 .
1 scalability
모we test the scalability of our system on the film data set over two parameters: query result size and snippet size.
query result size. the scalability test with respect to query result size is shown in figure 1  a . a query result of qf1 is replicated between 1 and 1 times to make the size of query result increasingly larger each time. the upper bound for the snippet size is fixed to be 1. we have tested the performances of the optimal algorithm and the greed algorithm on these query results. as we can see  the processing time of the optimal algorithm grows very rapidly as the complexity of the optimal algorithm is high-order polynomial to the size of query result  the order of which is the size of the snippet information list. on the other hand  the processing time of the greedy algorithm grows slowly. for query result of 1kb  it only requires 1 second for snippet generation.
snippet size. in this test we evaluate the performance of the greedy algorithm and the optimal algorithm with respect to the increase of snippet size upper bound  while keeping the query result size to be 1kb. recall that when the snippet size increases  more items in the snippet information list can be included in the snippet  thus more nodes in the query result need to be processed in order to cover those items. the result in figure 1  b  shows that the processing time of the greedy algorithm increases much slower than that of the optimal algorithm  where the later has a time complexity exponential to the number of informative items to be output.
모in summary  experimental evaluation shows that the snippets generated by our algorithm for xml search has high quality  as reflected by a high score in user evaluations  and high precision and recall with respect to the user defined ground truth. the snippet generation is efficient for various queries  and scales well when the query result size and snippet size increase. compared with the optimal algorithm  our algorithm based on a greedy approach has a close quality in practice  and is much more efficient.
1. related work
모to the best of our knowledge  the research on result snippet generation is within the scope of keyword search on text documents. early search engines generated query-independent snippets  consisting of the first several bytes of the result document. such an approach is efficient but often ineffective. selecting sentences for inclusion in the summary based on the degree to which they match the keywords has become the state-of-the-art of query-biased result snippet generation for text documents  1  1  1  1 . commonly used metrics for sentence selection include whether the sentence is a heading or the first line of the document  the number of keywords and distinct keywords that appear in the sentence  etc. snippet generation considering implicit evidence observed from users' behaviors has also been studied . approaches for improving efficiency have been investigated . however  snippet generation techniques designed for text documents are unable to leverage the hierarchical structure of xml data  and therefore do not perform well  as observed in the user studies.
모there are many works on generating meaningful query results for xml keyword search by inferring the semantics from various perspectives. some works focus on identifying relevant keyword matches  1  1  1  1  1  1  1   some investigate in how to display query results  1  1 . as we have discussed  our work addresses the problem of result snippet generation  which takes as input the query results that can be produced by any of the existing xml keyword search engines  and generates meaningful yet small snippets.
모there are also many proposals on designing effective ranking schemes on xml search  including  1  1  1  1 . factors including the distance between keyword matches  term frequency  document frequency  links in the xml documents are explored. ranking for keyword search on relational databases and graphs have also been investigated  1  1 .  discusses how to order the attributes in a tuple to reflect its influence on the rank of this tuple. result snippet generation is orthogonal to ranking functions. due to the ambiguity of keyword search  no ranking scheme can be absolutely perfect and fit all users. the design principles of snippets are therefore independent to those of the ranking scheme  such that the users can make their own relevance judgement based on the snippets without being biased by the relevance assessment made by ranking schemes. ranking and snippets complement each other to help users find relevant results.
모xml data summarization has also been investigated   which uses a small amount of space to store the xml data while still achieving accurate results as much as possible for query processing. techniques are thus developed for data compression  e.g.  storing one instance of each distinct tag name with its number of occurrences  recording the frequency that a node name is nested in another node name  and the distribution of values using histograms  wavelets  etc. the goal of data summarization is for query processing efficiency and the data summary is often not user readable  while the goal of snippet generation is to provide meaningful snippets such that users can easily assess the relevance of the corresponding query results.
1. conclusions
모to the best of our knowledge  this is the first work that addresses the problem of generating result snippets for xml search. we identify four features of a good xml result snippet: self-contained  distinguishable  representative and small. to meet the first three requirements in generating semantically meaningful snippets  we identify the most significant information in the query result that should be selected into a snippet in a snippet information list. to satisfy the fourth requirements  we need to generate the snippet that is maximally informative with respect to this list given an upper bound of the snippet size. however  its decision problem is proven to be np-complete. finally  we have designed and implemented a novel algorithm to efficiently generate informative yet small snippets. we verified the effectiveness and efficiency of our approach through experiments.
1. acknowledgments
모this research was supported in part by nsf grant iis1 and iis-1.
1. repeatability assessment result
모all results except user study  figure 1 and 1  in this paper have been verified by the sigmod repeatability committee.
