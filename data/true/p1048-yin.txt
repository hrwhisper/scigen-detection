the world-wide web has become the most important information source for most of us. unfortunately  there is no guarantee for the correctness of information on the web. moreover  different web sites often provide conflicting information on a subject  such as different specifications for the same product. in this paper we propose a new problem called veracity  i.e.  conformity to truth  which studies how to find true facts from a large amount of conflicting information on many subjects that is provided by various web sites. we design a general framework for the veracity problem  and invent an algorithm called truthfinder  which utilizes the relationships between web sites and their information  i.e.  a web site is trustworthy if it provides many pieces of true information  and a piece of information is likely to be true if it is provided by many trustworthy web sites. our experiments show that truthfinder successfully finds true facts among conflicting information  and identifies trustworthy web sites better than the popular search engines.
categories and subject descriptors: h.1  database management : database applications - data mining general terms: algorithms.
keywords: data quality  web mining  link analysis.
1. introduction
﹛the world-wide web has become a necessary part of our lives  and might have become the most important information source for most people. everyday people retrieve all kinds of information from the web. for example  when shopping online  people find product specifications from web sites like amazon.com or shopzilla.com. when looking for inter-

 the work was supported in part by the u.s. national science foundation nsf iis-1/1 and nsf bdi1. any opinions  findings  and conclusions or recommendations expressed here are those of the authors and do not necessarily reflect the views of the funding agencies.  xiaoxin yin has joined google inc.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee.
kdd'1  august 1  1  san jose  california  usa.
copyright 1 acm 1-1-1/1 ...$1.
esting dvds  they get information and read movie reviews on web sites such as netflix.com or imdb.com.
﹛ is the world-wide web always trustable   unfortunately  the answer is  no . there is no guarantee for the correctness of information on the web. even worse  different web sites often provide conflicting information  as shown below.
example 1: authors of books. we tried to find out who wrote the book  rapid contextual design   isbn: 1 . we found many different sets of authors from different online bookstores  and we show several of them in table 1. from the image of the book cover we found that a1 books provides the most accurate information. in comparison  the information from powell's books is incomplete  and that from lakeside books is incorrect.
web siteauthorsa1 bookskaren holtzblatt  jessamyn burns wendell 
shelley woodpowell's booksholtzblatt  karencornwall booksholtzblatt-karen  wendell-jessamyn burns 
woodmellon's bookswendell  jessamynlakeside bookswendell  jessamynholtzblatt  karenwood  shelleyblackwell onlinewendell  jessamyn  holtzblatt  karen 
wood  shelleybarnes & noblekaren holtzblatt  jessamyn wendell  shelley woodtable 1: conflicting information about book authors
﹛the trustworthiness problem of the web has been realized by today's internet users. according to a survey on credibility of web sites  1% of internet users trust news web sites at least most of time  while this ratio is only 1% for web sites that sell products  and is merely 1% for blogs.
﹛there have been many studies on ranking web pages according to authority based on hyperlinks  such as authorityhub analysis   pagerank   and more general link-based analysis . but does authority or popularity of web sites lead to accuracy of information  the answer is unfortunately no. for example  according to our experiments the bookstores ranked on top by google  barnes & noble and powell's books  contain many errors on book author information  and some small bookstores  e.g.  a1 books  provide more accurate information.
﹛in this paper we propose a new problem called veracity problem  which is formulated as follows: given a large amount of conflicting information about many objects  which is provided by multiple web sites  or other types of information providers   how to discover the true fact about each object. we use the word  fact  to represent something that

﹛﹛﹛﹛﹛figure 1: input of truthfinder is claimed as a fact by some web site  and such a fact can be either true or false. there are often conflicting facts on the web  such as different sets of authors for a book. there are also many web sites  some of which are more trustworthy than some others. a fact is likely to be true if it is provided by trustworthy web sites  especially if by many of them . a web site is trustworthy if most facts it provides are true.
﹛because of this inter-dependency between facts and web sites  we choose an iterative computational method. at each iteration  the probabilities of facts being true and the trustworthiness of web sites are inferred from each other. this iterative procedure is rather different from authority-hub analysis . the first difference is in the definitions. the trustworthiness of a web site does not depend on how many facts it provides  but on the accuracy of those facts. nor can we compute the probability of a fact being true by adding up the trustworthiness of web sites providing it. these lead to non-linearity in computation. second and more importantly  different facts influence each other. for example  if a web site says a book is written by  jessamyn wendell   and another says  jessamyn burns wendell   then these two web sites actually support each other although they provide slightly different facts.
﹛in summary  we make three major contributions in this paper. first  we formulate the veracity problem about how to discover true facts from conflicting information. second  we propose a framework to solve this problem  by defining the trustworthiness of web sites  confidence of facts  and influences between facts. finally  we propose an algorithm called truthfinder for identifying true facts using iterative methods.
﹛the rest of the paper is organized as follows. we describe the problem in section 1  and propose the computational model in section 1. experimental results are presented in section 1  and we conclude this study in section 1.
1. problem definitions
﹛the input of truthfinder is a large number of facts about properties of a certain type of objects. the facts are provided by many web sites. there are usually multiple conflicting facts from different web sites for each object  and the goal of truthfinder is to identify the true fact among them. figure 1 shows a mini example dataset. each web site provides at most one fact for an object.
﹛we first introduce the two most important definitions in this paper  the confidence of facts and the trustworthiness of web sites.
﹛definition 1.  confidence of facts.  the confidence of a fact f  denoted by s f   is the probability of f being correct  according to the best of our knowledge.
﹛definition 1.  trustworthiness of web sites.  the trustworthiness of a web site w  denoted by t w   is the expected confidence of the facts provided by w.
industrial and government track short paper
﹛different facts about the same object may be conflicting. however  sometimes facts may be supportive to each other although they are slightly different. for example  one web site claims the author to be  jennifer widom  and another one claims  j. widom . if one of them is true  the other is also likely to be true.
﹛in order to represent such relationships  we propose the concept of implication between facts. the implication from fact f1 to f1  imp f1 ↙ f1   is f1's influence on f1's confidence  i.e.  how much f1's confidence should be increased  or decreased  according to f1's confidence. it is required that imp f1 ↙ f1  is a value between  1 and 1. a positive value indicates if f1 is correct  f1 is likely to be correct. while a negative value means if f1 is correct  f1 is likely to be wrong. the details about this will be described in section 1.1.
﹛please notice that the definition of implication is domain specific. when a user uses truthfinder on a certain domain  he should provide the definition of implication between facts. if in a domain the relationship between two facts is symmetric  and the definition of similarity is available  the user can define imp f1 ↙ f1  = sim f1 f1    basesim  where sim f1 f1  is the similarity between f1 and f1  and basesim is a threshold for similarity.
﹛based on common sense and our observations on real data  we have four basic heuristics that serve as the bases of our computational model.
heuristic 1: usually there is only one true fact for a property of an object.
heuristic 1: this true fact appears to be the same or similar on different web sites.
heuristic 1: the false facts on different web sites are less likely to be the same or similar.
heuristic 1: in a certain domain  a web site that provides mostly true facts for many objects will likely provide true facts for other objects.
1. computational model
﹛based on the above heuristics  we know if a fact is provided by many trustworthy web sites  it is likely to be true; if a fact is conflicting with the facts provided by many trustworthy web sites  it is unlikely to be true. on the other hand  a web site is trustworthy if it provides facts with high confidence. we can see that the web site trustworthiness and fact confidence are determined by each other  and we can use an iterative method to compute both. because true facts are more consistent than false facts  heuristic 1   it is likely that we can distinguish true facts from false ones at the end. in this section we discuss the computational model.
1 web site trustworthiness and fact confidence
﹛we first discuss how to infer web site trustworthiness and fact confidence from each other.
1.1 basic inference
﹛as defined in definition 1  the trustworthiness of a web site is just the expected confidence of facts it provides. for web site w  we compute its trustworthiness t w  by calculating the average confidence of facts provided by w.
	 	 1 
where f w  is the set of facts provided by w.
namedescriptiont w w而 w wf w wf s f f考 f f考  f fw f fo f fimp fj ↙ fk fj to fktable 1: variables and parameters of truthfinder
﹛in comparison  it is much more difficult to estimate the confidence of a fact. as shown in figure 1  the confidence of a fact f1 is determined by the web sites providing it  and other facts about the same object.
t w1  ↙而 w1 

figure 1: computing confidence of a fact
﹛let us first analyze the simple case where there is no related fact  and f1 is the only fact about object o1  i.e.  f1 does not exist in figure 1 . because f1 is provided by w1 and w1  if f1 is wrong  then both w1 and w1 are wrong. we first assume w1 and w1 are independent.  this is not true in many cases and we will compensate for it later.  thus the probability that both of them are wrong is  1   t w1   ﹞  1   t w1    and the probability that f1 is not wrong is 1    1   t w1   ﹞  1   t w1  . in general  if a fact f is the only fact about an object  then its confidence s f  can be computed as
	 	 1 
where w f  is the set of web sites providing f.
﹛in equation  1   1   t w  is usually quite small and multiplying many of them may lead to underflow. in order to facilitate computation and veracity exploration  we use logarithm and define the trustworthiness score of a web site as
	而 w  =  ln 1   t w  .	 1 
而 w  is between and 1 and +﹢  which better characterizes how accurate w is. for example  suppose there are two web sites w1 and w1 with trustworthiness t w1  = 1 and t w1  = 1. we can see that w1 is much more accurate than w1  but their trustworthiness do not differ much as t w1  = 1 ℅ t w1 . if we measure their accuracy with trustworthiness score  we will find 而 w1  = 1℅而 w1   which better represents the accuracy of web sites.
similarly  we define the confidence score of a fact as
	考 f  =  ln 1   s f  .	 1 
﹛a very useful property is that  the confidence score of a fact f is just the sum of the trustworthiness scores of web sites providing f. this is shown in the following lemma.
lemma 1.
	 	 1 
proof. according to equation  1  
.
take logarithm on both side and we have


1.1 influences between facts
﹛the above discussion shows how to compute the confidence of a fact that is the only fact about an object. however  there are usually many different facts about an object  such as f1 and f1 in figure 1   and these facts influence each other. suppose in figure 1 the implication from f1 to f1 is very high  e.g.  they are very similar . if f1 is provided by many trustworthy web sites  then f1 is also somehow supported by these web sites  and f1 should have reasonably high confidence. therefore  we should increase the confidence score of f1 according to the confidence score of f1  which is the sum of trustworthiness scores of web sites providing f1. we define the adjusted confidence score of a fact f as

老 is a parameter between 1 and 1  which controls the influence of related facts. we can see that 考  f  is the sum of confidence score of f and a portion of the confidence score of each related fact f multiplies the implication from f to f. please notice that 1 when f is conflicting with f.
﹛we can compute the confidence of f based on 考  f  in the same way as computing it based on 考 f   defined in equation  1  . we use s  f  to represent this confidence.
	s  f  = 1   e 考  f .	 1 
1.1 handling additional subtlety
﹛one problem with the above model is we have been assuming different web sites are independent with each other. this assumption is often incorrect because errors can be propagated between web sites. according to the definitions above  if a fact f is provided by five web sites with trustworthiness of 1  which is quite low   f will have confidence of 1! but actually some of the web sites may copy contents from others. in order to compensate for the problem of overly high confidence  we add a dampening factor 污 into equation  1   and redefine fact confidence as s  f  = 1   e 污﹞考  f   where 1   污   1.
﹛the second problem with our model is that  the confidence of a fact f can easily be negative if f is conflicting with some facts provided by trustworthy web sites  which makes 考  f    1 and s  f    1. this is unreasonable because even with negative evidences  there is still a chance that f is correct  so its confidence should still be above zero. therefore  we adopt the widely used logistic function   which is a variant of equation  1   as the final definition for fact confidence.
	.	 1 
when 污 ﹞ 考  f  is significantly greater than zero 
is very close to s  f  because .
when 污﹞考  f  is significantly less than zero  s f  is close to zero but remains positive  which is consistent with the real situation. equation  1  is also very similar to sigmoid function   which has been successfully used in various models in many fields.
1 iterative computation
﹛as described above  we can infer the web site trustworthiness if we know the fact confidence  and vice versa. as in authority-hub analysis  and pagerank   truthfinder adopts an iterative method to compute the trustworthiness of web sites and confidence of facts. initially  it has very little information about the web sites and the facts. at each iteration truthfinder tries to improve its knowledge about their trustworthiness and confidence  and it stops when the computation reaches a stable state.
﹛we choose the initial state in which all web sites have a uniform trustworthiness t1.  t1 is set to the estimated average trustworthiness  such as 1.  in each iteration  truthfinder first uses the web site trustworthiness to compute the fact confidence  and then recomputes the web site trustworthiness from the fact confidence. it stops iterating when it reaches a stable state. the stableness is measured by the change of the trustworthiness of all web sites  which is represented by a vector ↙ t . if ↙ t only changes a little after an iteration  measured by cosine similarity between the old and the new  ↙t    then truthfinder will stop.
1. empirical study
﹛in this section we present experiments on a real dataset  which shows the effectiveness of truthfinder. we compare it with a baseline approach called voting  which chooses the fact that is provided by most web sites. we also compare truthfinder with google by comparing the top web sites found by each of them.
﹛all experiments are performed on an intel pc with a 1ghz dual-core processor  1gb memory  running windows xp professional. all approaches are implemented using visual studio.net  c# . the two parameters in equation  1  are set as 老 = 1 and 污 = 1. the maximum difference between two iterations  汛  is set to 1%.
1 book authors dataset
﹛this dataset contains the authors of many books provided by many online bookstores. it contains 1 computer science books published by addison wesley  mcgraw hill  morgan kaufmann  or prentice hall. for each book  we use its isbn to search on www.abebooks.com  which returns the book information on different online bookstores that sell this
book. the dataset contains 1 bookstores  and 1 listings  i.e.  bookstore selling a book . on average each book has 1 different sets of authors.
industrial and government track short paper
﹛truthfinder performs iterative computation to find out the set of authors for each book. in order to test its accuracy  we randomly select 1 books and manually find out their authors. we find the image of each book  and use the authors on the book cover as the standard fact.
﹛we compare the set of authors found by truthfinder with the standard fact to compute the accuracy. for a certain book  suppose the standard fact contains x authors 
truthfinder indicates there are y authors  among which z authors belong to the standard fact. the accuracy of
truthfinder is defined as 
sometimes truthfinder provides partially correct facts.
for example  the standard set of authors for a book is  graeme
c. simsion and graham witt   and the authors found by truthfinder may be  graeme simsion and g. witt . we consider  graeme simsion  and  g. witt  as partial matches for  graeme c. simsion  and  graham witt   and give them partial scores. we assign different weights to different parts of persons' names. each author name has total weight 1  and the ratio between weights of last name  first name  and middle name is 1:1. for example   graeme simsion  will get a partial score of 1 because it omits the middle name of  graeme c. simsion . if the standard name has a full first or middle name  and truthfinder provides the correct initial  we give truthfinder half score. for example   g. witt  will get a score of 1 with respect to  graham witt   because the first name has weight 1  and the first initial  g.  gets half of the score.
﹛the implication between two sets of authors f1 and f1 is defined in a very similar way as the accuracy of f1 with respect to f1. one important observation is that many bookstores provide incomplete facts  such as only the first author. for example  if a web site w1 says a book is written by  jennifer widom   and another web site w1 says it is written by  jennifer widom and stefano ceri   then w1 actually supports w1 because w1 is probably providing partial fact. therefore  if fact f1 contains authors that are not in fact f1  then f1 is actually supported by f1. the implication from f1 to f1 is defined as follows. if f1 has x authors and f1 has y authors  and there are z shared ones  then

figure 1: accuracies of truthfinder and voting
﹛figure 1 shows the accuracies of truthfinder and voting. one can see that truthfinder is significantly more accurate than voting even at the first iteration  where all bookstores have the same trustworthiness. this is because truthfinder considers the implications between different facts about the same object  while voting does not. as truthfinder repeatedly computes the trustworthiness of bookstores and the confidence of facts  its accuracy increases to about 1% after the third iteration and remains stable. it takes truthfinder 1 seconds to pre-computes the implications between related facts  and 1 seconds to finish the four iterations. voting takes 1 seconds.

figure 1: relative changes of truthfinder
﹛figure 1 shows the relative change of the trustworthiness vector after each iteration  which is defined as one minus the cosine similarity of the old and new vectors. we can see
truthfinder converges in a steady speed. in table 1 we manually compare the results of voting  truthfinder  and the authors provided by barnes & noble on its web site. we list the number of books in which each approach makes each type of errors. please notice that one approach may make multiple errors for one book.
type of errorvotingtruthfinderbarnes
& noblecorrect11miss author s 11incomplete names11wrong first/middle names11has redundant names11add incorrect names11no information11table 1: compare the results of voting  truthfinder  and barnes & noble
﹛voting tends to miss authors because many bookstores only provide subsets of all authors. on the other hand 
truthfinder tends to consider facts with more authors as correct facts because of our definition of implication for book authors  and thus makes more mistakes of adding in incorrect names. one may think that the largest bookstores will provide accurate information  which is surprisingly untrue. table 1 shows barnes & noble has more errors than
voting and truthfinder on these 1 randomly selected books.
﹛finally  we perform an interesting experiment on finding trustworthy web sites. it is well known that google  or other search engines  is good at finding authoritative web sites. but do these web sites provide accurate information  to answer this question  we compare the online bookstores that are given highest ranks by google with the bookstores with highest trustworthiness found by truthfinder. we query google with  bookstore 1  and find all bookstores that exist in our dataset from the top 1 google results. the accuracy of each bookstore is tested on the 1 randomly selected books in the same way as we test the accuracy of truthfinder. we only consider bookstores that provide at least 1 of the 1 books.
truthfinderbookstoretrustworthiness#bookaccuracythesaintbookstore11.1mildredsbooks11.1alphacraze.com11.1marando.de
versandbuchhandlung11.1blackwell online11.1annex books11.1stratford books11.1movies with a smile11.1aha-buch11.1players quest11.1average accuracy1googlebookstoregoogle rank#bookaccuracybarnes & noble11powell's books11ecampus.com11average accuracy1table 1: compare the accuracies of top bookstores
by truthfinder and by google
table 1 shows the accuracy and number of books provided
 among the 1 books  of different bookstores. truthfinder can find bookstores that provide much more accurate information than the top bookstores found by google. truthfinder also finds some large trustworthy bookstores  such as a1 books  not among the top 1 shown in table 1  which provides 1 of 1 books with accuracy of 1. please notice that truthfinder uses no training data  and the testing data is manually created by reading the authors' names from book covers. therefore  we believe the results suggest that there may be better alternatives than google for finding accurate information on the web.
1. conclusions
﹛in this paper we introduce and formulate the veracity problem  which aims at resolving conflicting facts from multiple web sites  and finding the true facts among them. we propose truthfinder  an approach that utilizes the interdependency between web site trustworthiness and fact confidence to find trustable web sites and true facts. experiments show that truthfinder achieves high accuracy at finding true facts and at the same time identifies web sites that provide more accurate information.
