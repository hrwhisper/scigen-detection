in this paper  we consider the problem of producing balanced clusterings with respect to a submodular objective function. submodular objective functions occur frequently in many applications  and hence this problem is broadly applicable. we show that the results of patkar and narayanan  can be applied to cases when the submodular function is derived from a bipartite object-feature graph  and moreover  in this case we have an efficient flow based algorithm for finding local improvements. we show the effectiveness of this approach by applying it to the clustering of words in language models.
1	introduction
the clustering of objects/data is a very important problem found in many machine learning applications  often in other guises such as unsupervised learning  vector quantization  dimensionality reduction  image segmentation  etc. the clustering problem can be formalized as follows. given a finite set s  and a criterion function jk defined on all partitions of s into k parts  find a partition of s into k parts {s1 s1 ... sk} so that jk  {s1 s1 ... sk}  is maximized. the number of k-clusters for a size n   k data set is roughly kn/k!  so exhaustive search is not an efficient solution. in   it was shown that a broad class of criteria are submodular  defined below   which allows the application of recently discovered polynomial time algorithms for submodular function minimization to find the optimal clusters. submodularity  a formalization of the notion of diminishing returns  is a powerful way of modeling quality of clusterings that is rich enough to model many important criteria  including graph cuts  mdl  single linkage  etc. traditionally  clustering algorithms have relied on computing a distance function between pairs of objects  and hence are not directly capable of incorporating complicated measures of global quality of clusterings where the quality is not just a decomposable function of individual

모모  part of this work was done while this author was at the university of washington and was supported in part by a microsoft research fellowship.  
모모this work was supported in part by nsf grant iis-1 and an intel corporation grant.
distances. submodularity allows us to model these decomposable criteria  but also allows to model more complex criteria. however one problem with all of these criteria is that they can be quite sensitive to outliers. therefore algorithmswhich only optimize these criteria often produce imbalanced partitions in which some parts of the clustering are much smaller than others. we often wish to impose balance constraints  which attempt to tradeoffoptimizing jk with the balance constraints. in this paper we show that the results that patkar and narayanan  derived for graph cuts are broadly applicable to any submodular function  and can lead to efficient implementations for a broad class of functions that are based of bipartite adjacency. we apply this for clustering words in language models.
1	preliminaries and prior work
let v be a ground set. a function 붞 : 1v 뫸 r  defined on all subsets of v is said to be increasing if 붞 a  뫞 붞 b  for all a   b. it is said to be submodular if 붞 a  + 붞 b  뫟 붞 a 뫋 b  + 붞 a 뫌 b   symmetric if 붞 a  = 붞 v   a   and normalized if 붞 뷋  = 1. for any normalized increasing submodular function 붞 : 1v 뫸 r+  the function 붞c : 1v 뫸 r+ defined by 붞c x  = 붞 x +붞 v  x  붞 v   is a symmetric submodular function. this function is called the connectivity function of 붞  and is normalized  symmetric and submodular. we can think of 붞c x  = 붞c v   x  = 붞c x v   x  as the cost of  separating  x from v   x. because 붞c is submodular  there are polynomial time algorithms for finding the non-trivial partition  x v   x  that minimizes 붞c. such normalized symmetric submodular functions arise naturally in many applications. one example is the widely used graph cut criterion.
모here  the set v to be partitioned is the set of vertices of a graph g =  v e . the edges have weights we : e 뫸 r+ which is proportional to the degree of similarity between the ends of the edge. the graph cut criterion seeks to partition the vertices into two parts so as to minimize the sum of the weights of the edges broken by the partition. for any x   v   let 붺 x  = set of edges having at least one endpoint in x
붻 x  = set of edges having exactly one endpoint in x
for example  if x = {1 1}  the red/darkshaded set in figure 1-left   then 붺 x  = { 1   1   1   1   1   1 }  the set of edges

  which can be shown to be a normalized in-figure 1: left: the undirected graph cut criterion: 붞c x  is the sum of weights of edges between x and v   x. right: the bipartite adjacency criterion: 붞c x  is the number of elements of f  features  adjacent to both x and v   x.
which are either dashed/red or solid/black  and 붻 x  is the set of solid/black edges { 1   1   1   1 }. it is easy to verify that for any  positive  weights that we assign to the edges we : e 뫸 r+   the function
 is a normalized
increasing submodular function  and hence the function 붞c x  = we 붻 x   = we 붺 x  +we 붺 v  x   we e 
is a normalized symmetric submodular function1. we will refer to this as the undirected graph cut criterion.
