the direct application of standard ranking techniques to retrieve individual elements from a collection of xml documents often produces a result set in which the top ranks are dominated by a large number of elements taken from a small number of highly relevant documents. this paper presents and evaluates an algorithm that re-ranks this result set  with the aim of minimizing redundant content while preserving the benefits of element retrieval  including the benefit of identifying topic-focused components contained within relevant documents. the test collection developed by the initiative for the evaluation of xml retrieval  inex  forms the basis for the evaluation.
categories and subject descriptors
h.1  information systems : information storage and retrieval-information search and retrieval
general terms
algorithms  measurement  performance  experimentation
keywords
xml  ranking  information retrieval
1. introduction
　the representation of documents in xml provides an opportunity for information retrieval systems to take advantage of document structure  returning individual document components when appropriate  rather than complete documents in all circumstances. in response to a user query  an xml information retrieval system might return a mixture of paragraphs  sections  articles  bibliographic entries and other components. this facility is of particular benefit when a collection contains very long documents  such as product manuals or books  where the user should be directed to the most relevant portions of these documents.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee.
sigir'1  august 1  1  salvador  brazil.
copyright 1 acm 1-1/1 ...$1.
 article 
 fm 
 atl text compression for
dynamic document databases /atl 
 au alistair moffat /au 
 au justin zobel /au 
 au neil sharman /au 
 abs  p  b abstract /b  for ... /p  /abs 
 /fm 
 bdy 
 sec  st introduction /st 
 ip1 modern document databases... /ip1 
 p there are good reasons to compress... /p 
 /sec 
 sec  st reducing memory requirements /st ...
 ss1  st 1 method a /st ...
 /sec 
...
 /bdy 
 /article 
figure 1: a journal article encoded in xml.
　figure 1 provides an example of a journal article encoded in xml  illustrating many of the important characteristics of xml documents. tags indicate the beginning and end of each element  with elements varying widely in size  from one word to thousands of words. some elements  such as paragraphs and sections  may be reasonably presented to the user as retrieval results  but others are not appropriate. elements overlap each other - articles contain sections  sections contain subsections  and subsections contain paragraphs. each of these characteristics affects the design of an xml ir system  and each leads to fundamental problems that must be solved in an successful system. most of these fundamental problems can be solved through the careful adaptation of standard ir techniques  but the problems caused by overlap are unique to this area  1  and form the primary focus of this paper.

figure 1: example xml tree.　the article of figure 1 may be viewed as an xml tree  as illustrated in figure 1. formally  a collection of xml documents may be represented as a forest of ordered  rooted trees  consisting of a set of nodes n and a set of directed edges e connecting these nodes. for each node x （ n  the notation x.parent refers to the parent node of x  if one exists  and the notation x.children refers to the set of child nodes of x. since an element may be represented by the node at its root  the output of an xml ir system may be viewed as a ranked list of the top-m nodes.
　the direct application of a standard relevance ranking technique to a set of xml elements can produce a result in which the top ranks are dominated by many structurally related elements. a high scoring section is likely to contain several high scoring paragraphs and to be contained in an high scoring article. for example  many of the elements in figure 1 would receive a high score on the keyword query
 text index compression algorithms . if each of these elements are presented to a user as an individual and separate result  she may waste considerable time reviewing and rejecting redundant content.
　one possible solution is to report only the highest scoring element along a given path in the tree  and to remove from the lower ranks any element containing it  or contained within it. unfortunately  this approach destroys some of the possible benefits of xml ir. for example  an outer element may contain a substantial amount of information that does not appear in an inner element  but the inner element may be heavily focused on the query topic and provide a short overview of the key concepts. in such cases  it is reasonable to report elements which contain  or are contained in  higher ranking elements. even when an entire book is relevant  a user may still wish to have the most important paragraphs highlighted  to guide her reading and to save time .
　this paper presents a method for controlling overlap. starting with an initial element ranking  a re-ranking algorithm adjusts the scores of lower ranking elements that contain  or are contained within  higher ranking elements  reflecting the fact that this information may now be redundant. for example  once an element representing a section appears in the ranking  the scores for the paragraphs it contains and the article that contains it are reduced. the inspiration for this strategy comes partially from recent work on structured documents retrieval  where terms appearing in different fields  such as the title and body  are given different weights . extending that approach  the re-ranking algorithm varies weights dynamically as elements are processed.
　the remainder of the paper is organized as follows: after a discussion of background work and evaluation methodology  a baseline retrieval method is presented in section 1. this baseline method represents a reasonable adaptation of standard ir technology to xml. section 1 then outlines a strategy for controlling overlap  using the baseline method as a starting point. a re-ranking algorithm implementing this strategy is presented in section 1 and evaluated in section 1. section 1 discusses an extended version of the algorithm.
1. background
　this section provides a general overview of xml information retrieval and discusses related work  with an emphasis on the fundamental problems mentioned in the introduction. much research in the area of xml retrieval views it from a traditional database perspective  being concerned with such problems as the implementation of structured query languages  and the processing of joins . here  we take a  content oriented  ir perceptive  focusing on xml documents that primarily contain natural language data and queries that are primarily expressed in natural language. we assume that these queries indicate only the nature of desired content  not its structure  and that the role of the ir system is to determine which elements best satisfy the underlying information need. other ir research has considered mixed queries  in which both content and structural requirements are specified  1 1 1 .
1 term and document statistics
　in traditional information retrieval applications the standard unit of retrieval is taken to be the  document . depending on the application  this term might be interpreted to encompass many different objects  including web pages  newspaper articles and email messages.
　when applying standard relevance ranking techniques in the context of xml ir  a natural approach is to treat each element as a separate  document   with term statistics available for each . in addition  most ranking techniques require global statistics  e.g. inverse document frequency  computed over the collection as a whole. if we consider this collection to include all elements that might be returned by the system  a specific occurrence of a term may appear in several different  documents   perhaps in elements representing a paragraph  a subsection  a section and an article. it is not appropriate to compute inverse document frequency under the assumption that the term is contained in all of these elements  since the number of elements that contain a term depends entirely on the structural arrangement of the documents  1 .
1 retrievable elements
　while an xml ir system might potentially retrieve any element  many elements may not be appropriate as retrieval results. this is usually the case when elements contain very little text . for example  a section title containing only the query terms may receive a high score from a ranking algorithm  but alone it would be of limited value to a user  who might prefer the actual section itself. other elements may reflect the document's physical  rather than logical  structure  which may have little or no meaning to a user. an effective xml ir system must return only those elements that have sufficient content to be usable and are able to stand alone as independent objects  1 . standard document components such as paragraphs  sections  subsections  and abstracts usually meet these requirements; titles  italicized phrases  and individual metadata fields often do not.
1 evaluation methodology
　over the past three years  the initiative for the evaluation of xml retrieval  inex  has encouraged research into xml information retrieval technology  1 . inex is an experimental conference series  similar to trec  with groups from different institutions completing one or more experimental tasks using their own tools and systems  and comparing their results at the conference itself. over 1 groups participated in inex 1  and the conference has become as influential in the area of xml ir as trec is in other ir areas. the research described in this paper  as well as much of the related work it cites  depends on the test collections developed by inex.
　overlap causes considerable problems with retrieval evaluation  and the inex organizers and participants have wrestled with these problems since the beginning. while substantial progress has been made  these problem are still not completely solved. kazai et al.  provide a detailed exposition of the overlap problem in the context of inex retrieval evaluation and discuss both current and proposed evaluation metrics. many of these metrics are applied to evaluate the experiments reported in this paper  and they are briefly outlined in the next section.
1. inex 1
　space limitations prevent the inclusion of more than a brief summary of inex 1 tasks and evaluation methodology. for detailed information  the proceedings of the conference itself should be consulted .
1 tasks
　for the main experimental tasks  inex 1 participants were provided with a collection of 1 articles taken from the ieee computer societies magazines and journals between 1 and 1. each document is encoded in xml using a common dtd  with the document of figures 1 and 1 providing one example.
