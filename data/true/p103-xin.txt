the family of threshold algorithm  i.e.  ta  has been widely studied for efficiently computing top-k queries. ta uses a sort-merge framework that assumes data lists are pre-sorted  and the ranking functions are monotone. however  in many database applications  attribute values are indexed by treestructured indices  e.g.  b-tree  r-tree   and the ranking functions are not necessarily monotone. to answer top-k queries with ad-hoc ranking functions  this paper studies an index-merge paradigm that performs progressive search over the space of joint states composed by multiple index nodes. we address two challenges for efficient query processing. first  to minimize the search complexity  we present a doubleheap algorithm which supports not only progressive state search but also progressive state generation. second  to avoid unnecessary disk access  we characterize a type of  empty-state  that does not contribute to the final results  and propose a new materialization model  join-signature  to prune empty-states. our performance study shows that the proposed method achieves one order of magnitude speed-up over baseline solutions.
categories and subject descriptors: h.1  database
management : systems - query processing
general terms: algorithms
keywords: top-k query  progressive merge  selective merge
1. introduction
모top-k queries ask for k tuples ordered according to a specific ranking function that combines the values from multiple attributes. efficient computation of top-k results has been one of the focusing points in research with numerous studies reported. a widely studied implementation method is the family of threshold algorithms  i.e.  ta   1  1  1 . ta uses a sort-merge framework that sequentially scans a set of pre-computed lists  each of which is sorted according to in-

 work supported by the u.s. national science foundation nsf iis-1/1/1 and bdi-1.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee.
sigmod'1  june 1  1  beijing  china.
copyright 1 acm 1-1-1/1 ...$1.
dividual scores  and merges data objects from different lists to compute the aggregated scores. usually  it stops scanning long before reaching the end of the lists. ta has been extensively studied in the context of middle-ware  information retrieval  and multimedia similarity search  where the aggregation functions are usually monotone. we say that a function f is monotone if
whenever xi 뫞 xi뫣  for every i. however  in many database applications  the ranking functions are not monotone  as demonstrated in the following examples.
example 1. in many business applications  prediction models  which are trained by historical data sets  are used to predict a target value based on other attributes. as a case study  suppose that someone wants to predict stock value v   based on earnings e and research expenditure r. a prediction model f e r  captures the trade-off between the current earnings e and future benefits by r. a typical query over the stock database is to find the top-k stocks that best match the prediction model. select top-k s.companyname from stock s order by  s.v   f s.e s.r  1 asc
example 1. consider a house database that maintains the price and location  e.g.  longitude and latitude  of each house. to search for a house that has expected price p and also is close to a good school s  using manhattan or euclidean distance d   we may formulate the ranking function as below  where 붸 is a weighting parameter. select top-k h.address from house h order by 붸|h.price   p| + d s h  asc
모in both above examples  the ranking functions are not monotone  and thus the sort-merge framework is not applicable. the naive solution that scans the whole database is not desirable for a large database and small k values. on the other hand  database systems often organize data attributes using tree-structured indices  e.g.  b-tree  r-tree   and the attributes involved in the ranking function are generally distributed in multiple indices. for example  in ex. 1  v e and r are typically indexed by three different b-trees  and in ex. 1  price and location may be indexed by a b-tree and an r-tree.
모for a relatively small value of k  the processing time can be reduced significantly by progressively merging indices. in general  indices are accessed in a top-down fashion such that the roots are first retrieved and child nodes are visited after their parents. to optimize the disk access  an important issue is to determine the right order to retrieve
nodes  i.e.  access scheduling . under the context of index merging  this scheduling problem often involves search over the space of joint states composed by multiple index nodes. we refer to this procedure as state search. following ex. 1  suppose price and location are indexed by a b-tree p and an r-tree l. the index-merge starts with the root state  p.root l.root   and is recursively called on the next promising state  until the top-k results are found. to determine the next state to access  the algorithm takes the cartesian product of all child nodes of p.root and those of l.root  and each pair is a new joint state. we refer to this procedure as state generation.
모in this paper  we study the problem of efficient processing top-k queries with ad-hoc ranking functions by an indexmerge paradigm  thus extending ta's sort-merge framework for monotone aggregate functions. while in sort-merge  data is accessed sequentially along the sorted lists  in indexmerge  access scheduling is more complicated  e.g.  by state search and state generation . we address two challenges for the index-merge framework. first  towards cpu optimality  how to minimize the number of states to be generated  secondly  towards i/o optimality  how to prune unnecessary disk accesses  to demonstrate the significance of these two challenges  table 1 shows a performance comparison between the basic index-merge and the improved algorithm developed in this paper 1.
index-mergestates generateddisk accessesbasic11improved11table 1: significance of the two challenges
모for the first challenge  similar work to reduce the search complexity was previously studied by spatial  or distance  joins  1  1  1   which ask for pairs of objects intersecting  or close  to each other. two popular optimization techniques were proposed to reduce the complexity of joint space search by joining two r-trees. the first  search space restriction  performs two linear scans over the entries of both nodes  and prunes out of each node the entries that do not intersect with the other node. the second  plane sweep  applies sorting on one dimension in order to reduce the cost of computing entry pairs to be joined. unfortunately  all these methods are tailored for spatial functions that measure intersection or distance between spatial objects. there is no principled solution for ad-hoc ranking functions.
모the second challenge is also imposed on the sort-merge approach in that objects near the top on one list may rank low in other lists  and hence a large portion of the retrieved data may not contribute to the final results at all. to remedy this  random access  1  1  1  1  1  1  is used to resolve missing scores of partially merged objects. in this paper  we show that random access  although effective in sort-merge  does not lead to early termination in the index-merge framework  see section 1 for detailed descriptions   and thus the previously studies are not applicable.
모this paper proposes new strategies for both challenges. to reduce the search complexity  we decouple the state search and state generation procedures. instead of fully expanding a joint state during search  our algorithm progressively and partially expands a state when necessary. we refer to this strategy as progressive merge. to prune unnecessary disk access  we characterize a type of  empty-state  that does not contribute to the final results  and present a simple materialization model  join-signature  to prune empty states. we refer to this strategy as selective merge. our experimental results show that the new method achieves one order of magnitude speedup over the basic index-merge approach. more specifically  the contributions of this paper are:
  we conduct a thorough analysis of the index-merge framework and study two optimal scenarios for query processing:  1  cpu optimal  which touches the minimal number of states in search; and on top of that   1  i/o optimal  which retrieves the minimal number of index nodes.
  we propose a double-heap algorithm which decouples the state search and state generation procedures. for all joint states scheduled for access  a global heap facilitates search; and for each joined state in the global heap  a local heap controls the progressive expansion.
  we develop a threshold expansion method to progressively expand a joint state for general functions. a function  though general over the entire region  may be monotone  or semi-monotone  in some sub-regions. a neighborhood expansion strategy can thus be developed.
  we propose join-signature to effectively prune disk access. the join-signature is a compressed summarization that indicates whether a joint state is empty or not. we show that the join-signature is compact  easy to compute and incurs very low overhead during query processing.
the rest of the paper is organized as follows. section 1 discusses related work. section 1 presents the framework for query processing  and analyzes the problem. the doubleheap algorithm and state expansion strategies are developed in section 1  and the selective merge with join-signature is presented in section 1. we report the experimental results in section 1  discuss the extensions in section 1  and conclude the study in section 1.
1. related work
모we have addressed the ta algorithms and the spatial joins in the last section. here  we discuss other related work.
모our index-merge uses a top-down search paradigm. computing top-k by interleaf traversal  which starts search from the leaf-nodes containing extreme points and progressively traverses to neighboring leaf-nodes  was exploited by  1  1 . the method requires the neighboring leaf-nodes to be well defined  and this may not be available in some index structures  e.g.  r-tree . on the other hand  top-down search is more general. moreover  we develop an adaptive search strategy for the top-down framework such that it conducts neighborhood expansion whenever applicable and switches to threshold expansion otherwise  see section 1 .
tidabf =  a   b 1t11t11t11t11t11t11t11t11 a.root  b.root 	joined states omitted
	 a1  b1   a1 b1   a1 b1   a1 b1 	......	 a1 b1 
 a  tree structured joined states
	state:  a.root  b.root  a1  b1   a1 b1 	......  a1 b1 
	f s :	1	1	......	1
 b  states sorted by f s 
table 1: a sample database	figure 1: indices on a and b	figure 1: space of joint states모the join-signature proposed in this paper is an extension of data cube  which pre-computes multi-dimensional aggregates. we treat each index as a dimension  and index nodes as values. with a boolean measure that indicates whether a joint state is empty or not  a join-signature is essentially a data cube over multiple index-dimensions. materializing join results is also explored by join indices  and ranking cube . the join-signature differs from them in that the join-signature is built at the index node granularity  rather than on the data record level.
모top-k queries are related to several other preference queries  including skyline query  and convex hull query . the methodology developed in this paper is also applicable to these queries under the context of index-merge  and we will discuss the extensions in section 1.
1. problem analysis
1 query and data model
모the task of finding top-k tuples from a database can be posed with either a maximization or a minimization criterion. since a maximal query can be turned into a minimal one by switching the sign of objective function  in the rest of the paper we assume minimization queries are issued. given a relation r with attributes a = {a1 a1 ... an}  a top-k query with an evaluation function f  which is formulated on a subset of attributes {a1뫣  a1뫣  ... am뫣 }   a  asks for k data tuples t1 t1 ... tk such that for any other t 뫍 r 
 . we further assume that the ranking function f has the following property: given a function f and the domain region   on its variables  the lower bound of f over   can be derived.
모we assume attributes involved in f are indexed by some hierarchical indices  e.g.  b-tree or r-tree   such that a subspace occupied by a tree node is always contained in the subspace of its parent node. suppose indices {i1 i1 ... im} are used to answer a top-k query. the space of joint states inherits the hierarchical property of the index. more specifically  the joint state can be recursively defined as follows. the root state is  i1.root i1.root ... im.root   and for each joint state  i1.n1 i1.n1 ... im.nm   its child states are the cartesian products of child nodes of ii.ni  i = 1 ... m . if
ii.ni for some i = 1 ... m is a leaf node  ii.ni itself is used in the cartesian products to generate child states. if all ii.ni are leaf nodes  the joined state is a leaf state. table 1 shows an example database  which consists of two attributes a and b  f is a demonstrating ranking function . indices on a and b are shown in figure 1 and the joint state space is assembled in figure 1.a.
1 framework for query processing
모to compare with  we review the sort-merge algorithm used by ta. ta sequentially retrieves data from the sorted lists. at any state  we can classify tuples into three categories: fully merged  partially merged and unseen. the algorithm maintains an upper bound 1 for the current topk fully merged tuples and a lower bound for the partially merged and unseen objects. if the upper bound score is no larger than the lower bound score  ta halts and returns the top-k results. additionally  for those partially merged objects  unknown scores from some attributes can be looked up by random access  thus facilitating the early termination. similarly  in index-merge  we need to define two strategies:  1  a way to schedule node access  and  1  a stop condition that guarantees the top-k results are found. given the value boundaries in index nodes  each joint state s is associated with a domain region   s . we define f s  as the lower bound of the ranking function f over a joint space s. for example  in figure 1    a1 b1  =  1  뫄  1   and f s  = 1 for ranking function f =  a   b 1. clearly  for each joint state  f s  뫟 f parent s  . the index-merge method starts with the joint root state  progressively finds the state with minimal f s  and examines its child states. in the meanwhile  the algorithm maintains an upper bound score of the current top-k results. the search stops when the upper bound score is no larger than the minimal f s   for all rest s . the procedure is described in algorithm 1.
algorithm 1 query processing by index-merge
input: a set of indices i  ranking function f  top-k
1: topk = 뷋; //heap with size k to hold current top-k
1:
1: while  g		=	 	 	 g		  
1:	remove top entry s from g heap;
1:	if s is a leaf state
1:	retrieve data and update topk;
1:	else //s is a non-leaf joint state
1:	insert all child states of s to g heap;
1: return

모we briefly explain the query processing as follows. the algorithm maintains two heaps. the topk heap keeps current best k results that are fully merged  and the root of the heap is the kth tuple. the g heap maintains candidate states for search  and the state with minimal f s  appears at the root. we also maintain a hashtable h for tuple merge. whenever a leaf state is retrieved  we look up tuples in h. if a tuple t is fully merged  and is better than topk.root  we remove the root from topk and insert t to topk.
1 optimal access scheduling
모we address two types of optimality for access scheduling: type-i that is cpu optimal and type-ii that is disk-access optimal. by bridging algorithm 1 and the optimal cases  we then identify two challenges.
1.1 type-i optimality
모suppose the upper bound score of final top-k results is s   remember that we use minimal k criteria in this paper . the type-i optimal scenario is that the algorithm only enumerates state s such that f s  뫞 s . we denote the optimal number of states as ni  = |{s|f s  뫞 s }|. as an example  the top-1 query with function f =  a   b 1 on the sample database  table 1  returns t1 as the final result. s  = 1  and only  a.root b.root    a1 b1  and  a1 b1  need to be enumerated. the states generated by algorithm 1 can be classified into:  1  examined states that appear on line 1; and  1  generated candidates that appear on line 1. we have the following lemma.
모lemma 1. for a top-k query involving m indices  the number of examined states by algorithm 1 is  and the number of generated candidates by algorithm 1 is upper bounded by  where ni  is the optimal number of states given by type-i optimality  and mi is the node fanout of index i.
모proof. we prove the claim for examined states  and the claim for generated candidates naturally follows. we show that for each examined state s  f s  뫞 s . at any stage  if f topk.root  = s   f s  뫞 s  is ensured by the while condition on line 1. if f topk.root    s   the top-k results have not been completely retrieved. since s appears at the root of g heap and f s  is the lower bound value of all future tuples  we have f s  뫞 s .
모while the number of examined states is type-i optimal  the number of generated candidates is significantly higher. fixing the page size as 1kb  the fanout of b-tree node is 1 . the number of child states  i.e.  cartesian product  of two b-tree indices is up to 1 뫄 1  and that of three b-tree indices is up to 1 뫄 1. this is clearly nontrivial cost in terms of both cpu and memory. to avoid full expansion  an alternative method that uses unidirectional expansion was discussed in . to expand a joined state s =  a b   either a is paired with all child nodes of b or b is paired with all child nodes of a. in this way  the number of child states is limited by the fanout of the node. however  the states generated by unidirectional expansion are less precise than those generated by full expansion  and thus the access scheduling may not be optimal. we identify the first challenges: how to efficiently generate candidate states while preserving the optimal  type-i  access scheduling .
1.1 type-ii optimality
모to achieve type-ii optimality  we first characterize two types of states: redundant state and empty state. an index node may appear in many joint states  and thus may be requested for retrieval for multiple times. we say a leaf index node is redundant if it has been retrieved previously. a non-leaf index node is redundant if all child nodes are redundant. consequently  a joint state is redundant if all composing index nodes are redundant. redundant states need not to be retrieved because all data tuples contained by them have already been seen by the query processing algorithm. since many index implementations buffer the previously retrieved index nodes  the redundant nodes  and thus the redundant states  can be identified on the fly. if the nodes are not buffered  the algorithm can maintain the ids of those redundant index nodes in a hash-table.
모to illustrate the definition of empty state  we build a mapping between data tuples and joint leaf states. we say a leaf state contains a tuple t if t appears in all the leaf index nodes joining the leaf state. a tuple may partially appear in many leaf states. however  there is a unique leaf state that contains it. on the other hand  a leaf state which contains one or more tuples is called non-empty state. otherwise  it is an empty state. for example  in figure 1.a   a1 b1  is an empty state and  a1 b1  is a non-empty state. the definition of empty  non-empty  state can be recursively extended to non-leaf state as follows: a state is empty if all child states are empty; otherwise  it is non-empty. let s t  be the leaf state containing tuple t. the following lemma shows a necessary condition of access scheduling using indexmerge framework.
모lemma 1. for any top-k query that is processed by the index-merge framework  suppose the final results are t1 t1 ... tk  and f s ti     f ti  for all i = 1 ... k. the leaf states s t1  s t1  ... s tk  must be retrieved when the query execution terminates1.
proof. in algorithm 1  the query processing terminates
   for current top-k re-
sults t1 ... tk. assume s ti  has not retrieved. we have f g heap.root  뫞 f s ti    which contradicts with f s ti     f ti  뫞 maxki=1 f ti  뫞 f g heap.root .
모since each ti in the top-k results will be retrieved from non-empty state s ti   it is safe to prune those empty-states. thus  the type-ii optimal scenario is that an algorithm only retrieves states s such that:  1  f s  뫞 s    1  s is not empty  and  1  s is not redundant. we refer to nii  as the optimal number of states given by type-ii optimality. following our example in figure 1.b  we may skip state  a1 b1   and only retrieve state  a.root b.root  and  a1 b1 .
모we demonstrate the importance of pruning empty states by examining the leaf-states only. suppose the database has 1m tuples  and each b+-tree index contains at least 1 leaf nodes  with fanout 1 . merging two indices leads to 1 뫄 1 leaf-states in total. among them  there are at most 1m non-empty states. thus  the probability that a leaf-state is empty is more than 1%.
모the sort-merge framework also has empty-state problem  where objects near top on one list may rank low in other lists. to avoid accessing the large portion of data which is in the middle of the sorted lists  random access is used to directly jump to the bottom of the lists and resolve missing values. in the following  we discuss why random access is not applicable in the index-merge framework. as presented in the last subsection  tuples can be classified into three categories: fully merged  partially merged and unseen. let sk be the upper bound score for current top-k fully merged tuples  sp and su be the lower bound scores for partially merged and unseen tuples. the search terminates when sk 뫞 min sp su . in sort-merge  we have sp 뫞 su because of the monotonicity of the ranking function. by issuing random accesses on partially merged tuples  sk may decrease and sp may increase. as the result  the termination condition may be satisfied without continuing to sequentially scan lists. while in index-merge  su = sp = f g heap.root  because for each partially merged and unseen tuple t  s t  has not been retrieved. issuing random accesses on partially merged tuples may decrease sk to sk뫣 . however  since for all partially merged t  f t  뫟 f s t   뫟 f g heap.root   we have sk뫣 뫟 f g heap.root  = su. we conclude that random access in index-merge does not lead to early termination.
모different from redundant states  which can be checked on the fly  the empty state can only be identified with the assistance of some pre-computed module. moreover  this module needs to be light-weighted. we identify the second challenge: how to effectively prune empty-states with low overhead 
1. progressive merge
모this section presents our solution for the first challenge. in algorithm 1  to search for the best child state  a parent state is fully expanded  on line 1 . in fact  most of them are never examined  on line 1 . for example  in figure 1.a  there are 1 child states expanded by  a.root b.root   and only  a1 b1  and  a1 b1  are examined. in fact  to ensure the type-i optimality  we only need to compute the next best child state  for a given state s. we abstract1 the interface that fulfills this requirement as s.get next.
모in the rest of this section  we first discuss a double-heap method that integrates s.get next with algorithm 1  and then discuss two implementations for s.get next.
1 the double-heap algorithm
모let s.num indicate how many times the s.get next is called. in our example  suppose s =  a.root b.root . the first call of s.get next returns  a1 b1  and the second call of s.get next returns  a1 b1 . s.get next returns nothing when all child states are returned. for simplicity  we denote snum as the numth best child state of s according to f snum .
모before we proceed to the implementation of s.get next  we first discuss how to integrate s.get next to algorithm 1. to distinguish the integrated algorithm from algorithm 1  we refer to the new algorithm as dheap  i.e.  double-heap . instead of fully expanding s  and then discarding s  on line 1 of algorithm 1   dheap gets snum  by calling s.get next  and inserts both snum and s to g heap. we keep s in g heap because the query execution may further request the next best child state of s. consequently  to reflect the status of partial expansion  we update f s  = f snum+1   which is the best possible score for all future child states. following our example in figure 1  when s =  a.root b.root  needs to be expanded  we get s1 =  a1 b1   update f s  = f s1  = f a1 b1  and insert both s1 and s into g heap.
모the complete framework for progressive and selective index merge is outlined in algorithm 1  where lines 1 to 1 are the updated query processing procedure  and lines
1 to 1 are the s.get next method. particularly  lines 1  1 and 1 exploit pruning empty-states by joinsignatures. the code is put here for the completeness of the algorithm  and the details will be discussed in the next section. the key components are neighborhood expand and threshold expand. the former works for some special scenario such that the best child state can be analytically found; and the latter is applicable on general cases. to avoid generating the same states along the multiple calls of s.get next  each s maintains the status of child states that have been already generated  using a heap  i.e.  l heap in s.get next .
we refer to this heap as local heap  in contrast to the global heap  i.e.  g heap on line 1  used in the main query processing loop. in the following subsections  we describe the two progressive search strategies one by one. for simplicity  we demonstrate both methods by merging two b-tree indices. the generalization to multiple indices is straightforward.
algorithm 1 progressive and selective merge
input: a set of indices i  ranking function f  top-k
1: topk = 뷋; //heap with size k to hold current top-k
1: g heap = {joint root}; //heap for state search
1: while  g heap 1= 뷋 and f topk.root    f g heap.root  1:remove top entry s from g heap;1:if  s is empty or redundant 1:continue;1:if  s is a leaf state 1:retrieve data and update topk;1:else //s is a non-leaf joint state1:next = s.get next  1:if  next 1= null  // non-empty non-redundant1:insert next to g heap;1:if  s.l heap 1= 뷋  // more child states in s1:insert s to g heap;1: return
procedure s.get next  
vars: local heap: l heap
1: if  l heap = 뷋 // the first time s.get next is called
1:	load state-signature sig;
1:	if  sig = null  //no signature for empty-states
1:	return null; //return nothing  keep l heap = 뷋
1:	load index nodes of s;
1: if  f is  semi- monotone in s ; //neighborhood
1:	next = neighborhood expand  ;
1: else //threshold
1:	next = threshold expand  ; //the best child state
1: if  l heap 1= 뷋  //there are child states left
1:	f s  = f l heap.root ; //l heap was updated
1: if  next is empty or redundant 
1:	next = null;
1: return next;

1 neighborhood expansion
모although an ad-hoc ranking function does not perform regularly over the entire region  it may have monotonicity or semi-monotonicity in some sub-regions. we say a function f is semi-monotone if
whenever |xi   oi| 뫞 |xi뫣   oi|  for every i. f achieves minimal value at  o1 o1 ... om . for example  figure 1 shows the plot of function f = ae a1 b1 over two attributes a and b. the function is neither monotone nor semi-monotone over the entire domain. however  in subregion  a =   1  b =   1    f is semi-monotone; and in sub-region  a =  1  b =   1  1    f is monotone. the index-merge method recursively partitions the joint space and it is very likely that an ad-hoc function f becomes monotone or semi-monotone within a joint state. we present the neighborhood expansion for these special cases.
	 a1  b1 	 a1  b1 
	1	 a1  b1 	 a1  b1 	 a1  b1 	 a1  b1 	 a1  b1 
	 1	 1figure 1: local monotonicity                                                       
figure 1: neighborhood expansion......    more states omitted      ......
figure 1: threshold expansion	a	......    more states omitted      ......모since the neighborhood expansion requires a total order to be defined on the entries of an index node  the method may not be used on r-tree indices. let s =  a1 b1  be the state to be expanded. a1 ... an and b1 ... bl are child entries of index node a1 and b1  respectively. without loss of generality  we assume both ai  i = 1 ... n  and bi  i = 1 ... l  are sorted by attribute values. suppose f is monotone over s and it achieves minimal value on  a1 b1   i.e.  initial state  referred as i s  . thus  we have f ai bj  뫞 min f ai+1 bj   f ai  bj+1  . the neighborhood expansion starts with the initial state and progressively generates neighboring states. a straightforward definition for the neighboring states of
 ai bj  is to enclose both  ai+1 bj  and  ai  bj+1 . since a state  ai+1 bi+1  can be generated by either  ai bi+1  or  ai+1 bi   this approach requires duplicate-checking  which incurs additional overhead. alternatively  we can define the neighborhood of a child state  ai bj  as:
	{ ai bj+1 }	if 1   j   l
n ai bj  =	{ ai+1 bj   ai bj+1 }	if j = 1 i   n 뷋	otherwise
모the definition of n is illustrated in figure 1. clearly  there is no duplicate states to be generated. whenever  ai bj  appears at the root of the local heap and is to be returned by s.get next  we will insert n ai bj  into the local heap. the procedure of neighborhood expansion is displayed as neighborhood expand in algorithm 1.
모we briefly discuss how to extend the method to semimonotone f. suppose the extreme point of f is o  =  x  y  . if o  falls in a child state  as bt   the initial state is i s  = { as bt }. otherwise  we can find an i  j  such that ai and ai+1  bj and bj+1  enclose x   y  . accordingly  i s  = { ai bj   ai+1 bj   ai bj+1   ai+1 bj+1 }. we define the neighborhood for i s  = { as bt } case as follows  the definition for the other case is similar:
	{ ai bj+1 }	if t   j   l
	{ ai bj 1 }	if 1   j   t
{ ai+1 bj   ai bj+1  
	 ai bj 1 }	if j = t s   i   n
n ai bj  =	{ ai 1 bj   ai bj+1  
	 ai bj 1 }	if j = t 1   i   s
{ ai 1 bj   ai bj+1  
 ai+1 bj   ai bj 1 } if i = s j = t 뷋	otherwise
모in general  to merge m indices  the cardinality of neighborhood for monotone functions is up to m and that for semi-monotone functions is up to 1m. lemma 1 gives the computational performance of the neighborhood expansion.
모lemma 1. suppose f is monotone  or semi-monotone  over the entire domain  and there are m indices to be merged. the number of states generated by neighborhood expansion is upper bounded by mni  for monotone functions and 1mni  for semi-monotone functions  where ni  is the type-i optimal number of states to be generated  section 1.1 .
모proof. according to lemma 1  s.get next will be called  times in algorithm 1. each time when the s.get next is called  the neighborhood expansion will generate up to m child states for monotone f and up to 1m child states for semi-monotone f. the conclusion follows.
algorithm 1 neighborhood and threshold expansions
procedure neighborhood expand  
1: if  l heap = 뷋 // the first time s.get next is called
1:	l heap = i s ;// insert initial states
1: remove top entry next from l heap;
1: insert n next  to l heap; 1: return next;
procedure threshold expand  
vars: s =  n1 ... nm   and ni =  e1i ... emi i  for each i
current threshold position ti  i = 1 ... m 
1: if  l heap = 뷋 // the first time s.get next is called
 ; // insert initial states
1:	t1 = ... = tm = 1; //initial threshold positions
1:	find next  ; //find the first candidate
1: remove top entry next from l heap;
1: find next  ;//search for next state 1: return next
procedure find next  
1: while	t	t
1:	and   i 뫍 {1 ... m} such that  ti 뫞 mi   
1:	s = argminji=1 f뫣 etii ;
 ;
1:	ts++;
1:	for each cs in news
1:	if  cs is not empty or redundant 
1:	insert cs to l heap;
1: return;

1 threshold expansion
모here we discuss the more general threshold expansion. different from the neighborhood expansion  where the initial and consequent child states can be analytically located  threshold expansion conducts searching over the child state space. suppose the state to be expanded is  a1 b1   and their entries are a1 a1 ... an and b1 b1 ... bl  respectively. we define f뫣 ai  = f ai b1   i = 1 ... n   which is the best score that ai can achieve by pairing with any bj  j = 1 ... l . similarly  we define f뫣 bj  = f a1 bj   j = 1 ... l . we sort ai and bj in ascending order of f뫣 ai  and f뫣 bj  values  respectively. without loss of generality  we assume the sorted orders are a1 a1 ... an and b1 b1 ... bl.
모the threshold expansion uses a sort-merge paradigm. we start search by inserting  a1 b1  to l heap  i.e.  local heap   and use two variables s and t to keep track of the next positions on ai and bj sorted lists  i.e.  threshold position . initially  s = t = 1. the stop condition is f l heap.root  뫞 min f뫣 as  f뫣 bt  . at that time  the l heap.root contains the next best child state. while the stop condition does not hold  the algorithm conducts progressive search. suppose f뫣 as    f뫣 bt   the algorithm creates t   1 new child states  as bj   j = 1 ... t   1   inserts them to l heap  and then increases s by 1. for example  when s = 1 and t = 1  the states that have been generated are shown in figure 1.
모in general  suppose s is joined by m index nodes  n1 ...  nm   and each ni consists of child entries e1i ... emi i  mi is the fanout of node ni . we define f뫣 eki   = f n1 ... eki   ... nm . the algorithm maintains a threshold position ti for each ni. whenever a ts is selected to advance  we generate the new child states by the cartesian product   ... etss  뫄 ... e1j ... etmm 1 . the algorithm is shown in algorithm 1 as threshold expand.
모a function f is general over the state s if for any ti  i = 1 ... m   the lower bound of  can only be derived by min   . accordingly  we refer to algorithms performing child state search under this assumption as general algorithms. the following lemma shows that the threshold expansion is instance optimal  with optimal ratio 1m  where m is the number of indices to be merged.
모lemma 1. assume f is general over state s =  n1 ...  nm   and for each node ni  its entries satisfy f뫣 e1i    f뫣 e1i    ...   f뫣 emi i . the threshold expand  or te  is instance optimal such that nte 뫞 1mnalg  where nte is the number of child states generated by te  nalg is the number of child states generated by any other general algorithm alg that correctly finds the next best child state.
모proof. suppose te halts at ti on each node ni  and the next best child state is . clearly  si   ti for all i = 1 ... m. we show that for all i  f뫣 etii 1    f뫣 eiti 1  뫞 f nb . assume the threshold position at node nk  k 1= i  is tk뫣 when te decides to advance to ti   1 on node ni. if f뫣 eiti 1    f nb   we have si   ti   1 and there must exist one k such that sk 뫟 tk뫣 . otherwise  the best state nb has already been generated by te and ti   1 will not be selected. on the other hand  we have
뫣
   which leads to con-
tradiction. since f is general over s  any general algorithm alg that correctly finds the best state has to generate and check all states from  
thus .
1. selective merge
모in this section  we address the challenge towards the typeii optimality. to prune empty-states in merging indices i1 i1  ... im  we materialize a join-signature of these m indices. suppose the database has j indices. an ideal scenario is to compute a join-signature on any combination of two or more indices  and this leads to  1j   j   1  different join-signatures in total. in reality  one can only compute join-signatures on index combinations which are possibly to be queried. alternatively  one can also materialize join-signatures on each pair of indices only  and use them to answer arbitrary queries. in the rest of this section  we discuss what is join-signature  how to compute join-signature and how to use join-signature during query processing.
1 join-signature
모the join-signature is composed by the state-signatures of all non-leaf and non-empty states. for each non-leaf and non-empty state s =  n1 ... nm   we define card s  = as the cardinality of the child states  where mi is the fanout of node ni. the state-signature is an m-way bit array  where each entry corresponds to a child state. if a child state is not empty  the entry is set to 1; otherwise  it is 1. using our example in figure 1  only s =  a.root b.root  is a non-leaf and non-empty state. the state-signature of s is a 1 뫄 1 bit array  as shown in figure 1.
tida.pathb.patht1h1ih1it1h1ih1it1h1ih1it1h1ih1it1h1ih1it1h1ih1it1h1ih1it1h1ih1i11111   b1 b1 b1 a1 a1 a1
                 
	figure 1: signature	table 1: pathes on indices
모the space consumption of the join-signature depends on the number of non-leaf and non-empty states  as well as the size of each state-signature. we discuss these two issues one-by-one. as defined in section 1.1  a leaf-state is nonempty if it contains at least one tuple. on the other hand  since tuples are exclusively distributed into different leafnodes in an index  tuples are also exclusively contained by different leaf-states. suppose the database has t tuples. we conclude that there are at most t non-empty leaf-states  and at most  d 1 t non-empty and non-leaf states  where d is the maximum depth among all joined indices .
모we then discuss how to control the size of each statesignature  such that each of which can be stored within size p. typically  p can be set as the page size. given a state s  the value of card s   i.e.  the number of child states  varies significantly from merging two indices to merging three indices. if card s  뫞 p  we store the state-signature as it is  and possibly  put neighboring state-signatures together if their accumulative size does not exceed p. since statesignatures are essentially bit-maps  one can further apply bit-map compression methods  such as run-length encoding  and prefix-compression encoding   to reduce the sizes. we omit the details in this paper.
when card s    p  we use bloom filter  for compression. bloom filter uses k hash functions and maps an entry to k positions in a bit array. during the building phase  the bits at those k positions are set to 1. at the query time  one can apply the k same hash functions to get k positions  and return true if and only if all of them are 1. false positives are possible. but it guarantees no false negative. to use bloom filter for state-signature  we set the array size as b 뫞 p   and insert to the bloom filter all  1  entries in the state-signature. during query execution  if the bloom filter returns false for a child state c  c must be an emptystate. suppose the number of non-empty child nodes  i.e.   1  entries  is ne. the optimal choice  for 
to control the computational complexity  i.e.  the number of hash functions   we set the maximum number of hash function as k몬. consequently 
모to reference a state-signature  we compute a unique key for each state s =  n1 n1 ... nm  as follows. a level-k node n is associated with a path from the root  level 1  to n's parent  level k   1 . the path consists of a sequence of entry positions: path n  = hp1 p1 ... pk 1i  where pi is the entry position at the level-i node. for example  node a1 in index a  figure 1  corresponds to path a1  = h1i. the key of s is a combination of paths of ni: key s  =  path n1  ... path nm  . in implementation  one can oneto-one map key s  to a string or an integer. for each joinsignature  we build an index on key s  for state-signatures.
1 computing join-signatures
모a na몮 ve method to compute the join-signature is to traverse the joint state space and find the non-empty and nonleaf states. this is obviously not a scalable solution  since the space of joint states grows exponentially with the number of indices. here we present a tuple-oriented approach.
모similar to the path generation for nodes  we can also compute a path for each tuple t. given an index with depth d  the path of a tuple t is path t  = hp1 ... pdi. since the joined space is defined on the node granularity  we only need to know which leaf-node contains t. hence  we can ignore the position on the leaf node  and path t  = hp1 ... pd 1i. the paths for tuples in the sample database  table 1  are shown in table 1.
모treating each index as a dimension  and tuple paths as values  we compute the join-signature by recursive-sorting. suppose we need to compute the join-signature for m indices
 i1 ... im   and the depth of each index is di  i = 1 ... m . according to the path generation discussed above  each tuple path has  di   1  entries in dimension ii. to compute the state-signature for joint root state  we sort the tuples according to the first path entry on each ii  i.e.  first compare i1.p1  then i1.p1  and so on . as an example  table 1 is sorted by the first path entries. we then scan the sorted tuple list again  and insert distinct  i1.p1 i1.p1 ... im.p1  into the state-signature  which is implemented by a bit array or a bloom filter. for each sub-list of tuples that share the same  i1.p1 i1.p1 ... im.p1   we recursively sort it on the second path entry on ii. at the same time   i1.p1  i1.p1  ...  im.p1  is the key to reference the next state-signature.
모the above method is similar to some sorting-based data cube computation methods . in fact  computing multiple join-signatures is indeed a multi-dimensional aggregation problem. as we mentioned earlier  suppose the database has j indices and we may compute up to  1j   j   1  different join-signatures. some techniques for efficient data cubing can be directly applied in our problem. first  when database is too large to fit in memory  one can partition the database  e.g.  by i1.p1  and compute each partial database . secondly  we can share the sorting on common indices  when computing multiple join-signatures. finally  when j is large and there are too many join-signatures  we can only compute the low-dimensional  e.g.  pairwise  join-signatures . the low-dimensional join-signatures can partially fulfill the task to prune empty-states in high-dimensional indexmerge  and this will be addressed in the next subsection. 1 pruning empty-state by join-signature
모after presenting the join-signature and its computation  we now discuss how to use it to prune empty-states during query processing. candidate states are generated by the s.get next procedure. to avoid generating empty-states  join-signatures can be integrated into s.get next procedure as shown in algorithm 1. when s.get next is called for the first time  we load the state-signature for s using key s   line 1 . for each candidate child state to be returned  i.e.  next   we check with the state-signature on line 1. a null state will be returned if next is an empty state or a redundant state.
모an even better solution is to push the empty-state checking into the threshold expand and neighborhood expand. for threshold expand  we verify each child state before it is inserted into l heap  line 1  algorithm 1 . however  for neighborhood expand  if a child state cs in n next  is empty  we still need to keep cs in the l heap. this is because we may need to further expand to n cs   which may be non-empty  non-redundant and only accessible by cs.
모a state-signature may be implemented by a bloom filter  which has false positives such that an empty state will be falsely recognized as a non-empty state. suppose s is a non-leaf empty-state and was falsely passed the signature checking. at certain stage  s may be scheduled for expansion. since key s  does not appear in join-signature  the algorithm notices that s is an empty state and the previous false positive will be corrected. for this purpose  we directly return null from s.get next  line 1 of algorithm 1 . since s.l heap is empty  s will also be discarded by the main query processing loop  line 1 of algorithm 1 . in this way  the false positives on non-leaf states will not propagate. we have the following lemma with proof omitted.
모lemma 1. in algorithm 1  the expect number of states retrieved is  ni   nii   fp+nii    where is the type-i optimal state number  section 1.1   nii = |{s|f s  뫞 s  and s is neither empty nor redundant}| is the type-ii optimal state number  section 1.1   and fp is the expected false positive rate of the join-signature.
모when the original bit-array is used  i.e.  fp = 1   the number of states retrieved by algorithm 1 is type-ii optimal. similarly  the expect number of disk accesses for statesignatures  referred as ds  is  ni뫣  nii뫣  fp+nii뫣   where ni뫣 and nii뫣 are the number of non-leaf states with respect to typei and type-ii optimality  respectively. since the majority states retrieved are leaf-states  we expect that ds is far less than nii  . on the other hand  retrieving a state s does not necessarily incur disk accesses because the index nodes involved in s are shared by other states and may have already been retrieved. hence  the number of index node accesses  referred as di  may also be less than nii  . in general  we
모
figure 1: execution time	figure 1: execution time
w.r.t. k  f = fs	w.r.t. k  f = fg
figure 1: execution time figure 1: disk access w.r.t. k  f = fc w.r.t. f  k = 1
모
observe ds   di. moreover  without state-signature  di will be significantly higher  e.g.  table 1 .
모as mentioned in section 1  one can use low-dimensional join-signatures to answer high-dimensional queries. suppose the system pre-computed join-signatures on all pairs of indices. if a query involves m   1 indices  for each state s =  n1 n1 ... nm   we will load state-signatures of states sab =  na nb   for all a b = 1 ... m and a 1= b . a child state is an empty state if any low-dimensional statesignature returns false. the low-dimensional join-signature may also speed-up child state generation in threshold expand procedure in that whenever a pair of child entries  ea eb  is identified as empty  all child states that are super-sets of  ea eb  can be safely pruned  on line 1 of algorithm 1 .
1. performance study
모this section reports our experimental results. we compare the query performance among four different methods: the table scan  ts  approach that sequentially scans the data file and computes top-k; the baseline  bl  index-merge approach using algorithm 1; the progressive expansion  pe  approach with the double heap algorithm only; and the progressive expansion and join-signature  pe+sig  approach that applies both double heap algorithm and join-signatures. we first discuss the experimental setting.
1 experimental setting
모we use both synthetic and real data sets for the experiments. the real data set is a variation of the forest covertype data set obtained from the uci machine learning repository web-site  www.ics.uci.edu/몲mlearn . this data set contains 1 1 data points with 1 selected attributes  cardinalities 1  1  1  1  1 and 1 . we also generate a number of synthetic data sets for our experiments. the ts approach sequentially reads tuples from file. in the meanwhile  ts maintains a heap with size k to keep track the current top-k results seen so far. for other approaches using index-merge framework  we assume the attributes involved in ranking functions are indexed by either b+-trees or r-trees. by default  the page size in index nodes is set as 1kb. all methods are implemented in java.
1 experimental results
모we use execution time as evaluation metric and conduct experiments to evaluate the query performance with respect to different ranking functions  different type of indices and the number of indices for merging. guided by the query performance  we further examine how to configure indices for efficient online query processing. finally  we show the scalability of the proposed methods  including both online query and offline computation costs.
1.1 query performance w.r.t. ranking functions
모since the index-merge paradigm is motivated by supporting non-monotonic ranking functions  we first evaluate query performance with respect to different types of functions. suppose the ranking function is formulated on two attributes a and b  and each of them is indexed by a b+-tree. for demonstration  we use three queries with controlled functions:  1  a semi-monotone query with function fs =  a   a 1 +  b   b 1 where a and b are random parameters. this is a typical nearest neighbor query  which is frequently used in database systems;  1  a general query with function fg =  a   b1. this query is often used to measure the min square error;  1  a constrained query with function fc =
  where 붾 b  = 1 if b1 뫞 b 뫞 b1  and 붾 b  = 1 otherwise. fc essentially constraints the value of b to be between b1 and b1  and b1 and b1 are two random parameters.
모we use synthetic data sets in this set of experiments. by default  all data contains 1m tuples. the query execution time with respect to different k values and different ranking functions are shown in figures 1 to 1. we observe that all the approaches using the index-merge framework perform better than table scan  while the speed-up margin differs from each ranking function: with fs and fc  both pe and pe+sig are almost one order of magnitude faster than bl  which is already one order of magnitude faster than ts; and with fg  pe+sig is 1 times faster than bl and pe  which are only around 1 times faster than ts. the experimental results show the effect of two optimization techniques  progressive merge and selective merge  with respect to different ranking functions.
모to explain the difference  we first analyze the properties of the three index-merge based approaches. the overall execution time can be decomposed into two parts: cpu time for state search and state generation; and i/o time for node retrieval. pe improves bl with respect to cpu cost  and pe+sig further improves pe in terms of i/o cost. we then examine the three ranking functions to see which cost  i.e.  cpu or i/o  dominates the overall performance. in fs  the top answers are close to point  a b   and it is very likely that only a few index nodes need to be retrieved. thus the i/o may be relatively cheap and the cpu cost dominates. the same observation is also applied on fc. the hypothesis is well supported by figures 1 and 1 in that:  1  bl is significantly faster than ts because bl requests much less

figure 1: states gener- figure 1: peak heap size figure 1: execution figure 1: execution ated w.r.t. f  k = 1 w.r.t. f  k = 1 time w.r.t. k  real data time w.r.t. r-tree	1	1e+1
	1	1	1	1
	top-k	top-k
figure 1: execution figure 1: peak heap size time w.r.t. k  1 indices w.r.t. k  1 indices
	1e+1.1
	1	1	1	1
	top-k	node size  kb 
figure 1:	disk access	figure	1:	execution
w.r.t. k  1 indices	time w.r.t. node size
모
i/o;  1  pe further improves bl by order of magnitude because cpu cost dominates in bl; and  1  the speed-up of pe+sig over pe is limited because the room for improvement is small  i.e.  i/o is already very cheap . on the other hand  fg is a difficult query function since the top results could scatter over the whole domain  and one has to retrieve more data to answer the query. as the result  the i/o cost dominates. as shown in figure 1  the speed-up of both bl and pe over ts is not significant. pe+sig achieves substantial improvement because the join-signature prunes many empty-states  and thus reduces the i/o requests.
모figure 1 shows the number of disk access for three functions when k = 1. for pe+sig  we further plot the number of index node requests and that of the state-signature requests. comparing with the i/o for index nodes  the i/o cost for join-signatures is much less. among the three functions  fg incurs most i/o costs  and this is consistent with the above analysis. figure 1 shows the number of generated states. we observe that the progressive expansion is quite effective in that it generates much less states. sometimes pe+sig generates less states because the pruning of empty states  and whose child states . finally  figure 1 shows the peak heap size. the heap size of pe and pe+sig are computed by the accumulative size of the global heap and all local heaps. note that even for fg  the peak heap size of pe  pe+sig  is 1  1  when k = 1. this is actually a very important property to support in-memory computation. we will further address this in section 1.1.
1.1 query performance on r-tree indices
모after reporting the results on b+-tree indices  we evaluate the query performance on r-tree indices in this subsection. we have demonstrated the differences of three ranking functions in the last subsection and their behaviors are similar with r-tree indices. for simplicity  we only use fs in the following experiments. suppose an r-tree index consists of d dimensions. merging two r-tree indices means there are 1 attributes in the ranking function. we define fs = 1i=1 ai ai 1  where ai is an attribute value and ai is the query parameter. it is possible that some attributes are not involved in ranking  and we will address this in section 1.1. as we discussed in section 1  neighborhood expansion is not applicable in r-tree  since the nodes are not fully ordered. we use threshold expansion only.
모we first conduct experiments on the real data set  whose 1 attributes are evenly divided into 1 groups. each group is indexed by an r-tree. we vary the value of k from 1 to 1  and the query execution time is shown in figure 1. clearly  pe+sig performs best among all approaches. an interesting observation is the bl is even worse than ts when k 뫟 1. this is because the ranking function involves 1 attributes  which make it more difficult to search for the final results. to verify this  we generate 1 different data sets with 1  1  1 and 1 dimensions  and build 1 r-tree indices  by evenly partition the attributes  on each of them. the execution time for k = 1 is shown figure 1. as expected  it is more expensive to answer queries with more attributes. however  even for 1d r-tree  pe  and also pe+sig  finishes query in around 1 seconds  which is more than 1 times faster than that by ts  1 seconds .
1.1 query performance on 1-way merge
모all the previous experiments are conducted upon 1-way index merge. here we examine query performance on 1-way index merge. we use fs = 1i=1 ai   ai 1  where ai are three attributes  and each of which is indexed by a b+-tree. as discussed in section 1  the pe+sig approach has two choices:  1  use one 1d join-signature; or  1  use three 1d join-signatures  e.g.   a1 a1    a1 a1  and  a1 a1  . we report query performance for both scenarios.
figure 1: partial at- figure 1: execution tributes in ranking time w.r.t. t
figure 1:	construction	figure 1:	size of join-
time w.r.t. t	signatures w.r.t. t
모
모figure 1 shows the execution time on a synthetic data set with 1 dimensions. we did not report results of bl  because bl generates too many states and runs out of memory. although pe can effectively control the heap size  its execution time becomes worse than ts when k = 1. both pe+sig approaches run significantly faster. particularly  the pe+sig with three 1d join-signatures  although not as effective as that with one 1d join-signature  performs very well in pruning empty states.
모setting k = 1  we plot the peak heap sizes in figure 1 and the number of disk access in figure 1. clearly  the margin between pe and pe+sig becomes much larger comparing with that in 1-way index merge  figures 1 and 1 . this is because the space of joint state grows exponentially with the number of merging indices. consequently  both cpu cost for state search and i/o cost for index node retrieval are higher. moreover  given the large number of candidate states  the probability that a state is not empty drops exponentially. pe+sig achieves significant gain by pruning empty states. we also observe that in both pe+sig approaches  the number of join-signature requests is several times less than that of index node requests.
1.1 index configuration
모having observed that merging multiple indices introduces high computational complexity in the above subsection  here we discuss how to alleviate the challenges with proper index configuration. suppose the database consists m dimensions  and the query attributes are randomly selected. one can build m b+-trees on each attribute. alternatively  one can group attributes with size r and build -trees on each group. for example  when m = 1  we can set r = 1 and build two r-tree indices.
모in section 1.1  we have shown that the ranking functions consisting 1 attributes can be answered fairly efficiently by merging r-tree indices  figure 1 . the experiments are conducted under the assumption that all attributes in r-trees are involved in ranking function. in contrast to using low dimensional indices to answer high-dimensional queries  it is interesting to further check whether the highdimensional indices  e.g.  r-tree  can efficiently process lowdimensional queries. we construct three sets of fs by selecting one  two and all attributes from each r-tree index  and run queries on the same data sets in figure 1. the experimental results of pe+sig  with k = 1  are shown in figure 1. not surprisingly  answering queries with full attributes is the most efficient. however  comparing with ts  the performance of partial attributes is still very attractive. for example  when m = 1 and r = 1  the execution time is around 1 seconds for one or two attributes. for the same query  ts needs more than 1 seconds.
모for some database with moderate number of ranking attributes  e.g.  1   our experiment results suggest that partitioning attributes into two groups and building r-tree index on each of them provides fairly robust query performance for queries involving any subset of attributes.
모as part of the index configuration  we also test the query performance by varying the index node size. typically  the node size is chosen from 1kb to 1kb. we generate a 1d synthetic data sets  and build b+-tree indices with size 1kb to 1kb on each attribute. the execution time for k = 1 is shown in figure 1. with smaller node size  the number of nodes increases  and so does the number of empty-states. on the other hand  with larger node size  the fanout of each node increases  and so does the number of states to be enumerated. in general  pe+sig considers both effects  and thus is not very sensitive to node size.
1.1 scalability
모the final set of experiments is to study the scalability of the proposed methods. we use synthetic data set with 1 b+tree indices  and vary the number of tuples from 1m to 1m. the query execution time  with k = 1  in figure 1 shows that all methods scale quite well. besides the online query performance  we also report the construction and space costs for the join-signature in figures 1 and 1. to compare with  we plot the query execution time used by ts in figure 1  which shows that the join-signature can be computed fairly efficiently in that it is comparable to table scan. we also compare the size of the join-signature with the size of one b+-tree index in figure 1  and observe that the size of join-signature is at least 1 times smaller.
1. discussion
모we discuss two extensions of the proposed methods:  1  merging indices from multiple relations  and  1  using the index-merge framework to answer other preference queries.
1 merge indices from multiple relations
모the methods developed in this paper can also be used to merge indices from multiple relations. particularly  we discuss how to extend the method to join primary keys and foreign keys. assume primary keys and foreign keys are stored together with attribute values in the leaf index nodes. thus the join condition can be evaluated during index merge.
모while the double heap algorithm with progressive expansions can be directly used  there is a small variation to com-
모
pute the join-signatures. to construct the join-signature of index a from relation r1 and index b from relation r1  we can first compute paths with respect to both indices for each tuple. suppose each tuple in r1 is associated with a path patha and each tuple in r1 is associated with a path pathb. we then conduct a sort-merge join on r1 and r1  and keep both patha and pathb in the join results in r1. the method presented in section 1 can be applied on r1 to compute the join-signature.
1 general preference queries
모top-k queries are related to several other preference queries  such as skyline query  and convex hulls . skyline query asks for the objects that are not dominated by any other object in all dimensions. a convex hull query searches a set of points that forms a convex hull of all the other data objects. the methodology developed in this paper is also applicable to these queries. the key observation is that all the queries can be processed progressively in the top-down fashion. for demonstration  we discuss how to apply our method for skyline computation as follows. the method for convex hull queries is similar.
모in   papadias et al. developed a branch-and-bound search algorithm that progressively retrieves r-tree nodes  from root to leaves  until all the skylines are found. at any stage  if a nodes n is dominated by a data object  all the child nodes of n can be pruned. the same rule can be applied on the state space in this paper: if a state s is dominated by a data object  all the child states of s can be pruned. as soon as all the states in the global heap are pruned  the search for the skyline objects halts. the join-signature can be used without any modification  since the empty-states do not contribute to the final results either.
모the progressive expansion methods are also applicable in skyline computation. let n and n be the maximal and minimal attribute values among the region covered by n. given a state s =  a1 b1   with child nodes  a1 a1 ... an  and  b1 b1 ... bm   we sort ai and bi according to ai and bi  respectively. similar to the threshold expansion in section 1  we can progressively generate child states until a threshold position  r t   such that there exists a generated child state


c =  a  b   satisfying a  뫞 ar and b  뫞 bt. consequently  the s.get next method returns all the generated child states  instead of one child state in top-k query  and updates s's coordinate values as ar and bt.
1. conclusions
모for efficient query processing  we address two challenges within the index-merge paradigm. first  to reduce the search complexity  we develop a double heap algorithm that consists of the neighborhood expansion and the threshold expansion. second  to avoid retrieving empty-state  we propose join-signature which is compact  easy to compute and incurs low overhead in query processing. our performance evaluation shows that the proposed solutions improves the baseline solution by one order of magnitude.
모there are many interesting research issues on further extensions of the index-merge methodology. for example  it will be useful to build a unified cost model for both state search and disk access so that the query processing can achieve the overall best performance. another interesting problem is to further improve the index configuration by leveraging the workload information.
