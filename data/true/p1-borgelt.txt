the fp-growth algorithm is currently one of the fastest approaches to frequent item set mining. in this paper i describe a c implementation of this algorithm  which contains two variants of the core operation of computing a projection of an fp-tree  the fundamental data structure of the fp-growth algorithm . in addition  projected fp-trees are  optionally  pruned by removing items that have become infrequent due to the projection  an approach that has been called fp-bonsai . i report experimental results comparing this implementation of the fp-growth algorithm with three other frequent item set mining algorithms i implemented  apriori  eclat  and relim .
1. introduction
one of the currently fastest and most popular algorithms for frequent item set mining is the fp-growth algorithm . it is based on a prefix tree representation of the given database of transactions  called an fp-tree   which can save considerable amounts of memory for storing the transactions. the basic idea of the fp-growth algorithm can be described as a recursive elimination scheme: in a preprocessing step delete all items from the transactions that are not frequent individually  i.e.  do not appear in a user-specified minimum number of transactions. then select all transactions that contain the least frequent item  least frequent among those that are frequent  and delete this item from them. recurse to process the obtained reduced  also known as projected  database  remembering that the item sets found in the recursion share the deleted item as a prefix. on return  remove the processed item also from the database of all transactions and start over  i.e.  process the second frequent item etc. in these processing steps the prefix tree  which is enhanced by links between the branches  is exploited to quickly find the transactions containing a given item and also to remove this item from the transactions after it has been processed.
in this paper i describe an efficient c implementation of the fp-growth algorithm. in section 1 i briefly review how the transaction database is preprocessed in a way that is common to basically all frequent item set mining algorithms. section 1 explains how the initial fp-tree is built from the  preprocessed  transaction database  yielding the starting point of the algorithm. the main step is described in section 1  namely how an fp-tree is projected in order to obtain an fp-tree of the  sub- database containing the transactions with a specific item  though with this item removed . the projection step is the most costly in the algorithm and thus it is important to find an efficient way of executing it. section 1 considers how a projected fp-tree may be further pruned using a technique that has been called fp-bonsai . such pruning can sometimes shrink the fp-tree considerably and thus lead to much faster projections. finally  in section 1 i report experiments with my implementation  comparing it with my implementations  1  1  of the apriori  1  1  and eclat  algorithms.
1. preprocessing
similar to several other algorithms for frequent item set mining  like  for example  apriori or eclat  fp-growth preprocesses the transaction database as follows: in an initial scan the frequencies of the items  support of single element item sets  are determined. all infrequent items-that is  all items that appear in fewer transactions than a user-specified minimum number-are discarded from the transactions  since  obviously  they can never be part of a frequent item set.
in addition  the items in each transaction are sorted  so that they are in descending order w.r.t. their frequency in the database. although the algorithm does not depend on this specific order  experiments showed that it leads to much shorter execution times than a random order. an ascending order leads to a particularly slow operation in my experiments  performing even worse than a random order.  in this respect fp-growth behaves in exactly the opposite way as apriori  which in my implementation usually runs fastest if items are sorted ascendingly  but in the same way as eclat  which also profits from items being sorted descendingly. 

permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee.
osdm'1  august 1  1  chicago  illinois  usa.
copyright 1 acm 1-1/1 ...$1.
this preprocessing is demonstrated in table 1  which shows an example transaction database on the left. the frequencies of the items in this database  sorted descendingly  are shown in the middle of this table. if we are given a user specified minimal support of 1 transactions  items f and g can be discarded. after doing so and sorting the items in each transaction descendingly w.r.t. their frequencies we obtain the reduced database shown in table 1 on the right.
d1b1c1a1e1f1g1a d fd a a c d ed c a e
b dd b b c dd b c
b cb c a b dd b a b d ed b e b c e gb c e
c d f a b dd c d b atable 1: transaction database  left   item frequencies  middle   and reduced transaction database with items in transactions sorted descendingly w.r.t. their frequency  right .

figure 1: fp-tree for the  reduced  transaction database shown in table 1.
1. building the initial fp-tree
after all individually infrequent items have been deleted from the transaction database  it is turned into an fp-tree. an fp-tree is basically a prefix tree for the transactions. that is  each path represents a set of transactions that share the same prefix  each node corresponds to one item. in addition  all nodes referring to the same item are linked together in a list  so that all transactions containing a specific item can easily be found and counted by traversing this list. the list can be accessed through a head element  which also states the total number of occurrences of the item in the database. as an example  figure 1 shows the fp-tree for the  reduced  database shown in table 1 on the right. the head elements of the item lists are shown to the left of the vertical grey bar  the prefix tree to the right of it.
in my implementation the initial fp-tree is built from a main memory representation of the  preprocessed  transaction database as a simple list of integer arrays. this list is sorted lexicographically  thus respecting the order of the items in the transactions  which reflects their frequency . the sorted list can easily be turned into an fp-tree with a straightforward recursive procedure: at recursion depth k  the k-th item in each transaction is used to split the database into sections  one for each item. for each section a node of the fp-tree is created and labeled with the item corresponding to the section. each section is then processed recursively  split into subsections  a new layer of nodes  one per subsection  is created etc. note that in doing so one has to take care that transactions that are only as long as the current recursion depth are handled appropriately  that is  are removed from the section before going into recursion.
of course  this is not the only way in which the initial fptree can be built. at first sight it may seem to be more natural to build it by inserting transaction after transaction into an initially empty fp-tree  creating the necessary nodes for each new transaction. indeed  such an approach even has the advantage that the transaction database need not be loaded in a simple form  for instance  as a list of integer arrays  into main memory. since only one transaction is processed at a time  only the fp-tree representation and one new transaction is in main memory. this usually saves space  because an fp-tree is often a much more compact representation of a transaction database.
nevertheless i decided against such a representation for the following reasons: in order to build a prefix tree by sequentially adding transactions  one needs pointers from parent nodes to child nodes  so that one can descend in the tree according to the items present in the transaction. however  this is highly disadvantageous. as we will see later on  the further processing of an fp-tree  especially the main operation of projecting it  does not need such parent-to-child pointers in my implementation  but rather child-to-parent pointers. since each node in an fp-tree  with the exception of the roots  has exactly one parent  this  in principle  makes it possible to work with nodes of constant size. if  however  we have to accomodate an array of child pointers per node  the nodes either have variable size or are unnecessarily large  because we have pointers that are not needed   rendering the memory management much less efficient.
it has to be conceded  though  that instead of using an array of child pointers  one may also link all children into a list. this  however  has the severe disadvantage that when inserting transactions into the fp-tree  one such list has to be searched  linearly!  for each item of the transaction in order to find the child to go to-a possibly fairly costly operation.
in contrast to this  first loading the transaction database as a simple list of integer arrays  sorting it  and building the fp-tree with a recursive function  as outlined above   makes it possible to do without parent-to-child pointers entirely. since the fp-tree is built top down  the parent is already known when the children are created. thus it can be passed down in the recursion  where the parent pointers of the children are set directly. as a consequence  the nodes of the fp-tree can be kept very small. in my implementation  an fp-tree node contains only fields for  1  an item identifier   1  a counter   1  a pointer to the parent node   1  a pointer to the successor node  referring to the same item  and  1  an auxiliary pointer that is used when projecting the fp-tree  see below . that is  an fp-tree node needs only 1 bytes  on a 1 bit machine .
however  if we used the standard memory management  allocating a block of memory for each node  there would be an additional overhead of 1 to 1 bytes  depending on the memory system implementation  for each node for bookkeeping purposes  for instance  for storing the size of the memory block . in addition  allocating and deallocating a large number of such small memory blocks is usually not very efficient. therefore i use a specialized memory management in my implementation  which makes it possible to efficiently handle large numbers of equally sized small memory objects. the idea is to allocate larger arrays  with several thousand elements  of these objects and to organize the elements into a  free  list  i.e.  a list of available memory blocks of equal size . with such a system allocating and deallocating fp-tree nodes gets very efficient: the former retrieves  and removes  the first element of the free list  the latter adds the node to deallocate at the beginning of the free list. as experiments showed  introducing this specialized memory management led to a considerable speed-up.
1. projecting an fp-tree
the core operation of the fp-growth algorithm is to compute an fp-tree of a projected database  that is  a database of the transactions containing a specific item  with this item removed. this projected database is processed recursively  remembering that the frequent item sets found in the recursion share the removed item as a prefix.
my implementation of the fp-growth algorithm contains two different projection methods  both of which proceed by copying certain nodes of the fp-tree that are identified by the deepest level of the fp-tree  thus producing a kind of  shadow  of it. the copied nodes are then linked and detached from the original fp-tree  yielding an fp-tree of the projected database. afterwards the deepest level of the original fp-tree  which corresponds to the item on which the projection was based  is removed  and the next higher level is processed in the same way. the two projections methods differ mainly in the order in which they traverse and copy the nodes of the fp-tree  branchwise vs. levelwise .
the first method is illustrated in figure 1 for the example fp-tree shown in figure 1. the red arrows show the flow of the processing and the blue  shadow  fp-tree is the created projection. in an outer loop  the lowest level of the fp-tree  that is  the list of nodes corresponding to the projection item  is traversed. for each node of this list  the parent pointers are followed to traverse all ancestors up to the root. each encountered ancestor is copied and linked from its original  this is what the auxiliary pointer in each node  which was mentioned above  is needed for . during the copying  the parent pointers of the copies are set  the copies are also organized into level lists  and a sum of the counter values in each node is computed in head elements for these lists  these head elements are omitted in figure 1 .
note that the counters in the copied nodes are determined only from the counters in the nodes on the deepest level  which are propagated upwards  so that each node receives the sum of its children. note also that due to this we cannot stop following the chain of ancestors at a node that has already been copied  even though it is clear that in this case all ancestors higher up in the fp-tree must already have been copied. the reason is that one has to update the number of transactions in the copies  adding the counter value from the current branch to all copies of the ancestors on the path to the root. this is what the second projection method tries to improve upon.
in a second traversal of the same branches  carried out in exactly the same manner  the copies are detached from their originals  the auxiliary pointers are set to null   which yields the independent projected fp-tree shown in figure 1. this

figure 1: computing a projection of the database w.r.t. the item e by traversing the lowest level and following all paths to the root.
figure 1: resulting projected fp-tree after it the original fp-tree.
fp-tree is then processed recursively with the prefix e. note  however  that in this fp-tree all items are infrequent  and thus all item sets containing item e and one other item are infrequent . hence in this example  no recursive processing would take place. this is  of course  due to the chosen example database and the support threshold.
the second projection method also traverses  in an outer loop  the deepest level of the fp-tree. however  it does not follow the chain of parent pointers up the root  but only copies the parent of each node  not its higher ancestors. in doing so  it also copies the parent pointers of the original fpnodes  thus making it possible to find the ancestors in later steps. these later steps consist in traversing the levels of the  partially constructed   shadow  fp-tree  not the levels of the original one!  from bottom to top. on each level the parents of the copied nodes  which are nodes in the original tree  are determined and copied  and the parent pointers of the copies are set. that is  instead of branch by branch  the fp-tree is rather constructed level by level  even though in each step nodes on several levels may be created . the advantage of this method over the one described above is that for branches that share a path close to the root  this common path has to be traversed only once with this method  as the counters for all branches are summed before they are passed to the next higher level . however  the experiments reported below show that the first method is superior in practice. as it seems  the additional effort needed for temporarily setting another parent etc. more than outweighs the advantage of the better combination of the counter values.
1. pruning a projected fp-tree
after we obtained an fp-tree of a projected database  we may carry out an additional pruning step in order to simplify the tree  thus speeding up projections. i got this idea from   which introduces pruning techniques in a slightly different context than pure frequent item set mining  suffice it to say that there are additional constraints . one of these techniques  however  can nevertheless be used here  a:1a:1 b:1b:1 c:1c:1 d:1d:1
figure 1: ¦Á-pruning of a  projected  fp-tree.

figure 1: results on bms-webview-1
namely the so-called ¦Á-pruning. the idea of this pruning is illustrated with a very simple example in figure 1. suppose that the fp-tree shown on the left resulted from a projection and that the minimum support is either 1 or 1. then item b is infrequent and is not needed in projections. however  it gives rise to a branching in the tree. hence  by removing it  the tree can be simplified and actually turned into a simple list  as it is shown on the right in figure 1.
this pruning is achieved by traversing the levels of the fptree from top to bottom. the processing starts at the level following the first level that has a non-vanishing support less than the minimum support.  items having vanishing support can be ignored  because they have no nodes in the fp-tree.  this level and the following ones are traversed and for each node the first ancestor with an item having sufficient support is determined. the parent pointer is then updated to this ancestor  bypassing the nodes corresponding to infrequent items. if by such an operation neighboring nodes receive the same parent  they are merged. they are also merged  if their parents were different originally  but have been merged in a preceding step. as an illustration consider the example figure 1: after item b is removed  the two nodes for item c can be merged. this has to be recognized in order to merge the two nodes for item d also.
1. experimental results
i ran experiments on the same five data sets that i already used in  1  1   namely bms-webview-1   t1d1k   census  chess  and mushroom . however  i used a different machine and an updated operating system  namely a pentium 1c 1ghz system with 1 gb of main memory running s.u.s.e. linux 1 and gcc version 1.1 . the results were compared to experiments with my implementations of apriori  eclat  and relim. all experiments were rerun to ensure that the results are comparable.
figure 1: results on t1d1k
figure 1: results on census
figure 1: results on chess
figure 1: results on mushroom figures 1 to 1 show  each for one of the five data sets  the decimal logarithm of the execution time over different  absolute  minimum support values. the solid black line refers to the implementation of the fp-growth algorithm described here  the dotted black line to the version that uses the alternative projection method. the grey lines represent the corresponding results for apriori  solid line   eclat  dashed line   and relim  dotted line .1
among these implementations  all of which are highly optimized  fp-growth clearly performs best. with the exception of the artificial dataset t1d1k  on which it is bet by a considerable margin by relim  and for higher support values on bms-webview-1  where relim also performs slightly better  presumably  because it does not need to construct a prefix tree   fp-growth is the clear winner. only on chess  eclat can come sufficiently close to be called competitive.
the second projection methods for fp-trees  dotted black line  generally fares worse  although there is not much difference between the two methods on chess and mushroom. this is a somewhat surprising result  because there are good reasons to believe that the second projection method may be able to yield better results than the first. i plan to examine this issue in more detail in the future.
1. conclusions
in this paper i described an implementation of the fpgrowth algorithm  which contains two methods for efficiently projecting an fp-tree-the core operation of the fp-growth algorithm. as the experimental results show  this implementation clearly outperforms apriori and eclat  even in highly optimized versions. however  the performance of the two projection methods  especially  why the second is sometimes much slower than the first  needs further investigation.
1. program
the implementation of the fp-growth algorithm described in this paper  windowstm and linuxtm executables as well as the source code  distributed under the lgpl  can be downloaded free of charge at http://fuzzy.cs.uni-magdeburg.de/ borgelt/software.html
at this url my implementations of apriori  eclat  and relim are also available as well as a graphical user interface  written in java  for finding association rules with apriori.
