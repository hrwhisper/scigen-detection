mobile devices will become an important platform for internet access. due to size constraints  in many circumstances speech is the most desirable mode of input. we have developed a system for spoken query based web navigation and searching. the spoken query is recorded by a lightweight client and transmitted to a server where the computationally intensive continuous speech recognition and query execution are performed. lightweight clients have been developed that can either be a small downloadable active x component running within a browser or a small application running on a handheld pocketpc. through these interfaces  users can search for contents in an encarta encyclopedia  content of a particular website  or navigate to popular websites.
keywords
mobile devices; multimodal user interface; information retrieval; speech recognition.
1. introduction
the next generation of internet devices will be mobile. the number of mobile handsets already exceeds the number of desktop computers. as existing technologies such as wap and ntt docomo's i-mode proliferate  the mobile web will become increasingly more ubiquitous.
a major barrier to usability of these mobile platforms is their user interface. because of their small form factor  tiny keypads or small styluses are typically used today  and text input is inconvenient  especially when searching for information . given the constraints of existing input modalities  speech provides a compelling solution. we envision that the next generation of mobile devices will include a multi-modal user interface  with keypads  styluses and touch screens used for selection type actions  and speech used for data entry .
we have developed a distributed client-server search system that uses a combination of spoken queries with a traditional ui for navigation of the search results. previous work on using voice for web browsing concentrated on using voice to access items on one's favorites list and selecting hotlinks on the current page. while the voice driven browsers are definitely useful in cases when the keyboard is not accessible  when a keyboard is available  the gain from using voice to drive the browser is more limited. in this paper  we focus on using voice to browse and search for information on the internet. the distinction is that the information to be browsed or searched reside on a server rather on the local machine used for browsing. our client uses an activex component to digitize speech  which is sent to a server application that uses microsoft's sapi sr engine to process the sampled speech . our system uses automatically constructed index and can operate in a chinese or english mode. we have also developed a client that runs on a pocketpc which communicates to the server through a wired or wireless network connection.
past work on voice-controlled web browsers has focused on using voice control as a replacement for a point and click user interface . for example  a user may say  back  and
 bookmark this page  or activate hyperlinks and hot list entries by reading their text. none of the systems we examined support dictation to complete form fields  which is precisely the most difficult task to accomplish on mobile devices.
from the information retrieval community  the most relevant area of research is spoken document retrieval  sdr . sdr is concerned with the recall of spoken documents  such as broadcast news or voicemail. sdr is essentially the inverse problem to our system  which is termed spoken query retrieval  sqr 
1. system description
figure 1 illustrates the current system. the client can be connected to the server through a wired or wireless network. the server returns result to spoken queries through matching the result of a speech recognition system with indices automatically generated by a separate crawler and indexer.

figure 1.	block diagram of the whole system.
1 crawling for content
the primary index used by our system is a mapping from urls to sets of optionally weighed keywords  with the index stored as a tab and space delimited flat text file. this choice of representation allows us to easily create indices during early phases of development. a website is crawled by a crawler  the html pages are sent to the indexer for indexing.
1 building an index
once the crawler has retrieved the html content to the file system  keywords are extracted from the text of the html.
first  the html is parsed  and blocks of text are extracted. the blocks of text are then segmented into tokens. during the parse of html  the title of the page  if present  is extracted and recorded.
for english pages  the blocks of text are segmented into tokens based on white space and punctuation. any purely or partially numerical  such as  y1k   terms are discarded  and words are converted to lower case. stopword removal is performed using a list of 1 terms from the smart system . for chinese pages  the blocks of text are segmented using a segmenter developed internally. during segmentation non-chinese terms are discarded  and after segmentation any numerical terms are removed. stopword removal is also performed using a list of 1 commonly occurring chinese words .
after keyword extraction has been completed  a flat text file containing a mapping from urls to keywords and their frequencies of occurrence is created. during this procedure  the keyword frequencies are transformed to weights according to the tfidf metric  one of the commonly used term-weighting metrics from information retrieval.
the output of the keyword weighting procedure is a file where each term is assigned a decimal normalized weight  and another file that contains the inverse document frequencies for each term in the vocabulary.
the server performs the computationally intensive continuous speech recognition  and executes retrieval using a vector space model. the server accepts tcp connections on a pre-specified socket. when the client connects  it transmits the audio data to the server. the server then passes the audio data to sapi based speech recognition server  which performs the csr. the output of sapi sr server is used to form the query  which is executed in a vector space model search engine. the hits are sent to client on the same tcp connection in text format  and then the server closes the connection.
speaker-independent continuous speech recognition is performed by microsoft's speech recognition engine  which is accessed through microsoft speech api  sapi . the sr engine operates in dictation mode  with lexicon adaptation performed using the keywords extracted from the website. because current sr engines are monolingual  the server can currently answer either chinese or english queries  but the languages cannot be intermixed.
we use the vector space model for information retrieval  where documents  urls  and queries are represented a vectors in high dimensional spaces where each dimension corresponds to a keyword. to execute a query  the similarity of the documents to the queries is computed by taking the cross product of word frequency vector in the query sentences and the word weighting vector for each document. the top n-ranked documents are returned to the client in a buffer  whose format is the title  followed by a tab character  followed by the url.
1 client processes

abc	1a	1b
figure 1. 1a shows the architecture of the client  1b shows the appearance of the client to a user of the system.
the voice search client is a combination of html  javascript and an activex component written with vc++. the architecture and visual appearance of the client are shown in figures 1a and 1b. a frameset with three frames constitutes the user interface. frame  a  contains the activex control and instructions on how to use the system. frame  b  is used to display the results of a search. frame  c  is used to navigate to the pages in the result set.
to perform a query  the user clicks the left mouse button on a button on an activex control and speaks the query. as the user speaks  they can see visual feedback in the form of a waveform monitor in the activex control. the speech data is transmitted to the server on a pre-specified tcp port. the activex control downloads the results returned by the server and raises an event in the javascript.
a javascript fragment responds to the event raised by the activex control  and retrieves the raw results from the control. the javascript formats the  title  url  pairs returned by the server into hyper linked html and shows them in frame b.
1. result and discussion
the work that we carried out thus far has demonstrated the feasibility of spoken query web search. users can ask for information from an encarta website such as  tell me something about cats  and receive an html page containing links to articles related to cats. currently  the accuracy of spoken queries is not as good as perfect text input due to misrecognitions. however  the ease of speaking can persuade the user to speak more search words  which can improve retrieval results. we also plan to study techniques for improving the accuracy of speech recognition  such as updating the language model used by the speech recognition engine in addition to updating the lexicon in a domain dependent fashion and indexing the content of the server in multiple levels of detail  ranging from phones  syllables  words  to phrases
the preliminary signal processing can be incorporated into the client  including feature vector computation . if the processing is done on the client side  the bandwidth requirements are modest  and could be supported by present generation of cellular networks. this is an area we plan to pursue in future work.
larger scale user studies need to be conducted to see how users would interact with a spoken language search engine. we may be able to identify a small collection of query formulations that could be incorporate into a hybrid cfg/lm csr system developed for the mipad project . this will provide the system with the ability to better handle common phrases such as  what is  and  tell me . we will also study how users interact with a mobile device in a multimodal fashion  where by allowing the user to speak the query and point to the correct result among the list provided by the server  the most efficient form of interaction becomes possible.
