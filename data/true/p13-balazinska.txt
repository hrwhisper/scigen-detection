we present a replication-based approach to fault-tolerant distributed stream processing in the face of node failures  network failures  and network partitions. our approach aims to reduce the degree of inconsistency in the system while guaranteeing that available inputs capable of being processed are processed within a specified time threshold. this threshold allows a user to trade availability for consistency: a larger time threshold decreases availability but limits inconsistency  while a smaller threshold increases availability but produces more inconsistent results based on partial data. in addition  when failures heal  our scheme corrects previously produced results  ensuring eventual consistency.
　our scheme uses a data-serializing operator to ensure that all replicas process data in the same order  and thus remain consistent in the absence of failures. to regain consistency after a failure heals  we experimentally compare approaches based on checkpoint/redo and undo/redo techniques and illustrate the performance trade-offs between these schemes.
1. introduction
　in recent years  a new class of data-intensive applications requiring near real-time processing of large volumes of streaming data has emerged. these stream processing applications arise in several different domains  including computer networks  e.g.  intrusion detection   financial services  e.g.  market feed processing   medical information systems  e.g.  sensor-based patient monitoring   civil engineering  e.g.  highway monitoring  pipeline health monitoring   and military systems  e.g.  platoon tracking  target detection .
　in all these domains  stream processing entails the composition of a relatively small set of operators  e.g.  filters  aggregates  and correlations  that perform their computations on windows of data that move with time. most stream processing applications require results to be continually produced at low latency  even in the face of high and variable input data rates. as has been widely noted  1  1  1   traditional data base management systems  dbmss  based on
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage  and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee.
sigmod 1 june 1  1  baltimore  maryland  usa.
copyright 1 acm 1-1/1 $1.
the  store-then-process  model are inadequate for such highrate  low-latency stream processing.
　stream processing engines  spes   also known as data stream managers  1  1  or continuous query processors   are a class of software systems that handle the data processing requirements mentioned above. much work has been done on data models and operators  1  1  1  1  1   efficient processing  1  1  1  1   and resource management  1  1  1  1  1  for spes. stream processing applications are inherently distributed  both because input streams often arrive from geographically distributed data sources  and because running spes on multiple processing nodes enables better performance under high load  1  1 . in a distributed spe  each node produces result streams that are either sent to applications or to other nodes for additional processing. when a stream goes from one node to another  the nodes are called upstream and downstream neighbors.
　in this paper  we add to the body of work on spes by addressing fault-tolerant stream processing  presenting a faulttolerance protocol  implementation details  and experiments. our approach enables a distributed spe to cope with a variety of network and system failures. it differs from previous work on high availability in streaming systems by offering a configurable trade-off between availability and consistency. previous schemes either do not address network failures  or strictly favor consistency over availability  by requiring at least one fully connected copy of the query network to exist to continue processing at any time . as such  our scheme is particularly well-suited for applications where it is possible to make significant progress even when some of the inputs are unavailable.
　as in most previous work on masking software failures  we use replication   running multiple copies of the same query network on distinct processing nodes. in our approach  when a node stops receiving data  or  heartbeat  messages signifying liveness  from one of its upstream neighbors  it requests the missing input streams from a replica of that neighbor  if it can find one . for a node to be able to correctly continue processing after such a switch  all replicas of the same processing node must be consistent with each other. they must process their inputs in the same order  progress at roughly the same pace  and their internal computational state must be the same. to ensure replica consistency  we define a simple data-serializing operator  called sunion  that takes multiple streams as input and produces one output stream with deterministically ordered tuples.
　at the same time  if a node is unable to find a new upstream neighbor for an input stream  it must decide whether to continue processing with the remaining  partial  inputs  or block until the failure heals. if it chooses to continue  a number of possibly incorrect results will be produced  while blocking makes the system unavailable.
　our approach gives the user explicit control of trade-offs between consistency and availability in the face of network failures  1  1 . we also ensure eventual consistency: i.e.  clients eventually see the complete correct results. we introduce an enhanced streaming data model in which results based on partial inputs are marked as tentative  with the understanding that they may subsequently be modified; all other results are considered stable and immutable.
　to provide high availability  each spe processes input data and forwards results within a user-specified time threshold of arrival  even if other inputs are currently unavailable. at the same time  to prevent downstream nodes from unnecessarily having to react to tentative data  an spe tries to avoid or limit the number of tentative tuples it produces. when a failure heals  each spe that processed tentative data reconciles its state by re-running its computation on the correct input streams. while correcting its internal state  the replica also stabilizes its output by replacing the previously tentative output with stable data tuples  allowing downstream neighbors to reconcile in turn. we argue that traditional approaches to record reconciliation  1  1  are illsuited for streaming systems  and adapt two approaches similar to known checkpoint/redo and undo/redo schemes  1  1  1  1  1  to allow spes to reconcile their states.
　our fault-tolerance protocol addresses the problem of minimizing the number of tentative tuples while guaranteeing that the results corresponding to any new tuple are sent downstream within a specified time threshold. the ability to trade availability  via a user-specified threshold  for consistency  measured by the number of tentative result tuples  since that is often a reasonable proxy for replica inconsistency  is useful in many streaming applications where having perfect answers at all times is not essential  see section 1 . our approach also performs well in the face of the non-uniform failure durations observed in empirical measurements of system failures: most failures are short  but most of the downtime of a system component is due to longduration failures  1  1 .
　we have implemented our approach in borealis . through experiments  we show that borealis meets the required availability/consistency trade-offs for failures of variable duration  even when query networks span multiple nodes. we show that it is necessary to process new tuples both during failure and reconciliation to meet the availability requirement for long failures. we find that reconciliation based on checkpoint/redo outperforms reconciliation based on undo/redo because it incurs lower overhead and achieves faster recovery.
1. model  assumptions  and goals
　this section describes our distributed stream processing model  failure assumptions  and design goals.
1 query and failure model
　a loop-free  directed graph of operators that process data arriving on streams forms a query network. figure 1 illustrates a query network distributed across four nodes. in many stream processing applications  input streams arrive from multiple sources across the network  and are processed by a union operator that produces a fifo order of the in-

figure 1: query network in a distributed spe.
puts before further processing. these inputs may come directly from data sources  such as network monitors sending synopses of connection information or other activity  or may be the results of processing at upstream spe nodes.
　to avoid blocking in face of infinite input streams  operators perform their computations over windows of tuples. some operators  such as join  still block when some of their inputs are missing. in contrast  a union is an example of a non-blocking operator because it can perform meaningful processing even when some of its input streams are missing. in figure 1  the failure of a data source does not prevent the system from processing the remaining streams. failure of node 1 or 1 does not block node 1 but blocks node 1.
　because many stream processing applications are geared toward monitoring tasks  when a failure occurs upstream from a non-blocking operator and causes some  but not all  of its input streams to be unavailable  it is often useful to continue processing the inputs that remain available. for example  in a network monitoring application  even if only a subset of monitors are available  processing their data might suffice to identify some potential attackers or other network anomalies. in this application  low latency processing is critical to mitigate attacks. however  some events might go undetected because a subset of the information is missing  and some aggregate results may be incorrect. furthermore  the state of replicas diverges as they process different inputs.
　after a failure heals  previously unavailable data streams are made available again. to ensure that replicas become once again consistent with one another and that client applications eventually receive the complete correct streams  it is important to arrange for each node to correct its internal state and the output it produced during the failure.
1 failure assumptions
　our approach handles fail-stop failures  e.g.  software crashes  of processing nodes  network failures  and network partitions where any subset of nodes lose connectivity to one another. when each node has n replicas  including itself   we tolerate up to n   1 simultaneous node failures. we consider long delays as network failures.
　we assume that data sources and clients implement the fault-tolerance protocols described in the next section. this can be achieved by having clients and data sources use a fault-tolerant library or by having them communicate with the system through proxies  or nearby processing nodes  that implement the required functionality. we also assume that data sources  or proxies acting on their behalf  log input tuples persistently  e.g.  in a transactional queue   before transmitting them to all replicas that process the corresponding streams. a persistent log ensures that all replicas eventually see the same input tuples  in spite of proxy or data source failures. the fail-stop failure of a data source  however  causes the permanent loss of input tuples that would have otherwise been produced by the data source.
　our scheme is designed for a low level of replication and a low failure frequency. we assume that replicas have spare processing and bandwidth capacity and that they communicate using a reliable  in-order protocol like tcp.
1 design goals
　our goal is to ensure  for each node  that any data tuple on an input stream is processed within a specified time bound  regardless of whether failures occur on other input streams or not. among possible ways to achieve this goal  we seek methods that produce the fewest tentative tuples. if ntentative is the number of tentative tuples produced by a node and delaynew  the maximum delay for that node to process an input tuple and produce a result  our goal is for each node to minimize ntentative  subject to delaynew   x.
　x is a measure of the maximum processing latency that an application or user can tolerate to avoid inconsistency. different algorithms are possible to convert an end-to-end latency into a per-node delay. we do not discuss this assignment in this paper and assume each node is given x. the constraint on delaynew implies that a node cannot buffer inputs longer than αx  where αx   x   p and p is the normal processing delay. alternatively  x could express an
added delay  but we use the former definition in this paper.
　reducing ntentative reduces the amount of resources consumed by downstream nodes in processing tentative tuples. ntentative may also be thought of as a  crude  substitute for the degree of divergence between replicas when the set of input streams is not the same at the replicas.
　our approach ensures that as long as some path of nonblocking operators is available between one or more data sources and a client application  the client receives results. furthermore  our approach favors stable results over tentative results when both are available. once failures heal  we ensure that clients receive stable versions of all results  and that all replicas converge to a consistent state. we handle single failures and multiple overlapping  in time  failures.
1. approach
　this section describes our replication scheme and underlying algorithms. each node implements the state machine shown in figure 1 that has three states: stable  up-
stream failure  up failure   and stabilization.
　as long as all upstream neighbors of a node are producing stable tuples  the node is in the stable state. in this state  it processes tuples as they arrive and passes stable results to downstream neighbors. to maintain consistency between replicas that may receive inputs in different orders  we define a data-serializing operator  sunion. section 1 discusses the stable state and the sunion operator.
　if one input stream becomes unavailable or starts carrying tentative tuples  a node goes into the up failure state  where it tries to find another stable source for the input stream. if no such source is available  the node has three choices to process the remaining available input tuples:
1. suspend processing until the failure heals and the failed upstream neighbors start producing stable data again.
1. delay new tuples for a short period of time before processing.
1. process each new tuple without any delay.
　the first option favors consistency. it does not produce any tentative tuples and may be used only for short failures given our goal to process new tuples with bounded delay.

figure 1: the borealis state machine.
the latter two options both produce result tuples that are marked  tentative;  the difference between the options is in the latency of results and the number of tentative tuples produced. section 1 discusses the up failure state.
　a failure heals when a previously unavailable upstream neighbor starts producing stable tuples again or when a node finds another replica of the upstream neighbor that can provide the stable version of the stream. once a node receives the stable versions of all previously missing or tentative input tuples  it transitions into the stabilization state. in this state  if the node processed any tentative tuples during up failure it must now reconcile its state and stabilize its outputs. we explore two approaches for state reconciliation: a checkpoint/redo scheme and an undo/redo scheme. while reconciling  new input tuples are likely to continue to arrive. the node has the same three options mentioned above for processing these tuples: suspend  delay  or process without delay. our approach enables a node to reconcile its state and correct its outputs  while ensuring that new tuples continue to be processed. we discuss the stabilization state in section 1.
　once stabilization completes  the node transitions to the stable state if there are no other current failures  or back to the up failure state otherwise.
1 data model
　with our approach  nodes and applications must distinguish between stable and tentative results. stable tuples produced after stabilization may override previous tentative ones  requiring a node to correctly process these amendments. traditionally  a stream is an append-only sequence of tuples of the form:  t a1 ... am   where t is a timestamp value and a1 ... am are attribute values . to accommodate our new tuple semantics  we adopt and extend the borealis data model . in borealis  tuples take the form:
 tuple type tuple id tuple time a1 ... am 
1. tuple type indicates the type of the tuple.
1. tuple id uniquely identifies the tuple in the stream.
1. tuple time is the tuple timestamp. we discuss these timestamps further in section 1.
　traditionally  all tuples are immutable stable insertions. we introduce two new types of tuples: tentative and undo. a tentative tuple is one that results from processing a subset of inputs and may subsequently be amended with a stable version. an undo tuple indicates that a suffix of tuples on a stream should be deleted and the associated state of any operators rolled back. as illustrated in figure 1  the undo tuple indicates the suffix with the tuple id of the last tuple not to be undone. stable tuples that follow an undo replace the undone tentative tuples. applications that do not tolerate inconsistency may thus simply drop tentative and
undo tuples t1 through t1
	stable tuples	tentative tuples	corrections and new tuples
	s1	s1	t1	t1	t1	u1	s1	s1	...
time
figure 1: example of using tentative and undo tuples. u1 indicates that all tuples following tuple with tuple id 1  s1 in this case  should be undone.
tuple typedescriptiondata streamsstableregular tupletentativetuple that results from processing a subset of inputs and may be corrected laterundosuffix of tuples should be rolled backboundaryall following tuples will have a timestamp equal or greater to the one indicatedundo startcontrol message from runtime to sunion to trigger undo-based recoveryrec donetuple that indicates the end of reconciliationcontrol streamssignals from sunionup failureentering inconsistent staterec requestinput was corrected  can reconcile statetable 1: types of tuples
undo tuples. we use a few additional tuples types in our approach but they do not fundamentally change the data model. table 1 summarizes the new tuple types.
1 stable state
　an operator is deterministic if its results do not depend on the times at which its inputs arrive  e.g.  the operator does not use timeouts ; of course  the results will usually depend on the input data order. if all operators are deterministic  we only need to ensure that replicas of the same operator process data in the same order to maintain consistency; otherwise  the replicas will diverge even without failures.
　since nodes communicate with tcp  tuples never get reordered within a stream and the problem affects only operators with more than one input stream  e.g.  union and join . we thus need a way to order tuples deterministically across multiple input streams that feed the same operator. the challenge is that tuples on streams may not be sorted on any attribute and they may arrive at significantly-different rates. to compute an order without the overhead of interreplica communication  we propose a simple data-serializing operator  sunion. sunion takes multiple streams as input
and applies a deterministic sort function on buckets of tuples. sunion uses tuple time values to place tuples in buckets of statically defined sizes. the sort function later typically orders tuples by increasing tuple time values  but other functions are possible. to distinguish between failures and lack of data  data sources send periodic heartbeats in the form of boundary tuples. these tuples have tuple type = boundary and each data source guarantees that no tuples with tuple time smaller than the boundary's tuple time will be sent
after the boundary1. boundary tuples are similar to punctuation tuples  or heartbeats .
　figure 1 illustrates the serialization of three streams. tuples in bucket i can be sorted and forwarded as stable because boundary tuples with timestamps greater than the bucket boundary have arrived  in bucket i+1 . these bound-

figure 1: example of serialization of streams s1  s1  and s1 with boundary interval d. the t's denote tentative inserts and b's denote boundary tuples.
ary tuples make the bucket stable as they guarantee that no tuples are missing from the bucket. neither of the other buckets can be processed  since both buckets are missing boundary tuples and bucket i + 1 contains tentative tuples. sunion operators may appear at any location in a query network. operators must thus set tuple time values on their output tuples deterministically as these values will affect tuple order at downstream sunions. operators must also produce periodic boundary tuples and tuple time values in boundary tuples must be monotonically increasing. if output tuples are not ordered on tuple time values  boundary tuples must propagate through the query network to enable downstream operators to produce correct boundary tuples.
　sunion is similar to the input manager in stream   which sorts tuples by increasing timestamp order and deduces heartbeats if applications do not provide them. sunion  in contrast  ensures that replicas process tuples in the same order  distinguishes failures from delays  offers a flexible availability/consistency trade-off  as we discuss in the next section   and corrects input streams after failures heal. the input manager does not make such distinctions. it assumes that delays are bounded.
　a natural choice for tuple time is to use wall clock time. by synchronizing clocks at the data sources  tuples will get processed approximately in the order they are produced. the ntp  network time protocol   is standard today and implemented on most computers and essentially all servers. ntp synchronizes clocks to within 1 ms. wall-clock time is not the only possible choice  though. in borealis  any integer attribute can serve to define the windows that delimit operator computations. when this is the case  operators also assume that input tuples are sorted on that attribute and tolerate only limited re-ordering . hence  using the same attribute for tuple time as for windows helps enforce the ordering requirement.
　sunion operators delay tuples because they buffer and sort them. this delay depends on three properties of boundary tuples. first  the interval between boundary tuples with increasing tuple time values as well as the bucket size determine the average buffering delay. second  the buffering delay further increases with disorder. the increase is bounded above by the maximum delay between a tuple with a tuple time  t  and a boundary tuple with a tuple time   t. third  a bucket is stable only when boundary tuples with sufficiently high tuple time values appear on all streams input to the same sunion. the maximum differences in tuple time values across these streams bounds the added delay. because the query network typically assumes tuples are ordered on the attribute selected for tuple time  we can expect serialization
delays to be small in practice. in particular  these delays should be significantly smaller than the maximum processing delay  x.

figure 1: example of replicated spes. rij is the j'th replica of processing node i.
1 upstream failure
　each node monitors the availability and consistency of its input streams by periodically requesting heartbeat responses from each replica of each upstream neighbor. these responses not only indicate if a replica is reachable but include the states  stable  up failure  or stabilization  of its output streams. even though a node is in up failure  a subset of its outputs may be unaffected by the failure and may remain in the stable state. additionally  a node monitors the data it receives  namely the identifiers of the last stable and tentative input tuples on each input stream.
　with the above information  if an upstream neighbor is no longer in the stable state or is unreachable  the node can switch to another stable replica of that neighbor and continue receiving data from the correct point in the stream. if no stable replica is reachable  the node will try to continue from a replica in the up failure state to ensure the required availability. the result of these switches is that any replica can forward data streams to any downstream replica or client and the outputs of some replicas may not be used  as illustrated in figure 1. we further discuss switching between upstream neighbors in various consistency states in section 1.
　to enable such switches  every node buffers its output tuples. we assume that these buffers can hold more tuples than the maximum number that can be delivered during a single failure and recovery; we further discuss buffer management in section 1.
　if a node fails to find a stable replica to replace an upstream neighbor it can either block or continue processing the available tentative tuples or even continue with a missing input stream. blocking avoids inconsistency and is thus the best approach for failures shorter than αx. for longer failures  the node must eventually stop blocking new tuples to ensure the required availability. when this occurs  sunions serialize the available tuples  labelling them as tentative  and buffering them in preparation for future reconciliation  sunions monitor all input streams . in the example from figure 1 if the boundary for stream s1 does not arrive within αx of the time the first tuple entered bucket i+1 or bucket i + 1 still contains tentative tuples αx time units after the first tuple entered that bucket  sunion will store and forward the remaining tuples as tentative.
　as a node processes tentative tuples  its state may start to diverge. the node can do one of two things: delay new tuples as much as possible or process them without delay. continuously delaying new tuples reduces the number of tentative tuples produced during failure but it constrains what the node can do during stabilization  as we discuss next.
1 stabilization
　a node determines that a failure healed when it is able to communicate with a stable upstream neighbor and receives corrections to previously-tentative tuples  or a replay of previously missing inputs . to ensure eventual consistency  the node must then reconcile its state and stabilize its outputs. this means that the node replaces previously tentative result tuples with stable ones  thus allowing downstream neighbors to reconcile their states in turn. to avoid correcting tentative tuples with other tentative ones  a node reconciles its state only after correcting all its input streams. we present state reconciliation and output stabilization techniques in this section. we also present a technique that enables each node to maintain availability  meet the delaynew   x requirement  while reconciling its state.
1.1 state reconciliation
　because no replica may have the correct state after a failure and because the state of a node depends on the exact sequence of tuples it processed  we propose that a node reconcile its state by reverting it to a pre-failure state and reprocessing all input tuples since then. to revert to an earlier state  we explore two approaches: reverting to a checkpointed state or undoing the effects of tentative tuples. both approaches require that the node suspends processing new input tuples while reconciling its state.
　checkpoint/redo reconciliation. in this approach  a node periodically checkpoints the state of its query network when it is in stable state. sunions on input streams buffer input tuples between checkpoints and they continue to do so during up failure. these input tuples must be buffered because they will be replayed if the node restarts from the checkpoint. when a checkpoint occurs  however  sunion operators truncate all buckets that were processed before that checkpoint.
　to perform a checkpoint  a node suspends all processing and iterates through operators and intermediate queues to make a copy of their states. checkpoints could be optimized to copy only differences in states since the last checkpoint. we do not investigate this optimization and show  in section 1  that it is actually not needed. to reconcile its state  a node re-initializes operator and queue states from the checkpoint and reprocesses all buffered input tuples. to enable this approach  operators must thus be modified to include a method to take a snapshot of their state or reinitialize their state from a snapshot.
　undo/redo reconciliation. to avoid the cpu overhead of checkpointing and to recover at a finer granularity by rolling back only the state on paths affected by the failure  another approach is to reconcile by undoing the processing of tentative tuples and redoing that of their stable counterparts. with undo/redo  sunions on input streams only need to buffer tentative buckets  truncating stable ones as soon as they process them.
　to support such an approach  all operators should implement an  undo  method  where they remove a tuple from their state and  if necessary  bring some tuples previously evicted from the state back into the current window. supporting undo in operators may not be straightforward-for example  suppose an input tuple  p  caused an aggregate operator to close a window and output a value. to undo p  the aggregate must undo its output but must also bring back all the evicted tuples and reopen the window.
　instead  we propose that operators buffer their input tuples and undo by rebuilding the state that existed right before they processed the tuple that must now be undone. to determine how far back in history to restart processing from  operators maintain a set of stream markers for each input tuple. the stream markers for a tuple p in operator u are identifiers of the oldest tuples on each input stream that still contribute to the operator's state when u processes p. to undo the effects of processing all tuples following p  u looks up the stream markers for p  scans its input buffer until it finds that bound  and reprocesses its input buffer since then  stopping right after processing p. a stream marker is typically the beginning of the window of tuples to which p belongs. stream markers do not hold any state. they are pointers to some location in the input buffer. to produce the appropriate undo tuple  operators must store the last tuple they produced with each set of stream markers.
　operators that keep their state in aggregate form must explicitly remember the first tuple on each input stream that begins the current aggregate computation s . in the worst case  determining the stream markers may require a linear scan of all tuples in the operator's state. to reduce the runtime overhead  rather than compute stream markers for every tuple  operators may set stream markers periodically. this will increase reconciliation time  however  as re-processing will restart from an inexact marker.
1.1 stabilizing output streams
　independently of the approach chosen to reconcile the state  a node stabilizes each output stream by deleting a suffix of the stream  normally all tentative tuples  with a single undo tuple and forwarding corrections in the form of stable tuples. when it receives an undo tuple  an sunion at a downstream node stabilizes the corresponding input stream by replacing  in its buffer  undone tuples with their stable counterparts. once all input streams are corrected  sunions trigger a state reconciliation.
　with undo/redo  operators process and produce undo tuples  which simply propagate to downstream nodes. to generate an undo tuple with checkpoint/redo  we introduce a new operator  soutput  that we place on each output stream that crosses node boundary. at runtime  soutput acts as a pass-through filter that also remembers the last stable tuple it produced. during checkpoint recovery  soutput drops duplicate stable tuples and produces the undo tuple.
　stabilization completes when one of two situations occurs. the node re-processes all previously tentative input tuples and catches up with normal execution  i.e.  it clears its queues  or another failure occurs and the node goes back into up failure. once stabilization completes  a node transmits a rec done tuple to its downstream neighbors. soutput operators generate and forward the rec done tuples.
1.1 processing new tuples during reconciliation
　after long failures  the reconciliation itself may take longer than x. a node then cannot suspend new tuples while reconciling. it must produce both corrected stable tuples and new tentative tuples. we propose to achieve this by using two replicas of a query network: one replica remains in up failure state and continues processing new input tuples while the other replica performs the reconciliation. a node could run both versions locally but because we already use replication  we propose that replicas use each other as the two versions  when possible. by doing so  we never create new replicas in the system. hence  to ensure availability  before reconciling its state  a node must find another replica and request that it postpone its own reconciliation.
　it is up to each downstream node to detect when any one of its upstream neighbors goes into the stabilization state and stops producing recent tuples in order to produce corrections. the downstream node then remains connected to that replica to correct its input stream while at the same time  connecting to another replica that is still in up failure state  if possible . the downstream node processes both streams in parallel  until it receives a rec done tuple on the corrected stream. at this point  it enters the stabilization state  in turn. sunion considers that tentative tuples between an undo and a rec done correspond to the old failure while tentative tuples that appear after the rec done correspond to a new failure. we discuss how a node produces the correct rec done tuple in spite of failures during its recovery in section 1.
　once again  we have a trade-off between availability and consistency. suspending new tuples during reconciliation reduces the number of tentative tuples but may eventually break the availability requirement. processing new tuples during reconciliation increases the number of tentative tuples but a node may still attempt to reduce their number by delaying new tuples as long as possible. we compare these alternatives in section 1.
1.1 failed node recovery
　a failed node restarts from an empty state and refuses new clients until it processes sufficiently many tuples to reach a consistent state. this approach is possible when operators are convergent capable : i.e.  they keep a finite state that is also updated in a manner that always converges back to a consistent state. our schemes could be extended to other types of operators by recovering using a combination of persistent checkpoints and logging.
1 analysis
　we now discuss the main properties of our approach. to help us state these properties  we start with a few definitions. a data source contributes to a stream  s  if it produces a stream that becomes s after traversing some sequence of operators  called a path. the union of paths that connect a set of sources to a destination  a client or an operator   forms a tree. a tree is valid if paths that traverse the same operator also traverse the same replica of that operator. a valid tree is stable if it contains all data sources that contribute to the stream received by the destination. a stable tree produces stable tuples during execution. if any of the missing sources
from a tree would connect to it through non-blocking operators  the tree is tentative. otherwise  the tree is blocking. figure 1 illustrates each type of tree.
　property 1. in a static failure state  if there exists a stable tree  a destination receives stable tuples. if only tentative trees exist  the destination receives tentative tuples from one of the tentative trees. in both cases  the destination receives results within at most a kx time-unit delay  where x is the delay assigned to each sunion operator and k is the number of sunions on the longest path in the tree. in other cases 
the destination may block.
　the above property comes from the ability of downstream nodes to monitor and switch upstream neighbors  preferring stable ones over those in up failure state and those in up failure state over no input at all. we study the delay properties in section 1  where we assume that the number

figure 1: example trees for a query network with three sources  one client  a union  and a join. {s1 s1 s1} contributes to the stream received by c. each operator has two replicas.
of sunions is equal to the number of nodes. if this is not the case  the delay assigned to a node must be divided among the sequence of sunions at the node.
　property 1. switching between trees never causes duplicate results and may only lose tentative tuples.
　we discuss this property by examining each possible neighbor-switching scenario:
　1  switching between stable upstream neighbors: because the downstream node indicates the identifier of the last stable tuple it received  a new stable replica can continue from that point in the stream either by waiting to produce that tuple or replaying its output buffer.
　1  switching from a neighbor in up failure state to a stable upstream neighbor: in this situation  the downstream node indicates the identifiers of the last stable and tentative tuples it received. this allows the new upstream neighbor to stabilize the stream and continue with stable tuples.
　1  switching to an upstream neighbor in up failure state: because nodes cannot undo stable tuples  the new upstream and downstream pair may have to continue processing tuples while in mutually inconsistent states  which can lead to duplicate or missing results. we choose to avoid duplications as this leads to fewer tentative tuples. we add a second timestamp  t max to tuples. t max of a tuple p is the tuple time of the most recent input tuple that affected p. the new upstream node forwards only output tuples that have a t max greater than the highest t max that the downstream node previously received. these tuples necessarily result from processing at least a partially non-overlapping sequence of input tuples. other techniques are possible.
　1  if an upstream neighbor is in the stabilization state  a node treats the incoming stream as redundant information that serves to correct input streams in the background.
　property 1. as long as one replica of each processing node never fails  assuming all tuples produced during a failure are buffered  when all failures heal  the destination receives the complete stable stream.
　after a failure heals  each node reconciles its state and stabilizes its output  letting its downstream neighbors correct their inputs and reconcile in turn. this process propagates all the way to the clients.
property 1. stable tuples are never undone.
　we show that our approach handles failures during failures and recovery without the risk of undoing stable tuples.
　undo/redo reconciliation: as soon as an operator receives a tentative tuple  it starts labeling its output tuples as tentative. therefore  undoing tentative tuples can never cause a stable output to be undone. when reconciling  sunions produce undo tuples followed by the stable versions of tuples processed during the failure. any new tentative input tuples will thus be processed after the undo and stable tuples such that any new failure will follow the reconciliation  without affecting it. while an undo tuple propagates on a stream  if a different input stream becomes tentative  and both streams merge at an operator  the operator could see the new tentative tuples before the undo tuple. in this case  when the operator finally processes the undo tuple  it rebuilds the state it had before the first failure and processes all tuples that it processed during that failure before going back to processing the new tentative tuples. the operator thus produces an undo tuple followed by stable tuples that correct the first failure  followed by the tentative tuples from the new failure. once again  the new failure appears to occur after stabilization.
　checkpoint/redo: soutput guarantees that stable tuples are never undone. when restarting from a checkpoint  soutput enters a  duplicate elimination  mode. it remains in that state and continues waiting for the same last duplicate tuple until it produces the undo tuple  even if another checkpoint or recovery occurs. after producing the undo  soutput goes back to its normal state  where it remembers the last stable tuple that it sees and saves the identifier of that tuple during checkpoints.
　in both cases  if a new failure occurs before the node had time to catch up and produce a rec done tuple  soutput forces a rec done tuple between the last stable and first tentative tuples that it sees.
1. implementation
　to implement our scheme in borealis  in addition to inserting sunion and soutput operators into query networks  we add a consistency manager and an ha   high availability   component to each spe node. figures 1 and 1 illustrate these modifications  arrows indicate communication between components .
　ha monitors all the replicas of a node and those of its upstream neighbors. it informs the query processor of changes in the states of their outputs. to modify the data path  nodes send each other subscribe and unsubscribe messages.
　the consistency manager makes all decisions related to failure handling. in stable state  it periodically requests that the spe checkpoints the state of the query network. when the node must reconcile its state  the consistency manager asks a partner to suspend its own reconciliation and chooses whether to use undo/redo or checkpoint/redo. for undo/redo  the consistency manager injects undo start tuples on input streams of affected sunion operators. for checkpoint/redo  the consistency manager requests that the spe performs checkpoint recovery.
　in addition to their tasks described in previous sections  sunion and soutput communicate with the consistency manager through extra control output streams. when an sunion can no longer delay tuples  it informs the consistency manager about the up failure  by producing an up failure tuple on its control stream. similarly  when input streams are corrected and the node can reconcile its state  sunion produces a rec request tuple. once reconciliation finishes  soutput forwards a rec done tuple on its control and output streams.
we also require operators to implement a simple api. for

figure 1: extended software node architecture.
checkpoint/redo  operators need the ability to take snapshots and recover their state   un packstate methods . for undo/redo  operators must be able to correctly process undo tuples. at runtime  they must compute stream markers and remember the last tuple they output. this functionality can be implemented with a wrapper  requiring that the operator itself only implements two methods: clear   clears the operator's state and findoldesttuple int stream id  returns the oldest tuple from input stream  stream id  that is currently in the operator's state. to propagate boundary tuples  operators must implement the method findoldesttimestamp   that returns the oldest timestamp that the operator can still produce. this value is typically the smaller of the oldest timestamp present in the operator's state and the oldest timestamp in the boundary tuples received on all input streams.
1. evaluation
　in this section  we evaluate the performance of our faulttolerance protocol through experiments with our prototype implementation. all single-node experiments were performed on a 1 ghz pentium iv with 1 gb of memory running linux  fedora core 1 . multi-node experiments were performed by running each pair of node replicas on a different machine. all machines were 1 ghz pentium iv's or faster with greater than 1 gb of memory.
　our basic experimental setup is the following. we run a query network composed of three input streams  an sunion that merges these streams into one  a join that serves as a generic query network with a 1 tuple state size  and an soutput. the aggregate input rate is 1 tuples/s. we create a failure by temporarily disconnecting one of the input streams without stopping the data source. after the failure  we send all missing tuples while continuing to stream new tuples. x is 1 s. α is 1  so αx is 1 s . each result is an average of at least three experiments.
　we first examine the performance of a single borealis node in the face of temporary failures of its input streams. in particular  we compare in terms of delaynew and ntentative different strategies regarding suspending  delaying  and processing new tuples during up failure and stabilization. as we point out  some combinations are unviable as they break the availability requirement for sufficiently long failures. in these experiments  the node uses checkpoint/redo to reconcile its state. second  we examine the performance of our approach when failures and reconciliation propagate through a sequence of processing nodes. third  we compare the undo/redo and checkpoint/redo reconciliation tech-

figure 1: delaying tuples during up failure reduces
ntentative. y-axes: left delaynew  right ntentative. failure duration: 1 s.
niques. we finally discuss the overhead of our approach.
　in our prototype  it takes a node approximately 1 ms to switch between upstream neighbors. given that this value is small compared with αx  our system masks node failures within the required availability constraints. we thus focus the evaluation on failures of input streams.
1 single-node performance
　the optimal approach to handling failures shorter than αx is to delay processing new tuples until the failure heals. this is therefore always our first line of defense. when a failure exceeds αx  however  a node must restart processing new tuples to satisfy the availability requirement. it can either continuously delay new tuples by αx or catch-up and process new tuples almost as they arrive. we call these alternatives delay and process and examine their impact on delaynew and ntentative.
　we cause a 1 s failure  vary αx from 1 ms to 1 s  and observe delaynew and ntentative until after stabilization completes. figure 1 shows the results. from the perspective of our optimization  delay appears better than process as it leads to fewer tentative tuples. indeed  with process  as soon as the initial delay is small compared with the failure duration  αx ＋ 1 s for a 1 s failure   the node has time to catch-up and produces a number of tentative tuples almost proportional to the failure duration. the ntentative graph approximates a step function. in contrast  delay reduces the number of tentative tuples proportionally to αx. with both approaches  delaynew increases linearly with αx.
　for sufficiently long failures  however  reconciliation itself may last longer than x. to avoid breaking the availability requirement  a node must thus continue processing new tuples while reconciling. it can do so in one of several ways. during the failure  the node can either delay new tuples  delay  or process them without delay  process . during stabilization the node can either suspend new tuples  suspend   or have a second version of the spe continue processing them with or without delay  delay or process . our goal is to examine all six combinations and determine the failure durations when each one produces the fewest tentative tuples without breaking the availability requirement.
　figure 1 shows delaynew and ntentative for each combination and for increasing failure durations. we only show results for failures up to 1 minute. longer experiments continue the same trends. in this experiment  we increase the input rate to 1 tuples/s to emphasize differences between approaches.

figure 1: delaynew  top  and ntentative  bottom  for each combination of delaying  processing  and suspending during up failure and stabilization. each approach offers a different consistency-availability trade-off. x-axis starts at 1 s. graphs on the right show results for longer failures.　because blocking is optimal for short failures  all approaches block for αx = 1 s and produce no tentative tuples for failures below this threshold. delaying tuples in up failure and suspending them during stabilization  delay & suspend  is unviable for failures longer than 1 s because it breaks the delaynew   x requirement as reconciliation last longer than 1 ms.  figure 1 top  . therefore  this combination is of no interest because it never wins and cannot be used for long failures.
　continuously processing new tuples during both up failure and stabilization  process & process  ensures that the maximum delay always remains below αx independently of failure duration. this combination  however  produces the most tentative tuples as it produces them for the duration of the whole failure and reconciliation. we can reduce the number of tentative tuples without hurting delaynew  by delaying new tuples during stabilization  process & delay   during up failure  or in both states  delay & delay .
　for short failures  however  process & suspend may win over delay & delay. if reconciliation is longer than αx  for d   1 s in the experiment   process & suspend produces fewer tentative tuples. it is thus better for such failures to process tuples during the failure in order to suspend new tuples during reconciliation. once reconciliation becomes longer than x  though  for d   1 s   process & suspend causes delaynew to exceed x. hence process & suspend outperforms delay & delay only for failures between 1 and 1 s  which is a small  barely significant window.
　hence to meet the availability requirement for longer failures  nodes must process new tuples not only during
up failure but also during stabilization. nodes can produce fewer tentative tuples  however  by always running on the verge of breaking that requirement.
1 multiple nodes
we now examine which of the above combinations meets the required availability while producing the fewest tentative tuples in a distributed spe. we cause a 1 second failure at the input of a chain of 1 to 1 spes. once the failure heals  the nodes reconcile their states in sequence: a node produces boundary tuples only after it goes back into stable state  while its downstream neighbors can start reconciling only after receiving these boundary tuples. we reduce the state of the joins to 1 tuples to speed-up the experiments.
　figure 1 top  shows the maximum end-to-end processing delay for new tuples. the process & process combination has the lowest delaynew. the delay is equal to only αx plus the normal processing delay through the chain. delay & delay leads to a slightly worse availability as delaynew increases by αx for each node in the sequence. both combinations  however  keep the end-to-end delay within the required kx  where k is the number of nodes in the chain. process & suspend once again is clearly unviable. delaynew is the sum of the stabilization delays of all nodes in the chain. this delay increases for each consecutive node as it undoes and redoes more tuples than its upstream neighbor.
　figure 1 bottom  shows ntentative received by the client application. with process & process  ntentative increases with the length of the chain because all nodes produce tentative tuples during stabilization  which occurs in sequence at each node. interestingly  delay & delay not only does not provide any benefit but can even hurt when compared with no delay. indeed  when stabilization starts  each consecutive node in the sequence runs behind by αx more than its upstream neighbor. when that neighbor stabilizes  both downstream replicas receive all tuples until the most recent ones. because the replica that continues processing new tuples is only supposed to delay new tuples by αx  it catches up and it does so while processing significantly more tuples than the savings during up failure.
　overall  for a chain of nodes  process & process is clearly the best approach as it maximize availability and produces the fewest tentative tuples.
 process & process	 delay & delay process & suspend
approachdelaynewcpu overheadmemory overheadcheckpointp + spcopy +  d + 1l λpprocspcopy

ls +  l + d λinundop + s pcomp + pproc  +  d + 1l λ pcomp + pproc spcomp
s +  l + d λstatefull
table 1: performance and overhead of checkpoint/redo and undo/redo reconciliations.

figure 1: performance and overhead of checkpoint/redo and undo/redo reconciliations. delaynew for increasing state size  left . delaynew for increasing failure size starting at 1 tuples  middle . cpu overhead  right . checkpoint/redo is faster than undo/redo but checkpoints can be expensive.figure 1: effects of path length on delaynew  top  and ntentative  bottom . process & suspend is unviable. process & process achieves the best availability without increased inconsistency.
1 reconciliation
　we now compare the overhead and performance of checkpoint/redo and undo/redo reconciliation. overheads due to sunion operators are examined in the next section. table 1 summarizes the analytical results. p is the per-node processing delay. pcomp is the time to read and compare a tuple. pcopy is the time to copy a tuple. pproc is the time an operator takes to process a tuple. we assume pproc is constant but it may increase with operators' state sizes.
　delaynew is the normal processing delay  p  plus the reconciliation time. for checkpoint/redo  the reconciliation time is the sum of spcopy  the time to copy the state with size s  and  d + 1l λpproc  the average time to reprocess all tuples since the last checkpoint before failure. d is the failure duration  l is the interval between checkpoints  and λ is the aggregate tuple rate on all input and intermediate streams. for undo/redo  reconciliation consists of processing the undo history up to the correct stream markers and reprocessing all tuples since then. producing an undo message takes a negligible time. we assume that the number of tuples necessary to rebuild an operator state is equal to the state size and that stream markers are computed ever l time units. the number of tuples in the undo log that must be processed backward then forward is thus:  d + 1l λ + s. hence  we expect checkpoint/redo to perform better but the difference should appear only for a large query network state size.
　figure 1 shows the experimental delaynew as we increase the state size  s  of the query network  left  or the number of tuples to re-process i.e.  dλ  middle . in this experiment  d is 1 seconds and we vary λ. for both approaches  the time to reconcile increases linearly with s and dλ. when we vary the state size  we keep the tuple rate low at 1 tuples/s. when we vary the tuple rate  we keep the state size at only 1 tuples.
　undo/redo takes longer to reconcile primarily because it must rebuild the state of the query network  spproc  rather than recopy it  spcopy   as shown in figure 1 left . interestingly  even when we keep the state size small and vary the number of tuples to reprocess  figure 1 middle    checkpoint/redo beats undo/redo  while we would expect the approaches to perform the same  『  d + 1l λpproc . the difference is not due to the undo history because when we do not buffer any tentative tuples in the undo buffer  undo  limited history  curve   the difference remains. in fact  an spe always blocks for αx  1 s in this experiment  before going into up failure. for checkpoint/redo  because we checkpoint every 1 ms  we always checkpoint the prefailure state and avoid reprocessing on average 1lλ tuples  which corresponds to tuples that accumulate between the checkpoint and the beginning of the failure. undo/redo always pays this penalty  as stream markers are computed only when the join processes new tuples.
　as shown in figure 1 left and middle   for both approaches  splitting the state across two operators in series  curves labeled  1 boxes    simply doubles λ and increases curve slopes.
　in theory  checkpoint/redo has higher cpu overhead than undo/redo because checkpoints are more expensive than scanning the state of an operator to compute stream markers  figure 1 right  . however  because a node has time to checkpoint its state when going into up failure state  it can perform checkpoints only at that point and avoid the
boundary interval  ms 111average processing delay111stddev of the averages1111table 1: latency overhead of serialization.
overhead of periodic checkpoints at runtime. stream markers can also be computed only once a failure occurs. hence both schemes can avoid overhead in the absence of failures. given that we checkpoint the state when entering up failure  l = 1. hence  the memory overhead for checkpoint/redo is only s + dλin  the state size plus the input tuples that accumulate during the failure  λin is the aggregate input rate . even if we assume that we need no more than s tuples to rebuild the state  the memory overhead for undo/redo is higher because we need to buffer tuples on all streams that feed stateful operators. λstateful will most frequently be significantly greater than λin.
　checkpoint/redo thus appears superior to undo/redo both in terms of reconciliation time and memory overhead. the main advantage of the undo-based approach  however  is the flexibility to undo any suffix of the input streams and propagate reconciliation only on paths affected by failures.
1 overhead and scalability
　in addition to undo and checkpoint overheads  sunions are the main cause of overhead. if the sorting function requires the operator to wait until a bucket is stable before processing tuples  the processing delay increases linearly with the boundary tuple interval  we assume this interval is equal to the bucket size . table 1 shows the average end-to-end delay from nine 1 s experiments and increasing bucket sizes. the memory overhead increases proportionally to the number of sunion operators  bucket sizes  and the rate of tuples that arrive into each sunion.
　other overheads imposed by our scheme are negligible. operators must check tuple types and must process boundary tuples. the former is negligible while the latter is equivalent to the overhead of computing stream markers. soutput must also save the last stable tuple that it sees in every burst of tuples that it processes.
　our approach relies on replication. it increases resource utilization proportionally to the number of replicas. these replicas  however  can actually improve runtime performance by forming a content distribution network  where clients and nodes connect to nearby upstream neighbors rather than a single  possibly remote  location.
　in this paper  we assume that tuples produced during failure and recovery are logged in output buffers and inside sunions on input streams. under normal operation  a node can truncate its output buffers once all replicas of all downstream neighbors acknowledge either receiving or fully processing a prefix of tuples. both techniques are acceptable. as discussed in   acknowledging only processed tuples has the advantage that input tuples necessary to rebuild the latest consistent state are stored at upstream neighbors  which speeds-up recovery of failed nodes. a similar approach can be used to truncate buffers during failures  preserving only enough tuples to rebuild the latest consistent state and correct the most recent tentative tuples. to truncate buffers  a node must hear at least from one downstream replica during a failure. otherwise  a node may have to use conservative estimates to truncate its buffers.
　in this paper  we assume that operators are convergentcapable but our techniques can be extended to support arbitrary operators. for such operators  however  when sufficiently long failures occur  the system must either drop tuples at system input  or replicas must communicate with each other to reach a mutually consistent state after failures heal. we plan to explore such extensions in future work.
1. related work
　until now  work on high availability in stream processing systems has focused on fail-stop failures of processing nodes  1  1 . these techniques either do not address network failures  or strictly favor consistency by requiring at least one fully connected copy of the query network to exist to continue processing . some techniques use punctuation   heartbeats   or statically defined slack  to tolerate bounded disorder and delays. these approaches  however  block or drop tuples when disorder or delay exceed expected bounds. another approach  developed for publishsubscribe systems tolerates failures by restricting all processing to  incremental monotonic transforms  .
　traditional query processing also addresses trade-offs between result speed and consistency  materializing query outputs one row or even one cell at the time  1  1 . in contrast to these schemes  our approach supports possibly infinite data streams and ensures that once failures heal all replicas produce the same final output streams in the same order.
　fault-tolerance through replication is widely studied and it is well known that it is not possible to provide both consistency and availability in the presence of network partitions . eager replication favors consistency by having a majority of replicas perform every update as part of a single transaction  1  1  but it forces minority partitions to block. with lazy replication all replicas process possibly conflicting updates even when disconnected and must later reconcile their state. they typically do so by applying system- or user-defined reconciliation rules  1  1   such as preserving only the most recent version of a record . it is unclear how one could define such rules for an spe and reach a consistent state. other replication approaches use tentative transactions during partitions and reprocess transactions possibly in a different order during reconciliation  1  1 . with these approaches  all replicas eventually have the same state and that state corresponds to a single-node serializable execution. our approach applies the ideas of tentative data to stream processing.
　some schemes offer users fine-grained control over the trade-off between precision  or consistency  of query results and performance  i.e.  resource utilization   1  1 . in contrast  we explore consistency/availability trade-offs in the face of failures and ensure eventual consistency.
　workflow management systems  wfms   1  1  1  share similarities with stream processing engines. existing wfmss  however  typically commit the results of each execution step  or messages these steps exchange  in a central highly-available storage server  or in persistent queues . some approaches allow replication of the central data server using standard lazy replication . they support disconnection by locking activities prior to disconnection .
　approaches that reconcile state after a failure using combinations of checkpoints  undo  and redo are well known  1  1  1  1  1 . we adapt and use these techniques in the context of fault-tolerance and state reconciliation in an spe and comparatively evaluate their overhead and performance in these environments.
1. conclusion
　we presented a replication-based approach to faulttolerant stream processing that handles node failures  network failures  and network partitions. our approach uses a new data model that distinguishes between stable tuples and tentative tuples  which result from processing partial inputs and may later be corrected. our approach favors availability but guarantees eventual consistency. additionally  while ensuring that each node processes new tuples within a predefined delay  x  our approach reduces the number of tentative tuples  when possible. to ensure consistency at runtime  we introduce a data-serializing operator called sunion. to regain consistency after failures heal  nodes reconcile their states using either checkpoint/redo or undo/redo.
　we implemented the approach in borealis and showed several experimental results. for short failures  spe nodes can avoid inconsistency by blocking and looking for a stable upstream neighbor. for long failures  nodes need to process new inputs both during failure and stabilization to ensure the required availability. checkpoint/redo leads to a faster reconciliation at a lower cost compared with undo/redo.
　many stream processing applications prefer approximate results to long delays but eventually need to see the correct output streams. it is important that failure-handling schemes meet this requirement. we view this work as an important first step in this direction.
1. acknowledgments
　we thank mehul shah and jeong-hyon hwang for helpful discussions. this material is based upon work supported by the national science foundation under grant no. 1. m. balazinska is supported by a microsoft fellowship.
