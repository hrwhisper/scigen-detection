given a point set p of customers  e.g.  wifi receivers  and a point set q of service providers  e.g.  wireless access points   where each q （ q has a capacity q.k  the capacity constrained assignment  cca  is a matching m   q 〜 p such that  i  each point q （ q  p （ p  appears at most k times  at most once  in m   ii  the size of m is maximized  i.e.  it comprises min{|p| pq（q q.k} pairs   and  iii  the total assignment cost  i.e.  the sum of euclidean distances within all pairs  is minimized. thus  the cca problem is to identify the assignment with the optimal overall quality; intuitively  the quality of q's service to p in a given  q p  pair is anti-proportional to their distance. although max-flow algorithms are applicable to this problem  they require the complete distance-based bipartite graph between q and p. for large spatial datasets  this graph is expensive to compute and it may be too large to fit in main memory. motivated by this fact  we propose efficient algorithms for optimal assignment that employ novel edge-pruning strategies  based on the spatial properties of the problem. additionally  we develop approximate  i.e.  suboptimal  cca solutions that provide a trade-off between result accuracy and computation cost  abiding by theoretical quality guarantees. a thorough experimental evaluation demonstrates the efficiency and practicality of the proposed techniques.
categories and subject descriptors
h.1  database applications : spatial databases and gis

 
 supported by grants hku 1e from hong kong rgc  and smu 1-c1-lee-1 from the lee foundation  singapore.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee.
sigmod'1  june 1  1  vancouver  bc  canada.
copyright 1 acm 1-1-1/1 ...$1.
general terms
algorithms
keywords
optimal assignment  spatial databases
1.	introduction
　consider a point set p of customers  e.g.  wifi receivers  and a point set q of service providers  e.g.  wireless access points . suppose that each service provider q （ q is able to serve at most q.k customers and every customer has at most one service provider. a subset m   q 〜 p is said to be a valid matching if  i  each point q （ q  p （ p  appears at most q.k times  at most once  in m and  ii  the size of m is maximized  i.e.  it is min{|p| pq（q q.k} . to quantify the quality of the matching m  we define its assignment cost as:
	Ψ m  = x dist q p 	 1 
 q p （m
where dist q p  denotes the euclidean distance between q and p. intuitively  a high-quality matching should have low assignment cost.
　figure 1 illustrates a scenario where p={p1  ...  p1}  q={q1  q1  q1}  q1.k = q1.k = 1  and q1.k = 1. intuitively  assigning to each qi the points pj that fall inside its voronoi cell  indicated by dashed lines in the figure  leads to the minimum matching cost. however  this approach ignores the service provider capacities. in our example  it assigns 1  1  and 1 objects to q1 q1 and q1  respectively  violating the capacity constraints of q1 and q1. the optimal cca
matching  on the other hand  would assign {p1 p1 p1} to q1  {p1 ... p1} to q1  and {p1 p1 p1} to q1  as shown by the three ellipses. in the general case pq（q q.k 1= |p|  i.e.  the customers may be fewer or more than the cumulative capacity of the service providers. cca assigns every pj （ p to a qi （ q  unless all service providers have reached their capacity. in figure 1  for instance  p1 is not assigned to any qi  since they are all full. conversely  it is possible that some service providers are not fully utilized. in any case  cca computes the maximum size matching with the minimum assignment cost  subject to the capacity constraints.
　besides the aforementioned wireless communication scenario  cca arises in many resource allocation applications

figure 1: spatial assignment example
that require matching between users and facilities based on capacity constraints and spatial proximity. for instance  the municipality could assign children to schools  with certain capacity each  such that the average  or  equivalently  the summed  traveling distance of children to their schools is minimized. another application  in welfare states  is the assignment of residents to designated  public clinics of given individual capacities.
　cca can be reduced to the well-known minimum cost flow  mcf  problem in a complete distance-based bipartite graph between q and p . in the operations research literature   there is an abundance of mcf algorithms based on this reduction. these solutions  however  are only applicable to small-sized datasets and main memory processing. in particular  the best of them have a cubic time complexity  elaborated on in section 1   and require that the bipartite graph  which contains |q|，|p| edges  resides in memory. for moderate and large size datasets  this graph requires a prohibitive amount of space  exceeding several times the typical memory sizes   and leads to an excessive computation cost as the cca complexity increases with the number of edges in the graph.
　motivated by the lack of cca algorithms for large datasets  we develop efficient and highly scalable cca techniques that produce an optimal assignment. specifically  we assume that p resides in secondary storage  indexed by a spatial access method  while q fits in main memory; in most real-world applications |q|    |p| and the capacities qi.k are in the order of tens or hundreds. we use the mcf reduction as a foundation  but we achieve space and computation scalability by exploiting the spatial properties of the problem and incrementally including into the graph only the necessary edges. targeted at a disk-resident p  our methods take into account and reduce the i/o cost by incorporating elaborate index-based enhancements. furthermore  we extend our framework with approximate solutions that leverage similar edge-pruning strategies and provide a tunable trade-off between processing cost and assignment quality; we analyze the inaccuracy incurred and devise theoretical bounds for the deviation from the optimal matching.
　the rest of the paper is organized as follows. section 1 covers background and existing work related to our problem. section 1 presents the central theorem our approach is stemming from  and then describes our optimal cca algorithms that utilize it. section 1 studies the trade-off between computation cost and matching quality  and develops approximate cca solutions with guaranteed matching quality. section 1 empirically evaluates our exact and approximate cca methods using synthetic and real datasets. finally  section 1 summarizes the paper and provides directions for future research.
1.	background and related work
　cca can be reduced to a flow problem on a graph. in section 1 we describe the graph formulation of cca  and in section 1 we describe a traditional main memory algorithm for the corresponding flow problem. even though this solution is inapplicable to our setting  it is fundamental to our techniques. in section 1 we survey spatial queries and algorithms related to our approach. table 1 summarizes the notation used in this and the following sections.
symboldescriptiondist qi pj 
the euclidean distance between qi and pje qi pj the  directed  edge from qi to pjsthe source nodetthe sink nodev.αminimum cost from s to node vv.τpotential value of node vv.prevprev. node of v in shortest path from s to vvminthe last node in current sp that belongs to ptable 1: notation
1	minimum cost flow on bipartite graph
cca can be reduced to a maximum flow problem on a
 directed  bipartite graph . consider the example in figure 1 a   where p = {p1 p1}  q = {q1 q1}  and q1.k = 1  q1.k = 1. this cca problem is represented by the flow graph shown in figure 1 b . the flow graph is a complete bipartite graph between q and p  extended with two special nodes s and t  called the source and the sink  respectively  and |q| + |p| extra edges from/to these nodes. specifically  letting v be the set of nodes in the graph  then v = qsp s{s t}. each node v （ v has a fixed balance f v . for every p （ p and q （ q  the balance is set to 1. for s and t  f s  = γ and f t  =  γ  where γ is the required flow and γ = min{|p| pq（q q.k}. in our example  γ = min{1} = 1 and the balances are shown next to each node in the figure.

	p1	f=1	f=1
 a  spatial locations	 b  flow graph
figure 1: cca reduction to the mcf problem
　let e represent the set of edges in the flow graph. each edge e vi vj  （ e has a cost w vi vj  and a capacity c vi vj . the set of edges e comprises:  i  an edge e s qi  for every service provider qi （ q  with cost 1 and capacity qi.k  modeling the capacity constraint of the service provider    ii  an edge e qi pj  for every pair of service provider qi （ q and customer pj （ p  with cost dist qi pj   e.g.  in figure 1  w q1 p1  = dist q1 p1  = 1  and capacity 1  implying that pair  qi pj  can appear at most once in the final matching m   and  iii  an edge e pj t  for every customer pj （ p  with cost 1 and capacity 1  implying that pj is assigned to at most one service provider . in figure 1 b   the label of each edge indicates  in parentheses  its cost and capacity.
　given the above graph  the minimum cost flow  mcf  problem is to associate an integer flow value x vi vj  （  1 c vi vj   with each edge e vi vj  （ e such that for every node v （ v it holds that:
	x	x
               x v vm   	x vm v  = f v 	 1  e v vm （e	e vm v （e and the following objective function z x  is minimized:
	z x  = x w vi vj  ， x vi vj 	 1 
e vi vj （e
an optimal cca assignment is derived by solving the mcf problem and including in m these and only these pairs  qi pj  for which x pj qi  = 1 . intuitively  every edge e pj qi  with x pj qi  = 1 incurs cost w pj qi  = dist pj qi 
and Ψ m  = z x . also  the required flow γ ensures  according to equation 1  that m has the full size  i.e.  that m covers the maximum possible number of customers.
　several algorithms have been proposed in the literature for solving mcf in main memory . the hungarian algorithm  1  1  constructs a cost matrix with |q| ， |p| entries  performs subtraction/addition for entries in specific rows/columns  until each row/column has at least one zero value. this solution is limited to small problem instances; it becomes infeasible even for moderate-sized problems  as the aforementioned matrix may not fit in main memory.
　the cost scaling algorithm  1  1  solves the assignment problem using a reduction to mcf. it processes the latter through successive approximations in a number of steps that is logarithmic to the maximum edge cost in the flow graph. this approach is inapplicable to cca  since it works only for one-to-one matching  i.e.  q.k = 1 for all q （ q  and strictly integer edge costs  versus real-valued ones in cca .
1	successive shortest path algorithm
　the successive shortest path algorithm  sspa  is a popular technique for the mcf problem defined above. sspa receives as input the flow graph defined in section 1 and performs γ = min{|p| pq（q q.k} iterations. in each iteration  it computes the shortest path from the source s to the sink t  and reverses the path's edges. after the last iteration  every  directed  edge from a point in p to a point in q corresponds to a pair in the optimal matching m.1
　algorithm 1 is the detailed pseudo-code of sspa. in each loop  sspa invokes dijkstra's algorithm to compute the shortest path sp between the source and the sink; the algorithm adheres to the edge directions and cannot pass through edges e s qi   or  e pj t   that were already included in c s qi   c pj t   respectively  shortest paths at previous loops. for a visited node v  i.e.  a node de-heaped during dijkstra's algorithm   we use v.α to refer to its minimum distance from the source  and v.prev to indicate the node it was reached from. we denote by vmin the last node in the current shortest path that belongs to p  note that sp may be passing via multiple points of p . upon sp computation in line 1  sspa traces it back and reverses the direction of all the edges it contains  lines 1  1 ; we say that this step augments the path into the graph. then  sspa updates the potential  to be discussed shortly  of the nodes visited by dijkstra's algorithm  lines 1  1   and the costs of the edges incident to these nodes  lines 1  1 .
algorithm 1 successive shortest path algorithm  sspa 
algorithm sspa set q  set p  edge set e 
1: for loop:=1 to γ do
1:vmin:=dijkstra q  p  e 1:v:=vmin //v is a local variable of node type1:while v.prev 1=   do1:add e v v.prev  to e  with c v v.prev = c v.prev v 1:delete e v.prev v  from e1:	v:=v.prev	. proceed with the previous object1:for all visited nodes vi do1:vi.τ:=vi.τ   vi.α + vmin.α1:for all edges e vi vj  incident to vi do1:w vi vj :=dist vi vj    vi.τ + vj.τ
　an important step in sspa is the edge cost updating performed in line 1. to ensure that no edge cost becomes negative  which is a requirement for the correctness of dijkstra's algorithm   sspa uses the concept of node potentials. the potential v.τ of a node v （ v is a non-negative real value that is initialized to 1 for all v （ v before the first sspa loop  and is subsequently updated in lines 1  1 whenever v is visited  i.e.  de-heaped  by dijkstra's algorithm. the cost of an edge w vi vj  varies during the execution of sspa  and is defined as dist vi vj    vi.τ + vj.τ at all times  we establish the convention that dist vi vj  = 1 if any of vi vj is s or t . the node potentials and the definition of edge costs play an important role in sspa and in our methods described in section 1.
example: consider the cca example and flow graph in figure 1. sspa performs in total γ = 1 iterations. figure 1 a  shows the flow graph of figure 1 b  appended with the initial potentials next to each node  all set to 1 . in the first iteration  sspa finds the shortest path sp1 = {s q1 p1 t} from the source to the sink. then  it augments sp and updates the flow graph to be used in the next iteration; figure 1 b  illustrates the reversed sp edges  the updated node potentials and the new edge costs. figure 1 c  shows in bold the shortest path sp1 = {s q1 p1 q1 p1 t} found in the second iteration. note that sp1 cannot pass through edges e s q1  and e p1 t   since they have already been used c s q1  = 1 and c p1 t  = 1 times in previous shortest paths  i.e.  in sp1 . figure 1 d  augments sp1 and updates the flow graph. even though this is the last iteration of sspa  it exemplifies an interesting case. edge e s q1  is part of sp1  but it is not  completely  reversed; its capacity is 1  and only one of its  instances  is reversed  which leads to  i  decreasing its capacity by 1  instead of deleting it   and  ii  creating reverse edge e q1 s  with capacity 1 and cost 1. to complete the example  optimal assignment m corresponds to edges from p to q in the resulting flow graph after the γ = 1 iterations  i.e.  it contains  q1 p1  and  q1 p1 .
　sspa requires that the entire flow graph resides in main memory. the graph contains an excessive number of o |q|，
	ττ==  1	ττ==  1	ττ==  1	ττ==  1
 1  1  ττq==  1  1 1   1 1  ττp==  1  1  1   1  1  1  q1  1  pp1  1  1 
	 1  1 	 1q 1 1 1 	 1  1 p1	 1  1 	 1 1  1 	 1  1 	  1 1	 1 1  1 
ττττ====    1 ssss	 1  1 	 1  1 	tttt ττττ====   1ττττ====   1 ssss	 1 1  1 	 1 1  1 	tttt ττττ====  1 1
	 1 1  1 	ττq==1	 1  1  pppp1	 1 1   1  1 1 	ττ==1  1  1 1  1  1  ττ=1=  1	 1  1 
 1  1  qq1  1 1  1  ττ== q1
 
	ττ==  1	ττ==  1	ττ== 1	ττ== 1
	 a  found sp1	 b  augmenting sp1
ττ==  1 ττ==  1 ττ==  1 ττ==  1 ττ==  1  1  1  ττ==  1 1  ττ== 1
	 1  1 	qqq1  1  1  ppp1	 1  1 	 1 1  1 	1    1 	1	 1  1 
	 1  1 	q1 1 	 1p  1 1	 1  1 	 1 	 1
 1 
ττττ===    1	ssss	 1  1 	 1  1 	tttt ττττ====   1ττ==  1 sss  1  1   1 1  1 	 1 1  1 	tttt ττττ====  1 1 ττ== 1 s	 1 1  
        1  1  ττ= 1  1  1 
	ττ==  1	ττ==  1	ττ== 1	ττ== 1
	 c  found sp1	 d  augmenting sp1
figure 1: example of sspa
|p|  edges  which do not fit in memory for large problem instances. moreover  the time complexity of sspa is o γ ，  |e| + |v | ， log|v |    where o |e| + |v | ， log|v |  is the cost to compute a shortest path. since in our targeted applications |e| is quite large  o |p| ， |q|    sspa is particularly slow. another fundamental problem of sspa is that it is designed for main memory processing and ignores the i/o cost  which generally is the most critical performance factor in the processing of disk-resident data.
1	spatial queries
　point sets are usually indexed by spatial access methods in order to accelerate query processing. the r-tree  and its variants  e.g.   1  1   are the most common such indexes. the r-tree is a disk-based  balanced tree that groups together nearby points into leaf nodes  and recursively groups these leaf nodes into higher level nodes  again based on their proximity  up to a single root. each non-leaf entry is associated with a minimum bounding rectangle  mbr  that encloses all the points in the subtree pointed by it.
　typical spatial search operations on a point set p are range and nearest neighbor  nn  queries. given a range value r and a query point q  the r-range query retrieves all points of p within  euclidean  distance r from q. if p is indexed by an r-tree  this query is evaluated by following recursively r-tree entries that intersect the circular disk with center at q and radius r. the k-nearest neighbor  knn  query receives as input an integer k and a query point q  and returns the k points of p that are closest to q. the stateof-the-art knn processing technique is the best-first nn algorithm   which employs a heap for organizing encountered r-tree entries and visiting them in ascending order of their distance from q  until k points are discovered.
　assignment problems in large spatial databases have recently received considerable attention. specifically   1  1  study the spatial matching  sm  join. given two point sets p and q  the sm join iteratively outputs the closest pair   p q  in p 〜 q  reports  p q  as an assigned pair  and removes both p and q from their corresponding datasets before the next iteration. this procedure continues until either p or q becomes empty.  enhances the performance of a na： ve  i.e.  repetitive closest pair  algorithm with several geometric observations. sm is related  yet different by definition from cca; sm greedily performs local assignments instead of minimizing the global assignment cost.
1.	exact methods
　in this section we present our methods for computing optimal cca assignments. in accordance with most real-world scenarios  we consider that q  the set of of service providers  is much smaller than p  the set of customers . we assume that q fits into main memory  while p is stored on the disk. in the following we consider two-dimensional points and that p is indexed by an r-tree. however  our algorithms can easily extend to problems of higher dimensionality and other spatial access methods.
　as explained in section 1  sspa is not applicable to large cca problem instances  as its  complete bipartite  flow graph leads to excessive memory consumption and expensive shortest path computations. to alleviate the space and running time problems incurred by the huge flow graph  we develop incremental sspa-based algorithms that start from an empty flow graph and insert edges into it gradually. intuitively  edges with low edge weights are highly probable to indicate pairs in the optimal assignment. a fundamental theorem  presented below  formalizes this intuition and excludes from consideration edges whose cost is too high to affect the result of sspa. additionally  our techniques exploit the spatial index of p to further improve performance. our general idea is to perform the search in a subgraph with edge set esub   e  where e is the complete set of flow graph edges. we refer to the euclidean distance between the nodes of an edge as its length. let function φ ，  take as input a set of edges and return the minimum edge length in it. to facilitate the derivation of distance bounds  we require esub to be distance-bounded  as defined below.
　definition 1. an edge set esub   e is said to be distancebounded if
  e qi pj  （ esub  dist qi pj  ＋ φ e   esub 
　in other words a distance-bounded esub contains those and only those edges in e that have length less than or equal to a threshold  i.e.  φ e   esub  . conversely  all the remaining edges  i.e.  edges in e esub  have length greater than or equal to that threshold. we stress that function φ ，  and definition 1 refer to edge lengths  and not to their costs  note that costs vary during the execution of our algorithms because the node potentials are updated .
　suppose that we are given a distance-bounded edge set esub. consider an execution of dijkstra's algorithm on esub that computes the shortest path sp between the source and the sink  and the potential values vi.τ for every node vi  derived as described in section 1. the following theorem determines the condition that should hold so that sp is the shortest path on the complete edge set e.
theorem 1. consider a distance-bounded edge set esub  
e. let sp be the shortest path  between source and sink  in esub and τmax = max{vi.τ|vi （ v } be the maximum potential value. if the total cost of sp is at most φ e   esub    τmax  then sp is also the shortest path  between source and sink  on the complete flow graph.
　proof. consider the edges in e esub. first  their minimum length is φ e esub . second  as explained in section 1  their costs are defined as w vi vj  = dist vi vj  vi.τ + vj.τ. since dist vi vj  − φ e   esub   vi.τ ＋ τmax  and vj.τ − 1  it holds that w vi vj  − φ e   esub    τmax  e ci vj  （ e   esub according to the above  and since edge costs are always nonnegative   any path passing through an edge in e   esub has at least a cost of φ e   esub    τmax. therefore  if the shortest path sp  on esub  has total cost no greater than φ e esub  τmax  then it must be the shortest path in the entire e too. 
　in the following we investigate approaches for gradually expanding the subgraph esub and use it to derive cca pairs. our first solution incrementally enlarges range searches around points in q. the other two aim at further reducing the size of esub by replacing range queries with incremental nearest neighbor searches .
1	range incremental algorithm
　our first method is the range incremental algorithm  ria . algorithm 1 presents the pseudo-code of ria. the procedure starts with an initial range t equal to a system parameter θ. for every point qi （ q  ria performs a t-range search in p; for each retrieved point pj （ p  edge e qi pj  is inserted into esub. ria invokes sspa in the resulting esub.
　observe that t serves as a lower bound for φ e   esub   i.e.  φ e esub  − t . assume that a dijkstra execution in line 1 finds a shortest path sp. if the total cost of sp is less than t τmax  line 1  then it is also less than φ e esub   τmax. in this case  sp is valid according to theorem 1; i.e.  it is a shortest path in the entire e too. thus  we augment sp  updating potential values and sp edges in the graph  lines 1  as in the basic sspa technique. otherwise  i.e.  sp cost is higher than t   τmax   the sp is not valid and is not augmented; ria performs new range searches with an extended t in order to insert more edges into esub  lines 1 . specifically  we extend t by θ and execute an annular range search for each point qi （ q  so that points of p within the distance range  t   θ t  from qi are identified  and the corresponding edges are inserted into esub . then  ria resumes from the iteration it stopped. ria continues this way and terminates when γ = min{|p| pq（q q.k} valid shortest paths are found in total. it can be easily shown that the ria matching is identical to that of sspa  which considers the entire e.

algorithm 1 range incremental algorithm  ria 
algorithm ria set q  set p  value θ 
1: t:=θ; τmax:=1; esub:= 
1: for all qi （ q do
1:	p1:=range-search qi t 
1:	insert edge e qi pj  into esub  for each pj （ p1
1: for loop:=1 to γ do
1:	vmin:=dijkstra q  p  esub 1:if vmin.α ＋ t   τmax then1:v:=reverseedges  1:updatepotentials  1:τmax:=max{qi.τ|qi （ q}. the highest potential1:else1:loop--; t:=t + θ1:for all qi （ q do1:	p1:=annular-range-search qi t   θ t 
1:	insert edge e qi pj  into esub  for each pj （ p1
1 to clarify the condition in line 1  the total cost of sp is by definition equal to vmin.α  since c vmin t  is always 1.
1	nearest neighbor incremental algorithm
　ria constrains the search on a small edge set esub by using system parameter θ. however  it is hard to fine-tune θ or derive it analytically. when θ is too large  set esub grows  leading to long computation time. in case θ is too small  ria performs numerous range searches  incurring high i/o cost. to tackle this problem  we develop a nearest neighbor incremental algorithm  nia   which performs incremental nearest neighbor search  to expand edge set esub. algorithm 1 is the pseudo-code of nia. we use a min-heap h  that organizes encountered edges in ascending cost order. specifically  we first compute for each point qi （ q its nearest neighbor pj in p and insert the corresponding edge e qi pj  into h. in each loop  nia de-heaps the shortest edge e qi pj  from h and inserts it into esub  lines 1  1 . then  it computes the next nearest neighbor of qi and inserts the corresponding edge into h  lines 1  1 . next  it computes the shortest path sp in the new esub.
　due to the min-heap ascending ordering and the incremental nearest neighbor search  it is guaranteed that the top edge in h has the minimum weight of edges in e   esub. letting topkey h  be the key  i.e.  length  of the top entry in h  it holds that  i  esub is a distance-bounded edge set and  ii  φ e   esub  = topkey h . from theorem 1 it follows that if the cost of sp  i.e.  vmin.α  is no greater than topkey h    τmax  then sp is a valid shortest path and is thus augmented into the graph.
　otherwise  i.e.  if the sp cost is larger than topkey h   τmax   sp is invalid and ignored. in this case  nia de-heaps the top edge e qi pj  from h and inserts it into esub. for the qi node of the de-heaped edge  nia finds its next nearest neighbor in p. letting pm be this neighbor  edge e qi pm  is inserted into h  with key equal to its length . a new shortest path is computed in the expanded esub and the procedure is repeated; the current iteration is considered complete when a valid shortest path is computed and augmented into the graph. overall  nia terminates after γ completed iterations  equivalently  after augmenting γ valid shortest paths .
algorithm 1 nearest neighbor incremental algo.  nia 
algorithm nia set q  set p 
1: h:=new min-heap
1: τmax:=1; esub:= 
1: for all qi （ q do
1:	pj:=nn of qi in p
1:	insert he qi pj  dist qi pj i into h
1: for loop:=1 to γ do
1:	de-heap the top entry he qi pj  dist qi pj i from h
1:	insert edge e qi pj  into esub
1:	pm:=next nn of qi in p
1:	insert he qi pm  dist qi pm i into h
1:	vmin:=dijkstra q  p  esub 
1:	if vmin.α ＋ topkey h    τmax then
1:	v:=reverseedges   1:	updatepotentials  
1:	τmax:=max{qi.τ|qi （ q}	. the highest potential
1:	else
1:	loop--	. invalid path; go to line 1

1	incremental on-demand algorithm
　in this section  we present the incremental on-demand algorithm  ida   which improves on nia by pruning more edges and accelerating sp computations. ida is based on the concept of full service providers and full customers.
　definition 1. a service provider qi （ q is said to be full when edge e s qi  has already been used qi.k times in previous  valid  shortest paths.
　for a full qi  since e s qi   with a fixed cost 1  has reached its capacity  dijkstra's algorithm can no longer pass through this edge. in other words  the shortest path from s to qi can no longer be this edge and  thus  qi.α  i.e.  the minimum cost from s to qi  may be greater than 1. this fact is exploited by ida  which leads to a more effective pruning of edges incident to qi.
　ida uses an edge heap h just like nia. unlike nia  where the key of the edges in h is their length dist qi pm   in ida the key of an edge e qi pm  is qi.α+dist qi pm . the rationale is that if qi is full  any sp going through qi should have cost at least qi.α + dist qi pm . this leads to earlier termination and smaller esub  since edges reachable through full service providers are not de-heaped  and  thus  not inserted into esub  unnecessarily early.
　as qi.α varies  whenever some dijkstra execution visits a full qi （ q and updates qi.α to a new value  ida accordingly updates the key of its corresponding edge e qi pj  in h to the new qi.α+dist qi pj . note that  in both nia and ida  for every qi （ q there is exactly one edge in h from qi to some pj （ p at all times. it is easy to show the correctness of ida  after replacing φ e esub  by Φ e esub  in theorem 1. Φ e   esub  models the minimum possible cost an sp could have if it passed through some edge in e   esub.
　similar to full service providers  ida also exploits the properties of full customers to improve the running time and  specifically  to accelerate shortest path computations. below we formally define full customers and provide a theorem that allows sp retrieval without invoking dijkstra's algorithm.
　definition 1. a customer pj （ p is said to be full when edge e pj t  has already been used in a previous  valid  shortest path.
　theorem 1. if no q （ q is full  then the shortest path  between source s and sink t  passes through a single edge e qi pj ; i.e.  sp = {e s qi  e qi pj  e pj t }  where qi （ q  pj （ p. furthermore  e qi pj  is the shortest edge in esub with a non-full pj.
　proof. since no q （ q is full  all q （ q are inserted into the dijkstra heap and visited  with cost q.α = 1  before any p （ p. therefore  after de-heaping the first pj （ p  and if pj is full  dijkstra cannot return to any q （ q. as a result  the current sp must be passing through exactly one edge e qi pj   with a non-full pj  followed by e pj t   i.e.  sp = {e s qi  e qi pj  e pj t }. since qi and pj are non-full  w s qi  = w pj t  = 1 and the sp cost is w qi pj .
　it remains to show that the cost order among edges e q p  （ esub with non-full p coincides with their length order. as described in section 1  w q p  = dist q p  q.τ+p.τ. note that a node p （ p becomes full when dijkstra's algorithm visits it for the first time. equivalently  all non-full ones have never been visited by dijkstra's algorithm and their potentials remain 1 since the initialization of the problem. as a result  p.τ = 1  and w q p  = dist q p  q.τ. also  the fact that all q （ q are non-full leads to their potentials being updated in every ida iteration to the same exact value  in line 1 in algorithm 1 . thus  the cost order among edges with non-full p coincides with their distance order. 
　according to the above theorem  as long as no service provider q （ q is full  ida computes the current sp  without invoking dijkstra's algorithm  by iteratively de-heaping edges e qi pj  from h1. if pj is full  we directly insert it into esub and de-heap the next entry; otherwise we report sp = {e s qi  e qi pj  e pj t }. note that after de-heaping any edge e qi pj  from h  we en-heap the edge from qi to its next nearest customer  as in lines 1 of algorithm 1 . algorithm 1 is the pseudo-code of ida. lines 1 initialize esub identically to nia. at line 1 we compute the current sp. note that if no service provider is full  we derive sp using theorem 1 and the method described above  we omit this enhancement from the pseudo-code for readability . at lines 1  if the last sp computation visited some full q （ q and altered its q.α value  then we accordingly update the key of its corresponding edge e q p  in h to the new q.α + dist q p   line 1 . lines 1 retrieve the next nn of qi  qi refers to e qi pj  de-heaped at line 1  and insert the corresponding edge into h. note that we perform this after updating the q.α values at lines 1 so that the en-heaped edge has an up-to-date key.
algorithm 1 incremental on-demand algorithm  ida 
algorithm ida set q  set p 
1: h:=new min-heap
1: τmax:=1; esub:= 
1: for all qi （ q do
1:	pj:=first nn of qi in p
1:	insert he qi pj  dist qi pj i into h
1: for loop:=1 to γ do1:de-heap he qi pj  keyi from h1:insert e qi pj  into esub1:vmin:=dijkstra q p esub 1:for all visited q （ q do1:if q is full and q.α changed in line 1 then1:update q.α in h1:pm:=next nn of qi in p1:insert he qi pm  qi.α + dist qi pm i into h1:if vmin.α ＋ topkey h    τmax then1:v:=reverseedges  1:updatepotentials  1:	τmax:=max{qi.τ|qi （ q}	. the highest potential1:else1:	loop--	. invalid path; go to line 1
example: consider the example in figure 1 a   where the table at the top illustrates the lengths of all encountered edges  i.e.  edges in esub and in the heap . the flow graph shown skips the source and sink for clarity and includes only edges between service providers and customers. service provider q1  shown shaded  is full with q1.α = 1. dashed edges e q1 p1  e q1 p1  and the bold one e q1 p1  have been enheaped but not yet inserted into esub. at the bottom  h1 and h1 illustrate the heap contents in nia and ida  respectively  assuming that so far they proceeded identically. their difference is the key of e q1 p1   which is 1 in nia and 1 in ida  since dist q1 p1  = 1 and q1.α = 1 . this leads to a different insertion order into esub and a faster ida termination. for the current sp to be valid  in line 1 of algorithm 1  in line 1 of algorithm 1   nia  ida  requires that its cost is no greater than 1-τmax  1-τmax   where 1  1  is the topkey h1  value  topkey h1   respectively . this implies that the current ida iteration has higher chances to terminate without needing to insert new edges and re-invoke dijkstra's algorithm.
dist qi pdist qdist qj  i pi ppj j1  pp1 p1 pp1 p1 pp1 p1 pp1 p1pp1 qq1 1 1 1 - -- - --
q1
	qq1 -	-- -	--	-	--	- --	1
q1
     qq1 1 1 -q1 1 1 -
　　pp1	pp p	p
	pp1 αα= 1= 1	α=αα1==1qq1	pp1 αα=1
p1 α= 1 pp
α 1 p1 α= 1 = 1 q1 p1 α= 1 αα==1 qq1 pp1 αα==1 qq1 pp1 αα== 1
	α= 1 q1	p	α= 1 q1	p1α= 1
p
	p1 α= ±	p1 α= ±
hh1  qq1pp1  1  1      qq1pp1  1  1      qq1pp1  1  1  
h1  q1 p1h  h1     qq1p1p  1  1  1      q q 1qpp1  1p  1   1      qq1pp1  1  1   hh1  qq1pp1  1  1      qq1pp1  1  1      qq1pp1  1  1  
h1  q1 p1  1   a  ida versus nia q1 p1  1   q1 p1  1 	h1  q1 pb  key update1  1   q1 p1  1   q1 p1  1 
figure 1: utilizing full service providers in ida
　let us now focus on ida. since the top edge in h1 is e q1 p1   shown bold   we insert it into esub. figure 1 b  shows the new flow graph  assuming that the subsequent dijkstra execution returned an sp passing through e q1 p1 . assuming that q1.k = 1  augmenting this sp makes q1 full with q1.α = 1  and alters q1.α to 1. since q1.α has changed  ida updates the key of e q1 p1  in h1 to dist q1 p1 +qi.α = 1. then  we find the next nn of q1  i.e.  p1  and insert the corresponding edge e q1 p1  into h1 with key q1.α + dist q1 p1  = 1. the bold edge  i.e.  e q1 p1   is the one to be inserted next into esub.
1	optimizations
　in this section we describe two enhancements that apply to nia and ida. section 1.1 proposes a technique that accelerates dijkstra's algorithm by reusing its previous computations. section 1.1 presents an incremental all nearest neighbor  ann  search that reduces the i/o cost.
1.1	reducing dijkstra executions
　unlike the bulk discovery and insertion of edges  through range search  in ria  nia/ida apply incremental nn search to discover the edges one-by-one  keeping esub small. however  since esub expands slowly  nia/ida may perform numerous dijkstra executions. to accelerate processing  we reduce the cost of dijkstra executions in nia/ida by reusing  i  the vi.α values computed in the previous sp computation and  ii  utilizing the entries that remained inside the dijkstra heap upon termination. assume that in the current nia/ida iteration some  invalid  sp has been computed  and that we need to find a new sp after inserting a new edge e q p  into esub  in line 1 of algorithm 1 or algorithm 1  respectively . let hd be the dijkstra search heap after last sp computation.
　our objective is  i  to identify the visited nodes v whose v.α value is affected by e q p   i.e.  e q p  leads to a shortest path from the sink to v  and  eventually   ii  to update the keys of nodes inside hd. this is performed by the path update algorithm  pua  to be described shortly. upon termination of pua  a new dijkstra execution is performed  which however directly uses the updated hd and avoids visiting nodes de-heaped in previous sp computation s  in the current nia/ida iteration.
　pua initializes an empty min-heap hf to play the role of a dijkstra-like search heap among previously visited nodes. hf organizes its entries  nodes  in ascending order of their α values. first  we insert into hf the q node of the new edge e q p . next  we iteratively de-heap the top node vi from hf and examine whether nodes vj connected to vi can be reached through a shortest path via vi. in particular  if vj.α   vi.α+w vi vj  then vj.α is updated to vi.α+w vi vj  and vj.prev is set to vi  to indicate that vj is now reachable via vi . if vj is in hd or hf  its key is updated to vj.α in its containing heap. otherwise  i.e.  if vj is neither in hd nor hf   it is inserted into hf with key vj.α. pua terminates when hf becomes empty. algorithm 1 presents pua.
algorithm 1 path update algorithm  pua 
algorithm pua set q  set p  heap hd  edge set esub  edge e q p  
1: hf:=new min-heap
1: insert hq q.αi into hf
1: while hf is not empty do1:de-heap top node vi  with the lowest vi.α value  from hf1:for all edges e vi vj  （ esub outgoing from vi do1:if vj.α   vi.α + w vi vj  then1:vj.α:=vi.α + w u v ; vj.prev:=vi1:if vj （ hd then1:update vj.α in hd1:else if vj （ hf then1:update vj.α in hf1:else1:insert hvj vj.αi into hf
example: we illustrate the pua technique with an example. figure 1 a  shows the current esub edges between  some nodes of  sets q and p  the α values of these nodes  and the edge costs  numbers above each edge  after the last dijkstra execution. the visited nodes are illustrated shaded  while the nodes remaining in hd are q1 and p1  having bold borders and lighter gray color . consider that edge e q1 p1  with cost w q1 p1  = 1 is inserted into esub. figure 1 b  shows the new edge  in bold  and the pua steps. first  q1 is inserted into hf with key q1.α = 1. its de-heaping leads to adjacent node p1 which is reachable with a lower cost  than the current p1.α  via q1. thus  p1 is inserted into hf with key equal to the new p1.α = q1.α + w q1 p1  = 1. similarly  the de-heaping of p1 leads to updating the key of q1 in hd to the new q1.α = 1. after these changes  the new sp can be computed by directly using hd = {hq1i hp1i} in the new dijkstra execution. note that the shortest paths to  and  accordingly  the α values of  q1 q1 p1 p1 have not been affected by the insertion of e q1 p1  and the new sp computation avoids unnecessary costs for them.
　pua can utilize results only among dijkstra executions taking place as part of the same nia/ida iteration. the reason why reusing cannot span multiple iterations is that sp augmentation  which signals the end of an iteration  al-
　our general approach consists of three phases. the first one is the partitioning phase  in which we form groups gm of either the points in q or points in p  so that the diagonal of their mbr does not exceed a threshold δ. parameter δ is used to control the quality of the assignment; the smaller δ is the better the computed matching approximates the optimal. the second phase  called concise matching  solves optimally a small cca problem extracting one representative point per group gm and using the set of representatives as the set of service providers  customers . finally  the refinement phase uses the assignment produced in the previous step to derive a matching on the entire sets p and q.
　sections 1 and 1 describe two methods  called service provider approximation  sa  and customer approximation  ca . sa and ca follow different approaches for partitioning and subsequent concise matching. specifically  sa groups the service providers and solves concise matching in the entire p  while ca groups the customers and performs concise matching in the entire q.1 section 1 de-1.1	incremental ann processing
　our cca algorithms invoke numerous nn search operations around the service providers to the r-tree rp that indexes the customers p. to reduce the i/o cost  we employ an incremental all-nearest-neighbors technique. first  we form service provider groups gm based on their hilbert space-filling curve ordering. for each group gm we maintain a min-heap hm that organizes encountered r-tree entries e in ascending mindist mbr gm  mbr e   order. for every qi （ gm we maintain a candidate min-heap resi that orders all encountered customers  i.e.  candidate nns  in ascending distance from qi.
　when we need to compute the  next  nn of some qi （ gm  we iteratively de-heap and visit the top r-tree en-
try in hm. if the de-heaped entry is a point p （ p  we insert it into the candidate min-heap of every service pro-
vider in gm. the procedure terminates when the top candidate pj in resi has key smaller than or equal to the top entry in hm; i.e.  dist qi pj  is smaller than or equal to mindist mbr gm  mbr e   for every unvisited r-tree entry e. at that point  we de-heap pj from resi and report it as the  next  nn of qi. algorithm 1 is a pseudo-code for the above procedure.
algorithm 1 incremental ann search
   algorithm ann group gm  r-tree rp  service provider qi  1: while top entry in resi has key   key of top entry in gm do
1:	de-heap top entry e from hm
1:	if e is an directory entry of r-tree rp then
1:	visit node pointed by e and insert its entries into hm
1:	else	. e is a leaf level entry  i.e.  a point p （ p
1:	for all qk in gm do
1:	insert hp dist p qk i into resk
1: de-heap top entry hpj dist pj qi i from resi
1: return pj as the next nn of qi
scribes refinement techniques that could be used with either sa or ca. finally  section 1 provides error bounds for both approaches.
1	service provider approximation
　partitioning in sa is performed on set q. the points q （ q are sorted according to their hilbert values and processed in this order. we start with zero service provider groups. each point q  in turn  is inserted into an existing group gm so that the diagonal of gm's mbr does not exceed δ. if no such group is found  then a new group is formed to include q. the process is repeated until all service providers q （ q are grouped.
　we proceed to concise matching by extracting one representative point per group. the representative point gm of

a group gm has capacity gm.k = pq（gm q.k and is located at its geometric centroid; each coordinate of gm is equal to the weighted average of points inside gm. weighting is performed according to the capacities q.k of points q （ gm  e.g.  the x-coordinate
　figure 1 shows a scenario where q = {q1 ... q1}. assume that spp produces the illustrated groups g1 g1 g1 according to parameter δ. the dashed lines correspond to group mbr diagonals and their lengths cannot be longer than δ. the representatives of these groups are shown as
g1.k = 1 g1.k = 1 g1.k = 1.
1
 we note here that we attempted to combine sa and ca  i.e.  to group both q and p   but this led to a very poor matching. thus  we omit this hybrid method.
　the resulting representatives form set q1 which is used as an approximation of q. the concise matching of sa solves an exact cca problem over q1 and p. this step is performed by the ida algorithm described in section 1  because  as will be demonstrated by our experiments  it is the most efficient among the exact methods. the matching m1 produced by this step will be refined into the final matching m using one of the techniques presented in section 1.
1	customer approximation
　ca is similar to sa  but groups customers instead of service providers. recall that p is indexed by an r-tree. we first initialize a set s of customer groups to  . given parameter δ  we traverse the r-tree. starting from the root entries  we compare the mbr diagonal of each of them with δ. if the diagonal of entry e is smaller than or equal to δ  we insert it into s  the corresponding group of customers are those in the subtree rooted at e . otherwise  i.e.  e's diagonal is larger than δ   we visit the corresponding node and recursively repeat this procedure for its entries.
　r-tree leaves are an exception to this procedure. in particular  if δ is small  it is possible that we reach an entry e corresponding to an r-tree leaf whose diagonal is larger than δ. an option would be to insert into s all points in e  but this would result in a large s. thus  we handle e as follows. we conceptually split its mbr into two equal halves on its longest dimension. we repeat this process until the diagonal of each partition becomes smaller than or equal to δ. then  we insert the resulting conceptual entries into s.
　upon termination of the above procedure  all entries in s have diagonal smaller than δ and the union of points in their subtrees is the entire p. the size of s  however  can be reduced  without violating the δ constraint  by an extra step that merges its contents. specifically  we use a procedure similar to sa and group entries in s into conceptual hyperentries whose diagonal does not exceed δ.
　let s be the final set of entries  conceptual or not . we produce a set p1 of customer representatives as follows. for each e （ s we derive a representative point g located at the geometric centroid of e. the representative has weight g.w equal to the number of points in the subtree of e.
　to exemplify ca partitioning  assume that the r-tree of p and parameter δ are as shown in figure 1  the r-tree is illustrated both in the spatial domain and as stored on the disk . we first access the root  and consider its entries e1 and e1. entry e1 has smaller diagonal than δ and is inserted into s. this is not the case for e1  whose pointed entries are loaded from the disk. among e1's entries  e1 and e1 satisfy the diagonal condition and are included in s. on the other hand  e1 is a leaf and still has diagonal larger than δ. thus  we conceptually divide it into two new entries on its long dimension  i.e.  x dimension . the resulting e1 and e1 have small enough diagonal and are placed into s. entries inserted into s are shown shaded. in the last step  we merge entries into larger ones  while still satisfying the δ condition ; e1 and e1 form a hyper-entry whose boundaries are shown dashed. every entry in the final s implicitly defines a group of customers gm. set p1 contains the representatives of the final entries in s  i.e.  p1 = {g1 g1 g1 g1}.
　in the concise matching phase  ca computes the optimal matching m1 between p1 and q. this is performed in main memory  where p1 and q reside  using ida. note that in this setting points in p1 also have capacities  the represen-

figure 1: customer partitioning
tative weights . this is not a problem  since ida  as well as ria and nia  can handle capacities in the customer side of the flow graph too. the difference is that m1 may assign  instances of a representative to multiple service providers.
1	refinement phase
　in both sa and ca  we are given a matching m1 between one approximate set  i.e.  q1 or p1  and one original set  p or q  respectively . in either case  m1 specifies for each group gm of service providers  customers  which customers  instances of service providers  are assigned to it. in other words  in both sa and ca the refinement phase has to solve several smaller problems of assigning a set of customers p1 to a set of service providers q1  where the number of points p （ p1 to be assigned to each q （ q1 is given by the concise matching phase . we could run an exact algorithm for each of these smaller problems. this  however  is expensive. instead  we propose the following two heuristics1  receiving smalls sets p1 and q1 as input.
nn-based refinement: this approach computes the  next  nn of each q （ q1 in a round-robin fashion in set p1. when discovering the nn p of service provider q  we include pair  q p  in the final assignment m and remove p from p1. if q has reached its number of instances to be assigned to p1  we also delete q from q1.
exclusive nn refinement: according to this strategy  we
identify the p （ p1 with the minimum distance from any q （ q1 that has not reached its number of instances to be assigned to p1  according to m1 . we insert into the final assignment m the corresponding pair  q p  and proceed with the next customer in p1.
1	assignment cost guarantee
　let m be the matching computed by sa and mcca be the optimal matching. the assignment cost error of m is:
	err m  = Ψ m    Ψ mcca  	 1 
where Ψ m  and Ψ mcca  are defined as in equation 1. we show that err m  is at most 1，γ ，δ. thus  we are able to control the assignment cost error through parameter δ.
　theorem 1. the assignment error of sa is upper bounded by 1 ， γ ， δ.
　proof. note that approximate matching m has the full size γ  since concise matching leaves customers unassigned only if all service providers are fully utilized  i.e.  they have reached their capacity . from the optimal matching mcca  we derive another matching mcca1 by replacing each pair  q p  （ mcca with pair  g p   where g is the representative of q's group. after the replacement  the cost of each pair increases/decreases by at most δ  since δ is the maximum possible distance between q and the weighted centroid g .
thus  Ψ mcca1	  ＋ Ψ mcca  + γ ， δ.
　note that mcca1 is not necessarily the optimal matching between q1  i.e.  the set of service provider representatives  and p. let m1 be the optimal matching between q1 and p. we know that Ψ m1  ＋ Ψ mcca1  . combining the two inequalities  we derive Ψ m1  ＋ Ψ mcca  + γ ， δ.
　sa replaces the pairs of m1 heuristically to form the final matching m  incuring a maximum error of δ per pair. hence  Ψ m  ＋ Ψ m1  + γ ， δ. from the last two inequalities  we infer that Ψ m  ＋ Ψ mcca  + 1 ， γ ， δ. 
the assignment error of ca is bounded as follows.
　theorem 1. the assignment error of ca is upper bounded by γ ， δ.
　proof. the proof follows the same lines as that of sa  the difference being that the maximum possible distance between a customer p and its group representative  since g is always the geometric centroid of p's group mbr . 
1.	experiments
　this section empirically evaluates the performance of our algorithms. all methods were implemented in c++ and experiments were performed on a pentium d 1ghz machine  running on ubuntu 1. section 1 describes the datasets  the parameters under investigation  and other settings used in our evaluation. in section 1 we study the performance of our algorithms on optimal cca computation. section 1 explores the efficiency and assignment cost error of our techniques on approximate cca computation.
1	data generation and problem settings
　the cca problem takes two spatial datasets as input: the service provider set q and the customer set p. both datasets were generated on the road map of san francisco  sf    using the generator of . in particular  the points fall on edges of the road network  so that 1% of them are spread among 1 dense clusters  while the remaining 1% are uniformly distributed in the network. this dataset selection simulates a real situation where some parts of the city are denser than others. to establish the generality of our methods  we also present results for different distributions. all datasets are normalized to lie in a  1 1 space.
　by default  the capacity k of all q （ q is 1 and the dataset cardinalities are |q|=1k and |p|=1k. parameter θ of ria is fine-tuned  and set to 1   for fairness in the comparison with nia and ida. table 1 shows the parameters under investigation. we assume that the service provider dataset q is small enough to fit in main memory. each p dataset is indexed by an r-tree with 1kbyte page size. we use an lru buffer with size 1% of the tree size. we record the memory usage  i.e.  |esub|  number of edges in the subgraph  and the cpu time. also  we measure i/o time by charging 1ms per page fault .
1	experiments on optimal assignment
　sspa requires that the complete flow graph is stored in main memory  as described in section 1 . for our default
parameterdefaultrange|q|  in thousands 1.1  1  1  1  1|p|  in thousands 1  1  1  1  1capacity k1  1  1  1  1diagonal δsa: 1  ca: 1  1  1  1  1table 1: system parameters
setting this leads to space requirements that exceed several times the available system memory. to provide  however  an intuition about  i  the inherent complexity of the problem and  ii  the relative performance of sspa versus our algorithms  we experiment on a smaller problem; we generate p and s as described in section 1  with |q| = 1 and |p| = 1k  so that the flow graph fits in main memory. for ria  nia  and ida  p is indexed by a memory-based r-tree. sspa does not utilize an index  as it involves no spatial searches. figure 1 shows the cpu time  in logarithmic scale  versus capacity k in this small problem. our methods are one to three orders of magnitude faster than sspa. we postpone the explanation of the observed trends for figure 1  with disk-resident p   but stress the excessive time requirements of sspa and the efficiency of our methods.

figure 1: cpu time vs. k  |q| = 1  |p| = 1k
　in the remaining experiments  we focus on disk-based p and large problem instances  excluding the inapplicable sspa. figure 1 a  shows the subgraph size esub as a function of k  setting |q| and |p| to their default values . we include the complete bipartite graph size |efull| = |q| ， |p| as a reference  indicated by full . due to the application of theorem 1  our algorithms  ria  nia  ida  use/store only a fragment of the complete bipartite graph. ida explores fewer edges than ria and nia for small values of k. the reason behind this is that for k ， |q|   |p|  providers are likely to become full early and the tighter bounds of ida over nia/ria can be effectively utilized. on the other hand  if k ， |q|   |p|  few or no providers become full  so ida does not achieve additional pruning compared to nia/ria.

	k	k=1 k=1 k=1 k=1 k=1
	 a  |esub|	 b  total time
figure 1: performance vs. k  |q| = 1k  |p| = 1k
　figure 1 b  shows the total execution time in the previous experiment  and breaks it into i/o and cpu cost. the i/o time depends primarily on  and thus follows the increasing trend of  |esub|. the cpu time also rises with k  since the flow graph size and the number of iterations γ increase with k. for large k values  however  the increase for ria is not as steep  while for ina and nia the cpu cost drops slightly. this happens because the capacity constraint is looser and  essentially  the problem becomes easier. nia has lower cpu time than ria because nia adds new edges one-by-one and keeps the subgraph small. note that even for large k  where the final |esub| is similar for ria and nia   the early iterations of nia run on a smaller esub which increases only towards its final iterations. on the other hand  ida is faster than nia because  i  theorem 1 computes the first assignments fast and  ii  the utilization of full service providers  i.e.  with non-zero qi.α values  avoids unnecessary edge insertions into esub and leads to earlier termination.
　the next experiment investigates the effect of service provider cardinality |q|  in figure 1 . in general  the relative performance of the algorithms is consistent with our observations in figure 1; ida prunes more edges than nia/ria when k ， |q|   |p|. the cost of the problem increases with |q|  but saturates when k ， |q|   |p|  since the optimal assignment is found before long edges  from service providers to their furthest neighbors  are examined.

	|q|  kilo 	|q|=1|q|=1 |q|=1 |q|=1 |q|=1
	 a  |esub|	 b  total time
figure 1: performance vs. |q|  k = 1  |p| = 1k
　figure 1 investigates the effect of |p|. when |p| increases  the complete flow graph grows but the subgraph explored by our algorithms shrinks. intuitively  if there are too many customers  the nns of each service provider are closer  and stand a higher chance to be assigned to it; i.e.  the problem becomes easier and fewer esub edges  and  thus  computations  are needed. however  for |p| = 1k the customer r-tree has one more level than smaller cardinalities  incurring more i/os and a higher overall cost. note that the difference of ida from ria/nia grows as |p| becomes larger compared to k，|q|  for the reasons mentioned earlier .

	|p|  kilo 	|p|=1 |p|=1 |p|=1 |p|=1 |p|=1
	 a  |esub|	 b  total time
figure 1: performance vs. |p|  k = 1  |q| = 1k
　so far we assumed that all service providers have equal capacities q.k. figure 1 compares the algorithms for problems where the providers have different k  taken randomly from the ranges shown as labels on the horizontal axis. the results are similar to those in figure 1; i.e.  mixed k values do not affect the effectiveness of our pruning techniques.

k1 1 1 1~1 a  |esub| b  total timefigure 1: perf. for mixed k  |q| = 1k  |p| = 1k
　figure 1 compares the algorithms when q and p follow varying distributions; uniform  u  places points uniformly in the sf network  while clustered  c  generates datasets in the way described in section 1. for example  label  uvsc on the horizontal axis corresponds to uniform service providers and clustered customers. we observe that the cost for computing the optimal assignment increases considerably when the two sets are distributed differently. if q is uniform and p is clustered  e.g.  customers gather in central squares during new year's eve   some providers are far from their nearest customer clusters and compete for points far from them  thus increasing the size of the examined subgraph. if q is clustered and p is uniform  e.g.  service providers concentrate around certain regions   the providers cannot fill their capacities with customers near them  and need to expand their search ranges very far. in both cases  nia is slower than ria  because the incremental edge retrieval  that is slower than a batch range-based insertion in ria  is invoked numerous times.

	 a  |esub|	 b  total time
figure 1: different distributions  default k |q| |p| 
1	experiments on approximate assignment
　in this section  we evaluate the accuracy of our approximate cca methods  i.e.  sa and ca  presented in section 1  and compare their execution time with ida  the best exact algorithm . we measure the accuracy of an approximate matching m by Ψ m /Ψ mcca   where mcca is the optimal assignment. for each of sa and ca  we implemented both the nn-based and exclusive nn refinement techniques  indicated by  n  and  e  after sa or ca in chart labels .
　figure 1 shows the approximation quality and the running time as a function of the diagonal parameter δ  used in the partitioning phase . observe that the ca variants are significantly better than those of sa in terms of quality and efficiency for all values of δ. an exception is δ = 1 where sa achieves a better approximation  at a cost  however  that is comparable to ida  since almost every provider forms a group by itself . as expected  accuracy and execution cost drop with δ. ca with as small δ as 1 achieves great performance improvement over ida  while producing a matching only marginally worse than the optimal.

	 a  quality	 b  total time
figure 1: quality vs. δ  default k |q| |p| 
　in the remaining experiments  we set δ to 1 for sa  and to 1 for ca  as those values achieve the best efficiency/accuracy trade-off. we evaluate the approximate solutions using the defaults and ranges in table 1 for k  |q|  and |p|. in figure 1  we vary k and observe that the approximation quality improves with it. as k increases  the providers are assigned more distant customers; i.e.  both Ψ m  and Ψ mcca  grow. on the other hand  the provider/customer group mbrs remain constant  as δ is fixed  and  hence  the relative error of a suboptimally assigned customer drops. the ca variants are more robust  i.e.  less affected by k  than sa  with a 1% error in the default  and 1% in the worst case. the execution time of sa/ca follows the trend of ida  due to their ida-based concise matching  but both sa and ca are several times faster .
　figure 1 evaluates the approximation methods for various service provider cardinalities. again  ca is more accurate than sa  while there are only marginal differences between its can and cae variants. the quality of ca worsens with |q|  because the more service providers around a customer group  the higher the chances for a suboptimal pair in m. on the other hand  in sa the provider groups have a fixed maximum diagonal δ  but their density varies. very low or very large densities lead to poor approximations.

|q|  kilo |q|=1 |q|=1 |q|=1 |q|=1 |q|=1 a  quality b  total timefigure 1: performance vs. |q|  k = 1  |p| = 1k
　in figure 1  we investigate the effect of |p|. the increase of |p| reduces the accuracy of sa; as the space around every provider group becomes denser with customers  the potential for suboptimal matchings becomes higher. the accuracy of ca is affected to a lesser degree by |p|. the slight error increase is because ca groups more customers together  implying a coarser partitioning and worse approximation.

	 a  quality	 b  total time
figure 1: performance vs. |p|  k = 1  |q| = 1k
　figure 1 compares the approximate methods for different q and p distributions. ca performs best in terms of running time for all distributions. ca is also more accurate than sa for similarly distributed q and p  which is the case in most applications . for differently distributed q and s  the quality of sa and ca is comparable  and close to optimal. to summarize the approximation experiments  ca typically computes a near-optimal matching  while being orders of magnitude faster than ida.
	 a  quality	 b  total time
figure 1: different distributions  default k |q| |p| 
1.	conclusion
　in this paper  we identify the capacity constrained assignment  cca  problem  which retrieves the matching  between two spatial point sets  with the lowest assignment cost  subject to capacity constraints. cca is important to applications involving assignment of users to facilities based on spatial proximity and capacity limitations. we present efficient cca techniques that expand the search space incrementally and effectively prune it. we also develop approximate cca solutions that provide a trade-off between computation cost and matching quality. according to our experimental results  ida is the best algorithm for the exact cca problem  while ca is the method of choice for approximate cca matching.
　in our assumed setting  the set of service providers fits in main memory  while the customers are indexed by a diskbased r-tree. in the future  we plan to extend our framework to the scenario where both sets are disk-resident  incorporating hash-based techniques.
1.	repeatability assessment result
　all the results in this paper were verified by the sigmod repeatability committee. code and/or data used in the paper are available at: http://www.sigmod.org/codearchive/sigmod1/
