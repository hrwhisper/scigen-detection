inspired by the pagerank and hits  hubs and authorities  algorithms for web search  we propose a structural re-ranking approach to ad hoc information retrieval: we reorder the documents in an initially retrieved set by exploiting asymmetric relationships between them. specifically  we consider generation links  which indicate that the language model induced from one document assigns high probability to the text of another; in doing so  we take care to prevent bias against long documents. we study a number of re-ranking criteria based on measures of centrality in the graphs formed by generation links  and show that integrating centrality into standard language-model-based retrieval is quite effective at improving precision at top ranks.
categories and subject descriptors: h.1  information search and retrieval : retrieval models general terms: algorithms  experimentation
keywords: language modeling  pagerank  hits  hubs  authorities  social networks  high-accuracy retrieval  graphbased retrieval  structural re-ranking
1. introduction
¡¡information retrieval systems capable of achieving high precision at the top ranks of the returned results would be of obvious benefit to human users  and could also aid pseudofeedback approaches  question-answering systems  and other applications that use ir engines for pre-processing purposes  1  1  1 . but crafting such systems remains a key research challenge.
¡¡the pagerank web-search algorithm  uses explicitlyindicated inter-document relationships as an additional source of information beyond textual content  computing which documents are the most central. here  we consider adapting this idea to corpora in which explicit links between documents do not exist.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee.
sigir'1  august 1  1  salvador  brazil.
copyright 1 acm 1-1/1 ...$1.
¡¡how should we form links in a non-hypertext setting  while previous work in summarization has applied pagerank to cosine-based links   we draw on research demonstrating the success of using language models to improve ir performance in general  1  1  and to model inter-document relationships in particular . specifically  we employ generation links  which are based on the probability assigned by the language model induced from one document to the term sequence comprising another.1 our use of such links echoes the standard language-model-based ranking principle  first introduced in   that a document is relevant to the extent that its corresponding language model assigns high probability to the query. however  given that we are working with multiple documents rather than a single query  we employ a technique that compensates for length bias in estimating generation probabilities.
¡¡we note that the analogy between hyperlinks and generation links is not perfect. in particular  one can attribute much of the success of link-based web-search algorithms to the fact that hyperlinks are  often  human-provided certifications that two pages are truly related . in contrast  automatically-induced generation links are surely a noisier source of information. to compensate  we advocate an approach  used elsewhere as well  1  1  1  1  1  1   that we term structural re-ranking: we use inter-document relationships to compute an ordering not of the entire corpus  but of a  possibly unranked  set of documents produced by an initial retrieval method. this set should provide a reasonable ratio of relevant to non-relevant documents  and thus form a good foundation for our algorithms. note that our approach differs in spirit from pseudo-feedback-based methods   which define a model based on the initially retrieved documents expressly in order to re-rank the entire corpus. indeed  since the quality of the initially retrieved results plays a major role in determining the effectiveness of pseudo-feedback-based algorithms   our methods can potentially serve to greatly enhance the input to them.
¡¡to compute centrality values for a given generation graph  we propose a number of methods  including variants of pagerank  and hits  a.k.a. hubs and authorities  . comparisons on various trec datasets against numerous baselines  including use of cosine-based links and re-ranking em-

1
 while the term  generate  is convenient  we do not think of a  generator  document or language model as literally  creating  others. other work further discusses this issue and proposes alternate terminology  e.g.   render   . ploying only document-specific characteristics  show that language-model-based re-ranking using centrality as a form of  document prior  is indeed successful at moving relevant documents in the initial retrieval results higher up in the list.
1. structural re-ranking
¡¡throughout this section  we assume that the following have been fixed: the corpus c  in which each document has been assigned a unique numerical id ; the query q; the set dinit   c of top documents returned by some initial retrieval algorithm in response to q  this is the set upon which re-ranking is performed ; and the value of an ancestry parameter ¦Á that pertains to our graph construction process.
¡¡for each document d ¡Ê c  pd ¡¤  denotes the smoothed unigram language model induced from d  estimation details appear in section 1 . we use g and o to distinguish between a document treated as a  generator  and a document treated as  offspring   that is  something that is generated  details below .
¡¡we use the notation  v wt  for weighted directed graphs: v is the set of vertices and w is the edge-weight function. thus  there is a directed edge between every ordered pair of vertices  but wt may assign zero weight to some edges. we write wt v1 ¡ú v1  to denote the value of wt on edge  v1 v1 .
1 generation graphs
¡¡our use of language models to form links can be motivated by considering the following two documents:
d1:	toronto sheffield salvador d1:	salvador salvador salvador
knowing that d1 is important  i.e.  central or relevant  would provide strong evidence that d1 is at least somewhat important. however  knowing that d1 is very important does not allow us to conclude that d1 is  since the importance of d1 might stem from its first two terms. using language models induced from documents enables us to capture this asymmetry in how centrality is propagated: we allow a document d to receive support for centrality status from a document o only to the extent that pd o  is relatively large.  if o is not in fact important  the support it provides may not be significant.  note that ranking documents by pd q   as first proposed by ponte and croft   can be considered a variation of this principle.
we are thus led to the following definitions.
definition 1. the top ¦Á generators of a document d ¡Ê
dinit  denoted topgen d   is the set of ¦Á documents g ¡Ê dinit {d} that yield the highest pg d   where ties are broken by document id.  we suppress ¦Á in our notation for clarity. 
¡¡definition 1. the offspring of a document d ¡Ê dinit are those documents that d is a top generator of  i.e.  the set {o ¡Ê dinit : d ¡Ê topgen o }.
note that multiple documents can share offspring  and that it is possible for a document to have no offspring.
¡¡we can encode top-generation relationships using either of two generation graphs gu =  dinit wtu  and gw =  dinit wtw   where for o g ¡Ê dinit 
wtu o ¡ú g =1	if g ¡Ê topgen o  
1	otherwise;wtw o ¡ú g =pg o 	if g ¡Ê topgen o   1	otherwise.thus  in both graphs  positive-weight edges lead only from offspring to their respective top ¦Á generators; but gu treats  edges to  the top generators of o uniformly  whereas gw differentially weights them by the probability their induced language models assign to o.
¡¡some of our algorithms require  smoothed  versions of these graphs  in which all edges  including self-loops  have non-zero weight  to work correctly. to be specific  we employ pagerank's  smoothing technique.
¡¡definition 1. given an edge-weighted directed graph g =  dinit wt  and smoothing parameter ¦Ë ¡Ê  1   the smoothed graph g ¦Ë  =  dinit wt ¦Ë   has edge weights defined as follows: for every o g ¡Ê dinit.
wt ¦Ë  o ¡ú g  =  1	t o ¡ú g 	 
the weights of all edges leading out of any given node in g ¦Ë  sum to 1 and thus may be treated as transition probabilities. with these concepts in hand  we can now phrase our centrality-determination task as follows: given a generation graph  compute for each node  i.e.  document  how much centrality is  transferred  to it from other nodes - by our edge-weight definitions  centrality therefore corresponds to the degree to which a document is responsible for  generating   perhaps indirectly  the other documents in the initially retrieved set. we now consider different ways to formalize this notion of transferrence of centrality.
1 computing graph centrality
¡¡a straightforward way to define the centrality of a document d with respect to a given graph g =  dinit wt  is to set it to d's weighted in-degree  which we call its influx:
def
	ceni d;g  =	wt o ¡ú d .	 1 
o¡Êdinit
the uniform influx algorithm sets g = gu  so that the only thing that matters is how many offspring d has; it is thus reminiscent of the journal impact factor function from bibliometrics   which computes normalized counts of explicit citation links. the weighted influx algorithm sets g = gw  so that the generation probabilities that d assigns to its offspring are factored in as well.
¡¡as previously noted by pinski and narin in their work on influence weights   one intuition not accounted for by weighted in-degree methods is that a document with even a great many offspring should not be considered central  or relevant  if those offspring are themselves very non-central. we can easily modify equation 1 to model this intuition; we simply scale the evidence from a particular offspring document by that offspring's centrality  thus arriving at the following recursive equation:
def
	cenri d;g  =	wt o ¡ú d  ¡¤ cenri o;g  	 1 
o¡Êdinit
where we also require that	d¡Êdinit cenri d;g  = 1. unfortunately  for arbitrary gu and gw  equation 1 may not have a unique solution or even any solution at all under the normalization constraint just given; however  a unique solution is guaranteed to exist for their pagerank-smoothed versions.1 by analogy with the two influx algorithms given above  then  we have the recursive uniform influx algorithm  which sets and is a direct analog of pagerank  and the recursive weighted influx algorithm  which sets.
1 incorporating initial scores
¡¡the centrality scores presented above can be used in isolation as criteria by which to rank the documents in dinit. however  if available  it might be useful to incorporate more information from the initial retrieval engine to help handle cases where centrality and relevance are not strongly correlated.  recall that it participates in any case by specifying the set dinit.  in our experiments  we explore one concrete instantiation of this approach: we apply language-modelbased retrieval  1  1  to determine dinit  and consider the following family of re-ranking criteria:
	cen d;g  ¡¤ pd q  	 1 
where d ¡Ê dinit and cen is one of the centrality functions defined in the previous section. this gives rise to the algorithms uniform influx+lm  weighted influx+lm  recursive uniform influx+lm  and recursive weighted influx+lm.
¡¡incidentally  our choosing pd q  as initial score function has the interesting consequence that it suggests interpreting cen d;g  as a document  prior  - in fact  lafferty and zhai write   with hypertext   a document prior  might be the distribution calculated using the 'pagerank' scheme  . we will return to this idea later.
1 estimatinggenerationprobabilities: length and entropy effects
¡¡generation probabilities form the basis for the graphs on which our algorithms are defined. this section describes our method for estimating these probabilities.
¡¡let tf w ¡Ê x  denote the number of times the term w occurs in the text or text collection x. what is often called the maximum-likelihood estimate  mle  of w with respect to x is defined as
.
some prior work in language-model-based retrieval  1  1  employs a dirichlet-smoothed version:
;
the smoothing parameter ¦Ì controls the degree of reliance on relative frequencies in the corpus rather than on the counts in x. both estimates just described are typically extended

1
 the edge weights correspond to the transition probabilities for a markov chain that is aperiodic and irreducible  and hence has a unique stationary distribution  that can be computed by a variety of means  1  1  1 . in our experiments  power iteration converged very quickly.
to distributions over term sequences by assuming that terms are independent: for an n-term text sequence w1 ¡¤¡¤¡¤wn 
n
	pmlex	 w1 ¡¤¡¤¡¤wn 	def=	pxmle wj ;
j=1 n
	p x¦Ì  w1 ¡¤¡¤¡¤wn 	def=	px ¦Ì  wj .
j=1
another estimation approach  which we adopt  incorporates the kullback-leibler divergence d between document language models  1  1   see also previously proposed ranking principles  1  1  : unless otherwise specified  for document d and word sequence s  in our setting  either a document or the query   we set pd s  to pkl ¦Ìd  s  def= exp  d psmle ¡¤  pd ¦Ì  ¡¤  .  1 
equation 1 has some useful properties. we can show that
 
	term a	term b
where h is the entropy function. now  observe that for both pmlex  ¡¤  and p x¦Ì  ¡¤   longer text sequences tend to be assigned lower probabilities; this would correspond to an unmotivated reduction of weights for edges out of long documents in the graph gw. however  term a length-normalizes
  via the geometric mean  which has helped ameliorate numerical problems in previous work . additionally  term b raises the generation probability for texts with high-entropy mle term distributions. high entropy may be correlated with a larger number of unique terms - for example  we get an entropy of 1 for the document  salvador salvador salvador  but log1 for  toronto sheffield salvador  - which  in turn  has previously been suggested as a cue for relevance  1  1 . hence  generators of documents inducing high-entropy language models may be good candidates for centrality status.  we hasten to point out  though  that for the algorithms based on smoothed graphs  definition 1   the entropy term cancels out due to our normalization of edge weights. 
1. related work
¡¡work on structural re-ranking in traditional ad hoc information retrieval has mainly focused on query-dependent clustering  wherein one seeks to compute and exploit a clustering of the initial retrieval results  1  1  1  1  1 . clusters represent structure within a document set  but do not directly induce an obvious single criterion or principle by which to rank documents; for instance  they have been used to improve rankings indirectly by serving as smoothing mechanisms . interestingly  some centrality measures have been previously employed to produce clusterings .
¡¡there has been increasing use of techniques based on graphs induced by implicit relationships between documents or other linguistic items  1  1  1  1  1  1  1 . the work in the domain of text summarization  1  1  most resembles ours  in that it also computes centrality on graphs  although the nodes correspond to sentences or terms instead of documents . perhaps the main contrast with our work is that links were not induced by generation probabilities; section 1 presents the results of experiments studying the relative merits of our particular choice of link definition.
¡¡our centrality scores constitute a relationship-based reranking criterion that can serve as a bias affecting the initial retrieval engine's scores  as in equation 1. alternative biases that are based on individual documents alone have also been investigated. functions incorporating document or average word length  1  1  1  are applicable in our setting; we report on experiments with  variants of  document length in section 1. other previously suggested biases that may be somewhat less appropriate for general domains include document source  and creation time   and webpage hyperlink in-degree and url form .
1. evaluation
1 experimental setting
¡¡the objective of structural re-ranking is to  re- order an initially-retrieved document set dinit so as to improve precision at the very top ranks of the final results. therefore  we employed the following three evaluation metrics: the precision of the top 1 documents  prec 1   the precision of the top 1 documents  prec 1   and the mean reciprocal rank of the first relevant document  mrr  .
¡¡we are interested in the general validity of the various structural re-ranking methods we have proposed. we believe that a good way to emphasize the effectiveness  or lack thereof  of the underlying principles is to downplay the role of parameter tuning. therefore  we made the following design decisions  with the effect that the performance numbers we report are purposely not necessarily the best achievable by exhaustive parameter search:
  the initial ranking that created the set dinit was built according to the function pkl ¦Ìd  q  where the value of ¦Ì was chosen to optimize the non-interpolated average precision of the top 1 retrieved documents. this is not one of our evaluation metrics  but is a reasonable general-purpose optimization criterion.  in fact  results with this initial ranking turned out to be statistically indistinguishable from the results obtained by optimizing with respect to the actual evaluation metrics  although of course they were lower in absolute terms. 
  we only optimized settings for ¦Á  the ancestry parameter controlling the number of top generators considered for each document  and ¦Ë  the edge-weight smoothing factor  with respect to precision among the top 1 documents  not with respect to all three evaluation metrics employed.
the search ranges for the latter two parameters were: ¦Á:	1 1 ... |dinit|   1 ¦Ë:	1.1.1.1 ... 1 1
as it turned out  for many instances  except for the weighted influx algorithm   the optimal value of ¦Á with respect to precision at 1 was either 1 or 1  suggesting that a relatively small number of generators per document should be considered when constructing the graph. in contrast  ¦Ë exhibited substantial variance in optimal value for precision at 1 in some of our datasets. we set |dinit|  the number of initiallyretrieved documents  to 1 in all results reported below  similar performance patterns were obtained when |dinit| = 1 . the remaining details are as follows. we conducted our experiments on the following four trec corpora:
corpus	# of docs	queries	disk s ap1 1-1-1
ap 1 1  1 1 wsj 1 1 1 trec1 1-1-1 ap1 is a subset of ap containing articles just from the year 1 . all documents and queries  in our case  trectopic titles  were stemmed using the porter stemmer and tokenized  but no other pre-processing steps were applied. we used the lemur toolkit  for language-model estimation. statistically-significant differences in performance were determined using the two-sided wilcoxon test at a confidence level of 1%.
1 results
¡¡in the tables that follow  we use the following abbreviations for algorithm names.
u-in	uniform influx
w-in	weighted influxr-u-in	recursive uniform influx
r-w-in	recursive weighted influxu-in+lm	uniform influx+lm
w-in+lm	weighted influx+lmr-u-in+lm	recursive uniform influx+lm
r-w-in+lm	recursive weighted influx+lm1.1 primary evaluations
¡¡our main experimental results are presented in table 1. the first three rows specify reference-comparison data. the initial ranking was  as described above  produced using pkl ¦Ìd  q  with ¦Ì chosen to optimize for non-interpolated precision at 1. the empirical upper bound on structural re-ranking  which applies to any algorithm that re-ranks dinit  indicates the performance that would be achieved if all the relevant documents within the initial fifty were placed at the top of the retrieval list: note that these bounds indicate that the initial rankings for ap1 are quite worse than those for the other three corpora. we also computed an optimized baseline for each metric m and test corpus c; this consists of ranking all the documents  not just those in dinit  by pkl ¦Ìd  q   with ¦Ì chosen to yield the best m-results on c. as a sanity check  we observe that the performance of the initial retrieval method is always below that of the corresponding optimized baseline  though not statistically distinguishable from it .
¡¡the first question we are interested in is how our structural re-ranking algorithms taken as a whole do. as shown in table 1  our methods improve upon the initial ranking in many cases  specifically  roughly 1 of the 1 relevant comparisons  1 centrality-based algorithms ¡Á 1 corpora ¡Á 1 evaluation metrics . an even more gratifying observation is that table 1 shows  via italics and boldface  that in many cases  our algorithms  even though optimized for precision at 1  can outperform a language model optimized for a different  albeit related  metric m even when performance is measured with respect to m; see  for example  the results for precision at 1 on the ap corpus.
ap1apwsjtrec1prec 1prec 1mrrprec 1prec 1mrrprec 1prec 1mrrprec 1prec 1mrrupper bound111111111111init. ranking111111111111opt. baselines111111111111
u-in111 o11 io1111111w-in11111 i1111 o111u-in+lm1111 i1 io111111 io1w-in+lm1111 i1 io111111 i1
r-u-in11111i1111111r-w-in111 o1 i1i o1111111r-u-in+lm1111 io1i o11 i1 i1111r-w-in+lm1111 io1i o11 i11111table 1: primary experimental results  showing algorithm performance with respect to our 1 evaluation settings  1 performance metrics ¡Á 1 corpora . for each evaluation setting  improvements over the optimized

baselines are given in italics; statistically significant differences between our structural re-ranking algorithms and the initial ranking and optimized baselines are indicated by i and o respectively; bold highlights the best results over all ten algorithms.
¡¡notice that even though the structural re-ranking algorithms were optimized for prec 1 only  and produce the best results for this metric   they still perform well with respect to the other two metrics.¡¡closer examination of the results in table 1 reveals that in about 1% of the 1 relevant comparisons  our algorithms not only are at least as effective when applied to the graph gw as when applied to gu  but often yield better performance results; the comparison between recursive weighted influx  r-w-in  and recursive uniform influx  r-u-in  is a good example. these results imply that it is a bit better to explicitly incorporate generation probabilities into the edge weights of our generation graphs than to treat all the top generators of a document equally.
¡¡another observation we can draw from table 1 is that adding in query-generation probabilities as weights on the centrality scores  see equation 1  tends to enhance performance. this can be seen by comparing rows labeled with some algorithm abbreviation  x  against the corresponding rows labeled  x+lm : about 1% of the 1 relevant comparisons exhibit this improvement. most of the counterexamples occur in settings involving precision at 1 and mrr  which we did not optimize our algorithms for.
¡¡similarly  by comparing  y -labeled rows with  r-y labeled ones  we see that in about 1% of the 1 relevant comparisons  it is better to use the recursive formulation of equation 1  where the centrality of a document is affected by the centrality of its offspring  than to ignore offspring centrality as is done by equation 1.
¡¡perhaps not surprisingly  then  the recursive uniform influx+lm and recursive weighted influx+lm algorithms  which combine the two preferred features just described  recursive centrality computation and use of the initial search engine's score function  appear to be our best performing algorithms: working from a starting point below the optimized baselines  they improve the initial retrieval set to yield results that even at their worst  are not only clearly better than the initial ranking for precision at 1 and 1  but are also merely statistically indistinguishable from the optimized baselines. moreover  in one setting  ap  precision at 1  they actually produce statistically significant improvements over the optimized baseline even though they were not optimized for that evaluation metric.
¡¡it is interesting to note that the relative performance of our algorithms does not seem to depend strongly on the quality of the initial ranking  in the following sense. the average percentage of relevant documents among the 1 that are initially retrieved is 1%  1%  1% and 1% for ap1  ap  wsj and trec1  respectively  but the relative improvements for precision at 1 and 1 that our algorithms achieve with respect to the initial ranking are almost always higher on ap1 than on wsj or trec1.
1.1 links based on the vector-space model
¡¡we have advocated the use of generation relationships to define centrality  where these asymmetric relationships are based on language-model probabilities. however  other inter-document relationships have been previously exploited in information retrieval. perhaps the most well-known is vector-space proximity  with the cosine frequently used as  symmetric  closeness metric; indeed  as mentioned above  previous work in summarization  has used the cosine to determine centrality in ways very similar to the ones we have considered. it is thus important to examine whether the performance improvements we have achieved can be reproduced  or even surpassed  by the use of vector-space-based links rather than language-model-based generation links.
¡¡to run this evaluation  we simply modified definition 1 and all eight of our structural re-ranking algorithms to use the cosine of the angle between log tf.idf document vectors  rather than language-model probabilities  to form the basis for determining the edge weights of our graphs.  note that the fact that the cosine is symmetric does not imply that edges  v1 v1  and  v1 v1  get the same weight even in our non-smoothed graphs - document d1 being a top  generator  of d1 with respect to the cosine does not imply the reverse.  it should be observed that the language-model weights on centrality scores  i.e.  the pd q  term in equation 1  on which the  +lm  algorithms are based  were not replaced with cosine values  which makes sense since we want our comparison to focus on the effect of different means of computing graph-based centrality.
	u-in	w-in	u-in+lm	w-in+lm	r-u-in	r-w-in	r-u-in+lm	r-w-in+lm
prec  1ap1prec  1
mrrprec  1apprec  1
mrrprec  1wsjprec  1
mrrprec  1trec1prec  1
mrrtable 1: structural re-ranking based on language models  lm  vs. structural re-ranking based on cosinemeasured vector-space proximity  vec . we indicate the settings in which the relative difference was at least 1% with either a      lm superior  or a      vec superior .
ap1apwsjtrec1prec 1prec 1mrrprec 1prec 1mrrprec 1prec 1mrrprec 1prec 1mrruniform  = init 111111111111w-in1111 1 1111111r-w-in111111111111length1111111 1 1 111log length 111111111 111entropy111111111 111uniqterms111111111111log uniqterms 111111111111 
table 1: comparison between our use of language-model-based structural-centrality scores in equation 1 vs. non-structural re-ranking heuristics. for each evaluation setting  italics mark improvements over the default baseline of uniform centrality scores  stars  *  indicate statistically significant differences with this default baseline  and bold highlights the best results over all eight algorithms.¡¡table 1 depicts the relative performance differences between using our language-model-based graphs and graphs induced using vector-space proximity in the manner just described. for each choice of algorithm  evaluation measure  and dataset  we indicate which formulation  if any  resulted in at least 1% relative improvement with respect to the other. as can be seen  in at least three of our four corpora  our language-modeling approach seems to be a more effective basis for determining document centrality than the vector-space/cosine. we hasten to point out  though  that in most instances  vector-space proximity yielded better performance than the corresponding baselines  the results are omitted since the precise numerical comparison does not yield additional information ; this finding provides further support to the idea that the overall structural re-ranking approach is a flexible and effective paradigm that can incorporate different types of inter-document relationships when appropriate.
1.1 inducing centrality with the hits algorithm
¡¡one well-known alternative method for computing centrality in a graph is the hits algorithm   originally proposed for web search. there has been some work utilizing it for text summarization in non-web domains as well . the reason we have not yet discussed it in detail is that it differs conceptually from our proposed algorithms in an important way: two different notions of centrality are identified  represented by hub and authority scores. while the concepts of hubs and authorities are highly suitable for websearch scenarios  it is less clear whether it is useful in our setting to distinguish between the two.
¡¡as a preliminary investigation  we experimented with using hub and authority scores as measures of centrality on the generation graphs we built. space constraints preclude a detailed discussion  but the results may be summarized as follows. we found that authority scores yielded better performance than hub scores  and that the results were generally at least as good as or better than those for the optimized baselines. however  they were slightly inferior in several cases to those of the corresponding influx algorithms. thus  it seems that our method for graph construction can support a variety of different algorithms  but that the hitsstyle hubs/authorities distinction may not be effective for the task we have addressed.
1.1 non-structural re-ranking
¡¡so far  we have discussed the use of graph-based centrality as a re-ranking criterion  the idea being that relationships between documents can serve as an additional source of information. our best empirical results seem to be produced by using the weighted formulation given in equation 1 from section 1:
cen d;g  ¡¤ pd q .
since  as noted above  in this equation cen d;g  can be regarded as a  prior  on documents  it is natural to ask whether other previously-proposed biases on generation probabilities might prove similarly useful. the comparison is especially interesting because these biases have tended to be isolated-document heuristics; we thus refer to their use as a replacement for cen d;g  as  non-structural re-ranking .
¡¡document length has been employed several times in the past to model the intuition that longer texts contain more information  1  1  1 . we refine this hypothesis to disentangle several distinct notions of information: the number of tokens in a document  the distribution of these tokens  and the number of types   salvador salvador salvador  contains three tokens but only one type . thus  as substitutions for centrality in the above expression  we consider not only document length  but also the entropy of the term distribution and the number of unique terms  used as the basis for pivoted unique normalization in  . as baseline  we took the initial retrieval results; note that doing so corresponds to using a uniform bias  or  equivalently  using no bias at all.
¡¡as can be seen in table 1  taking the log of token or type count is an improvement over using the raw frequencies  often yielding above-baseline performance. the entropy is more effective than raw frequency of either tokens or types  and in two cases leads to the best performance overall. however  in the majority of settings  structural re-ranking gives the highest accuracies.
1.1 re-ranking vs. ranking
¡¡we posed our centrality-computation techniques as methods for improving the results returned by an initial retrieval engine  and showed that they are successful at accomplishing this goal. but one can ask whether it is necessary to restrict our attention to an initial pool dinit; that is  would we expect similarly good results if we based our generation graphs on the entire corpus  as it happens  preliminary experiments with the recursive uniform influx+lm and recursive weighted influx+lm algorithms on two full corpora  ap1 and la combined with fr  showed that one would be better off sticking with the standard language-modeling approach if no pre-filtering of documents is available.
¡¡we do not see this finding as surprising  for our intuition is that in the re-ranking case  there is a more direct connection between centrality and relevance since we can assume that relevant documents comprise a reasonable fraction of the initial retrieval results.
1. conclusion
¡¡we have proposed and evaluated a number of methods for structural re-ranking using inter-document generation relationships based on language models. our main experiments showed that even non-optimized instantiations of our overall approach yield results rivaling those of optimized baselines. further analysis revealed that generation relationships seem more effective within our centrality-computation framework than relationships based on vector-space proximity do  and that using inter-document relationships seems to be a promising alternative to employing the isolateddocument heuristics we implemented  several of which were novel to this study . based on our results  we believe that exploring other methods for combining statistical language models and explicitly graph-based techniques is a fruitful line for future research.
acknowledgments. we thank james allan  bruce croft  carmel domshlak  jon kleinberg  fernando pereira and the anonymous reviewers for valuable discussions and comments. we also thank cmu for its hospitality during the year. this paper is based upon work supported in part by the national science foundation under grant no. iis1 and ccr-1; sri international under subcontract no. 1 on their project funded by the department of the interior's national business center; and an alfred p. sloan research fellowship. any opinions  findings  and conclusions or recommendations expressed are those of the authors and do not necessarily reflect the views or official policies  either expressed or implied  of any sponsoring institutions  the u.s. government  or any other entity.
