most previous work on the recently developed languagemodeling approach to information retrieval focuses on document-specific characteristics  and therefore does not take into account the structure of the surrounding corpus. we propose a novel algorithmic framework in which information provided by document-based language models is enhanced by the incorporation of information drawn from clusters of similar documents. using this framework  we develop a suite of new algorithms. even the simplest typically outperforms the standard language-modeling approach in precision and recall  and our new interpolation algorithm posts statistically significant improvements for both metrics over all three corpora tested.
categories and subject descriptors
h1  information search and retrieval : language models  clustering  smoothing
general terms
algorithms  experiments
keywords
language modeling  aspect models  interpolation model  clustering  smoothing  cluster-based language models
1. introduction
　as is well known  a basic problem in information retrieval is to determine how relevant a particular document is to a query. in the automatic ad hoc retrieval setting  examples of relevant documents are not supplied. given this absence of explicit relevance evidence  it is important to consider what other information sources can be exploited.
　in methods patterned after the classic tf.idf documentvector approach to text representation  the focus is mostly
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee.
sigir'1  july 1 1  sheffield  south yorkshire  uk.
copyright 1 acm 1-1/1 ...$1.
on utilizing within-document features  such as term frequencies. information drawn from the corpus as a whole generally consists of aggregates of statistics gathered from each document considered in isolation; for example  the inverse document frequency is based on checking  for each document  whether that document contains a particular term.
　recent work has demonstrated the effectiveness of an alternative approach wherein probabilistic models of text generation are constructed from documents  and these induced language models  lms  are used to perform document ranking  1  1 . like tf.idf and related techniques  though  language-modeling methods typically use only individual-document features and corpus-wide aggregates of the same.  corpus term counts are generally employed for smoothing  so that unseen text can be assigned non-zero probability. 
　neither of the aforementioned approaches typically makes use of a potentially very powerful source of information: the similarity structure of the corpus. clusters are a convenient representation of similarity whose potential for improving retrieval performance has long been recognized  1  1 . from our point of view  one key advantage is that they provide smoothed  more representative statistics for their elements  as has been recognized in statistical natural language processing for some time . for example  we could infer that a document not containing a certain query term is still relevant if the document belongs to a cluster whose component documents generally do contain the term.
　however  relying on clusters alone has some potential drawbacks. clustering at retrieval time can be very expensive  but off-line clustering seems  by definition  query-independent and therefore may be based on factors that are irrelevant to user information need. also  cluster statistics may overgeneralize with respect to specific member documents.
　we therefore propose a framework for incorporating both corpus-structure information - using pre-computed  overlapping clusters - and individual-document information. importantly  although cluster formation is query-independent  within our framework the choice of which clusters to incorporate can depend on the query. we then consider several of the many possible algorithms arising as specific instantiations of our framework. these include both novel methods and  as special cases  both the standard  non-clusterbased lm approach and a variant of the cluster-based aspect model .
　our empirical evaluation consists of experiments in an array of settings created by varying several parameters and meta-parameters; these include the corpus  the information representation  e.g.  language models versus tf.idf-style vectors   and  when applicable  the smoothing method selected. we find that even the worst-performing of our novel algorithms is competitive with the lm approach  and indeed always provides substantial improvement in recall. in general  our algorithms provide good performance in comparison to a number of recently proposed methods  thus demonstrating that our integration approach to incorporating document and corpus-structure information is an effective way to improve ad hoc retrieval.
notational conventions. we use d q c and c to denote a document  query  cluster  and corpus  respectively. a fixed vocabulary is assumed. we use the notation pd ，  for the language model - which assigns probabilities to text strings over the fixed vocabulary - induced from d by some prespecified method  and pc ，  for the language model induced from c.  section 1 describes the induction methods we used in our experiments. 
　it is convenient to use kronecker delta notation δ s  to set up some definitions. the argument s is a statement; δ s  = 1 if s holds  1 otherwise.
1. retrieval framework
　as noted above  when we rank documents with respect to a query  we desire per-document scores that rely both on information drawn from the particular document's contents and on how the document is situated within the similarity structure of the ambient corpus.
structure representationvia overlappingclusters. document clusters are an attractive choice for representing corpus similarity structure  see  1  chapter 1  for extended discussion . clusters can be thought of as facets of the corpus that users might be interested in. given that a particular document can be relevant to a user for several reasons  or to different users for different reasons  we believe that a set of overlapping clusters1 forms a better model for similarity structure than a partitioning of the corpus. furthermore  employing intersecting clusters may reduce information loss due to the generalization that clustering can introduce  1  pg. 1 .
information representation. motivated by the empirical successes of language-modeling-based approaches  1  1   we use language models induced from documents and clusters as our information representation. thus  pd q  and pc q  specify our initial knowledge of the relation between the query q and a particular document d or cluster c  respectively.  however  section 1 shows that using a tf.idf representation also yields performance improvements with respect to the appropriate baseline  though not to the same degree as using language models does. 
information integration. to assign a ranking to the documents in a corpus c with respect to q  we want to score each d （ c against q in a way that incorporates information from query-relevant corpus facets to which d belongs. while one could compute clusters specific to q at retrieval time  efficiency considerations compel us to create clusters c   the

1
we include soft or probabilistic clusters in this category.
set of clusters  in advance  and hence in a query-independent fashion. to compensate  at retrieval time we base the choice of appropriate facets on the query.
　how might cluster information be used  our discussion above indicates that clusters can serve two roles. insofar as they approximate true facets of the corpus  they can aid in the selection of relevant documents: we would want to retrieve those that belong to clusters corresponding to facets of interest to the user. on the other hand  clusters also have the capacity to smooth individual-document language models  since they pool statistics from multiple documents. finally  we must remember that over-reliance on pc q  can over-generalize by failing to account for document-specific information encoded in pd q .
　these observations motivate the algorithm template shown in figure 1. this template is fairly general: both the standard language-modeling approach  and the aspect model  are concrete instantiations. in the template  the choice of facetsq d  corresponds to utilizing clusters in their selection role. the scoring step can be thought of as integrating pd q  with cluster-based language models in their smoothing role. the optional re-ranking step is used as a way to further bias the final ranking towards document-specific information  if desired. note that re-ranking can change the average non-interpolated precision but not the absolute precision or recall of the retrieval results; we therefore use it  when necessary  to enhance average precision.  section 1 reports experiments studying its efficacy. 
offline: create clusters c 
given q and n  the number of documents to retrieve:
for each d （ c 
choose a cluster subset facetsq d    clusters c 
score d by a weighted combination of pd q  and the pc q 's for all c （ facetsq d 
set topdocs n  to the rank-ordered list of n topscoring documents
optional: re-rank d （ topdocs n  by pd q  return topdocs n figure 1: algorithm template.
　in the next section  we describe a number of specific algorithms arising from this template  concentrating on their degree of dependence on cluster-induced language models.
1. retrieval algorithms
　table 1 summarizes the algorithms we consider  which represent a few choices out of the many possible ways to instantiate the template of figure 1. our preference in picking these algorithms has been towards simpler methods  so as to focus on the impact of using cluster information  as opposed to the impact of tuning many weighting parameters .
facetsq d scorere-rank by pd q  lmn/apd q  redundant basis-select set-select bag-select{cohort cc :: dd （（ dcc}} }”””topclusterstopclusterstopclustersqq  qmm m   
{
{pd q  ， δ |facetsq d |   1  pd q  ， δ |facetsq d |   1  pd q  ， |facetsq d | redundant 
 redundant  yesuniform-aspect-x aspect-x{c : d （ c} ” topclustersq m 
{c : d （ c} ” topclustersq m pc（facetsq d  c q  p
pc（facetsq d  c q  ， pc d  pyes yesinterpolation	c : d	c	topclustersq m λpd q  +  1	λ 	c facetsq d  pc q pc d no	{	（ } ”	，	  p （	，
table 1: algorithm specifications.first step: cluster formation and selection. there are many algorithms that can be used to create clusters c   the set of overlapping document clusters required by figure 1's template. in our experiments  we simply have each document d form the basis of a cluster cohort d  consisting of d and its k 1 nearest neighbors  where k is a free parameter.  note that two clusters with different basis documents may contain the same set of documents.  inter-document distance is measured by the kullback-leibler  kl  divergence between the corresponding  smoothed  language models  as in .
　the idea behind our use of cohorts is that a document's nearest neighbors in similarity space represent a local  fragment  or  tile  of the overall similarity structure of the corpus. our evaluation results show that even this relatively unsophisticated way to approximate facets enables effective leveraging of corpus structure; at the very least  it serves as a form of nearest-neighbor smoothing  see below .
　the first retrieval-time action specified by our algorithm template is to choose facetsq d   a query-dependent subset of clusters c . in all the algorithms described below except the baseline  which doesn't use cluster information   there is a document-selection aspect to this subset  in that only documents in some c （ facetsq d  can appear in the final ranked-list output. ideally  we would use the clusters best approximating those  true  facets of the corpus that are most representative of the user's interests  as expressed by q; therefore  we require that facetsq d  be a subset of topclustersq m   the top m clusters c with respect to pc q . but we also want to evaluate d only with respect to the facets it actually exhibits. thus  in what follows  except for the baseline   facetsq d  is always defined to be a subset of {c : d （ c}”topclustersq m ; we assume m is large enough to produce the desired number of retrieved documents n.
baseline method. the baseline for our experiments  denoted lm  is to simply rank documents by pd q  - no cluster information is used. details of our particular implementation are given in section 1.
selection methods. in this class of algorithms  the clusterinduced language models play a very small role once the set facetsq d  is selected. in essence  the standard languagemodeling approach  that is  ranking by pd q   is invoked to rank  some of  the documents comprising the clusters in facetsq d . this method of scoring is intended to serve as a precision-enhancing mechanism  downgrading documents that happen to be members of some c （ facetsq d  by dint of similarity to d in respects not pertinent to q.
　in the basis-select algorithm  the net effect of the definition given in table 1 is that only the basis documents of the clusters in topclustersq m  are allowed to appear in the final output list. thus  this algorithm uses the pooling of statistics from documents in cohort d  simply to decide whether d is worth ranking; the rank itself is based solely on pd q .
the set-select algorithm differs in that all the documents
in the clusters in topclustersq m  may appear in the final output list - the  set  referred to in the name is the union of the clusters in topclustersq m . the idea is that any document in a  best  cluster  basis or not  is potentially relevant and should be ranked. again  the ranking of the
selected documents is by pd q .1
　another natural variant of the same idea is that documents appearing in more than one cluster in topclustersq m  should get extra consideration  given that they appear in several  approximations of  facets thought to be of interest to the user. this idea gives rise to the bag-select algorithm  so named in reference to the incorporation of a document's multiplicity in the bag formed from the  multi-set union  of all the clusters in facetsq d . first  each selected document d is assigned a score consisting of the product of its language-modeling score pd q  and the number of  top  clusters it belongs to. the n top-scoring documents are then re-ranked via pd q  and presented in the new sorted order.
aspect-xmethods. we now turn to algorithms making more explicit use of clusters as smoothing mechanisms. in particular  we study what we term  aspect-x  methods. our choice of name is a reference to the work of hofmann and puzicha   which conceives of clusters as explanatory latent variables underlying the observed data.  the  x  stands for  extended  . in our setting  this idea translates to using pc q  as a proxy for pd q   where the degree of dependence on a particular pc q  is based on the strength of association between d and c. the aspect-x algorithm measures this association by pc d ; the uniform-aspect-x algorithm assumes that every d （ c has the same degree of association to c. in both cases  re-ranking by pd q  is applied.
　the scoring function we use for our aspect-x algorithm can be motivated by appealing to the probabilistic derivation of the aspect model   as follows. it is a fact that
	.	 1 
the aspect model assumes that a query is conditionally independent of a document given a cluster  which is a way of using clusters to smooth individual-document statistics   in which case p q|d  = pc p q|c p c|d . if we further assume that p d  and p c  are constant  we can write p q|d  =

1
 because our implementation treats clusters and their component documents in a  fifo  manner  it deviates slightly from the template. let n be the number of documents in the m   1 highest-ranked clusters. then  only the documents in the m'th cluster that are closest  in the kldivergence sense  to the cluster's basis are allowed into topdocs n .
αpc p q|c p d|c   where α is a constant that doesn't affect ranking. our aspect-x algorithm then arises by replacing the conditional probabilities with the corresponding language models and only summing over the clusters in facetsq d . constraining which clusters participate in the sum to those of relatively high rank is important: experiments indicate that using a large number of clusters could be detrimental. we note  however  that it appears difficult within the strictly probabilistic framework of the original aspect model to incorporate such a constraint: a particular cluster's rank depends on all the other clusters  but none of the terms in the basic aspect-model equation explicitly conditions on them.
ahybridalgorithm. the selection-only algorithms emphasize pd q  in scoring a document d; in contrast  the aspect-x algorithms rely on pc q . we created the interpolation algorithm to combine the advantages of these two approaches. the algorithm can be derived by dropping the original aspect model's conditional independence assumption - namely  that p q|d c  = p q|c  - and instead setting p q|d c  in equation 1 to λp q|d + 1 λ p q|c   where λ indicates the degree of emphasis on individual-document information. if we do so  then via some algebra we get p q|d  = λp q|d  +  1  λ pc p q|c p c|d . finally  applying the same assumptions as described in our discussion of the aspect-x algorithm yields a score function that is the linear interpolation of the score of the standard lm approach and the score of the aspect-x algorithm. note that no re-ranking step occurs; as we shall see  the interpolation algorithm's incorporation of document-specific information yields higher precision.
1. related work
　document clustering has a long history in information retrieval  1  1 ; in particular  approximating topics via clusters is a recurring theme . arguably the work most related to ours by dint of employing both clustering and language modeling in the context of ad hoc retrieval1 is that on latent-variable models  e.g.   1  1  1  1   of which the classic aspect model is one instantiation. such work takes a strictly probabilistic approach to the problems we have discussed with standard language modeling  as opposed to our algorithmic viewpoint. also  a focus in the latent-variable work has been on sophisticated cluster induction  whereas we find that a very simple clustering scheme works rather well in practice. interestingly  hofmann  linearly interpolated his probabilistic model's score  which is based on  soft  clusters  with the usual cosine metric; this is quite close in spirit to what our interpolation algorithm does.
　implicit corpus structure is also exploited by lafferty and zhai's expanded query language model . their method uses interleaved document-term markov chains  which can be thought of as tracing  paths  between related documents  to enhance language models built from queries. this is similar conceptually to our framework's use of inter-document similarities to enhance the performance of document language models  although in our work the notion of similarity is more explicit.

1
 see e.g.      and  for applications of clustering in related areas.
1. experimental setup
data. we conducted our experiments on trec data. we used titles  rather than full descriptions  as queries  resulting in an average length of 1 terms. some characteristics of our three corpora are summarized in the following table.
corpus	# of docs	queries	previous workap1 1-1-1	lafferty & zhai 
ap1	1	1	lavrenko & croft 
la+fr	1	1	-the first two data corpora  ap1 and ap1  were chosen because they have served as data for previous research on state-of-the-art algorithms somewhat related to but considerably extending the basic lm approach. we used the same stemming and stopword-removal policies as in those previous experiments; hence  we applied the porter stemmer to the ap1 collection  disk one   and we ran the krovetz stemmer on ap1 and removed both inquery stopwords  and length-one tokens. la+fr  disk 1 and 1  respectively   which is part of the trec-1 corpus  we used trec-1 ad hoc queries   was neither stemmed nor subjected to stopword removal. this corpus is more heterogeneous than the other two.
induction of base language models. unless otherwise specified  we use unigram dirichlet-smoothed language models  which were previously shown to yield good performance for short queries   in the following manner. for the purposes of this discussion  we use the term  document  and notation d to refer either to a true document in the corpus c or to a query. let f x （ y  be the number of times word x occurs in item y. for a text sequence  the dirichlet-smoothed language model induced from d assigns the following probability to w:
  
where the free parameter μ controls the degree to which the document's statistics are altered by the overall corpus statistics  and  ml  indicates the maximum-likelihood estimate. then  for any two documents d and d  we set  to

 normalizing when appropriate   where d is the kullbackleibler divergence. this formulation is actually equivalent to a log-likelihood criterion under certain assumptions   but in practice is less sensitive than  to variations in the length of d.
　for a given cluster c  the corresponding language model pc ，  is induced by concatenating c's component documents and then applying the document-lm induction method to the new  document .
baseline: lmbasis-sset-sbag-suniformaspect-xinterp.pseudo-feedback markov chainsavg. prec.1%1% 1% 1% 1%1% 1% 1%prec. at 1.1%1%1%1%1%1%1%1%recall1%1%1%1% 1%1% 1% 1%table 1: ap1 results  1 relevant documents . cluster size k = 1; interpolation parameter λ = 1.
baseline: lmbasis-sset-sbag-suniformaspect-xinterp.relevance modelavg. prec.1%1% 1% 1% 1%1% 1% 1%prec. at 1.1%1%1%1%1%1%1%1%recall1%1%1% 1% 1%1% 1% 1%table 1: ap1 results  1 relevant documents . cluster size k = 1; interpolation parameter λ = 1.referencecomparisons. while one of our goals is to demonstrate that incorporating corpus structure as in our retrieval framework can provide improvements over the performance of the standard lm algorithm  we also wish to detemine whether our algorithms are competitive with state-of-the-art language-modeling-based algorithms. one natural choice for comparison is lafferty and zhai's pseudo-feedback markov chains algorithm   which extends the expanded query language model described above by forcing the chains to pass through top-ranked documents  as determined using the standard lm approach. another obvious candidate is lavrenko and croft's relevance model  which was the first method to explicitly incorporate relevance into the languagemodeling framework  and which demonstrated excellent performance. note that both algorithms  in contrast to our framework  depend on pseudo-feedback mechanisms to cope with the lack of true user feedback.
implementation. we used the lemur toolkit  to run our experiments. our implementations of the baseline used optimized smoothing-parameter settings with respect to average non-interpolated precision1  computed via line search. for our novel algorithms  we optimized the cluster-size parameter k and the interpolation algorithm's interpolation parameter λ  but the other parameters were set to default values suggested in the previous literature ; thus  the baseline algorithm was given an extra advantage.
　rather than re-implement the pseudo-feedback markovchain and relevance-model algorithms described above  we report results presented in the previous literature  1  1 . we do realize that minor differences in performance could stem from specific implementation issues  but as stated above  our goal was to test the competitiveness of our algorithms' performance with respect to that of other prominent algorithms  not to prove our algorithms' superiority.
1. experimental results
　for our evaluation measures  we used average non-interpolated precision  interpolated precision at 1  and recall  all for n = 1 selected documents. our main experimental results are given by tables 1  1  and 1 and figure 1.
　in the tables  for each evaluation metric  the strongest performance is boldfaced and all results above the baseline  lm  are italicized. also  the wilcoxon two-sided test was employed with significance threshold p = 1 - all statistically significant performance improvements and degradations for our algorithms relative to the baseline are marked with a star  * .
clearly  at the indicated settings  given in the captions  

1
 optimization with respect to recall yielded results which were statistically indistinguishable with respect to each of our performance metrics.
even at worst our algorithms are always competitive with the baseline lm approach  and with occasional exceptions  mostly for precision at 1  generally do better. we also observe that the aspect-x and interpolation algorithms are competitive with the pseudo-feedback markov-chains algorithm  see table 1  and the relevance-model algorithm  see table 1  with respect to all performance measures.
　figure 1 shows 1-point precision/recall curves for our algorithms and the baseline. in all three corpora  the interpolation algorithm does best overall. on ap1 and ap1  our cluster-based algorithms on the whole generally perform demonstrably better than the baseline. in la+fr  however  the new algorithms  with the exception of the interpolation algorithm  seem difficult to distinguish from lm  as is borne out by the relative lack of statistical-significance indications in table 1.
　the fact that the aspect-x algorithm was usually superior to uniform-aspect-x indicates that incorporating withincluster structure  as represented by pc d   is important.
　finally  the generally high performance of our aspect-x and interpolation algorithms seems to support our claims as to the importance of using corpus-structural information in the particular ways we have suggested: specifically  in these two algorithms  clusters play both a selection and a smoothing role  and both document-specific information and intra-cluster structure are incorporated as well.
　in what follows  we discuss the results of further experimental studies. for space reasons  we present only a subset of the performance figures for a selection of corpora.
parameter selection. the cluster-size parameter k does have a noticeable impact on performance. a series of preliminary experiments  whose results are omitted due to space restrictions  indicate that small values of k  e.g.  1 or 1  yield better results than the baseline lm for all but the uniform-aspect-x method  demonstrating the usefulness of even tiny document clusters. however  increasing k to 1 resulted in superior performance on the ap1 and ap1 datasets  which suggests that the re-rank step of our algorithm template can compensate to a degree for the extra irrelevant documents that large clusters may bring into consideration.
we must also choose m  the number of clusters to be re-
baseline: lmbasis-sset-sbag-suniformaspect-xinterp.avg. prec.1%1%1%1%1%1%1% prec. at 1.1%1%1%1%1%1%1%recall1%1%1%1%1%1% 1% table 1: results for la+fr  1 relevant documents . cluster size k = 1; interpolation parameter λ = 1.
	ap1	ap1	la+fr
	1-pt precision curves  corpus = ap1  cluster size=1-pt precision curves  corpus = ap1  cluster size=1-pt precision curves  corpus = la+fr  cluster size=1

1.1.1.1.1	1.1.1.1.1	1.1.1.1.1 recall	recall	recall
figure 1: 1-point precision/recall curves. for ap1 and ap1  k = 1; for la+fr  k = 1.trieved  recalling that we wish to return a fixed number n = 1 of documents. in the experimental results reported above  two different schemes were used. for the algorithms using clusters solely for selection  we set m to either 1 or the minimum value needed for there to be 1 documents receiving a non-zero score.1 for the remaining algorithms  aspect-x  uniform-aspect-x  and interpolation   we set m = 1. the former group of algorithms were more sensitive to choice of m than the latter  where as long as m did not exceed 1  satisfactory improvements with respect to the baseline algorithms were observed. however  drawing upon more clusters than this - which in a sense is what the classic aspect model  does - was clearly detrimental for some of the data corpora.
　an important regard in which the interpolation algorithm differs from the other methods we have introduced is in its inclusion of an additional free parameter λ  representing the degree of dependence on pd q  relative to the aspect-x algorithm. figure 1 plots the  trajectories  of the interpolation algorithm through performance space as λ is increased. this figure makes visually clear the interplay between cluster and document information: small λ's  emphasizing clusters  result in better recall but relatively poor precision; but large λ's  emphasizing documents  improve precision at the expense of recall. the performance of  average  values  around .1  shows that integrating document- and clusterlevel information provides better performance than either can produce alone.
　we note that the aspect-x algorithm can be viewed as a version of the interpolation algorithm in which λ = 1 and re-ranking is added to improve average precision. in return for some performance degradation relative to the interpolation algorithm  it offers the advantage of having one fewer parameter to tune  and is fairly robust to m's value as well.
the re-rank step. how important is the re-ranking step  in which the top-ranked documents are re-scored by their document-specific language models  to producing good precision  we ran several experiments to explore this issue.
first  we observed considerable degradation in average

1
 in the bag-select algorithm we chose m = 1  although lower values would have sufficed.
ap1ap1la+frre-rank yesnoyesnoyesnoavg. prec.1%1%1%1%1%1%prec. at 1.1%1%1%1%1%1%table 1: effect of re-rank step on aspect-x precision. for ap1 and ap1  k=1; for la+fr  k=1.
precision if we removed the pd q  term from the score functions of the basis-select and set-select algorithms  for which re-ranking is redundant. note that this version of the basisselect algorithm corresponds to applying the basic lm approach to the  document  cohort d  rather than d itself  and so can be thought of as a smoothing method wherein the document language model is created by backing off completely to a cluster language model.
　next  we examined the role of the optional re-ranking step in the algorithms that explicitly incorporate it. when the aspect-x and uniform-aspect-x algorithms - the two cases in which the scoring function does not incorporate pd q  - were run without the optional re-ranking phase  low average precision and precision at 1 resulted  implying that reliance on pc ，  alone suffers from over-regularization; the results for the aspect-x algorithm are shown in table 1. furthermore  re-ranking is also required to achieve reasonable precision for the bag-select algorithm  even though its scoring function incorporates pd q : when re-ranking is not applied  average precision suffers when clusters are small.
　in the case of the interpolation algorithm  however  the additional re-rank phase is not needed as long as the interpolation weight λ for the document-based language model is large enough. this can be seen in figure 1  where the difference between average precision without and with re-rank at different values of λ is reported - observe that for λ   1  re-ranking degrades performance.
　these results suggest that  1  for best results  it is important to strike the right balance between document-specific and inter-document information  and  1  for some algorithms  re-ranking creates this balance  but in others it can upset it.

figure 1: interpolation algorithm's recall vs average precision as λ grows  increments of .1 until .1  then .1  .1  .1  .1  .1 . recall that λ = 1 would yield the baseline language-model scoring function. similar patterns were observed on the la+fr corpus; we omit the results for clarity.effect of re-rank on average precision for the interp algorithm

figure 1: effect of re-rank step on average precision for the interpolation algorithm as λ varies. for ap1 and ap1 k=1; for la+fr k=1.
smoothing. the sensitivity of the lm approach to choice of smoothing technique and smoothing parameters has prompted a great deal of research  1  1  1 . however  we found that for our algorithms  simply setting the dirichlet smoothing parameter μ to a suggested value of 1   or  as it turned out  randomly-chosen values within the neighborhood of 1  outperformed the μ-optimized baseline. moreover  experiments with jelinek-mercer and absolute discounting - two other well-known single-parameter smoothing methods  - yielded the same outcome of relative insensitivity to choice of parameter value for the underlying smoothing method employed.
feature selection. another interesting observation is that effective incorporation of cluster information somewhat obviates the need for feature selection. in particular  table 1 shows one case where using the aspect-x and interpolation algorithms without a stemmer or stop-word list outperforms the baseline with access to the porter stemmer with respect to average precision and recall. on the other hand  stemming led to degradation of precision at zero. results for cluster sizes other than 1 and different corpora were consistent with these findings.
is it all due to language modeling  throughout this paper  we have used language models as our information representation. an interesting question is whether it is the representation  e.g.  pc ，    or the source of this representation  e.g. c itself  that matters most. we therefore explored the effect of using an alternative representation. specifically  both the queries and the documents were represented using log-based tf.idf  with the inner product as distance measure. as before  clusters were treated as large documents formed by concatenating their contents. altering our selection algorithms  basis-select  set-select  and bag-select  in this way led to improved performance with respect to the basic tf.idf retrieval algorithm  as shown in table 1. on the other hand  these algorithms did not do as well as their original  lm-based counterparts. we thus see that our algorithmic framework can boost performance for other information representations over the structure-blind alternative  but language models do seem to have advantages  at least in comparison to tf.idf.
1. conclusions
　in summary  we have proposed a general framework that enables the development of a variety of algorithms for integrating corpus similarity structure  modeled via clusters  and document-specific information. although our proposal is motivated by the recent language-modeling approach to information retrieval  and the specific algorithms presented here do use language models for representation purposes to good effect  we observed that the framework also can be used with basic classic ir techniques such as tf.idf.
s-baselineu-baselines-aspect-xu-aspect-xs-interpolation  λ = 1 u-interpolation  λ = 1 avg. prec.1%1%1% 1% 1% 1% prec. at 1.1%1%recall1%1%1%1%1%1%table 1: stemming comparison on ap1. s-: stemmed version; u-: un-stemmed version. cluster size k = 1. significant differences are reported with respect to the corresponding baseline.
tf.idf versionlm versionbaselinebasis-selectset-selectbag-selectbaselinebasis-selectset-selectbag-selectavg. prec.1%1%1% 1% 1%1%1%1%prec. at 1.1%1%1%1%1%1%1%1%recall1%1%1%1%1%1%1%1%table 1: simple similarity metric based on tf.idf vs. lm-based similarity on la+fr. cluster size k = 1.　an interesting direction for future work is to explore the effect of using alternative clustering algorithms. we would also like to study the role that overlapping plays in our framework: is most of the performance gain due to the  high  degree of overlap in our clusters or to the way structure and individual-document information are integrated  another interesting direction is to examine whether other algorithms  such as the lm-based pseudo-feedback methods we used for reference comparisons  1  1   can benefit if we replace the basic lm retrieval algorithm they employ with one of ours.
　most importantly  we would like to develop a principled probabilistic interpretation of the framework we have proposed. we have done some preliminary work based on considering the factorization p q|d  = pc p q|d c p c|d ; some of the components of our scoring functions can be considered to be  very rough  approximations of the terms in this factorization. creating a rigorous probabilistic foundation for the work described here is one of our main future goals.
acknowledgments	we thank eric breck  claire cardie 
shimon edelman  thorsten joachims  art munson  bo pang  ves stoyanov  and the anonymous reviewers for valuable comments. thanks to chengxiang zhai and victor lavrenko for answering questions about their work  and andr＞es corrada-emmanuel for responding to queries about lemur. this paper is based upon work supported in part by the national science foundation under grants itr/im iis-1 and iis-1 and by an alfred p. sloan research fellowship. any opinions  findings  and conclusions or recommendations expressed above are those of the authors and do not necessarily reflect the views of the national science foundation or sloan foundation.
