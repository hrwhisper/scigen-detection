requests for dynamic and personalized content increasingly dominate current-day internet traffic. to efficiently serve this trend  several server-side and cache-side techniques have recently been proposed. although such techniques  which exploit different forms of reuse at the sub-document level  appear promising  a significant impediment to evaluating their effectiveness on general workloads is the lack of synthetic content generators. more fundamental and the underlying reason for this shortcoming  is the absence of good models describing characteristics of dynamic web content.
   this paper describes our onging research  which attempts to address both of these shortcomings. by analyzing the content of several web sites that provide dynamic content  we derive a set of models that capture the characteristics of such content in terms of independent parameters such as the distributions of object sizes and their freshness times. these models in turn drive a java-based dynamic content emulator  dyce  which generates edge side include  esi  based dynamic content and serves requests for both whole documents and separate objects. dyce is available for public use and is being used internally to evaluate design choices for the conca edge-server architecture  which attempts to improve the cacheability of dynamic and personalized web content.
keywords:
object characteristics  dynamic web content  dynamic content emulator
1 introduction
researchers have recently proposed several server-side and cache-side mechanisms to improve the generation and serving of dynamic web content. server-side techniques  exemplified by techniques such as delta encoding   data update propagation   fragment-based page generation  1  1   reduce the load on the server by allowing reuse of previously generated content to serve new requests. cache-side techniques  exemplified by systems such as active cache   gemini   conca   and the content assembly technique proposed by wills et al.   attempt to reduce the latency of dynamic content delivery by moving some functionality to the edge of network. similar trends are also visible in commercial caching and edge server products  most notably ibm's websphere  and akamai's edgesuite . despite their difference in focus  both server-side and cache-side approaches share the same rationale  specifically that it is possible to view the document in terms of a quasi-static template  expressed using formatting languages such as xsl-fo  or edge-side include  esi     which is filled out with multiple individually cacheable and/or uncacheable objects. this object composition assumption enables surrogates and downstream proxy caches to reuse templates and cached objects to efficiently serve subsequent requests and additionally reduce server load  bandwidth requirements  and user-perceived latencies by allowing only the unavailable objects to be fetched.
   although the above techniques appear promising  it is difficult to predict to what extent their stated benefits apply to a workload different than the one they were evaluated on. as an example of the challenges  consider the following questions that we were faced with when trying to come up with general policies for our conca architecture : at what granularity must objects be cached to achieve sufficient reuse  is their a sharp threshold for choosing this granularity  or is it the case that the benefits are continuously varying  can we estimate likely freshness times of objects from the duration they have been present in the cache  one way of answering these questions is to try out various policies using a synthetic content generator. however  the state-of-the-art is such that neither a template-based dynamic content generator  nor  more fundamentally  models describing the characteristics of such content  exist.
   this paper describes our efforts on addressing both of these shortcomings. by analyzing the content of several web sites that serve dynamic content  we derive a set of models that characterizes this content in terms of a small number of independent parameters. using these models  we then design and implement an effective java-based dynamic content emulator  dyce .
1 characterizing dynamic content
from the perspective of surrogates and proxy caches that are attempting to improve delivery of dynamic content  there are several metrics of interest: number of objects that make up a document  their size distribution  and their freshness times. if one has access to the web server and/or application server of content providers  it is a relatively straightforward exercise to instrument these to obtain the above metrics of interest. unfortunately  many commercial web sites which create dynamic content are proprietary. therefore  we adopt an alternative approach based on the analysis of dynamic content  an html file  downloaded from various web sites.
   the biggest difficulty that must be overcome in our chosen approach is the lack of an explicit template associated with the document  which can help identify its component objects. to work around this difficulty  we make the assumption that the document template can be expressed as a nested table  an assumption that is true of pretty much every web site we have examined.
   given this assumption  our approach first extracts the template associated with the document  then identifies the  logical  objects that fill out this template  grouping neighboring objects that exhibit the same freshness time characteristics   and finally aggregates logical objects into physical objects that serve as the granularity at which document characteristics are modeled. to cope with the absence of an explicit template in the documents  we inferred both the template and the component objects using parameterized level-based and size-based splitting techniques described in additional detail in a technical report 
1 analysis of dynamic content characteristics
we analyzed traces collected from six representative web sites  with frequently changing dynamic content: three news sites  www.cnn. com  dailynews.yahoo.com  www.nytimes.com   two e-commerce sites  www.amazon.com  www.barnesnoble.com   and an entertainment site  www.windowsmedia.com . the traces consisted of downloads of the main page at each of the sites  every ten minutes over a two-week interval.

	 a  size	 b  freshness time
figure 1: the measured cumulative distribution of  a  object sizes and  b  freshness times for different size limit settings settings for traces collected from the www.cnn.com site.
   each of these traces was analyzed using the methodology described earlier . due to space restrictions  we discuss only the results for the cnn trace  which is representative of the others. figure 1 shows the measured cumulative distribution of object sizes and freshness times for different size-limit settings; the latter parameter denotes the target of the document splitting process outlined earlier. we find that a large number  about 1%  of objects in our documents are of relatively small size  smaller than 1 bytes   and while half of the objects exhibit freshness times that fall between a few minutes and a day  a significant fraction  almost 1%  of the objects are relatively long-lived  remaining essentially unchanged over the duration of the trace.
looking across all of the traces  our results are summarized in the following general observations:
  the sizes of component objects making up a dynamic web page can be captured very well using an exponential distribution. this is in contrast to how static documents are modeled  usually with a heavy-tailed pareto distribution.
  except for a considerable fraction of objects that change very infrequently  the freshness times of component objects can be captured using a weibull distribution. for two of the sites  www.amazon.com and www.bn.com   this distribution degenerates into a sharp bimodal one: all of the objects either change on almost every access or change very infrequently.
  content from all of the six sites demonstrated significant opportunity for reuse across both the temporal and spatial  in linked documents  dimensions. more interesting is the relationship between content reuse and the object granularity: for four of the sites
 www.cnn.com  dailynews.yahoo.com  www.nytimes.com  www.windowsmedia.com   there was a graceful degradation of reusability with increasing object granularity  while the degradation was much sharper for the other two.
1 dyce: dynamic content emulator
using the above models  we designed and implemented a dynamic content emulator  dyce   which generates parameterizable dynamic content that adheres to a subset of the esi specification. dyce builds on top of the tomcat web server from the jakarta open source initiative   and can service requests for both whole documents as well as individual components. dyce is easy to configure  extend  and use and should prove a useful tool for other researchers in this area. to validate both our models and their use in dyce  we wrote an idealized cache simulator that works off both the real trace data as well as the output of dyce. comparing the outputs of this simulator for the two cases verifies that dyce effectively models real content  and at a significant simulation cost advantage. the source code of dyce is available for public use at http://www.cs.nyu.edu/ weisong/dyce.html.
   dyce separates out the functions of content generation and content representation into two modules: the dynamic content generator  dcg  and the dynamic content presentor  dcp . dcp interfaces with requesters and appears as a traditional web server augmented with additional functionality described later in the section. the content presented to requesters by the dcp is currently packaged as an html document augmented with edge side include  esi  directives.  see figure 1 .

 object id=1 
 /object 
 object id=1 
 /object 
 object id=1 
 /object figure 1: the architecture of dynamic content emulator  which includes two components: a dynamic content generator and a web server-like dynamic content presenter. the extra functionality of dynamic web presenter is provided by a module called the dynamic content warden.
   to simplify its use  dcp supports a fairly simple interface  servicing two kinds of requests  either for the document template or for a
   set of selected objects. the dcg takes three parameters as input to create the corresponding document template and individual objects: the dynamic content type  the size limit and the level limit  two parameters that stem from our proposed splitting schemes.
   the dyce implementation extends the esi specification in two ways that enables  1  combining of requests for multiple objects from the same document into a single request and response message  and  1  association of per-individual object freshness times. these extensions permit efficient implementation of object-level coherence between a proxy cache or surrogate and a web server.
1 conclusions and future work
in this paper  we have modeled the characteristics of dynamic web content by analyzing document traces from dynamic web servers. using these models  we have designed and implemented a tool  the dynamic content emulator  dyce   which emulates a web server serving dynamic content. our future work consists of using dyce to evaluate and further refine the design of our conca prototype   which incorporates a novel design for efficient caching of dynamic and personalized content.
