in this article we describe a visual-analytic tool for the interrogation of evolving interaction network data such as those found in social  bibliometric  www and biological applications. the tool we have developed incorporates common visualization paradigms such as zooming  coarsening and filtering while naturally integrating information extracted by a previously described event-driven framework for characterizing the evolution of such networks. the visual front-end provides features that are specifically useful in the analysis of interaction networks  capturing the dynamic nature of both individual entities as well as interactions among them. the tool provides the user with the option of selecting multiple views  designed to capture different aspects of the evolving graph from the perspective of a node  a community or a subset of nodes of interest. standard visual templates and cues are used to highlight critical changes that have occurred during the evolution of the network. a key challenge we address in this work is that of scalability - handling large graphs both in terms of the efficiency of the back-end  and in terms of the efficiency of the visual layout and rendering. two case studies based on bibliometric and wikipedia data are presented to demonstrate the utility of the toolkit for visual knowledge discovery.
categories and subject descriptors: h.1 database
management: database applications - data mining
general terms: algorithms  measurement keywords: graph visualization  visual analytics  dynamic interaction networks

 contact author
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee.
kdd'1  august 1  1  las vegas  nevada  usa. copyright 1 acm 1-1-1/1 ...$1.
1. introduction
　in many scientific domains  visual aids and interactivity are often key to forming important insights  particularly when targeting hard problems. given the nature of the knowledge discovery process with a human-in-the-loop  a visual analytic interactive front-end is extremely beneficial for effective information synthesis.
　in this article  we present such a visual analytic toolkit targeted toward the analysis of dynamic interaction networks. many real world problems can be modeled as complex interaction networks where nodes represent entities of interest and edges mimic the relationships among them. fueled by technological advances and inspired by empirical analysis  the number of such problems and the diversity of domains from which they arise - physics  sociology  technology  biology  chemistry  metabolism and nutrition - is growing steadily. in a large number of such domains the networks governing interactions are known to evolve or change - bibliometric data  social network data  epidemiology data  biological networks  and the world wide web to name a few examples.
　in such networks  the addition and deletion of edges and nodes can be used to represent changes in the interactions among the modeled entities. the challenge is to identify and localize the portions of the network that are changing to help characterize the type of change and its potential causes  visually. a related challenge is to facilitate interactive interrogation  i.e.  the user needs to be able to interactively select and zoom down to clusters  entities of interest  as well as specific dynamic interactions and events that govern the evolution of interaction networks over time.
　to address these challenges  we introduce a visual toolkit specifically designed to analyze dynamic graphs. figure 1 provides a schematic representation of the components of our proposed visual analysis toolkit. the back-end of our toolkit leverages a previously developed event-detection framework for analyzing dynamic interaction networks . this framework presents a methodology to detect critical events affecting nodes and communities in such networks and offers a principled way to characterize their evolution through the composition of various incrementally computable behavioral indices such as stability  sociability and influence. as shown in figure 1  this information is tightly integrated with

　　　　figure 1: overview of proposed toolkit our front-end providing a highly interactive interface for the user.
　to facilitate visual analysis  the front-end of the toolkit presents the user with the option of multiple views - a graph view which is a cumulative snapshot representation of the graph at different points in time  a community view which represents the cluster arrangements of the snapshot graphs  an event view which demonstrates the transformations that have occurred over time  and a node view which details the evolutionary behavior of individual entities. we allow the user to pick the intervals of interest and drill down onto the corresponding events and behavioral measures within that time-frame. we use a weighting function to associate different behavioral characteristics such as influence and sociability with nodes and importance and recency  temporal stability  with edges. these weights are then mapped onto effective visual cues to localize features of interest. overall  the front-end conforms to the popular mantra - overview  zoom  filter and details on demand .
　for exploratory visual analysis  timeliness of the computation and presentation is important  particularly when considering large real-world graphs such as social networks like myspace and flickr. even simple layout and plotting tools suffer when the size of the graph is very large. for our toolkit  we make use of key optimizations to speed up computation in the back-end  and leverage the use of coarsening mechanisms to provide scalable performance in the front-end to squeeze relevant information in the available pixel space. in short  the challenges that we address in our work are:
1. identifying  tracking and representing interesting behavioral properties of interactions among nodes and communities such as stability  popularity  frequency etc.
1. analysis and visualization of communities over time to discovers key events depicting changes that occur with respect to other nodes and communities. also  we target the incorporation of semantic content to rank and evaluate interesting events.
1. analysis and visualization of the relationships of a node with its neighbors to discover trends in its importance.
1. ensure scalability to large graphs and facilitate interactive exploratory visual analysis.
we present two case studies on real evolving graph datasets to underline some of the benefits of our toolkit for visual analysis.
1. related work
　recently  there has been considerable interest in analyzing dynamic interaction graphs. leskovec et al  studied the evolution of graphs based on various topological properties  such as the degree distribution and small-world properties of large networks and proposed the forest-fire graph generation model. backstrom et al  studied formation of groups and the ways they grow and evolve over time. chakrabarti et al  introduced evolutionary clustering which involves incrementally obtaining high-quality clusters for a set of objects. in the context of event-based feature analysis samtaney et al  described an approach for extracting coherent regions from 1-dimensional and 1-dimensional scalar and vector fields for tracking purposes. to study the evolution of these regions over time  they present certain evolutionary events for objects. event-based methods have also been applied on spatial data .
　there has been considerable amount of work in visualization of social networks. heer and boyd  have developed the vizster tool for visualizing online social networks. the authors use a graph representation for visualizing data collected from the friendster online community. the toolkit can be used to explore communities  linkage and supports keyword search. perer and schneiderman  have presented a general social network visualization toolkit. the toolkit supports ranking of nodes based on various properties of the graph like centrality  cut-points etc. abello and others  have presented a graph visualization toolkit called ask-graphview. the toolkit uses a clustering algorithm to construct a hierarchy which is easy to browse. henry and fekete  have presented a dual representation for visualizing social networks. the proposed toolkit matrixexplorer uses a synchronized graph and matrix representation of the network for visualization. a key difference separating our work from the above methods is that they are designed to operate primarily on static interaction graphs.
　gloor and zhao  1  1  have developed iquest  a visual toolkit to understand topics of discussion among actors in a semantic web. kumar and garland  have presented algorithms to visualize a graph in hierarchical fashion by exploiting existing correlations. time-varying graphs are handled by producing animations composed of static snapshots. qeli et al.  have proposed algorithms to visualize time-varying matrices. the matrices used in the article represent clustering results. the authors generate a cumulative matrix and use colors to denote changes in memberships. the toolkit can also be used to find a group of elements which are part of the same cluster for an extended period of time. the community view presented in our work serves a similar purpose. we also provide views showing changes to nodes  neighborhoods and communities across time. the tight integration of our event detection back-end is a key difference from the above methods.
1. background: event detection
　this section provides the reader with a synopsis of our previous work in order that this document be self contained. additional details can be found elsewhere . we define a temporal snapshot si =  vi ei  of a graph g =  v e  to be a graph representing only entities and interactions active in a particular time interval  tsi tei   called the snapshot interval.
　as the graph evolves  its dynamic behavior over time can be represented as a set of s non-overlapping temporal snapshots. we use clusters of the graph to represent its structure at different snapshots. we believe that studying the evolution of these clusters  in particular their formation  transitions and dissolution  can be extremely useful for effectively characterizing the corresponding changes to the network over time. let ci and ci+1 denote the set of clusters over two consecutive time intervals respectively. the critical events we define are:
1  continue: a cluster  is marked as a continuation of is the same as vik  i.e their vertex sets are the same . note that we do not impose the constraint that the edge sets should be the same.

1  κ-merge: two different clusters cik and cil are marked as merged if there exists a cluster in the next timestamp that contains at least κ% of the nodes belonging to these two clusters. the essential condition for a merge is : merge cik cil κ  = 1 iff  cij+1 such that
%
and and . this condition will only hold if there exist edges between vik and vil in timestamp i +1. we allow the user the option of varying the κ parameter in the visual interface.
1  κ-split: a single cluster cij is marked as split if κ% of nodes from this cluster are present in 1 different clusters in the next timestamp. the essential condition is that: such that
%
and .
1  form: a new cluster is said to have been formed if none of the nodes in the cluster were grouped together at the previous time interval i.e. no 1 nodes in existed in the same cluster at time period i.  such that intuitively  a form indicates the creation of a new community or new collaboration.
1  dissolve: a single cluster cik is said to have dissolved if none of the vertices in the cluster are in the same cluster in the next timestamp i.e. no two entities in the original cluster have an interaction between them in the current time
 such that
　intuitively  a dissolve indicates the lack of contact or interactions between a group of nodes in a particular time period.
1 join: a node is said to join cluster cij if it exists in the cluster at timestamp i and it was not present in a similar cluster in the previous timestamp.
join v  cij  = 1 iff  cij and such that
k
and and v （ vij
the cluster similarity condition ensures that cij is not a newly formed cluster.
1 leave: a node is said to leave cluster if it no longer is present in a cluster with most of the nodes in.
leave v cij  = 1 iff  cij and such that
k
and and v /（ vij
the similarity constraint between the two clusters is used to maintain cluster correspondence.
behavioral analysis:.
　we use the join and leave events  described above  to define four behavioral measures that can be incrementally computed at each time interval using the events discovered in the current interval.
stability index: the stability index measures the tendency of a node to have interactions with the same nodes over a period of time. let cli x  represent the cluster that node x belongs to in the ith time interval. the stability index  si  for node x over t timestamps is measured incrementally as:

sociability index: a related measure is the sociability index  which is a measure of the number of different interactions that a node participates in. let cli x  be the cluster that node x belongs to at time i. then  the sociability index is defined as:
soi x  = |activity x |
and |activity x |   minactivity
where  indicates the number of intervals that node x is active. the measure gives high scores to nodes that are involved in interactions with different groups. the threshold minactivity corresponds to the minimum number of active intervals for a node to be considered sociable. 1
influence index: the influence index of a node is a measure of the influence this node has on others. the intuition is that  if a large number of nodes leave or join a cluster with high frequency when a certain node x does  it suggests that node x has a certain positive influence on the movement of the others. let companions x  represent all nodes over all timestamps that join or leave clusters with node x. the influence for node x is given by:
         |companions x | inf x  = 
|moves x |
here moves x  represents the number of join and leave events x participates in. note that  this definition by itself  does not measure influence  since nodes that interact and move along with highly influential nodes will have high influence score values as well. such nodes are down-weighted accordingly as described previously.

popularity index: the popularity index of a cluster at time interval  i i + 1  is a measure of the number of nodes that are attracted to it during that interval. it is defined as:
	vi	vi
pi cij  =  xjoin x cij      xleave x cij  
	x=1	x=1
1. datasets
dblp dataset: we used a subset of the dblp bibliography 1 to generate a co-authorship network representing authors publishing in several important conferences in the field of ai  databases and data mining. we chose all papers over a 1 year period  1  that appeared in 1 key conferences spanning mainly these three areas. we converted this data into a co-authorship graph  where each author is represented as a node and an edge between two authors corresponds to a joint publication by these two authors. we chose the snapshot interval to be a year  resulting in 1 consecutive snapshot graphs  containing 1 nodes and 1 edges. it has been shown that collaboration networks display many of the structural features of social networks 1  1 . hence  this is a good representative dataset for this study.
wikipedia dataset: the wikipedia online encyclopedia is a large collection of webpages providing comprehensive information concerning various topics. the dataset we employ represents the wikipedia revision history and was obtained from berberich . it consists of a set of webpages as well as links among them. it comprises of the editing history from january 1 to december 1. the temporal information for the creation and deletion of nodes  pages  and edges  links  are also provided. we chose a large subset of the provided dataset  consisting of 1 nodes  webpages  and 1 m edges. we constructed snapshots of 1 month intervals  and considered the first 1 snapshots for our analysis.
1. optimizations for fast event detection
　the event detection proceeds in an iterative manner  with every two successive snapshots analyzed to compute events among them. so  at each stage  we analyze the respective clusters of ti and ti+1 and compute events between them. first  it is important to note that  since we will be considering only a pair of timestamps at a time  we do not need to consider all n nodes  since many of the nodes may not be active over the time period. hence  for event detection between ti and ti+1  we need to examine only the nodes active over either of the two timestamps. this greatly reduces the complexity of the event detection algorithm. table 1 gives the percentage of active nodes  for both datasets. it can be observed that the percentage of active nodes for a pair of snapshots never increases beyond 1% of the total number of nodes.
　to facilitate exploratory visual analysis  we need to ensure that event detection can be performed quickly  as the events need to be shown to the user for further analysis. our detection algorithm relies on finding intersections and unions of the cluster sets  as evident from the formulae presented in the previous section. when the number of clusters

time# of clusters# of clustersstamp dblp  wikipedia 1111111111111　　　　　　table 1: number of clusters. is large  finding these intersections and unions can be expensive even with the bit matrix operations we described in our earlier work. finding the intersection between ki clusters of ti and ki+1 clusters of ti+1 has time complexity o ki   ki+1 ; for most real-world graphs  the number of communities can be quite large  ki*ki+1 n . the number of clusters obtained for each timestamp of the dblp and wikipedia graphs are shown in table 1.
　to enhance the performance of the back-end  particularly when scaling to datasets like the wikipedia data  we develop an optimization to calculate the cluster intersection matrix i in o m  time  where m is the number of nodes active in either ti or ti+1  m =n . the idea is as follows. we first construct two cluster vectors  for the two timestamps considered   to represent the clusters  community  that a node belongs to in a timestamp. we then traverse these vectors sequentially and update the cluster intersection matrix i  as shown in algorithm 1.

algorithm 1 intersection ci ci+1 

input: set of m active nodes for m = 1 to m do
clusteri m =cluster id that node m belongs to in timestamp ti
clusteri+1 m =cluster id that node m belongs to in
timestamp ti+1
end for
// we then traverse these cluster vectors from left to right. for m = 1 to m do
if m is active in ti and ti+1 then
　i clusteri m   clusteri+1 m   + +; end if
end for

　the cluster unions can be computed easily by taking the sum of the cluster sizes and subtracting the intersection obtained from i.
　note that all the behavioral measures described above can be computed incrementally. we maintain a vector in memory for each of the behavioral indices. as the increments are computed for each timestamp  the corresponding values are updated. thus  at any given time point  one can obtain the index values in a straightforward manner. these measures are displayed to the user as part of the node view  which will be described in the next section.
　the timing results for the event detection and index computation are given in table 1. to emphasize the savings  we also present the performance of our earlier implementation on the wikipedia dataset  without the above mentioned optimizations  see table 1 . in a nutshell the optimizations are very effective and ensure that the back-end is
dblpwikipediatimeactive nodestimeactive nodestimestamps secs  secs 1111111111111111111111111111111111111table 1: computation times for the back end.
timeoldoptimizedstamps secs  secs 111111111111111table 1: computation time comparison.
significantly faster than before and is within very reasonable limits given the scale of the data being operated on.
1. visual analysis
　in this section  we highlight the key components of the interface along with associated user interaction features. we also motivate the benefits of these components with respect to the overall goal of knowledge extraction from evolving graphs. the key components of the toolkit are:
data loader: this component is used for reading the input data and label files. the data to be read is in the form of temporal snapshot graphs  as we described in section 1. each graph corresponds to one time step and is stored in an edge file format. additionally  a label file is read which associates each node in the graph with a unique identifier and name  if available. if clusters are already available  then we provide an option to read in the cluster file as well. if not  clustering can be performed online. we provide options for kmetis or mcl clustering. once the data is read  preprocessing is done to create the cluster vectors  described in the previous section  for the first two timestamps.
view mode selector: once the data is ready  the user selects one of the four supported views and the relevant parts of the interface get activated. before detailing the views  we describe our hierarchical representation.
coarsening: to visualize large graphs on the screen  we choose to coarsen the graphs  using the cluster information to construct multi-level hierarchies of nodes. this facilitates easy visual interpretation  since it provides the user the ability to identify and drill down to sections of interest in the graph. the graph is initially clustered to produce base clusters 1. these clusters are then further clustered internally by our coarsening algorithm into multiple levels. the kmetis algorithm is used for performing clustering. each level consists of a graph of supernodes  each of which represents a cluster of lower-level nodes. at the lowest level in the hierarchy  we have the nodes and edges of the graph. before coarsening  a new edge file is created by transferring edges between nodes of different clusters to the corresponding su-


figure 1: illustration of coarsened high-level view. a region can be selected to drill down.
pernodes  representing these clusters. this edge file is used by kmetis to obtain the higher level supernodes. the user is initially provided with a high level view in the form of connected supernodes  representing different regions  as shown in fig 1. the physical sizes of the supernodes in the interface reflect the sizes of the cluster they represent. clusters that contain a large number of nodes can thus be differentiated from singleton clusters with ease. dynamic behavioral information about the nodes and clusters are also provided  as we will describe below. at any level  the user can select one or a group of interesting supernodes to drill down and visualize the corresponding section of the original graph.
graph view- in this view  the entire dynamic network is displayed as a graph. as mentioned above  the graph is presented as a multi-level hierarchy. the bottom-most level represents the graph itself in the form of nodes and edges. the level immediately above represents supernodes  where each node is a cluster of the lowest-level nodes. each supernode in this level is labeled with the popularity index value of the cluster it corresponds to. it is also color-coded to reflect the strength of the popularity index values. the user can select an interesting set of clusters  and descend to the lower level to visualize the nodes in question. in our implementation  the sequence of colors for nodes  from low weight to high weight  is dark yellow  light yellow  light green  dark green. similarly  for edges the sequence is dark red  light red  light blue  dark blue. the progression of colors for nodes and edges is shown in the bottom right corner of the visual interface. at the lowest level  properties of nodes - sociability  stability and influence are computed as described in section 1 to assign a weight. finally  the weights are normalized between  1  and are mapped to a color which is then used to render the graphs. we also provide a facility for multi-weighting a node  where we compute the weight taking into account two of these behavioral measures. this is beneficial for discovering correlations among properties of nodes. the relative importance of each edge is primarily captured by its temporal stability  i.e.  for how many consecutive time steps that particular edge is observed. note that  the importance of an edge  interaction  in terms of these measures can be determined based on the nodes involved. for instance  the stability of the edge can

         figure 1: event view for wikipedia be represented as the product of the stability indices of the two nodes i.e si x y t  = si x t    si y t . moreover  to give less importance to old edges  which are not observed recently   we use different line styles. for example  if an edge also occurred in the previous time stamp  we use a dashed line to represent temporal stability. edges that were not observed recently are represented by a straight line.
community view- this view displays various clusters or communities present in the network. once the user selects this view  the system presents the user with the clusters that the nodes belong to. the membership of nodes to the clusters are taken into account by using the same color and same marker for rendering.
event view- the event view is designed to provide information regarding transformations that occur in the graph over time. this view displays a set of all critical events that occur between the current and previous intervals. the user can choose different time intervals and observe the events that transpire among them. figure 1 shows the set of events between clusters of timestamps 1 and 1. at the top of the gui  there are three bars a  b and k which correspond to the α β and κ parameters for the event detection algorithm described earlier. the user can vary these parameters and examine the critical events obtained. in the middle of the screen  the gui provides a list of all critical events observed. the user can select one of these events  which provides details on the nodes and clusters involved. we present an example of a merge and a split event in the case study section. the detailed representation of the event is visualized on the screen giving the user a representation of the nodes involved and the change that has occurred. for the merge and split events in the event view  we also provide a semantic similarity ranking. this is of use for graphs that have associated category or term hierarchy information. to begin with  the information content  ic  of a term  category or keyword-set   using resnik's definition   is given as:

where ki represents a term and f ki  is the frequency of encountering that particular term over all the entire corpus. here  f root  is the frequency of the root term of the hierarchy. note that frequency count of a term includes the frequency counts of all subsumed terms in an is-a hierarchy. also note that terms with smaller frequency counts will therefore have higher information content values  i.e. more informative . using the above definition  the semantic similarity  ss  between two terms  categories  can be computed as follows:
ss ki kj  = ic lcs ki kj  
where lcs ki kj  refers to the lowest common subsumer of terms ki and kj. to define the semantic similarity between two clusters  one can employ an information theoretic mutual information measure. given probabilities of terms m and n occurring in a cluster as p m  and p n  respectively  and their co-occurrence probability p mn   the semantic mutual information  smi  between the two clusters cia and cjb can be given as:
	ka	kb
smi cia cib  = xx ss m n    p mn    logka kb p mp  mn  p  n  m=1n=1
however  while this measure accurately captures similarities  it is not very scalable for graphs with large category hierarchies  due to the amount of computation required and memory consumed. in these cases  the semantic similarity between two clusters can be computed as:

note that  the semantic similarity values between terms are pre-computed  while computing the inter ss   of clusters or local neighborhoods is scalable. 1 clusters with high values of inter ss    can be expected to contain authors or webpages with similar topics and thus merge events that comprise of such clusters are semantically meaningful  semantic merges . hence  the merge events are ranked in decreasing order of the inter ss   of the merging clusters. for the split events  we compute the inter ss   of the split clusters. we will illustrate both types of semantic events in the next section. note that our toolkit can output semantic similarity scores for clusters  not shown .
node view- all the above-mentioned views deal with global properties of the network. the node view presents the user with localized information. once the user chooses node view  the toolkit provides a list of nodes ranked in decreasing order of the properties available  sociability  stability and influence . the user can then select a node from the node list for further observation. this prompts the corresponding neighborhood graphs of that particular node over time to be displayed to the user. the displayed graphs includes the chosen node and its neighborhoods over time. one can gain insight into changes occurring in the neighborhoods of the selected node. for instance  in the case of influence  one can identify spheres of influence for a node over time. we will demonstrate the benefits of the node view in the case studies in the next section.
zoom filters: as the name suggests  this feature is used to zoom into certain sections of the graph. the user can select the area of interest by drawing a rectangle using the mouse.

the selected part is then zoomed into and displayed. it is also possible to zoom out to a lower resolution. figure 1 a  b  demonstrates the zoom feature on the dblp dataset. the zoom feature can be used multiple times to increase the resolution.
time browser: this functionality is used to observe the network across time. this provides the user the capability to detect time instants when graph topology has changed considerably. the back and forward buttons at the bottom of the gui can be used by the user to control the time  moving through the different time intervals.
keyword search: in many cases  one is interested in searching for particular nodes  and their evolution over time. as we described above  we use a multi-level hierarchy of supernodes to visualize sections of the graph. we also store a multi-level index that allows the querying and extraction of specific nodes of interest. if one is interested in a particular node and its behavior  we can extract the exact location of the node and visualize the corresponding section of the graph.
evolution of neighborhoods: we also provide the option of visualizing the evolution of node neighborhoods. when the user is presented with a view of a region of the graph  she has the option of selecting a particular set of nodes or communities and viewing the evolution of the neighborhoods of these nodes over time. once a region is chosen  we track the neighborhoods of all nodes in that region over time.
community-driven layout: an integral component of our visual framework is the layout component. once we have a set of nodes and edges to render on the screen  we need to map them to suitable coordinates that represent the relationships that exist among them. as a first step we leveraged the graphviz http://www.graphviz.org/  layout tool to obtain coordinates. however  since the graph is dynamically evolving  we observed that directly employing graphviz led to a loss in visual correspondence of nodes and more importantly communities across timesteps. resolving this problem is not straightforward since nodes and edges may not be active at all time points. to handle this correspondence problem  we compute a novel communitydriven layout scheme. the central idea is to ensure that communities that overlap across time steps are laid out in corresponding regions in consecutive time steps  thus maintaining relatively stable coordinates over time. the heuristic procedure we adopt involves identifying the most stable communities  using the continue and stability computations described earlier  and suitably ensuring that global coordinates for such communities from their formation until they change drastically  remain consistent. this leads to the desirable property of visual correspondence across time stamps. note however that individual nodes that join or leave communities are moved around based on their behavior  as are communities that change significantly.
1. case studies : visual analysis
1 dblp bibliography dataset
　in this case study  we demonstrate the effectiveness of our toolkit for visual data analysis on the dblp dataset. our tool provides us with a list of authors ranked by behavioral attributes such as sociability and influence  as described previously. our tool also allows one to combine information from multiple metrics by specifying an affine combination of these values  menu-driven option not shown . for this study  we chose dr rakesh agrawal  who unsurprisingly ranks highly on both sociability and influence  see fig 1 . we equally weighted the contribution of each index.
upon inspection  one can see that the neighborhoods for dr agrawal differ significantly between successive snapshots from 1 to 1  one can make out the progression in his sociability and influence index  as conveyed by the gradation of the color of the node representing him 1. after 1  however  many of his neighbors  collaborators  remain fairly consistent  the sociability index is lower but the influence  of collecting more neighbors in the cluster he is in balances this out very nicely. this correlates with his interests shifting to the focused area of privacy preserving data mining and trust and security applications of databases. his collaborators in the last few timestamps shown are primarily from this area and this area has also taken off very nicely since agrawal and srikant's seminal paper in the area in 1.
　also  one can readily see that 1 nodes in particular appear quite frequently  namely r. srikant  r. bayardo and j kiernan  after 1  represented by dashed edges. these are some of agrawal's frequent collaborators. another interesting trend is that the graph also identifies quite naturally collaborators of agrawal's who have a high sociability and influence index  i.e. christos faloutsos  gerhard weikum  dimitrios gunopulos  johannes gehrke  prabhakar raghavan  and surajit chaudhary .
1 wikipedia webgraph
　in the next case study  we analyze the wikipedia webgraph. in particular  we demonstrate the use of semantic analysis with event detection. in the event view  the toolkit provides us with a list of different events. as we mentioned in the previous section  we have the facility of ranking the merge and split events in terms of semantic meaningfulness. first  we will consider a semantic merge event  that had the highest semantic similarity  shown in in figure 1 a . in the first snapshot  there are 1 clusters of size 1 and 1  that have considerable semantic similarity  as can be ascertained from the labels. the clusters deal with logic and philosophy and the merge event is thus justifiably meaningful. the merged cluster is shown on the right.
for a split event  one would expect the two split clusters to be semantically dissimilar. while  this is mostly true  there can be occurrences where interesting minute differences can cause clusters to split up. these kind of split events can indicate subtle changes across snapshots  where a cluster splits into two parts due to a small semantic difference among the associated categories. these splits can be interesting as they can reveal differences that may not be obvious. this can be considered akin to drilling down a hierarchy to discover subtle specializations of a category. we can find such interesting occurrences by considering split clusters with low inter ss  . an example of such a split event is shown in figure 1 b . as can be observed  the original cluster which deals with the berlin wall  splits into two clusters on east and west berlin respectively. understandably  these two split clusters had reasonably high semantic similarity values.



figure 1: zoom feature

figure 1: node view : neighborhood of r. agrawal  weighted by sociability & influence index 

figure 1: examples of a  merge event b  split event

1. conclusions
　we have presented a toolkit for visualizing and analyzing dynamic interaction graphs. our toolkit provides multiple views of the data and is designed to incorporate features for multi-scale and multi-resolution analysis and supports the overview  zoom  filter and details-on-demand paradigm.
　we have shown how the toolkit can be employed for estimating interesting behavioral properties of nodes and communities in the graph  such as stability and influence. the node view also allows one to visualize trends in these properties over time. additionally  the graph and event views permit us to discover and characterize specific changes that occur  with respect to other nodes and communities. we have shown how the incorporation of semantic content can aid evaluation and ranking of events discovered. our novel community-driven layout component can aid exploratory analysis and handle the correspondence problem in plotting trends of nodes and communities over time.
　to ensure scalability to large graphs  we have presented optimizations that can provide speedup and facilitate interactive visual analysis. the toolkit also supports visualizing the cumulative graphs with different scoring mechanisms to assign color to each edge and node. the coloring scheme captures behavioral properties and provides useful visual cues to discover important and interesting parts of the graph. we have shown how the toolkit can perform visual analysis by taking into account the evolution of nodes and communities as well as key events over time. using illustrations on the dblp and wikipedia datasets  we have shown how the interactive features aid the user in answering common queries about dynamic networks in an effective and efficient manner. as part of ongoing work we are currently investigating the use of pivot-based algorithms to further enhance the visual correspondence of communities across timesteps  while also improving the scalability of the layout process. we are also looking to incorporate the dense subgraph visualization algorithms from our above-mentioned work into the toolkit. to further improve scalability of the semantic similarity computations  we will leverage min-wise hashing methods .
1. acknowledgements
this work is supported in part by the doe early career
principal investigator award no. de-fg1er1  nsf career grant iis-1 and nsf sger grant iis1. we would like to thank klaus berberich and evgeniy gabrilovich for providing us with the wikipedia dataset and the category hierarchy respectively.
