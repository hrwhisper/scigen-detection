we present new algorithms for performing fast computation of several common database operations on commodity graphics processors. specifically  we consider operations such as conjunctive selections  aggregations  and semi-linear queries  which are essential computational components of typical database  data warehousing  and data mining applications. while graphics processing units  gpus  have been designed for fast display of geometric primitives  we utilize the inherent pipelining and parallelism  single instruction and multiple data  simd  capabilities  and vector processing functionality of gpus  for evaluating boolean predicate combinations and semi-linear queries on attributes and executing database operations efficiently. our algorithms take into account some of the limitations of the programming model of current gpus and perform no data rearrangements. our algorithms have been implemented on a programmable gpu  e.g. nvidia's geforce fx 1  and applied to databases consisting of up to a million records. we have compared their performance with an optimized implementation of cpu-based algorithms. our experiments indicate that the graphics processor available on commodity computer systems is an effective co-processor for performing database operations.
keywords: graphics processor  query optimization  selection query  aggregation  selectivity analysis  semi-linear query.
1. introduction
　as database technology becomes pervasive  database management systems  dbmss  have been deployed in a wide variety of applications. the rapid growth of data volume for the past decades has intensified the need for high-speed database management systems. most database queries and  more recently  data warehousing and data mining applications  are very data- and computation-intensive and therefore demand high processing power. researchers have actively sought to design and develop architectures and algo-
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage  and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee.
sigmod 1 june 1  1  paris  france.
copyright 1 acm 1-1/1 . . . $1.
rithms for faster query execution. special attention has been given to increase the performance of selection  aggregation  and join operations on large databases. these operations are widely used as fundamental primitives for building complex database queries and for supporting on-line analytic processing  olap  and data mining procedures. the efficiency of these operations has a significant impact on the performance of a database system.
　as the current trend of database architecture moves from disk-based system towards main-memory databases  applications have become increasingly computation- and memorybound. recent work  1  1  investigating the processor and memory behaviors of current dbmss has demonstrated a significant increase in the query execution time due to memory stalls  on account of data and instruction misses   branch mispredictions  and resource stalls  due to instruction dependencies and hardware specific characteristics . increased attention has been given on redesigning traditional database algorithms for fully utilizing the available architectural features and for exploiting parallel execution possibilities  minimizing memory and resource stalls  and reducing branch mispredictions  1  1  1  1  1  1  1  1 .
1 graphics processing units
　in this paper  we exploit the computational power of graphics processing units  gpus  for database operations. in the last decade  high-performance 1d graphics hardware has become as ubiquitous as floating-point hardware. graphics processors are now a part of almost every personal computer  game console  or workstation. in fact  the two major computational components of a desktop computer system are its main central processing unit  cpu  and its  gpu . while cpus are used for general purpose computation  gpus have been primarily designed for transforming  rendering  and texturing geometric primitives  such as triangles. the driving application of gpus has been fast rendering for visual simulation  virtual reality  and computer gaming.
　gpus are increasingly being used as co-processors to cpus. gpus are extremely fast and are capable of processing tens of millions of geometric primitives per second. the peak performance of gpus has been increasing at the rate of 1   1 times a year  much faster than the moore's law for cpus. at this rate  the gpu's peak performance may move into the teraflop range by 1 . most of this performance arises from multiple processing units and stream processing. the gpu treats the vertices and pixels constituting graphics primitives as streams. multiple vertex and pixel processing engines on a gpu are connected via data flows. these processing engines perform simple operations in parallel.
　recently  gpus have become programmable  allowing a user to write fragment programs that are executed on pixel processing engines. the pixel processing engines have direct access to the texture memory and can perform vector operations with floating point arithmetic. these capabilities have been successfully exploited for many geometric and scientific applications. as graphics hardware becomes increasingly programmable and powerful  the roles of cpus and gpus in computing are being redefined.
1 main contributions
　in this paper  we present novel algorithms for fast computation of database operations on gpus. the operations include predicates  boolean combinations  and aggregations. we utilize the simd capabilities of pixel processing engines within a gpu to perform these operations efficiently. we have used these algorithms for selection queries on one or more attributes and generic aggregation queries including selectivity analysis on large databases.
　our algorithms take into account some of the limitations of the current programming model of gpus which make it difficult to perform data rearrangement. we present novel algorithms for performing multi-attribute comparisons  semilinear queries  range queries  computing the kth largest number  and other aggregates. these algorithms have been implemented using fragment programs and have been applied to large databases composed of up to a million records. the performance of these algorithms depends on the instruction sets available for fragment programs  the number of fragment processors  and the underlying clock rate of the gpu. we also perform a preliminary comparison between gpubased algorithms running on a nvidia geforcefx 1 ultra graphics processor and optimized cpu-based algorithms running on dual 1 ghz intel xeon processors.
　we show that algorithms for semi-linear and selection queries map very well to gpus and we are able to obtain significant performance improvement over cpu-based implementations. the algorithms for aggregates obtain a modest gain of 1   1 times speedup over cpu-based implementations. overall  the gpu can be used as an effective co-processor for many database operations.
1 organization
　the rest of the paper is organized as follows. we briefly survey related work on database operations and use of gpus for geometric and scientific computing in section 1. we give an overview of the graphics architectural pipeline in section 1. we present algorithms for database operations including predicates  boolean combinations  and aggregations in section 1. we describe their implementation in section 1 and compare their performance with optimized cpu-based implementations. we analyze the performance in section 1
　and outline the cases where gpu-based algorithms can offer considerable gain over cpu-based algorithms.
1. related work
　in this section  we highlight the related research in mainmemory database operations and general purpose computation using gpus.
1 hardware accelerated database operations
　many acceleration techniques have been proposed for database operations. ailamaki et al.  analyzed the execution time of commercial dbmss and observed that almost half of the time is spent in stalls. this indicates that the performance of a dbms can be significantly improved by reducing stalls.
　meki and kambayashi used a vector processor for accelerating the execution of relational database operations including selection  projection  and join . to utilize the efficiency of pipelining and parallelism that a vector processor provides  the implementation of each operation was redesigned for increasing the vectorization rate and the vector length. the limitation of using a vector processor is that the load-store instruction can have high latency .
　modern cpus have simd instructions that allow a single basic operation to be performed on multiple data elements in parallel. zhu and ross described simd implementation of many important database operations including sequential scans  aggregation  indexed searches  and joins . considerable performance gains were achieved by exploiting the inherent parallelism of simd instructions and reducing branch mispredictions.
　recently  sun et al. present the use of graphics processors for spatial selections and joins . they use color blending capabilities available on graphics processors to test if two polygons intersect in screen-space. their experiments on graphics processors indicate a speedup of nearly 1 times on intersection joins and within-distance joins when compared against their software implementation. the technique focuses on pruning intersections between triangles based on their 1d overlap and is quite conservative.
1 general-purpose computing using gpus
　in theory  gpus are capable of performing any computation that can be mapped to the stream-computing model. this model has been exploited for ray-tracing   global illumination  and geometric computations .
　the programming model of gpus is somewhat limited  mainly due to the lack of random access writes. this limitation makes it more difficult to implement many data structures and common algorithms such as sorting. purcell et al.  present an implementation of bitonic merge sort  where the output routing from one step to another is known in advance. the algorithm is implemented as a fragment program and each stage of the sorting algorithm is performed as one rendering pass. however  the algorithm can be quite slow for database operations on large databases.
　gpus have been used for performing many discretized geometric computations . these include using stencil buffer hardware for interference computations   using depth-buffer hardware to perform distance field and proximity computations   and visibility queries for interactive walkthroughs and shadow generation .
　high throughput and direct access to texture memory makes fragment processors powerful computation engines for certain numerical algorithms  including dense matrix-matrix multiplication   general purpose vector processing   visual simulation based on coupled-map lattices   linear algebra operations   sparse matrix solvers for conjugate gradient and multigrid   a multigrid solver for boundary value problems   geometric computations  1  1   etc.
1. overview
　in this section  we introduce the basic functionality available on gpus and give an overview of the architectural pipeline. more details are given in .
1 graphics pipeline
　a gpu is designed to rapidly transform the geometric description of a scene into the pixels on the screen that constitute a final image. pixels are stored on the graphics card in a frame-buffer. the frame buffer is conceptually divided into three buffers according to the different values stored at each pixel:
  color buffer: stores the color components of each pixel in the frame-buffer. color is typically divided into red  green  and blue channels with an alpha channel that is used for blending effects.
  depth buffer: stores a depth value associated with each pixel. the depth is used to determine surface visibility.
  stencil buffer: stores a stencil value for each pixel. it is called the stencil buffer because it is typically used for enabling/disabling writes to portions of the frame-buffer.

figure 1: graphics architectural pipeline overview: this figure shows the various units of a modern gpu. each unit is designed for performing a specific operation efficiently.
　the transformation of geometric primitives  points  lines  triangles  etc.  to pixels is performed by the graphics pipeline  consisting of several functional units  each optimized for performing a specific operation. fig 1 shows the various stages involved in rendering a primitive.
  vertex processing engine: this unit receives vertices as input and transforms them to points on the screen.
  setup engine: transformed vertex data is streamed to the setup engine which generates slope and initial value information for color  depth  and other parameters associated with the primitive vertices. this information is used during rasterization for constructing fragments at each pixel location covered by the primitive.
  pixel processing engines: before the fragments are written as pixels to the frame buffer  they pass through the pixel processing engines or fragment processors. a series of tests can be used for discarding a fragment before it is written to the frame buffer. each test performs a comparison using a user-specified relational operator and discards the fragment if the test fails.
- alpha test: compares a fragment's alpha value to a user-specified reference value.
- stencil test: compares the stencil value of a
fragment's corresponding pixel with a user-specified reference value.
- depth test: compares the depth value of a fragment to the depth value of the corresponding pixel in the frame buffer.
the relational operator can be any of the following : =        ＋  −  and 1=. in addition  there are two operators  never and always  that do not require a reference value.
　current generations of gpus have a pixel processing engine that is programmable. the user can supply a custom fragment program to be executed on each fragment. for example  a fragment program can compute the alpha value of a fragment as a complex function of the fragment's other color components or its depth.
1 visibility and occlusion queries
　current gpus can perform visibility and occlusion queries . when a primitive is rasterized  it is converted to fragments. some of these fragments may or may not be written to pixels in the frame buffer depending on whether they pass the alpha  stencil and depth tests. an occlusion query returns the pixel pass count  the number of fragments that pass the different tests. we use these queries for performing aggregation computations  see section 1 .
1 data representation on the gpus
　our goal is to utilize the inherent parallelism and vector processing capabilities of the gpus for database operations. a key aspect is the underlying data representation.
　data is stored on the gpu as textures. textures are 1d arrays of values. they are usually used for applying images to rendered surfaces. they may contain multiple channels. for example  an rgba texture has four color channels red  blue  green and alpha. a number of different data formats can be used for textures including 1-bit bytes  1-bit integers  and floating point. we store data in textures in the floating-point format. this format can precisely represent integers up to 1 bits.
　to perform computations on the values stored in a texture  we render a single quadrilateral that covers the window. the texture is applied to the quadrilateral such that the individual elements of the texture  texels  line up with the pixels in the frame-buffer. rendering the textured quadrilateral causes a fragment to be generated for every data value in the texture. fragment programs are used for performing computations using the data value from the texture. then the alpha  stencil  and depth tests can be used to perform comparisons.
1 stencil tests
　graphics processors use stencil tests for restricting computations to a portion of the frame-buffer based on the value in the stencil buffer. abstractly  we can consider the stencil buffer as a mask on the screen. each fragment that enters the pixel processing engine corresponds to a pixel in the frame-buffer. the stencil test compares the stencil value of a fragment's corresponding pixel against a reference value. fragments that fail the comparison operation are rejected from the rasterization pipeline.
　stencil operations can modify the stencil value of a fragment's corresponding pixel. examples of such stencil operations include
  keep: keep the stencil value in stencil buffer. we use this operation if we do not want to modify the stencil value.
  incr: increment the stencil value by one.
  decr: decrement the stencil value by one.
  zero: set the stencil value to zero.
  replace: set the stencil value to the reference value.
  invert: bitwise invert the stencil value.
　for each fragment there are three possible outcomes based on the stencil and depth tests. based on the outcome of the tests  the corresponding stencil operation is performed:
  op1: when a fragment fails the stencil test 
  op1: when a fragment passes the stencil test and fails the depth test 
  op1: when the fragment passes the stencil and depth tests.
we illustrate these operations with the following pseudocode for the stencilop routine:
stencilop  op1  op1  op1 
if  stencil test passed  /* perform stencil test */
/* fragment passed stencil test */ if depth test passed  /* perform depth test */ /* fragment passed stencil and depth test */ perform op1 on stencil value
else
/* fragment passed stencil test */ /* but failed depth test */ perform op1 on stencil value
end if
else
/* fragment failed stencil test */ perform op1 on stencil value
end if
1. basicdatabaseoperationsusing gpus
　in this section  we give a brief overview of basic database operations that are performed efficiently on a gpu. given a relational table t of m attributes  a1 a1 ... am   a basic sql query is in the form of
select a
from t
where c
where a may be a list of attributes or aggregations  sum  count  avg  min  max  defined on individual attributes  and c is a boolean combination  using and  or  exist  not exist  of predicates that have the form ai op aj or ai op constant. the operator op may be any of the following: = 1=   −   ＋. in essence  queries specified in this form involve three categories of basic operations: predicates  boolean combinations  and aggregations. our goal is to design efficient algorithms for performing these operations using graphics processors.
  predicates: predicates in the form of ai op constant can be evaluated via the depth test and stencil test. the comparison between two attributes  ai op aj  can be transformed into a semi-linear query ai   aj op 1  which can be executed on the gpus.
  boolean combinations: a boolean combination of predicates can always be rewritten in a conjunctive normal form  cnf . the stencil test can be used repeatedly for evaluating a series of logical operators with the intermediate results stored in the stencil buffer.
  aggregations: this category includes simple operations such as count  sum  avg  min  max  all of which can be implemented using the counting capability of the occlusion queries on gpus.
　to perform these operations on a relational table using gpus  we store the attributes of each record in multiple channels of a single texel  or the same texel location in multiple textures.
1 predicate evaluation
　in this section  we present novel gpu-based algorithms for performing comparisons as well as the semi-linear queries.
1.1 comparison between an attribute and a constant
　we can implement a comparison between an attribute  tex  and a constant  d  by using the depth test functionality of graphics hardware. the stencil buffer can be configured to store the result of the depth test. this is important not only for evaluating a single comparison but also for constructing more complex boolean combinations of multiple predicates.
　to use the depth test for performing comparisons  attribute values need to be stored in the depth buffer. we use a simple fragment program for copying the attribute values from the texture memory to the depth buffer.
　a comparison operation against a depth value d is implemented by rendering a screen filling quadrilateral with depth d. in this operation  the rasterization hardware uses the comparison function for testing each attribute value stored in the depth buffer against d. the comparison function is specified using the depth function. routine 1 describes the pseudo-code for our implementation.
1.1 comparison between two attributes
　the comparison between two attributes  ai op aj  can be transformed into a special semi-linear query  ai   aj op 1   which can be performed very efficiently using the vector processors on the gpus. here  we propose a fast algorithm that can perform any general semi-linear query on gpus.
compare  tex  op  d  
1 copytodepth  tex  
1 set depth test function to op
1 renderquad  d  
copytodepth  tex  
1 set up fragment program
1 rendertexturedquad  tex  
routine 1: compare compares the attribute values stored in texture tex against d using the comparison function op. copytodepth called on line 1 copies the attribute values in tex into the depth buffer. copytodepth uses a simple fragment program on each pixel of the screen for performing the copy operation. on line 1  the depth test is configured to use the comparison operator op. the function renderquad d  called on line 1 generates a fragment at a specified depth d for each pixel on the screen. rasterization hardware compares the fragment depth d against the attribute values in depth buffer using the operation op.
semi-linear queries on gpus
applications encountered in geographical information systems  gis   geometric modeling  and spatial databases define geometric data objects as linear inequalities of the attributes in a relational database . such geometric data objects are called semi-linear sets. gpus are capable of fast computation on semi-linear sets. a linear combination of m attributes is represented as:
i=m x si ， ai
i=1
where each si is a scalar multiplier and each ai is an attribute of a record in the database. the above expression can be considered as a dot product of two vectors s and a where s =  s1 s1 ... sm  and a =  a1 a1 ... am .
semilinear  tex  s  op  b  
1 enable fragment program semilinearfp s  b 
1 rendertexturedquad  tex  
semilinearfp  s  op  b 
1 a = value from tex 1 if dot  s  a  op b
1	discard fragmentroutine 1: semilinear computes the semi-linear query by performing linear combination of attribute values in tex and scalar constants in s. using the operator op  it compares the the scalar value due to linear combination with b. to perform this operation  we render a screen filling quad and generate fragments on which the semi-linear query is executed. for each fragment  a fragment program semilinearfp discards fragments that fail the query.
semilinear computes the semi-linear query:
 s ， a  op b
where op is a comparison operator and b is a scalar constant. the attributes ai are stored in separate channels in the texture tex. there is a limit of four channels per texture. longer vectors can be split into multiple textures  each with four components. the fragment program semilinearfp   performs the dot product of a texel from tex with s and compares the result to b. it discards the fragment if the comparison fails. line 1 renders a textured quadrilateral using the fragment program. semilinear maps very well to the parallel pixel processing as well as vector processing capabilities available on the gpus. this algorithm can also be extended for evaluating polynomial queries.
evalcnf  a  
1 clear stencil to 1.
1 for each of ai  i = 1 .. k
1 do
1 if   mod i 1    /* valid stencil value is 1 */
1 stencil test to pass if stencil value is equal to 1
1 stencilop keep keep incr 
1 else /* valid stencil value is 1 */
1 stencil test to pass if stencil value is equal to 1
1 stencilop keep keep decr 
1 endif
1 for each bji  j = 1 .. mi
1 do
1 perform bji using compare
1 end for
1 if   mod i 1   /* valid stencil value is 1 */
1 if a stencil value on screen is 1  replace it with 1
1 else /* valid stencil value is 1 */
1 if a stencil value on screen is 1  replace it with 1
1 endif
1 end for
routine 1: evalcnf is used to evaluate a cnf expression. initially  the stencil is initialized to 1. this is used for performing true and a1. while evaluating each formula ai  line 1 sets the appropriate stencil test and stencil operations based on whether i is even or odd. if i is even  valid portions on screen have stencil value 1. otherwise  valid portions have stencil value 1. lines 1   1 invalidate portions on screen that satisfy  a1 … a1 … ... … ai 1  and fail  a1 … a1 … ... … ai . lines 1   1 compute the disjunction of bji for each predicate ai. at the end of line 1  valid portions on screen have stencil value 1 if i is odd and 1  otherwise. at the end of the line 1  records corresponding to non-zero stencil values satisfy a.
1 boolean combination
　complex boolean combinations are often formed by combining simple predicates with the logical operators and  or  not. in these cases  the stencil operation is specified to store the result of a predicate. we use the function stencilop  as defined in section 1  to initialize the appropriate stencil operation for storing the result in stencil buffer.
　our algorithm evaluates a boolean expression represented as a cnf expression. we assume that the cnf expression has no not operators. if a simple predicate in this expression has a not operator  we can invert the comparison operation and eliminate the not operator. a cnf expression ck is represented as a1 …a1 …...…ak where each ai is represented as . each bji j = 1 .. mi is a simple predicate.
　the cnf ck can be evaluated using the recursion ck = ck 1 … ak. c1 is considered as true. we use the pseudocode in routine 1 for evaluating ck. our approach uses three stencil values 1 1 for validating data. data values corresponding to the stencil value 1 are always invalid. initially  the stencil values are initialized to 1. if i is the iteration value for the loop in line 1  lines 1   1 evaluate ci. the valid stencil value is 1 or 1 depending on whether i is even or odd respectively. at the end of line 1  portions on the screen with non-zero stencil value satisfy the cnf ck. we can easily modify our algorithm for handling a boolean expression represented as a dnf.
range queries
a range query is a common database query expressed as a boolean combination of two simple predicates. if  low high  is the range for which an attribute x is queried  we can evaluate the expression  x − low  and  x ＋ high  using evalcnf. recent gpus provide a feature gl ext depth bounds test   useful in accelerating shadow algorithms. our algorithm uses this feature for evaluating a range query efficiently. the pseudo-code for our algorithm range is given in routine 1. although a range query requires the evaluation of two simple predicates  the computational time for our algorithm in evaluating range is comparable to the time required in evaluating a single predicate.
range  tex  low  high   1 setupstencil  
1 copytodepth  tex  
1 set depth bounds based on  low  high 
1 enable depth bounds test
1 renderquad low 
1 disable depth bounds testroutine 1: setupstencil is called on line 1 to enable selection using the stencil buffer. copytodepth called on line 1 copies the attribute values in tex into the depth buffer. line 1
sets the depth bounds based on  low  high . the attribute values copied into the depth buffer and falling within the depth bounds pass the depth bounds test. lines 1 perform the depth bounds test. the stencil is set to 1 for the attributes passing the range query and 1 for the other.
1 aggregations
　several database operations aggregate attribute values that satisfy a condition. on gpus  we can perform these operations using occlusion queries to return the count of records satisfying some condition.
1.1 count
　using an occlusion query for counting the number of records satisfying some condition involves three steps:
1. initialize the occlusion query
1. perform the boolean query
1. read back the result of the occlusion query into count
1.1 min and max
　the query to find the minimum or maximum value of an attribute is a special case of the kth largest number. here  we present an algorithm to generate the kth largest number. k-th largest number
computing the k-th largest number occurs frequently in several applications. we can utilize expected linear time selection algorithms such as quickselect  to compute the k-th largest number. most of these algorithms require data rearrangement  which is extremely expensive on current gpus because there is no functionality for data writes to arbitrary locations. also  these algorithms require evaluation of conditionals and may lead to branch mispredictions on the cpu. we present a gpu-based algorithm that does not require data rearrangement. in addition  our algorithm exhibits simd characteristics that exploit the inherent parallelism available on the gpus.
　our algorithm utilizes the binary data representation for computing the k-th largest value in time that is linear in the number of bits.
kthlargest  tex  k  
 maximum number of bits in the values in tex
1 for i = b max-1 down to 1
1 count = compare  tex  −  x +1i  
1 if count   k - 1
1 x = x +1i
1 return xroutine 1: kthlargest computes the k-th largest attribute value in texture tex. it uses b max passes starting from the msb to compute the k-th largest number. during a pass i  it determines the i-th bit of the k-th largest number. at the end of bmax passes  it computes the k-th largest number in x.
　the pseudocode for our algorithm kthlargest is shown in routine 1. kthlargest constructs in x the value of the k-th largest number one bit at a time starting with the most significant bit  msb   b max-1. as an invariant  the value of x is maintained less than or equal to the k-th largest value. line 1 counts the number of values that are greater than or equal to x+1i  the tentative value of x with the ith bit set. this count is used for deciding whether to set the bit in x according to the following lemma:
lemma 1: let vk be the k-th largest number in a set of values. let count be the number of values greater than or equal to a given value m.
  if count   k   1 : m ＋ vk
  if count ＋  k   1  : m   vk
proof: trivial.
if count   k   1 then the tentative value of x is smaller than the k-th largest number. in this case  we set x to the tentative value on line 1. otherwise the tentative value is too large so we leave x unchanged. at the end of line 1  if the loop iteration is i  the first i bits from msb of x and vk are the same. after the last iteration of the loop  x has the value of the k-th largest number. the algorithm for the k-th smallest number is the same  except that the comparison in line 1 is inverted.
1.1 sum and avg
　an accumulator is used to sum a set of data values. one way of implementing an accumulator on current gpus is using a mipmap of a floating point texture. mipmaps are multi-resolution textures consisting of multiple levels. the highest level of the mipmap contains the average of all the values in the lowest level  from which it is possible to recover the sum by multiplying the average with the number of values. a fragment program must be used to create a floating-point mipmap. computing a floating-point mipmap on current gpus tends to be problematic for three reasons. firstly  reading and writing floating-point textures can be slow. secondly  if we are interested in the sum of only a subset of values  e.g. those that are greater than a given number  then introduce conditionals in the fragment program. finally  the floating point representation may not have enough precision to give an exact sum.
　our accumulator algorithm avoids some of the problems of the mipmap method. we perform only texture reads which are more efficient than texture writes. moreover  we calculate the precise sum to arbitrary precision and avoid conditionals in the fragment program. one limitation of the algorithm is that it works only on integer datasets  although it can easily be extended to handle fixed-point datasets.
accumulator  tex  
1 alpha test = pass with alpha − 1
1 sum = 1
1 for i = 1 to b max do
1 enable fragment program testbit i 
1 initialize occlusion query
1 rendertexturedquad  tex  
1 count = pixel count from occlusion query
1 sum + = count  1i
1 return sum
testbit i 
1 v = value from tex
1 fragment alpha = frac v /1 i+1  
routine 1: accumulator computes the sum of attribute values in texture tex. it performs b max passes to compute the sum. each pass computes the number of values with i-th bit set and stores it in count. this count is multiplied with 1i and added to sum. at the end of the b max passes  the variable sum aggregates all the data values in the texture.
accumulator sums the values stored in the texture tex utilizing the binary data representation. the sum of the values xj in a set x can be written as:
|x|	|x| k xxj = xxaij1i
	j=1	j=1 i=1
where aij （ {1} are the binary digits of xj and k is the maximum number of bits used to represent the values in x. currently  no efficient algorithms are known for summing the texels on current gpus. we can  however  quickly determine the number of texels for which a particular bit i is set. if we reverse the order of the summations  we get an expression that is more amenable to gpu computation:

the inner summation is simply the number of xj that have the ith bit set. this summation is the value of count calculated on lines 1 where we render a quad textured with tex.
　the fragment program testbit ensures that only fragments corresponding to texels with the ith bit set pass the alpha test. determining whether a particular bit is set is trivial with bit-masking operations. since current gpus do not support bit-masking operations in fragment programs  we use an alternate approach. we observe that an integer x has its ith bit equal to 1 if and only if the fractional part of x/1i+1 is at least 1. in testbit  we divide each value by 1i+1 and put the fractional part of the result into the alpha channel. we use the alpha test for rejecting fragments with alpha less than 1. it is possible to perform the comparison and reject fragments directly in the fragment program  but it is faster in practice to use the alpha test. pseudocode for our algorithm is shown in the routine 1.
　accumulator can be used for summing only a subset of the records in tex that have been selected using the stencil buffer. attributes that are not selected fail the stencil test and thus make no contribution to the final sum. we use the accumulator algorithm to obtain sum. avg is obtained by computing sum and count  and computed as avg = sum/count.
1. implementation&performance
　we have implemented and tested our algorithms on a high end dell precision workstation with dual 1ghz intel xeon processors and an nvidia geforcefx 1 ultra graphics processor. the graphics processor has 1mb of video memory with a memory data rate of 1mhz and can process upto 1 pixels at processor clock rate of 1 mhz. this gpu can perform single-precision floating point operations in fragment programs.
1 benchmarks
　for our benchmarks  we have used a database consisting of tcp/ip data for monitoring traffic patterns in local area network and wide area network and a census database  consisting of monthly income information. in the tcp/ip database  there are one million records in the database. in our experiments  each record has 1 attributes   data count data loss flow rate retransmissions .
　each attribute in the database is stored in as a floatingpoint number encoded in a 1 bit rgba texture. the video memory available on the nvidia geforce fx 1 graphics processor can store more than 1 attributes  each in a texture of size 1 〜 1  amounting to a total of 1 million values in the database. we transfer textures from the cpu to the graphics processor using an agp 1x interface.
　the census database consists of 1k records. we used four attributes for each record of this database. we have benchmarked our algorithms using the tcp/ip database. our performance results on the census data are consistent with the results obtained on the tcp/ip database.
1 optimized cpu implementation
　we implemented the algorithms described in section 1 and compared them with an optimized cpu implementation. we compiled the cpu implementation using intel compiler 1 with full compiler optimizations 1. these optimizations include
  vectorization: the compiler detects sequential data scans and generates code for simd execution.
  multi-threading: we used the compiler switch -qparallel to detect loops which may benefit from multithreaded execution and generate appropriate threading calls. this option enables the cpu implementation to utilize hyper-threading technology available on xeon processors.
  inter-procedural optimization  ipo : the compiler performs function inlining when ipo is enabled. it reduces the function call branches  thus improving its efficiency.
for the timings  we ran each of our tests 1 times and computed the average running time for the test.
cate evaluation with 1% selectivity by a cpu-based and a gpu-based algorithm. timings for the gpu-based algorithm include time to copy data values into the depth buffer. considering only computation time  the gpu is nearly 1 times faster than a compiler-optimized simdquery with 1% selectivity using a gpubased and a cpu-based algorithm. timings for the gpu-based algorithm include time to copy data values into the depth buffer. considering only computation time  the gpu is nearly 1 times faster than a compiler-optimized simdfigure 1: execution time of a multiattribute query with 1% selectivity for each attribute and a combination of and operator. timei is the time to perform a query with i attributes. we show the timings for cpu and gpu-based implementations.figure 1: execution time of a predi-	figure 1: execution time of a range	implementation.	implementation.

figure 1: plot indicating the time taken for copying data values in a texture to the depth buffer.
1 gpu implementation
　our algorithms described in section 1 are implemented using the opengl api. for generating the fragment programs  we used nvidia's cg compiler . as the code generated by the compiler is often sub-optimal  we examined the assembly code generated by the current compiler and reduced the number of assembly instructions to perform the same operation.
　for the counting operations  we chose to use gl nv occlusion query for image-space occlusion queries. these queries can be performed asynchronously and often do not add any additional overhead.
1 copy operation
　various database operations  such as comparisons  selection  etc  require the data values of an attribute stored in the depth buffer. for these operations  we copy the corresponding texture into the depth buffer. a fragment program is used to perform the copy operation. our copy fragment program implementation requires three instructions.
1. texture fetch: we fetch the texture value corresponding to a fragment.
1. normalization: we normalize the texture value to the range of valid depth values  1 .
1. copy to depth: the normalized value is copied into the fragment depth.
　figure 1 shows the time taken to copy values from textures of varying sizes into the depth buffer. the figure indicates an almost linear increase in the time taken to perform the copy operation as a function of the number of records. in the future  it may be possible to copy data values from textures directly to a depth buffer and that would reduce these timings considerably. also  the increase in clock rates of graphics processors and improved optimizations to perform depth buffer writes  could help in reducing these timings.
1 predicate evaluation
　figure 1 shows a plot of the time taken to compute a single predicate for an attribute such that the selectivity is 1%. in our experiments  we performed the operation on the first attribute of each record in the database. the plot compares a compiler-generated simd optimized cpu code against a simple gpu implementation. the gpu timings include the computational time for evaluating the predicate  as well as the time taken to copy the attribute into the depth buffer. we observe that the gpu timings are nearly 1 times faster than the cpu timings. if we compare only the computational time on the gpu  we observe that the gpu implementation is nearly 1 times faster than the simd optimized cpu implementation.
1 range query
　we tested the performance of range by timing a range query with 1% selectivity. to ensure 1% selectivity  we set the valid range of values between the 1th percentile and 1th percentile of the data values. again  in our tests  we used the data count as our attribute. figure 1 compares the time taken for a simple gpu implementation and a compiler-optimized simd implementation on cpu. in the gpu timings  we included the time taken for the copy operation. we observe that overall the gpu is nearly 1 times faster than the cpu implementation. if we consider only the computational time on gpu and cpu  we observe that the gpu is nearly 1 times faster than the compiler optimized cpu implementation.
1 multi-attribute query
　we have tested the performance of our hardware-based multi-attribute queries by varying the number of attributes and also the number of records in the database. we used queries with a selectivity of 1% for each attribute and applied the and operator on the result for each attribute. in
figure 1: time to compute k-th largest figure 1: time taken to compute the figure 1: time taken to compute the number on the data count attribute. we median using kthlargest and quicks- k-th largest number by the two imple-
used a portion of the tcp/ip database elect on varying number of records. mentations.with nearly 1k records.

figure 1: execution time of a semi-linear query using four attributes of the tcp/ip database. the gpu-based implementation is almost one order of magnitude faster than the cpu-based implementation.
our tests  we used up to four attributes per query. for each attribute in the query  the gpu implementation copies the data values from the attribute's texture to the frame-buffer. figure 1 shows the time taken by the gpu and cpu respectively  to perform multi-attribute queries with the varying number of attributes and records. the timings indicate that the gpu implementation is nearly 1 times faster than the cpu implementation. if we consider only the computational times on the gpu by ignoring copy times  we observe that the gpu is nearly 1 times faster than the optimized cpu implementation.
1 semi-linear query
　we performed a semi-linear query on the four attributes by using a linear combination of four random floating-point values and compared it against an arbitrary value. figure 1 summarize our timings for various number of tests on gpu and cpu. in our tests  we observe that the gpu timings are 1 times faster than an optimized cpu implementation.
1 k-th largest number
　we performed three different tests to evaluate our kthlargest algorithm on gpu. in each of these tests  we compared kthlargest against a cpu implementation of the algorithm quickselect . in our experiments  we used the data count attribute. this attribute requires 1 bits to represent the largest data value and has a high variance. test 1: vary k and compute the time taken for kthlargest and quickselect. the tests were performed on 1k records in the database. figure 1 shows the timings obtained using each of the implementations. this plot indicates that time taken by kthlargest is constant irrespective of the value of k and is an interesting characteristic of our algorithm. on an average  the gpu timings for our algorithm are nearly twice as fast in comparison to the cpu implementation. it should be noted that the gpu timings include the time taken to copy values into the depth buffer. comparing the computational times  we note that the average kthlargest timings are 1 times faster than quickselect.
test 1: in these tests  we compared the time taken by kthlargest and quickselect to compute a median of a varying number of records. figure 1 illustrates the results of our experiments. we observe that the kthlargest on the gpu is nearly twice as fast as quickselect on the cpu. considering only the computational times  we observe that kthlargest is nearly 1 times faster than quickselect. test 1: we also compared the time taken by kthlargest and quickselect for computing a median with on data values with 1% selectivity. figure 1 indicates the time taken by kthlargest and quickselect in computing the median as a function of the number of records. our timings indicate that kthlargest with 1% selectivity requires exactly the same amount of time as performing kthlargest with 1% selectivity. we conclude from this observation that the use of a conditional to test for valid data has almost no effect on the running time of kthlargest. for the cpu timings  we have copied the valid data into an array and passed it as a parameter to quickselect. the timings indicate that the total running time is nearly the same as that of running quickselect with 1% selectivity.
1 accumulator
　figure 1 demonstrates the performance of accumulator on the gpu and a compiler-optimized simd implementation of accumulator on the cpu. our experiments indicate that our gpu algorithm is nearly 1 times slower than the cpu implementation  when including the copy time. note that the cpus have a much higher clock rate as compared to the gpu. 1 selectivity analysis
　recently  several algorithms have been designed to implement join operations efficiently using selectivity estimation  1  1 . we compute the selectivity of a query using the count algorithm  section 1 . to obtain the selectivity count  image-space occlusion queries are used. we performed the experiments described in sections 1  1  1  1. we observed that there is no additional overhead in obtaining the count of selected queries. given selected data values scattered over a 1 〜 1 frame-buffer  we

figure 1: time required to sum the values of an attribute by the cpu and by the gpu-based accumulator algorithm
can obtain the number of selected values within 1 ms.
1. analysis
　in the previous section  we have highlighted the performance of our algorithms on different database operations and performed a preliminary comparison with some cpubased algorithms. in this section  we analyze the performance of our algorithms and highlight the database operations for which the gpus can offer considerable gain in performance.
1 implementing basic operations on gpus
　there are many issues that govern the performance of the algorithms implemented on a gpu. some of the upcoming features in the next generation gpus can improve the performance of these algorithms considerably.
precision: current gpus have depth buffers with a maximum of 1 bits. this limited precision can be an issue. with the increasing use of gpus in performing scientific computing  graphics hardware developers may add support for higher-precision depth buffers.
copy time: several of our algorithms require data values to be copied from the texture memory to the depth buffer. current gpus do not offer a mechanism to perform this operation efficiently and this operation can take a significant fraction of the overall algorithm  e.g. algorithms for relational and range queries . in the future  we can expect support for this operation on gpus which could improve the overall performance.
integer arithmetic instructions: current gpus do not offer integer arithmetic instructions in the pixel processing engines. in addition to database operations  several image and video compression algorithms also require the use of integer arithmetic operations. fragment programs were introduced in just the last few years. the instruction sets for these programs are still being enhanced. the instructions for integer arithmetic would reduce the timings of our accumulator algorithm significantly.
depth compare masking: current gpus support a boolean depth mask that enables or disables writes to a depth buffer. it is very useful to have a comparison mask specified for the depth function  similar to that specified in the stencil function. such a mask would make it easier to test if a number has i-th bit set.
memory management: current high-end gpus have up to 1mb of video memory and this limit is increasing every year. however  due to the limited video memory  we may not be able to copy very large databases  with tens of millions of records  into gpu memory. in such situations  we would use out-of-core techniques and swap textures in and out of video memory. another related issue is the bus bandwidth. current pcs use an agp1〜 bus to transfer data from the cpu to the gpu and the pci bus from the gpu to the cpu. with the announcement of pci-express bus  the bus bandwidth is going to improve significantly in the near future. asynchronous data transfers would also improve the performance of these algorithms.
no branching: current gpus implement branching by evaluating both portions of the conditional statement. we overcome this issue by using multi-pass algorithms and evaluating the branch operation using the alpha test or the depth test.
no random writes: gpus do not support random access writes  which makes it harder to develop algorithms on gpus because they cannot use data rearrangement on gpus.
1 relative performance gain
　we have presented algorithms for predicates  boolean combinations and aggregations. we have also performed preliminary comparison with optimized cpu-based implementations on a workstation with dual 1 ghz xeon processors. due to different clock rates and instruction sets  it is difficult to perform explicit comparisons between cpu-based and gpu-based algorithms. however  some of our algorithms perform better than others. we classify our algorithms into three categories: high performance gain  medium performance gain and low performance gain.
1.1 high performance gain
　in these algorithms  we have observed an order of magnitude speedup over cpu-based implementations. these include algorithms for semi-linear queries and selection queries. the main reason for the improved performance are:
  parallel computation: gpus have several pixel processing engines that process multiple pixels in parallel. for example  on a geforce fx 1 ultra we can process 1 pixels in parallel and reduce the computational time significantly. also  each pixel processing engine has vector processing capabilities and can perform vector operations very efficiently. the speedup in selection queries is mainly due to the parallelism available in pixel processing engines. the semi-linear queries also exploit the vector processing capabilities.
  pipelining: gpus are designed using a pipelined architecture. as a result  they can simultaneously process multiple primitives within the pipeline. the algorithms for handling multiple-attribute queries map well to the pipelined implementation.
  early depth-culling: gpus have specialized hardware that early in the pipeline can reject fragments that will not pass the depth test. since the fragments do not have to pass through the pixel processing engines  this can lead to a significant performance increase.
  eliminate branch mispredictions: one of the major advantages in performing these selection queries on gpus is that there are no branch mispredictions.
branch mispredictions can be extremely expensive on the modern cpus. modern cpus use specialized schemes for predicting the outcome of the branch instruction. each branch mis-prediction can cost several clock cycles on current cpus. for example  on a pentium iv a branch misprediction can have a penalty of 1 clock cycles .
1.1 medium performance gain
　several of our algorithms for database operations are only able to use a subset of the capabilities of the gpus. in these cases  we have observed a speedup of nearly a factor of 1 to 1 times in comparison to an optimized-cpu implementation. for example  the kthlargest   routine exhibits these characteristics. the speedup in the kthlargest   is mainly due to the parallelism available in pixel processing engines. given the gpu clock rate and the number of pixel processing engines  we can estimate the time taken to perform kthlargest   under some assumptions. we assume that there is no latency in the graphics pipeline and in transmitting the pixel pass count from the gpu to the cpu. on a geforce fx 1 ultra with clock rate 1mhz and processing 1 pixels per clock cycle  we can render a single quad of size 1〜1 in 1 ms. in our experiments  we render 1 such quads to compute the k-th largest number. rendering these quads should take 1 ms. the observed time for this computation is 1 ms  which indicates that we are utilizing nearly 1% of the parallelism in the pipeline. the observed timings are slightly higher due to the latencies in transmitting the data from the gpu to the cpu and viceversa. a key advantage of our algorithm kthlargest   in comparison with other parallel order statistic algorithms is that it does not require any data rearrangement. data rearrangements can be expensive when combined with branching.
1.1 low performance gain
　in some cases  we did not observe any gain over a cpubased implementation. our gpu based accumulator algorithm is much slower than the cpu-based implementation. there are several reasons for this performance:
  lack of integer arithmetic: current gpus do not support integer arithmetic instructions. therefore  we used a fragment program with at least 1 instructions to test if the i-th bit of a texel is 1. there are several ways to implement such a feature in the hardware. a simplest mechanism is to copy the i-th bit of the texel into the alpha value of a fragment. this can lead to significant improvement in performance.
  clock rate: not only are we comparing two architectures with different instruction sets  but they also have different clock rates. our cpu implementation used top-of-the-line dual xeon processors operating at 1ghz. each xeon processor has four simd processors that can perform four operations in parallel. on the other hand  the current gpu clock rate  1mhz  is much lower than the cpu clock rate. it is possible that the increasing parallelism in the gpus and development of new instruction sets for fragment programs can bridge this gap in performance.
　our preliminary analysis indicates that it is advantageous to perform selection and semi-linear queries on gpus. in addition  gpus can also be used effectively to perform order statistics algorithms.
1. conclusions and future work
　in this paper  we have presented novel algorithms for performing database operations on the gpus. these include algorithms for predicates  boolean combinations  and aggregation queries. we have implemented these algorithms on a state-of-the-art gpu and highlighted its performance for following queries: relational query  range query  multiattribute query  semi-linear query  kth-largest number computation  accumulator and selectivity analysis. we have also performed preliminary comparisons with optimized implementations of cpu-based algorithms. in some cases  we observed noticeable performance gain.
　we have shown that gpus are excellent candidates for performing some of the databases operations. some reasons for this finding include:
  commodity hardware: high-end gpus are freely available on pcs  consoles and workstations. the cost of a high-end gpu is typically less than the cost of a high-end cpu  by a factor of two or more .
  higher growth rate: over the last decade the growth rate of gpu performance has been higher than that of cpus. this trend is expected to continue for the next five years or so. the performance gap between the cpus and gpus will probably increase considerably and we can obtain improved performance for database queries on the gpus.
  multiple fragment processors and improved programmability: current high-end gpus already have 1 fragment processors. this number is expected to increase in the future. as the instruction sets of fragment programs improve  the running time of many of our algorithms will further decrease.
  useful co-processor: overall  the gpu can be used as an effective co-processor along with the cpus. it is clear that gpu is an excellent candidate for some database operations  but not all. therefore  it would be useful for database designers to utilize gpu capabilities alongside traditional cpu-based code.
　there are many avenues for future work. it is possible to use new capabilities and optimizations to improve the performance of many of our algorithms. furthermore  we would like to develop algorithms for other database operations and queries including sorting  join  and indexed search  and olap and data mining tasks such as data cube roll up and drill-down  classification  and clustering  which may benefit from multiple fragment processors and vector processing capabilities. we also plan to design gpu-based algorithms for queries on more complicated data types in the context of spatial and temporal databases and perform continuous queries over streams using gpus.
acknowledgements
this research is supported in part by aro contract daad1-
1-1  nsf award aci-1  onr contracts n1-1 and n1-1  and intel corporation. we would like to thank nvidia corporation especially steven molnar  paul keller and stephen ehmann for their support. we would also like to thank jasleen sahni for providing access to the tcp/ip database.
