i. introduction
　the categorization task for the 1 genomics track uses data from the mouse genome informatics  mgi   system and is a document triage task. the categorization task looks at how well systems can categorize articles for four major categories of information collected and catalogued by mgi. these four categories include articles about:
1  alleles of mutant phenotypes 
1  embryologic gene expression 
1  gene ontology  go  
1  tumor biology 
　to find information on mouse genomics biology  relating to the categories listed above and others  mgi follows a three step process . in the first step new scientific literature is automatically scanned for records containing one or more instances of the words  mouse    mice   and  murine . in the second triage step the articles that should be sent for curation are identified by mgi personnel. the goal of this triage process is to limit the number of articles sent to human curators for more exhaustive analysis. articles that pass this step go into the mgi system with a tag for go  tumor  expression  etc. tagged articles are then sent for the actual curation by human curators. for example  for the gene function category curators identify genes for which there is experimental evidence to warrant assignment of go codes within an article. the categorization task for the 1 genomics track is to automate the triage task that involved correctly classifying which articles have been selected for curation in the four categories. the 1 genomics track also included the triage task . however  in it  only the gene ontology category for assignment of go codes was considered.
　different machine learning methods have been used for the classification of text documents . support vector machines  svm    naive bayes classification  and a number of other machine learning techniques have shown a lot of promise in text categorization tasks. a variety of implementations of the various machine learning methods are available. for example  the weka toolkit  comprises a suite of machine learning tools that can be used for classification. similarly 
svmlight  and libsvm  are implementations of svm.
　many of the top teams in 1 used the mesh terms from the medline records as one of the features . an ontology like medical subject headings  mesh   provides a set of broad-based  multidisciplinary concepts and categories to annotate the content of biological literature in terms of key concepts describing genes  proteins  cell function  anatomical objects  diseases and so on. also depending on the application  either features selected from the full article or carefully selected sections of it have been shown to give different results . such an approach where sections are weighted differently is possible when the documents are structured.
　this paper presents techniques to automatically triage the articles into the four categories. we have tried to incorporate category specific knowledge to improve the classification accuracy. we have used category specific word lists from mgi to select the features for the classification. we approach the classification task in three ways. in the first approach we considered a machine learning based method. we represent the article as a bag of concepts. we chose a set of concepts which best represent the classes and these features are then used to classify the articles. we tried different category specific features  like using specialized term lists and mesh terms  and also different ways of selecting the relevant features.
　our second approach consisted of identifying concepts that can be used to filter the articles. in the 1 task it was noted that the utility for the mesh term  mice  for go classification was better than all but the best run . we try to identify a larger set of concepts that are specific to the categories and help in improving the utility when used to filter the documents.

data settotalalleleexpr.gotumorarticlesposnegposnegposnegposnegtraining data11111test data11111　　　　　table i description of the data set	fig. 1.	classification system block diagram
for example  the presence of the concept  tumor  is a strong indicator of an article being positive for the tumor biology category  where as  the presence of the concept  transplanted tumor  is a strong negative indicator for the same class.
　in our final approach we use a two stage classifier. in the first step articles are filtered based on the presence or absence of a predefined set of concepts. in the second step the positive documents  after the first step  were classified using a machine learning based method. as stated above  the features for the machine learning approach were the mesh terms and concepts chosen using specialized dictionaries relevant to the category. the best performing run in 1 had also used a two stage classifier . however  there the presence of mesh term  mice  alone was used in the first step for identifying positive articles.
　the paper is organized as follows. section ii presents an overview of the system along with a brief discussion of the trec 1 data set  the resources we used and our methodology. section iii presents and discusses the results. finally section iv concludes the paper.
ii. system overview and methodology
　a block diagram of the classifier system is shown in figure 1. for a given document we construct a feature vector comprising the mesh terms obtained from pubmed and look up terms identified in the document using specialized dictionaries. in the machine learning based approach svm classification is done based on the feature vectors after filtering the documents using the mesh term  mice . for the rule based approach only the filtering is done using a list of positive and negative concepts. in the combined approach both the filter and the svm classifier come into play. these methods are described in more detail subsequently in this section.
a. data set
the dataset for the 1 task is same as that used at trec
1  which is a collection of articles from three journals over two years  1 and 1 . the articles are available in structured sgml format. the 1 articles form the training set and the 1 articles form the test set. the training data had a total of 1 articles and and the test data 1 articles. table i shows the distribution of the positive and negative examples in the training and test sets for the four categories. as can be seen the number of positive examples is quite low for all the categories but it is especially very low in the tumor and expression categories.
　apart from the articles we also had the pubmed id of all the articles. we obtained the medline records by crawling the pubmed database. importantly for us the medline records contained the mesh terms assigned to the articles.
b. evaluation measure
the evaluation measure used for the task was the normalized
utility 
and
umax = ur tp + fn 
where  ur = relative utility of relevant articles and
unr = relative utility of non relevant articles
and tp - true positive  tn - true negative  fp - false positive and fn - false negative.
　for the trec runs it was officially given that  unr =  1 and the values for ur were officially calculated to be 1 for allele  1 for expression  1 for go and 1 for tumor by using mgi's current practice of triaging everything. the high values of ur imply that errors on positive examples are very heavily penalized. effectively this means a high recall is very important even if the precision is low.
c. feature generation for machine learning approaches
　for each of the categories we identified a list of concepts that we could use as features. we used bioannotator  to look up the concepts in the articles. bioannotator is a tool we have developed for finding and annotating biological concepts in documents based on different dictionaries and ontologies. it is possible to load different dictionaries and ontologies into
bioannotator for look up. in this case the concepts of interest to us were gene ontology  gene expression and phenotypic lists from mgi . table ii shows the specialized lists used for concept look up in the articles for each of the categories. for the tumor category we could not locate a tumor specific term list. using these specialized lists allowed us to select features relevant to a category.
table ii
term lists used for lookup
categoryontologies/term lists usedgogotumor biologyexpressiongene expressionallelesphenotypic data　for the machine learning approaches the features  for an article  comprised the assigned mesh terms from medline plus look up on the mgi dictionary concepts. we also tried other features like look up on umls  terms followed by chi-square feature selection. for the go category look up on umls results in a feature set of over 1  1 concepts  where as  using mesh and mgi lists results in a compact feature set of about 1 concepts. using mesh and mgi based features also resulted in much better performance compared to umls based features. this underlines the importance of using the right features in the classification. we first used the complete article but on finding that using only the title and abstract worked just as well  we confined the look up to the title and abstract.
d. selection of concepts for filtering documents
　the trec participants were provided a cheat sheet  developed by mgi for its curators who triage articles. this sheet contained instructions on what to look for in positive and negative articles. for example  for the go category the cheat sheet asks the curator to always select an article that reports  protein studies  e.g. enzyme assays  binding studies  . we used the instructions in the cheat sheet to come up with negative and positive concepts. the presence of a negative concept implied the document should not be selected and the presence of a positive concept meant that the document should be selected. for allele  expression and go classes  in addition to the terms identified from the cheat sheet  all the terms present in the phenotypic  gene expression and gene ontology lists from mgi   respectively  and the mesh term  mice  were taken as positive concepts. some examples of other positive concepts are   fibroma  and  sarcoma  for the tumor category. some examples of negative concepts are   syngeneic  and  transplanted tumors  for the tumor category and mesh term  synthetic genes  for go etc. we selected the concepts that gave a high tp/fp ratio as positive concepts and those with high tn/fn ratio as negative concepts. since fns are heavily penalized by the very high utility factor  the selection of negative concepts was very strict.
table iii
utilities for mesh term  mice 
alleleexpressiongotumortest set1111train set1111e. machine learning approach
　the cosine normalized term frequency vectors formed the input to the machine learning system. the svm implementation we used was the svmlight implementation . the svmlight implementation of svm requires the user to specify a number of parameters. we used the radial basis function  rbf  kernel. we set the j parameter  which specifies the cost factor by which training errors on positive examples outweigh errors on negative examples to be equal to the relative utility for the category. for example  for the tumor category we set j=1. we set the c and g parameters for each category at the value that gave the best performance over the training data set. we also used the weka implementation of naive bayes but found that svm outperformed it by a large factor. we found that using a two stage classifier  where  in the first stage we only select articles containing the mesh term  mice   gave the best performance. thus  even for our  pure  machine learning run we did use this filter step.
f. rule based approach
　the selection of concepts based on the ratios over the training set allowed us to come up with sets of positive and negative concepts using which we could define rules for filtering articles. the rules were simply:
1  if article contains a negative concept mark it as negative
1  else if article contains a positive concept mark it as positive
1  else mark it as negative
the results for using an empty negative concept set and mesh term  mice  in the positive concept set are shown in table iii. by adding more carefully chosen concepts to each of these sets we improved the utilities.
g. combined approach
　in this approach we combine the rule based approach with the machine learning approach. we used a two step classifier. in the first step articles are filtered based on the rule based approach. in the second step the positive articles  remaining after filtering  were classified using svm. the rules were chosen to be high recall rules and the primary purpose of the svm step was to improve the precision.
table iv
utilities obtained on training set
alleleexpressiongotumorsvm1111rule1111combined1111table v
results obtained on test set for allele and expression categories  official run 
methodalleleexpressionpr.rec.f-scoreutilpr.rec.f-score	utilsvm11111111rule11111111combined11111111best11111111median11111111worst1111111-1table vi
results obtained on test set for go and tumor categories  official run 
methodgotumorpr.rec.f-scoreutilpr.rec.f-scoreutilsvm11111111rule11111111combined11111111best11111111median11111111worst111-11111iii. results and discussion
　the results of applying our classification systems to the training set are presented in table iv. for the svm and combined approaches we split the training set into two equal parts for validation. the scores over the test set are given in table v and table vi. the precision  recall  f-score and utility obtained by us and the best  median and worst scores for the track are given in these tables.
　in the trec 1 categorization task many teams reported much higher utilities on the training set than over the test set. our results over the training and test sets did not vary greatly. over three of the four categories our utilities for the svm run were quite close for the training and test data sets. we believe our results did not vary over the two sets because the use of specific biological knowledge about the category  in the form of category specific dictionaries and the cheat sheet instructions  was incorporated into the system resulting in the selection of better features. further  after the release of the results we tried to change the svm parameters to see if we could get better results. for the allele category the svm performance over the official run was 1 and by changing of the svm parameters the highest possible result was 1 which are reasonably close. this indicates that we were able to choose the svm parameters quite close to the best possible.
　one of the reasons for the difference in performance over the test and training sets is the choice of features. cohen et. al.  had observed a conceptual drift in the documents over the period of one year. they observed that as the field of science changes over time  so does the language used to describe it. they observed that for the go class the similarity between their top features in the test and training sets was very small. they reasoned that since the test and training collections were collected over non-overlapping periods of time  the features identified as strong predictors had changed over time. their features consisted of words selected using chi-square feature selection from the set consisting of all stopped and stemmed words from different sections of the document and the mesh terms. for their features they found that the dice similarity coefficient was 1  the jaccard similarity coefficient was 1  and the cosine similarity was 1  where for two binary vectors x and
y   dice=  jaccard=  and cosine= . the conceptual drift that  observed was not as pronounced over the features we obtained. the dice similarity coefficients between the training and test features were  allele: 1  expr.: 1  go: 1 and tumor: 1. the jaccard similarity coefficients were  allele: 1  expr.: 1  go: 1 and tumor: 1. the cosine similarity coefficients were  allele: 1  expression: 1  go: 1  and tumor: 1. the tumor category had the lowest similarity and hence also the maximum difference between the test and training sets for the svm run. for this class the value of using the cheat sheet is clearly brought out in the results. the utility is greatly improved in the combined run as compared to the svm run. on the other hand  the results for the expression class show that wrong selection of concepts for the rule run can result in deterioration of utility.
　there is a strong case for incorporating biological knowledge into the classification system. further improvements can result from incorporating even more biological knowledge for the selection of relevant features and for forming rules. it is also necessary to find ways of incorporating the rules directly into the machine learning process. in this paper  though  we tried to incorporate category specific knowledge  we are not biomedical experts  and some of the rules are decided by statistics rather than biological reasoning. hence  the contribution of an expert in biological taxonomy would greatly increase the efficiency of classification as our results tend to indicate.
iv. conclusion
　automatic document triage can be an useful aid to the mgi triage process. our results show that the careful use of category specific knowledge can result in good utility. this is a strong case for incorporating more biological knowledge into the classification system.
