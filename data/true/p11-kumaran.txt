handling long queries can involve either pruning the query to retain only the important terms  reduction   or expanding the query to include related concepts  expansion . while automatic techniques to do so exist  roughly 1% performance improvements in terms of map have been realized in past work through interactive variants. we show that selectively reducing or expanding a query leads to an average improvement of 1% in map over the baseline for standard trec test collections. we demonstrate how user interaction can be used to achieve this improvement. most interaction techniques present users with a fixed number of options for all queries. we achieve improvements by interacting less with the user  i.e.  we present techniques to identify the optimal number of options to present to users  resulting in an interface with an average of 1% fewer options to consider. previous algorithms supporting interactive reduction and expansion are exponential in nature. to extend their utility to operational environments  we present techniques to make the complexity of the algorithms polynomial. we finally present an analysis of long queries that continue to exhibit poor performance in spite of our new techniques.
categories and subject descriptors
h.1  information search and retrieval : query formulation
general terms
algorithms  experimentation  performance
keywords
user interaction  interactive retrieval efficiency  query reduction  query expansion  query analysis

 this work was done while the author was a graduate student at university of massachusetts amherst
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee.
sigir'1  july 1  1  singapore.
copyright 1 acm 1-1-1/1 ...$1.
1.	introduction
　past work suggests that richer expressions of information need by users can be leveraged to improve search performance. the richer expression can take the form of longer than usual queries  i.e.  more than two to four terms in length   inclusion of additional terms the user believes are related to the query   identifying documents containing similar information   identifying topics the query is related to  and so on. we refer to all such expressions as long queries. handling long queries is however difficult as they usually contain a lot of noise. this noise is in the form of extraneous terms that the user believes are important to conveying the information need  but in fact are confusing to automatic systems. creating a more concise query by identifying and retaining the important terms in the long query  query reduction  is thus an important and challenging problem that needs to be solved. as opposed to automatic means  interactive query reduction  iqr   is particularly effective  section 1  in solving this problem.
　automatic query expansion techniques like pseudo-relevance feedback  prf   also help improve performance for certain types of long queries. greater gains can be obtained from interactive query expansion  iqe  section 1   which involves asking the user to help remove wrong terms suggested by the automatic technique.
　user interaction requires cognitive and physical effort from the user. guided by the philosophy that users must get the maximum benefit  effectiveness  for their investment of time and effort  we explore ways to make user interaction for long queries more effective in section 1. determining when to interactively reduce or expand a query  figure 1  can deliver the sort of improved effectiveness  over 1%  we seek. automatic techniques to consistently determine whether to expand a query or not have had limited success ; we will show we can perform selective interactive reduction and expansion  sire  using implicit feedback from the user.
　our past explorations of iqr and iqe techniques  involved asking a user to select from ten options for each and every query. this can be detrimental to the user experience. developing techniques to identify and present a minimal set of options to users is thus important. after demonstrating the similarity of the problem with set cover  a np-complete optimization problem  we utilize a greedy algorithm to provide an approximate solution  section 1 . additionally  we exploit the presence of redundant information in the interface to further prune the set of options presented to the user.
p 1p 1ndcg 1mapwhat is the effect of turkish river control projects on iraqi water resources 1 1 1 1 1 1 1 1 1
11 1 1 1 1 1 1 1 1
11 1 1 1 1 1 1 1 1
11 1 1 1 1 1 1 1 1
1h
o
o
o
o
o
o
o
o
oturkey's south east anatolian project  1 : water supply a thorny issue - downstream neighbours resent turkey's control... channel under the embankment. on that occasion  marked by the presence of president turgut ozal  turkish engineers staunched the euphrates for a period of 1 days  trapping the water behind the dam for future irrigation and power generation. syria and iraq  turkey's downstream neighbours  both protested.turkey river iraq resource water turkey iraq river water turkey river iraq water river project water turkey river iraq project water river resource water turkey iraq control turkey river iraq turkey iraq watertable 1: the top ten sub-queries presented for the description portion of trec topic 1. the original query is provided in the header row. using a tabbed interface  users could select a sub-query and view the associated snippet in a window to the right. in our example  a hypothetical user has selected turkey river iraq resource water  and is shown the associated snippet of text  which turns out to be relevant . clicking on other sub-queries will result in different snippets being loaded in the display area. the corresponding evaluation measures for each option are included in the left hand portion of the table  not part of the interface . in this example three out of ten options had a map better than the baseline of 1.　our previous work on iqr and iqe  involved analyzing all possible combinations of the terms in the long query  sub-queries  or set of terms suggested by prf  expansion sets  to determine the set of top options1 to present to users. such a technique is difficult to realize in practice due to the exponential number of options that need to be analyzed. in section 1 we present a technique based on analyzing the properties of ideal queries  and using those observations to prune the option search space.
　while our techniques helped improve performance of a significantly larger fraction of long queries compared to automatic techniques  there still remained a few queries that were not amenable to either automatic or interactive handling. in section 1 we analyze such queries and categorize the reasons for their failure. we believe this analysis will be useful not only to determine the categories of problems that have been addressed by our techniques  but also to help plan strategies to tackle those that were not.
1.	motivation
1	past approach
　in this section we provide an overview of the interaction technique for long queries that we build on in this paper. the right side of table 1 provides an example of the interface provided to users in response to a long query for iqr. the long query in the example is the description portion of trec topic 1. sub-queries are presented to the user along with a corresponding top-ranking snippet of text retrieved by each of them. which sub-queries to select for display from the available exponential number of choices is based on a technique described in the next paragraph. the tabbed interface allows the user to click on each sub-query  view the associated snippet  and select the most promising one as their new query. the table also contains various performance measures  not shown to the user  that provide an idea of the utility of each sub-query. notice that simple ad-
dition and deletion of terms can produce marked changes in performance. the interface for iqe is similar: the sub-

queries are replaced by subsets of terms  expansion sets  from a set identified using prf.
　to identify top-ranking options we represented each of the 1n options as a graph constructed with the constituent terms as vertices  and the mutual information  between the terms as edge weights. the maximum spanning tree  was identified on each graph  and its weight used to represent the quality of the option. after ranking the entire set of options by the weight of their corresponding maximum spanning trees  the top ten were selected.
　in previous work  we performed user studies that demonstrated that users could use such an interface to select better alternatives  and obtain significant improvements in performance. this performance was also better than that acheived by simply using the title portion of the trec query. since we are improving on that interaction technique  in this paper we will confine ourselves to performing simulated user studies. we hypothesize that improvements such as more efficient background processes  fewer options presented to users  and better quality of options will naturally extend to improving the interaction experience and performance.
　table 1 shows the best performance that can be achieved under various conditions. all results are reported for 1 trec description queries from the robust 1 track. we will treat the description portion of trec queries as long queries for our experiments. baseline refers to a querylikelihood  ql  run using the indri search engine   while prf refers to automatic query expansion using prf1. upper bound  refers to the situation when the best sub-query and best expansion set was used for query reduction and expansion respectively. in other words  if we had access to an oracle that always provided us the best sub-query and best expansion set for a query  we can obtain the indicated upper bound on performance.  interaction upper bound  refers to the upper bound on the performance that can be obtained from user interaction  i.e. the user always selects the best option from the ten presented.

systemp 1p 1ndcg 1mapbaseline  ql 1111prf  best 1111query reductionupper bound  ub 1111interaction ub1111query expansionupper bound  ub 1111interaction ub1111table 1: the utility of iqr and iqe. italicized values indicate that the scores are significantly better than the baseline  while those in bold are significantly better than prf. statistical significance was measured using a paired t-test  with α set to 1.

figure 1: difference in map due to selective iqr and iqe.
1	opportunities
　the results in table 1 for query reduction and expansion show that user interaction can lead to significant improvements in performance for long queries. further improvements can be obtained if we selectively invoke iqr or iqe. figure 1 shows the ordered distribution of the difference between the potential gains due to iqr and iqe. some queries are better suited for iqr  while others can be better improved through iqe. if we can selectively invoke iqr or iqe for each query we can potentially obtain a 1%  from 1 to 1  compared to 1 and 1 for only iqr and only iqe respectively  improvement in map over the baseline. determining when to reduce and when to expand is similar in flavor to the problems of determining when to perform prf  or when to perform stemming : correct answers to either can lead to significant improvements in performance. the tremendous scope for improvement makes the reduce/expand problem worthy of further investigation. we will show in section 1 that we can address this problem through implicit feedback from the user.
　the current interaction paradigm involves always presenting users with ten options for all queries. there is clearly scope for reducing the number of options presented to users  especially when on average only three out of ten of them are better than the baseline. figure 1 is a histogram of the number of options better than the baseline for each of the 1 queries we used for training. clearly  a large fraction

figure 1: distribution of the number of options in the ten presented to users that are better than the baseline query  for a set of 1 training queries.
of the options presented to users have no utility  and can potentially degrade the user experience. in section 1 we present techniques that enable us to reduce the number of options we present to users significantly  without degrading performance.
　iqr and iqe as reported in past work require a large amount of background processing. for query reduction the top ten options have to be selected from an exponential number of candidates since a query of length n has 1n subqueries. similarly  for query expansion  we need to analyze all 1n combinations of expansion terms from the n suggested by prf. such exhaustive exploration of the sub-query space is infeasible in an operational environment. also in section 1 we will present a simple technique based on empirical observations that significantly reduces the search space  without sacrificing performance.
1. selective interactive reduction and expansion  sire 
　tremendous gains in performance can be obtained by selectively expanding or reducing long queries. for each long query  our approach involved selecting the top five sub-queries and top five expansion sets and providing the user a merged list for interaction. the downside of this technique was that we risked losing potentially useful options ranked between six and ten. however  as table 1 shows  this risk was insignificant when compared to the potential for improvement through sire. by viewing this mix of expansion and reduction options  along with a snippet of text to guide selection  the user can implicitly guide the system towards expansion or reduction of the query.
　table 1 summarizes the improvements in performance that can be achieved using the sire technique1. when iqr and iqe are used with five options  the performance is as detailed. however  when the options are combined  sirecomb  

systemp 1p 1ndcg 1mapavg. num. optionsbaseline1111-iqr1.1.1.1.1.1iqe1.1.1.1.1sirecomb11111iqr1.1.1.1.1.1iqe1.1.1.1.1.1table 1: the subscript in the system name indicates the number of options presented to users.
the sirecomb technique involves merging iqr1 and iqe1. for comparison  performance of iqr and iqe with ten options is also provided.
the user can potentially achieve better performance than could be achieved with either iqr or iqe with not only five  but also ten options. if we started with using ten options each from iqr and iqe  we can expect even higher performance improvements. another interesting aspect of the result is that map is significantly improved. iqr is primarily a precision enhancing technique  while iqe is both precision as well as recall enhancing. the advantages of each technique have thus been carried over to the hybrid sire technique in the form of improved map.
1.	minimal option sets
　the technique to analyze the options makes use of cooccurrence information of the constituent terms. while this provides a good sense of the cohesiveness of the option  it does not inform the user of the relative utility of an option with respect to the other ones shown. given that some options differ by just a single term  its quite likely that they might all direct the user to the same search space. in such cases it is wasteful to show similar options  and instead displaying a minimal subset of options that covers the original search space s  might be better. this intuition forms the basis for our technique to prune the original set of options shown to the user. we introduce the set cover problem before going into the details of our technique.
　the set covering problem  is a np-complete optimization problem. an instance  x f  of the set covering problem consists of a finite set x and a family f of subsets of x  such that every element of x belongs to at least one subset in f. mathematically 
	x =   s	 1 
s（f
the subset s is said to cover the elements in x. the goal is to find a minimum-size subset c  c   f  whose members cover all of x i.e.
	x =   s	 1 
s（c
　since finding the exact solution is np-complete  we used a greedy set cover algorithm  that works by selecting the subset that covers the most number of elements in x in an iterative fashion. the advantage of using the greedy algorithm is that it not only runs in time polynomial in |x| and |f| but also returns a  ln |x|  + 1  approximation to the solution.
1	overlapping search results
　we now show how the problem of finding minimal option sets can be cast as a set cover problem. each option is used as a query to retrieve a set of ten documents. let x be the union of sets of ten documents retrieved. the sets of ten documents correspond to the family f of subsets whose union is x. our goal is to identify a minimal set of subsets c from f that cover x.
　table 1 shows the impact on performance metrics as well as the number of options presented to users due to the various techniques. we can observe in the case of  set-coverbased pruning for iqr that for an average decrease of two options per query  there is no  statistically  significant drop in performance. in the case of iqe  it is drastic: an average reduction of six options per query without significant performance loss. this result for iqe can be understood by considering the fact that query expansion results in a much longer query than the original  and the subtle differences between options  usually by a term or two  do not lead to radically different sets of documents being retrieved. the results for sire show that the pruning strategy works for it too  and performance comparable to iqr is achievable by showing 1% fewer options. in summary  judging by the insignificant drops in performance  we successfully retained the useful options and removed the redundant ones.
1	identical snippets
　the user is guided in making a decision on which option to select using a snippet of text. this snippet is extracted from the top-ranking document that is retrieved when the option is used as a query. frequently  the snippets returned by different options are the same  making the task of selecting an option difficult. retaining a single option from the set that retrieves the same snippet can further decrease the number of options presented to users. the results for  snippet-based pruning in table 1 show the impact of this pruning strategy. with the exception of p 1 for iqe  this strategy results in an average reduction of approximately one option without significantly impacting performance.
1.	option analysis
　a good query is long enough to describe key concepts but also short enough to avoid containing unnecessary terms. to determine the appropriate length of sub-queries  we plotted the distribution of the query lengths of the best performing sub-query for each query in our training set. figure 1 shows the distribution  and compares it with the distribution of the lengths of the original queries. we can observe that the best sub-queries are never more than ten terms in length  with most having six or fewer. this observation informed the decision to restrict analysis of sub-queries to those of length less than or equal to six. table 1 shows the impact on  interaction upper bound performance due to this restriction. the restriction not only results in a reduced number of sub-queries analyzed but also maintains the potential for improvement through iqr.
systemp 1p 1ndcg 1mapavg. # optionsbaseline  ql 1111-interactive query reduction  iqr interaction upper bound11111set cover-based pruning11111snippet-based pruning11111interactive query expansion  iqe interaction upper bound11111set cover-based pruning11111snippet-based pruning11111selective interactive reduction and expansion  sire interaction upper bound11111set cover-based pruning11111snippet-based pruning11111table 1: effect of option-pruning strategies on performance metrics  and number of options presented to　in a similar fashion  we analyzed the size of the best expansion subset for our training queries  figure 1 . we can observe that the best expansion sets are frequently between eight to twelve terms in length. this observation again informed the decision to restrict analysis of expansion sets to those of length less than or equal to twelve. the section for iqe in table 1 conveys that this restriction actually helped users.

1 
1 1 1 1 1 1 1 1 1 1 1 1 1
query lengths
figure 1: distribution of lengths of original and best reduced queries

figure 1: length distribution of best expansion sets
systemp 1p 1ndcg 1mapinteractive query reduction  iqr interaction ub1111interaction ub with size threshold1111interactive query expansion  iqe interaction ub1111interaction ub with size threshold1111table 1: effect of thresholding the lengths of options analyzed. ub refers to upper bound.
avoid some bad options  and raised the potential for improvement through iqe.
1.	experimental setup
　we used version 1 of the indri search engine  developed as part of the lemur1 project. we used the query-likelihood variant of statistical language modeling as our baseline  and used the prf mechanism based on relevance models  to generate terms for iqe.
　as our data sets we used the trec robust 1  robust 1   trec 1 ad-hoc  and hard 1  document collections. the 1 robust collection contains around half a million documents from the financial times  the federal register  the la times  and fbis. the robust 1 collection is the one-million document aquaint collection. the choice of robust tracks was motivated by the fact that the associated queries were known to be difficult  and conventional ir techniques were known to fail for a number of them. the trec 1 ad-hoc collection consists of trec disks 1 and 1  and presented a standard ad-hoc retrieval setting. the hard 1 collection  a subset of the aquaint corpus and us government corpus containing 1 documents in all  was also selected since it was created for a track with focus on user interaction. the fifty queries in the robust 1 data set overlap with those in the robust 1 data set we used for training. however  since the collections are different  we do not stand the risk of over-fitting. the hard data set uses the same collection as the robust 1

data set  but has a different set of fifty queries. finally  the trec 1 data set shares neither the queries nor the collection with the robust 1 data set. we believe that this choice of test data sets will provide a comprehensive validation of our techniques. all collections were stemmed using the krovetz stemmer provided as part of indri. 1 queries from the trec robust 1 track were used to study the impact of the various techniques presented in this paper  and to learn parameters used for thresholding. the remaining 1 queries  1 each from the three remaining tracks  were used to test the generality of our techniques.
　al-maskari et al.  have shown that measures based on cumulative gain  and precision correlate well with users' satisfaction of the results. for all systems  we report precision at five documents  p 1   precision at ten documents  p 1   normalized discounted cumulative gain at 1 documents  ndcg 1  as defined in    and mean average precision  map .
1.	results and analysis
　in this section we analyze the effect of using our techniques on different data sets  the results of which are presented in table 1.
　for all collections we notice trends similar to that observed for the robust 1 data set namely the higher performance of the sire system compared to iqr and iqe with not only five options but also ten. sire remains competitive or better even after option pruning: with an average of six options it meets or beats ten-option iqr and iqe.
　we now analyze the performance of iqr  iqe  and sire with respect to the baseline  automatic  system. figure 1 shows the scatter plots of the map values of the baseline system with respect to each of the interactive techniques  for 1 robust 1 queries. the line y = x is included to identify the queries that were improved or hurt by each technique. a point above the y = x line means that performance was improved through interaction  while a point below the line means that interactive retrieval did not help the query. we can observe that a larger fraction of queries was improved by iqr  figure 1 a   in comparison to iqe  figure 1 b  . the plot for iqe  figure 1 b   has greater spread  and higher density in the upper left hand corner compared to iqr. this means that when iqe helps  it helps to a greater extent than iqr. however overall improvements are mitigated by the fact that iqe performs worse on already poorly performing queries. the sire system combines the best of iqr and iqe. not only are there fewer queries below the y = x line  but the density in the upper left hand corner is greater. these observations mean that sire provides a more comprehensive improvement over a set of queries.
　we now turn our attention to the lower left hand corner of figure 1 c  - the area containing the set of queries that were not only poorly-performing to start with  but also were unaffected by iqr  iqe  and sire. we define poorlyperforming queries as those that had a baseline  iqr  iqe  and sire map of less than or equal to 1. we analyzed each of the 1 such queries  and also the corresponding best reduced and expanded versions that were used to generate the  upper bound  scores in table 1. for situations when the best reduced and expanded queries were themselves lowperforming  it was clear that the user would have to enter a completely new query. table 1 summarizes the failure categories we identified and suggests directions for future

 a  baseline versus iqr

 b  baseline versus iqe

 c  baseline versus sire
figure 1: scatter plots of baseline performance  map  and performance due to iqr  iqe  and sire. iqr and iqe used ten options  while sire used a combination of five options from each of iqr and iqe
analysis#
queriesterm mismatch: new query required1corpussystemp 1p 1ndcg 1mapavg. # optionsrobust 1baseline1111-iqr with 1 options iqe with 1 options1
11
11
11
11
1sire with combined options
sire with set cover-based pruning1
11
11
11
11
1sire with snippet-based pruning11111iqr with 1 options11111iqe with 1 options11111hard 1baseline1111-iqr with 1 options iqe with 1 options1
11
11
11
11
1sire with combined options
sire with set cover-based pruning1
11
11
11
11
1sire with snippet-based pruning11111iqr with 1 options11111iqe with 1 options11111trec 1baseline1111-iqr with 1 options iqe with 1 options1
11
11
11
11
1sire with combined options
sire with set cover-based pruning1 11 11 11
11 1sire with snippet-based pruning11111iqr with 1 options11111iqe with 1 options11111table 1: summary of the results of using the sire and option-pruning techniques on test data sets.system failure in identifying sub-query
  best sub-query incomprehensible to human	1
  human could have identified it	1
  nlp techniques could have helped	1

table 1: breakdown of the analysis of lowperforming queries. by nlp techniques  we refer to identification of phrases in the query and treating them as a unit.
work.  system failure in identifying sub-query  or expansion set   refers to the situation when a better option was available  but the technique we used to rank the options failed to place it in the top 1. of these  1 of the options were of the type that a user with a similar information need could be expected to issue. another 1  1  of them would have been difficult for a human to come up with without a complete understanding of how the underlying search engine works. for the 1 queries for which nlp techniques would have worked  we expect that identifying noun phrases in the original query would have helped.
1.	related work
　irrespective of the environment  most user studies  1  1  have reported improvements in performance from user interaction. various studies  1  1  also acknowledge the importance of good interfaces and decision support mechanisms to realize the potential of user interaction. our work continues along this line and shows that given the right interactive technique and support mechanism  user interaction can provide great mileage.
　an earlier exploration involving the user in iqe was carried out by harman . positive user experiences were observed. magennis and van rijsbergen  extended these investigations to simulated experiments on a larger scale. the idea of expanding the original query with sub-sets of predetermined length from the expansion term set is similar to ours  though the motivation was to find an upper bound on performance. ruthven  extended this idea further by examining various query expansion techniques and performing user studies to compare iqr and iqe. his experiments showed that while there is potential for improvement through iqe  realizing the potential in practice is dependent on a number of limiting factors. salton and lesk  showed that user selection of expansion terms did not do as well as just having the system expand automatically. they reasoned that users did not know enough about how the ir system worked to do effective prediction. this problem can however be solved by showing users a preview of the information retrieved by each selection  as is the case in the interaction technique we developed  table 1   . we explored the idea of trying to find the appropriate query terms from a long description of a user's information need  and showed that automatic techniques supplemented by user interaction can deliver significant improvements in performance .
　numerous efforts have been made towards finding techniques for predicting query quality. accurately predicting when a query would fail  can be used to attempt an alternate technique like prf. cronen-townsend et al.  developed the clarity measure to serve as a predictive measure for tracking map. he and ounis  explored a number of features derived from the query to determine query effectiveness. recent work by carmel et al.  attempted to formalize the query difficulty problem. we have tackled a variant of the problem  namely determining if iqr or iqe is better suited for a query.
　harman and buckley  conducted a workshop to identify the reasons why search engines fail. they analyzed the performance and outputs of multiple participating sites and identified ten reasons for failure of information retrieval systems on trec description queries. while the categories we report are not identical to theirs  we plan on expanding our current limited analysis to determine the categories of problems they found that our techniques helped solve.
1.	conclusions
　we have presented techniques to improve the effectiveness and efficiency of user interaction for information retrieval using long queries. the sire technique has been shown to be an extremely effective way to capitalize on the strengths of the iqr and iqe techniques. presenting users with the right number of options is an often-ignored aspect of interactive information retrieval. we have developed a sound framework for identifying a minimal set of options  and demonstrated that this technique retains good options and removes the redundant ones. we hypothesize that this technique  which can be used in any interactive environment  will enhance effectiveness by reducing the cognitive load on users. the exponential-sized analysis of options has been shown to be unnecessary  and reduced to polynomial-sized analysis without degrading performance. the ease with which the analysis process can be parallelized  different machines can analyze options of different lengths and follow up with a merge  and reduction in the complexity can pave the way for live deployment of the effective interaction techniques we have presented in this paper.
　some directions for future work include parsing long queries using nlp techniques to support user interaction. while the option analysis procedure doesn't involve any querying of the index  the option-pruning procedure requires querying the index to obtain top-ranked documents. a better technique to approximate the top-ranking documents will make the process more efficient. iqr results in a concise version of the long query that is potentially better. in future work we plan to explore using the query identified thorough iqr as a starting point for either automatic or interactive query expansion. this two-stage interaction could potentially improve effectiveness even further.
acknowledgments
we wish to thank the anonymous reviewers of this paper for their very helpful comments. this work was supported in part by the center for intelligent information retrieval and in part by the defense advanced research projects agency  darpa  under contract number hr1-c-1. any opinions  findings and conclusions or recommendations expressed in this material are the authors' and do not necessarily reflect those of the sponsor.
