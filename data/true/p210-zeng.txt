organizing web search results into clusters facilitates users' quick browsing through search results. traditional clustering techniques are inadequate since they don't generate clusters with highly readable names. in this paper  we reformalize the clustering problem as a salient phrase ranking problem. given a query and the ranked list of documents  typically a list of titles and snippets  returned by a certain web search engine  our method first extracts and ranks salient phrases as candidate cluster names  based on a regression model learned from human labeled training data. the documents are assigned to relevant salient phrases to form candidate clusters  and the final clusters are generated by merging these candidate clusters. experimental results verify our method's feasibility and effectiveness. 
categories and subject descriptors 
h.1  information storage and retrieval : information search and retrieval - search process  clustering  selection process; g.1 
 probability and statistics : correlation and regression analysis 
general terms 
algorithms  experimentation 
keywords 
search result organization  document clustering  regression analysis 
1. introduction 
existing search engines such as google   yahoo  and msn  often return a long list of search results  ranked by their relevancies to the given query. web users have to go through the list and examine the titles and  short  snippets sequentially to identify their required results. this is a time consuming task when multiple sub-topics of the given query are mixed together. for example  when a user submits query  jaguar  into google and wants to get search results related to  big cats   s/he should go to the 1th  1th  1nd and 1st results.  
a possible solution to this problem is to  online  cluster search 
 
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  or republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee. 
sigir'1  july 1  1  sheffield  south yorkshire  uk. 
copyright 1 acm 1-1/1...$1. 
jwma math.pku.edu.cn
results into different groups  and to enable users to identify their required group at a glance. hearst and pedersen  showed that relevant documents tend to be more similar to each other  thus the clustering of similar search results helps users find relevant results. in the above example for query  jaguar   if there is a group named  big cats   the four relevant results will be ranked high in the corresponding list  as shown in figure 1 . several previous works  are conducted to develop effective and efficient clustering technology for search result organization. in addition  vivisimo  is a real demonstration of this technique. 
	jaguar 	1. jaguar - woodland park zoo animal facts 
features classification and range of the jaguar. learn about their life 
  jaguar cars  1  	cycle  diet  reproduction and habitat  view picture. 
http://www.zoo.org/educate/fact sheets/jaguar/jaguar.htm 
  panthera onca  1  	 
  mac os  1  	1powerful feline is the only roaring . wild ones  the - jaguar cat in the americas. learn about its 
  big cats  1  	behavior  diet  and habitat. 
  clubs  1  	http://www.thewildones.org/animals/jaguar.html  
  others  1  	1. thinkquest - the wild habitat  jaguar 
along with a photo of this striking animal  this profile discusses physical characteristics  hunting  feeding  and reproductive behavior. http://library.thinkquest.org/1/jaguar any.html 
 
1. big cats on-line 
learn about the better and lesser known wild cats. with facts and figures  a glossary  information about conservation  and a family tree. http://dialspace.dial.pipex.com/agarman 
 
figure 1. an example of search result clustering 
clustering methods don't require pre-defined categories as in classification methods. thus  they are more adaptive for various queries. nevertheless  clustering methods are more challenging than classification methods because they are conducted in a fully unsupervised way. moreover  most traditional clustering algorithms cannot be directly used for search result clustering  because of some practical issues. zamir and etzioni  gave a good analysis on these issues. for example  the algorithm should take the document snippets instead of the whole documents as input  since the downloading of original documents is time-consuming; the clustering algorithm should be fast enough for online calculation; and the generated clusters should have readable descriptions for quick browsing by users  etc. we also follow these requirements to design our algorithm. 
in this paper  we reformalize the search result clustering problem as a salient phrases ranking problem. thus we convert an unsupervised clustering problem to a supervised learning problem. although a supervised learning method requires additional training data  it enhances the performance of search result grouping significantly  and enables us to evaluate it accurately. given a query and the ranked list of search results  our method first parses the whole list of titles and snippets  extracts all possible phrases  n-grams  from the contents  and calculates several properties for each phrase such as phrase frequencies  document frequencies  phrase length  etc. a regression model learned from previous training data is then applied to combine these properties into a single salience score. the phrases are ranked according to the salience score  and the top-ranked phrases are taken as salient phrases. the salient phrases are in fact names of candidate clusters  which are further merged according to their corresponding documents. 
our method is more suitable for web search result clustering because we emphasize the efficiency of identifying relevant clusters for web users. it generates shorter  and thus hopefully more readable  cluster names  which enable users to quickly identify the topics of a specified cluster. furthermore  the clusters are ranked according to their salience scores  thus the more likely clusters required by users are ranked higher. 
the paper is organized as follows. some related works are introduced in section 1. the problem is defined in section 1  together with the whole algorithm described. in section 1  we enumerate several properties for salient phrase ranking. the learning techniques that combine these properties are described in section 1. the evaluations and clustering result examples are presented in section 1. finally we conclude the paper and give some future works in section 1. 
1. related works 
the problem of clustering search results has been investigated in a number of previous works. some of them  e.g.   apply traditional clustering algorithms which first cluster documents into topically-coherent groups according to content similarity  and generate descriptive summaries for clusters. however  these summaries are often unreadable  which make it difficult for web users to identify relevant clusters. zamir and etzioni  presented a suffix tree clustering  stc  which first identifies sets of documents that share common phrases  and then create clusters according to these phrases. our candidate phrase extraction process is similar to stc but we further calculate several important properties to identify salient phrases  and utilize learning methods to rank these salient phrases.  
some topic finding  or text trend analysis  works are also related to our method. the difference is that we are given titles and short snippets rather than whole documents. meanwhile  we train regression model for the ranking of cluster names  which is closely related to the efficiency of users' browsing. 
1. problem formalization and algorithm 
we convert the unsupervised clustering problem into a supervised ranking problem. more precisely  we are given the original ranked list of search result r={r di|q }  where q is current query  di is a document  and r is some  unknown  function which calculates the probability that di is relevant to q. traditional clustering techniques attempt to find a set of topic-coherent clusters c according to query q. each cluster is associated with a new document list  according to the probability that di is relevant to both q and current cluster: 
 	c = {rj}  where rj = {r di|q  rj } 	 1  
in contrast  our method seeks to find a ranked list of clusters c'  with each cluster associated with a cluster name as well as a new ranked list of documents: 
 	c' = {r' ck  rk|q }  where rk = {r di|q  ck } 	 1  
as shown in eq. 1 and eq. 1  we modify the definition of clusters by adding cluster names ck  and emphasize the ranking of them by function r'. since we eliminate the requirement of topic-coherence of clusters  the complexity of the algorithm is lowered down. the non-topic-coherence isn't supposed to be a drawback of our method because it doesn't affect the efficiency of users' browsing behavior. 
our algorithm is composed of the four steps: 
1. search result fetching  
1. document parsing and phrase property calculation  
1. salient phrase ranking  and 
1. post-processing. 
we first get the webpages of search result lists returned by a certain web search engine. these webpages are analyzed by an html parser and the result items are extracted. generally  there are only titles and query-dependent snippets available in each result item. we assume these contents are informative enough because most search engines are well designed to facilitate users' relevance judgment only by the title and snippet  thus it is able to present the most relevant contents for a given query. each extracted phrase is in fact the name of a candidate cluster  which corresponds to a set of documents that contain the phrase. meanwhile  several properties for each distinct phrase are calculated during the parsing. these properties are described in detail in section 1.  
in the parsing  titles and snippets can be weighted differently  since there is generally a higher probability that salient phrases occur in titles. we apply stemming to each word using porter's algorithm. the stop words are included in n-gram generation  so that they could be shown when they are adjacent to meaningful keywords in cluster names. in the post-processing  we filter out pure stop words. for the same reason  the query words themselves are also included in the parsing but are filtered out in the postprocessing. 
given the properties  we utilize a regression model  as described in section 1   which is learned from previous training data  to combine these properties into a single salience score. the salience phrases are then ranked by the score in descending order. after salient phrases are ranked  the corresponding document lists constitute the candidate clusters  with the salient phrases being cluster names.  
in the post-processing  the phrases that contain only stop words or the query words are filtered out. we then merge the clusters and phrases  to reduce duplicated clusters. specifically  if the overlapped part of two clusters exceeds a certain threshold  in our experiment  we use 1% as the threshold   they are merged into one cluster. meanwhile  the cluster names are adjusted according to the new generated cluster. finally  the topmost clusters are shown to user.  
when a user selects a cluster  the corresponding document list is shown to the user  with both query words and salient phrases highlighted. this document list could be in the original order  or be re-ranked according to the associated salient phrase. 
1. salient phrases extraction 
in this section  we list the five properties which are calculated during the document parsing. these properties are supposed to be relative to the salience score of phrases. in the following  we denote the current phrase  an n-gram  as w  and the set of documents that contains w as d w . 
phrase frequency / inverted document frequency 
this property is calculated just as the traditional meaning of term frequency / inverted document frequency  tfidf . 
 	tfidf = f  w  log	n	 	 1  
d w 
where f represents frequency calculation.  
intuitively  more frequent phrases are more likely to be better candidates of salient phrases; while phrases with higher document frequency might be less informative to represent a distinct topic.  
phrase length 
the phrase length  denoted by len  property is simply the count of words in a phrase. for example  len  big  =1 and len  big cats  =1. generally  a longer name is preferred for users' browsing. 
 	len = n 	 1  
intra-cluster similarity 
intuitively  if a phrase is a good representation of a single topic  the documents which contain the phrase will be similar to each other. we use intra-cluster similarity  ics  to measure the content compactness of documents contain the phrase. first  we convert documents into vectors in the vector space model: di= xi1  xi1  ... . each component of the vectors represents a distinct unigram and is weighted by tfidf of this uni-gram. for each candidate cluster  we then calculate its centroid as: 
 	 o =	1 ¡Ædi 
d w  di ¡Êd w 
ics is calculated as the average cosine similarity between the documents and the centroid. 
 	ics =	1 ¡Æcos di o  	 1  
d w  di ¡Êd w 
cluster entropy 
for given phrase w  the corresponding document set d w  might overlaps with other d wi  where wi¡Ùw. at one extreme  if d w  is evenly distributed in d wi   w might be a too general phrase to be a good salient phrase. at the other extreme  if d w  seldom overlaps with d wi   w may have some distinct meaning. take query  jaguar  as an example   big cats  seldom co-occur with other salient keywords such as  car    mac os   etc. therefore the corresponding documents may constitute a distinct topic. however   clubs  is a more general keyword which may co-occur with both  car  and  mac os   thus it should have less salience score. 
we use cluster entropy  ce  to represent the distinctness of a phrase. 
 	 ce = ¡Æ d w ¡Éd t  log d w ¡É d t  	 1  t	d w 	d w 
where it is defined that 1 log1. 
phrase independence 
according to   a phrase is independent when the entropy of its context is high  i.e. the left and right contexts are random enough . we use ind to measure the independence of phrases. the following is the equation for indl which is independence value for left context  where 1 log1 is also defined. in our experiment  we only consider one adjacent keyword as context. 
 	indl =  ¡Æ f  t  log f  t  
	t=l w   tf	tf
the indr value for right context could be calculated similarly. the final ind value is the average of those two. 
 	ind = indl + indr 	 1  
1
1. learning to rank salient phrases 
given the above five properties  we could use a single formula to combine them and calculate a single salience score for each phrase. however  this might be too heuristic to adapt to different domains. instead  we utilize training data to learn a regression model.  
regression is a classic statistical problem which tries to determine the relationship between two random variables x =  x1  x1  ...  xp  and y. in our case  independent variable x can be just the vector of the five properties described in section 1: x =  tfidf  len  ics  ce  ind   and dependent y can be any real-valued score. we use y to sort salient keywords in a descending order  thus the most salient keywords are shown on the top. 
several regression models could be used  such as linear regression  logistic regression  and support vector regression . we summarize them in the below and will further compare their effectiveness in the experiments.  
linear regression 
linear regression attempts to explain the relationship of x and y with a straight line fit to the data. the linear regression model postulates that: 
p
 	y=b1 +¡Æbjxj +e 	 1  
j=1
where the  residual  e is a random variable with mean zero. the coefficients bj  1 ¡Ü j ¡Ü p  are determined by the condition that the sum of the square residuals is as small as possible. therefore the linear combination with bj should be better than those with any other coefficients. the variables xj can come directly from inputs  or some transformations  such as log or polynomial  of inputs. 
logistic regression 
when the dependent variable y is a dichotomy  logistic regression is more suitable because what we want to predict is not a precise numerical value of a dependent variable  but rather the probability that it is 1 rather than 1   q = p y=1   .  
logistic regression attempts to find coefficients bj  1 ¡Ü j ¡Ü p  to fit x to a logistic transformation of the probability  which is also called logit.  
 	logit   q = log q = +b1 ¡Æp b xj	j +e  	 1  1 q	j=1
whereas q can only range from 1 to 1  logit q  ranges from negative infinity to positive infinity.  
instead of using a least-squared deviations criterion for the best fit  logistic regression uses a maximum likelihood method  which maximizes the probability of getting the observed results given the regression coefficients.  
support vector regression 
in support vector regression  the input x is first mapped onto a high dimensional feature space using some nonlinear mapping  and then a linear model is constructed in this feature space. support vector regression uses a new type of loss function called ¦Å-insensitive loss function:  
 l¦Å y  f  x ¦Ø   =   y   f  x1 ¦Ø  ¦Å if yotherwise  f  x ¦Ø ¡Ü¦Å 	 1  
support vector regression tries to minimize ||¦Ø||1. this can be described by introducing  non-negative  slack variables ¦Îi  ¦Îi*  i=1 ... n  to measure the deviation of training samples outside ¦Åinsensitive zone. thus support vector regression is formalized as minimization of the following functional: 
         n  	min   ||¦Ø||1 +c¡Æ ¦Îi +¦Îi*  
i=1
 yi 
 	s.t.  f  xi  ¦Ø    yi ¡Ü¦Å+¦Îi 	 1  
 
  ... n
this optimization problem can be transformed into the dual problem and so that non-linear kernel functions could be used to do non-linear regression.  
1. experiments 
we conduct several experiments to validate the effectiveness of the proposed properties and learning methods.  
1 experiment setup 
a real search result clustering system is designed  as shown in figure 1. the system accepts query inputs from users and pass them to one of the following search engines: google  msn  and altavista  but in our experiments  only msn is used . the default result numbers are set to 1. this system is used for both training data collection and algorithm evaluation. 
in the parsing  we extract all n-grams from the documents where n ¡Ü 1  and the phrases with frequency no greater than 1 times are considered as noise and are filtered out. 
we use svm-light  and set the option  -z r  to do support vector regression. in all the support regression experiments  the parameters c and ¦Å  are set to default. 
1.1 evaluation measure 
traditional clustering algorithm is difficult to be evaluated  but in our method  evaluation is relatively easy because the problem is defined to be a ranking problem. thus we could use classical evaluation method in information retrieval. 
we use precision  p  at top n results to measure the performance: 
 	p  n= | c¡Ér | 	 1    
| r |
where r is the set of top n salient keywords returned by our system  and c is the set of manually tagged correct salient keywords. in most our experiments  we use p 1  p 1 and p 1 for evaluation. 
1.1 training data collection 
we asked 1 human evaluators to label ground truth data for 1 queries. the 1 queries are selected from one day's query log from msn search engine. we specially select three types of queries: ambiguous queries  entity names and general terms  since these queries are more likely to contain multiple sub-topics and will benefit more from clustering search results. all the 1 queries are listed in table 1.  
table 1. thirty queries selected from query log 
type queries ambiguous queries jaguar  apple  saturn  jobs  jordan  tiger  trec  ups  quotes  matrix entity names susan dumais  clinton  iraq  dell  disney  world war 1  ford  general terms health  yellow pages  maps  flower  music  chat  games  radio  jokes  graphic design  resume  time zones  travel  
for each query  we extract all the n-grams  n¡Ü1  from the search results as candidate phrases  order them alphabetically  and show them to the evaluators. there are more than one hundred candidate phrases for each query. the three evaluators are asked to first browse through all search results returned by our system  and then select from the candidates 1  good phrases   assign score 1 to them  and 1  medium phrases   assign score 1 to them . the scores of other phrases are zero. the agreements of the 1 evaluators are high for good phrases. for example  in all the good phrases for query  jaguar   1 phrases are selected by all 1 evaluators  1 are selected by 1 evaluators and other 1 are selected by only 1 evaluator. but for medium phrases the agreements are much lower.  
finally  we add the three scores together and assign 1 to the y values of phrases with score greater than 1  and assign 1 to the y values of others. the average ratio of the positive examples  whose y values are 1  is about 1. take  jaguar  as example again  there are totally 1 examples  in which 1 are positive examples. we only assign 1 or 1 to the y values to facilitate the comparison of 1 regression models  but it should be noted that the testing output of regression model ranges from 1 to 1 in logistic regression  and ranges from negative infinity to positive infinity in other regressions.  
the manually selected phrases often fail to match against our generated phrases just because of some minor difference. here we store each manually tagged phrase as a sequence of word stems  with stop words removed. generated phrases are processed in the same way before we do exact matching. 
1 experimental results 
we first compare different properties and different learning methods for salient phrases ranking. 
1.1 property comparison 
we first use the each single property described in section 1 to rank phrases  and evaluate the precisions for all the 1 queries. the average precisions at top 1  top 1 and top 1 are shown in figure 1. note that many phrases have the same len value  so tfidf is used as secondary ranking criterion in the evaluation of len.  

  
figure 1. performance for each single property 
from figure 1  we can see that each property doesn't work very well alone  but phrase independence  ind   whose p 1.1%  and tfidf  whose p 1.1%  are better indicators for phrase salience score. it is interesting to note that intra-cluster similarity  ics  is a not a good indicator. the reason might be that documents are composed of short titles and snippets  so that the vector space model-based similarity has large error.  
1.1 learning methods comparison 
we randomly partition the ground-truth data into 1 parts and use three-fold cross validation to evaluate the average performance of linear regression  logistic regression  and support vector regressions. for support vector regression  different kernel functions are used: linear kernel  denoted by sv-l   rbf kernel  denoted by sv-r  and sigmoid tanh kernel  denoted by sv-s . the comparison of the 1 methods is shown in figure 1. 
by using regression  we achieve significant improvement on the precision compared to any single property. for example the p 1 of linear regression is 1%  outperforms about 1% over the best precision when using single property ind. we can also find that the performance of linear regression  p 1.1%   logistic regression  p 1%  and support vector regression with linear kernel  p 1.1%  are almost same. this shows the linearity of our problem. 

 
figure 1. performance comparison for different regression methods 
we write down the coefficients of one of the linear regression models  as follows: 
y =   1  + 1 ¡Á tfidf  
+ 1 ¡Á len  
  1 ¡Á ics  
+ 1 ¡Á ce  
+ 1 ¡Á ind 
in the above equation  each single property is normalized by their corresponding maximal value  so that we could observe which property plays more important role in the linear combination. from the above equation  we can see that the ind  len and tfidf are more important than other properties. the coefficient of intra-cluster similarity  ics  is even negative  which also indicate that the content-based similarity has small impact on the salient phrase ranking.  

 
figure 1. using support vector regression  linear kernel  for various queries 
figure 1 shows individual ranking precision for 1 example queries  where we use the rest of queries as training data. the xaxis is the 1 queries with the average of them at the right-most column. from this figure  we can see that the performance depends heavily on the search results returned by web search engine. for some queries such as  apple  and  jokes   the web search engine results are mainly in a single domain  most results for  apple  are about computer . therefore the vocabularies are relatively limited  and the salient phrases can be extracted precisely. but for queries like  clinton  and  yellow pages   the search engine results contain various vocabularies. the performance for them is relatively low. 
1.1 input document number 
we also use the precision of one query to explain the reason why we use top 1 search results as basic document set  as the experiment result shown in figure 1. it is clear that the three precision measures arrive at peak when the result count equal to 1. although the training set is based on 1 search results  the figure still effectively shows that our algorithm only require a small number of document input to achieve fairly good performance. 

 
figure 1. performance curve along with document number 
1.1 time complexity  coverage and overlap 
we select a query as the example and analyze the time complexity of our algorithm as shown in figure 1  in which the x-axis stands for the number of results returned from original search engine  and the y-axis is the time spent in the whole algorithm  in seconds . the support vector regression is chosen as regression model. we didn't optimize the program code  and the time values in this figure are total processing time  including web page parsing. but we could still observe from this figure that the time complexity is approximately linear. 
figure 1 shows the coverage of clusters generated by our algorithm for 1 queries. the x-axis is the 1 queries with the average of them at the right-most column. we can see from the figure that  in average  the clusters of top 1 salient phrases contain about half of the search results. the results for the other 1 queries are similar  1% and 1% respectively . this might be a drawback of our proposed method  compared to traditional clustering algorithms. we will further refine it in the future by designing more sophisticate cluster merge algorithm. 
figure 1 shows the overlap of the top n clusters. the x-axis is the same 1 queries as figure 1. in average  the overlap of top 1 clusters is about 1%  which means there are about 1 distinct documents in 1 documents. the overlap of top 1 clusters is about 1%  which means there are only 1 distinct documents in 1 documents. 

 
figure 1. time complexity analysis 

 
figure 1. coverage of generated clusters 

 
figure 1. overlap of generated clusters 
1.1 example queries 
we select three queries from three types of queries  i.e.   jaguar  from ambiguous queries   iraq  from entity names and  resume  from general terms. for the three queries  we list the top ten salient phrases and the corresponding top five document titles  as shown in figure 1. for each salient phrase  we also show its occurrence frequency in parenthesis. 
1. conclusion and future works 
we reformalize the search result clustering problem as a supervised salient phrase ranking problem. several properties  as well as several regression models  are proposed to calculate salience score for salient phrase. experimental results demonstrate that we can generate correct clusters with short names  thus hopefully is more readable   thus could improve users' browsing efficiency through search result. 
we will further investigate several problems on search result clustering. first  we will try to extract syntactic features for keywords and phrases to assist the salient phrase ranking. second  current clustering is still a flat clustering method. we believe a hierarchical structure of search results is necessary for more efficient browsing. third  some external taxonomies such as web directories contains much knowledge which is familiar to web users  thus a combination of classification and clustering might be helpful in this application. 
