large tables are often decomposed into smaller pieces called partitions in order to improve query performance and ease the data management. query optimizers rely on both the statistics of the entire table and the statistics of the individual partitions to select a good execution plan for a sql statement. in oracle 1g  we scan the entire table twice  one pass for gathering the table level statistics and the other pass for gathering the partition level statistics. a consequence of this gathering method is that  when the data in some partitions change  not only do we need to scan the changed partitions to gather the partition level statistics  but also we have to scan the entire table again to gather the table level statistics. oracle 1g adopts a one-pass distinct sampling based method which can accurately derive the table level statistics from the partition level statistics. when data change  oracle only re-gathers the statistics for the changed partitions and then derives the table level statistics without touching the unchanged partitions. to the best of our knowledge  although the one-pass distinct sampling has been researched in academia for some years  oracle is the first commercial database that implements the technique. we have performed extensive experiments on both benchmark data and real customer data. our experiments illustrate the this new method is highly accurate and has significantly better performance than the old method used in oracle 1g.
categories and subject descriptors
h.1  information systems : database management
general terms
algorithms  management  performance

 patents have been filed for the techniques discussed in this paper.
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee.
sigmod'1  june 1  1  vancouver  bc  canada.
copyright 1 acm 1-1-1/1 ...$1.
keywords
large databases  partitioned tables  statistics gathering  sampling  synopses
1.	motivations
　the oracle query optimizer uses object and system statistics to choose the best execution plan within the search space it considers. best is relative to a cost model that provides a cost for various database operators such as hash-join. object statistics include information such the number of rows and column distribution in a table. the accuracy of object statistics affects the quality of the execution plan selected by the query optimizer.
　in very large databases  tables are often decomposed into smaller pieces called partitions . for example  suppose a table lineitem contains line item records. a dba can partition the lineitem table on the shipdate column so that line items that are shipped in the same month fall into the same partition. table partitioning was first introduced in oracle 1. partitioning is used to improve the query performance  as well as the availability and manageability of the database.
1	partition statistics and global statistics
　for a partitioned table  oracle maintains statistics at two different levels  partition  called partition statistics  and the entire table  called global statistics . both statistics are important to the oracle query optimizer.
　partition statistics are useful because of a technique called partition pruning. partitioning usually captures the natural decomposition of the data along some business dimension  e.g.  time or location. the queries issued against partitioned tables usually follow this decomposition. for instance  the queries on the lineitem table often contain a restriction on the partitioning column. an example query can be select * from lineitem where shipdate between '1-1' and '1-1' and tax   1. given a query  the oracle query optimizer will eliminate  i.e.  prune  access to the unnecessary partitions based on the restriction. this statement will only access the data in the june 1 partition. partition pruning reduces the volume of data accessed and leads to substantial performance improvement.
　if a query accesses only one partition  the statistics on this particular partition are used to help the optimizer in finding a good execution plan. in the previous example  suppose there is an index on column tax in all partitions. the optimizer relies on partition statistics to estimate the selectivity of predicate tax   1 in the june 1 partition to choose between a table scan and an index access on the partition.
　in contrast  the global statistics are used when a query does not contain a restriction on the partitioning column or the query is pruned down to access more than one partition.
1	old approach and limitations
　for some kind of statistics  we can efficiently and accurately gather them at both partition and global level. these include the number of rows  number of blocks  average row length  number of null values  maximal and minimal values etc. these statistics at the global level can be accurately derived from the partition statistics. for example  the global number of null values in a column is the sum of number of null values in each partition. no separate scan on the table for gathering the global statistics is needed.
　the statistic that is more challenging to gather is the number of distinct values  abbreviated as ndvs . global ndvs cannot be accurately derived from partition ndvs alone. suppose a table has two partitions p1 and p1. column c has 1 and 1 distinct values in p1 and p1 respectively. in the entire table  column c may have any number of distinct values from 1  when domain of c in p1 is a subset of that in p1  to 1  when domain of c in p1 does not intersect with that in p1 . oracle supports aggregating partition ndvs to derive a global ndvs  making assumption of linear distribution of distinct values within each partition. but there is no guarantee about the quality of the derived global ndvs since the linear distribution assumption may not necessarily be true.
　the accuracy of ndvs is crucial for selecting an execution plan  because it is used in the selectivity estimation formula when histograms are not available . therefore  oracle recommends gathering both statistics instead of aggregating the partition statistics to get the global statistics. oracle uses a two-pass statistics gathering approach  one pass for gathering the statistics on each partition and another pass for gathering the global statistics.
　the performance of the two-pass statistics gathering may be acceptable when the size of the table is not very large. however  with the size of the data stored in partitioning tables exceeding a terabyte in many applications nowadays  this approach puts a significant burden on the system. dbas were faced with two choices  either skipping collecting statistics at the global level or reducing the sample size. both of these two solutions trade shorter time to gather the statistics for lower accuracy of statistics. lower accuracy is likely to lead to inaccurate cost estimation which in turn leads to missing a good plan.
1	new approach: synopsis-based statistics
gathering and incremental maintenance
　to solve the scalability issue of statistics gathering on large partitioned tables  we introduced a new method in oracle 1g to gather the statistics. this method is more efficient and more accurate than the previous methods. the method is based on two techniques  namely  approximate ndvs and synopsis aggregation  which are described as follows.
approximate ndvs. for each partition  oracle maintains a new structure called synopsis. during partition statistics gathering  oracle scans the entire partition and stores a sample of distinct values for each column whose ndvs needs to be gathered. in a second phase  oracle derives the ndvs of the columns in the partition from the synopses. we prove that the ndvs computed based on the synopses is highly accurate.
synopsis aggregation. oracle applies an algorithm which aggregates the synopses of all partitions to derive the global ndvs. note that the synopsis aggregation technique is also beneficial to initial statistics gathering on a partitioned table. oracle first scans all partitions to get their partition statistics and then aggregates their statistics to get the global statistics.
　the intuition is that when gathering ndvs at the partition level  we maintain an additional structure called  synopsis . after we have gathered synopses for all partitions  we derive the global ndvs by accessing the synopses only. we will prove mathematically that the global ndvs derived from the synopses is very accurate. this method eliminates the need to scan the table to gather statistics at the global level. it dramatically improves the performance of the statistics gathering process without compromising the accuracy of statistics.
　this new statistics gathering method improves the performance of both initial statistics gathering  i.e.  no previous statistics exist  and the statistics maintenance  i.e.  previous statistics exist but data changes happen . let us first take a look at how the statistics are maintained when we use the old two-pass gathering method. suppose in a partitioned table  the data in m1 partitions is modified as a result of dml statements  update  delete  or insert   the remaining m1 partitions are intact. oracle would need to scan these m1 partitions to refresh their statistics. in addition  the global statistics need to be refreshed. the entire table  including the partitions that have not been changed  will be scanned. overall  we have to scan m1 +  m1 + m1  = 1 + m1 partitions.
　in the same situation  the new synopsis-based method first scans the m1 changed partitions and refreshes their statistics. this is similar to the old method. however  global statistics are derived from the partition statistics instead of scanning the entire table. in contrast to 1 + m1 partitions scanned by the two-pass method  the new synopsisbased method only scan m1 partitions.
　the performance improvement of the new synopsis-based method can be huge in the statistics maintenance scenario. it is quite common that only a single partition  the most recently added partition  in a partitioned table is affected by dml statements. for example  when new data is loaded into table lineitem  partitioned on shipdate  then it will get loaded into the partition corresponding to the current month. furthermore  the data stored in the oldest partitions  referred to as historical data  is likely to be stored on slow devices since it is not modified and is much less accessed than the data in the more recent partitions. this practice is used to reduce storage costs in large databases . this makes the performance gains from using the synopsis-based method to be even more dramatic because it avoids access to the partitions stored on slow devices.
1	contribution of our work
　the synopsis-based method falls into the one-pass distinct sampling category  1  1  1  1  1  of the statistics gathering techniques. to the best of our knowledge  although academic research in one-pass distinct sampling has been done for some years  oracle is the first commercial database that implements these techniques. we have performed extensive experiments on both benchmark data and real customer data. our experiments illustrate the practicability of the synopsis-based method. now we list the merits of the synopsis-based method we have observed:
1. the synopsis-based method is significantly faster thenthe old two-pass method in oracle 1g for both initial statistics gathering and statistics maintenance.
1. the statistics gathered by the synopsis-based methodare highly accurate. the accuracy rate  i.e. 
  is 1% in most cases.
even in the worse case in all of our experiments  the accuracy rate is at high as 1%.
1. the method is well suited for parallelization. the approximate ndvs technique is not limited to gather statistics on a partition. it can be also used to gather statistics on a partitioned table  a non-partitioned table  a portion of a table as well. the synopsis aggregation technique is also not limited to aggregate partition synopses. it can be also used to aggregate synopses from different portions of a table.
1. this method uses a bounded amount of memory. wechoose an appropriate memory size to control the accuracy of the approximate ndvs algorithm.
1. this method can also be used for on-line statisticsmaintenance because of its small memory footprint.
1	roadmap
　in section 1 we describe the related work. we introduce the approximate ndvs and synopsis aggregation techniques in section 1. in section 1  we describe the incremental maintenance process. section 1 describes a series of experiments on both synthetically generated benchmark data  tpc-h and tpc-ds  and real world customer data including both skewed and non skewed data. finally  we conclude in section 1.
1.	related work
　in this section we discuss both the techniques used in commercial database systems and the related research work for computing number of distinct values.
1	statistics gathering in commercial databases
　most of the commercial database systems read rows from the table and count the number of distinct values by performing an expensive aggregate operation. the aggregate operation involves sorting or hashing the input rows. the database systems minimize the resources by performing the aggregation on a subset of rows produced by sampling of the data. the count computed from the sample is then scaled up to represent the entire population. the research work that is foundation of such approaches can be found in  1  1  1  1  1 .
there are two types of sampling as described below.
1. row sampling reads rows without regard to their physical placement on disk. this provides the most random data for estimates  but it can result in reading more data than necessary. for example  a row sample might select one row from each block  requiring a full scan of the table or index.
1. block sampling reads a random sample of blocks and uses all of the rows in those blocks for estimates. this reduces the amount of i/o activity for a given sample size  but it can reduce the randomness of the sample if rows are not randomly distributed on disk. this can affect the quality of the estimate of number of distinct values.
　oracle supports row sampling in version 1 and block sampling in oracle 1i  released in 1 . oracle uses row sampling by default since it gives more accurate statistics even if the data is clustered. starting oracle 1i release 1  1   it uses a technique for automatically determining what an adequate sample size is for estimating the number of distinct values. this is done via an iterative approach. we start with a small sample. for each column which may need a larger sample  we increase the sample size. in the next iteration of sampling  we restrict the information we collect to only those columns which need the larger sample. the determination that a sample size is sufficient is based on statistical analysis. typically columns with very few distinct values or almost unique columns require a small sample size. so this technique maximizes the performance by using small samples when feasible without loosing accuracy.
　microsoft sql server supports block sampling. the default sampling rate is a slow-growing function of the table size  which allows statistics to be gathered relatively quickly even for very large tables . if the sampling causes some objects to have inaccurate statistics  microsoft recommends collecting statistics for those objects manually using 1% sample and leave them untouched by automatic statistics collection .
　starting in version 1  released in 1   ibm db1 supports both row sampling and block sampling . the runstats command  which collects optimizer statistics in db1 uses 1% sampling percentage by default. the automated statistics collection uses sampling techniques .
　teradata  recommends sampling when collecting statistics for very large tables with uniformly distributed data. by default  teradata will begin with a 1% sample. if  after generating statistics for that sample  teradata detects any skewing  it will increase the sample bit by bit to as high as 1%  until it determines that the sample percent is in line with the observed skewing.
1	one-pass distinct sampling
　in this section  we describe a class of sampling techniques for counting ndvs called one-pass distinct sampling. the techniques in this class estimate ndvs in a single pass of read over the table using only a small additional storage  1  1  1  1  1 . we now use the distinct sampling algorithm proposed by gibbons  as an example.
　in gibbons' algorithm  the target table is fully scanned. for each column whose ndvs is interested  gibbons maintains synopses which are a sample of rows. the synopses of a target column c are generated as follows. the sampling procedure is associated with a number called level which is initially 1. for each row that is seen  the value of column c is mapped to a random number. if this random number is no less than the current level  this row is then stored in the synopses. for each distinct value v of column c  up to t rows are stored where each row r satisfies that r.c = v. if the synopses of c have reached the specified capacity  the level is incremented by one. also  those rows whose values of c are mapped to numbers less than the new level are removed from the synopses. this procedure repeats until all the rows in the table have been seem.
　the above distinct sampling procedure ensures two  uniformity . first  a uniform random sample of the distinct values is stored for each target column. that is to say  each distinct value has an equal probability of being included in the sample. second  for each distinct value in the sample  each row containing this distinct value has an equal probability of being included in the sample.
　recently  researchers have also worked on building samples on evolving data sets  1  1  1 . these techniques allow efficient incremental maintenance of samples as data changes. in particular   studies how to derive ndvs after multi-set operations such as union  intersection and difference  are performed on data that is divided into partitions.
　the above work provides the theoretical foundations for one-pass distinct sampling techniques. our work instead focuses on an efficient implementation of the one-pass distinct sampling techniques in a commercial database.
1.	approximate ndvs and synopsis aggregation
　in this section we describe the algorithms  approximate ndvs  and  synopsis aggregation . we describe the approximate ndvs algorithm in section 1. we give probabilistic bounds on its accuracy in section 1. finally  we describe the synopsis aggregation algorithm in section 1.
1	approximate ndvs algorithm
　the approximate ndvs algorithm  like other probabilistic ndvs counting algorithms before it  uses a uniform hash function to map values from the input domain into lists of bits . since the hash function is at the core of the algorithm  we describe it first and then go into the details of the algorithm itself.
1.1	the uniform hash function
　the approximate ndvs algorithm uses a uniform hash function h to map values into a list of bits. suppose the target column in a table contains values a1 ... an where n is the number of rows. some  or even all  of the values may be duplicates. one can use any hash function as long as the following properties are observed:
  for each value ai the function h ai  gives a list of k bits. we denote these bits as hi1 ... hik.  k is a constant chosen for the algorithm. 
  for any j （  1 k   hij has equal probability of being 1 or 1.
  all the bits are independent. this means the value of hij has no dependence on the value of hi＞j＞ unless ai = ai＞ and j = j＞.
　the fact that we only store hash values in our synopses means that we actually estimate the number of distinct values among h a1  ... h an . this number may be lower than the actual number of distinct values in the column. to prevent a large error in the estimate we use a large number of bits in each hash value. for practical purposes we use k = 1.
1.1	the approximate ndvs algorithm
　we now give the algorithm for gathering ndvs on a partition.

algorithm 1 an algorithm for gathering ndvs on a par-
tition

1: s =  
1: d = 1
1: for each column value ai do
1:	hi = hash ai  where hi = hi1 ... hik
1:	while hi1 = ... = hid = 1 and hi 1（ s do
1:	ifthen
1:	+ 1
1:	delete from s all hj such that hjd = 1.
1:	else
1:	add hi to s
1:	end if
1:	end while
1: end for
1: return 1d ， |s|
　in this algorithm  s denotes a set containing up to n hash values. when the algorithm starts  s is empty. d is an integer which is a counterpart of level in gibbon's algorithm. it denotes how many times we divided the domain of hash values we are interested in.
　the algorithm iterates over all values a1 ... an in order. at any point in time  the set s contains all hash values h ai  for values we have seen so far  such that the first d bits in the hash values are 1. this means that we are interested in 1 d of the hash value domain  and the size of s is approximately 1 d of the number of distinct hash values we have seen so far.
　we start with d = 1. whenever s becomes full  exactly n items  and we need to add a new hash value into it  we split s into two parts. we do this by removing from s all hash values that have a value of 1 in the d+1 position. we then increment d by 1.
　in the end  the size of s is the number of distinct hash values we observed from a 1 d portion of the hash value domain. to estimate the total number of distinct values we multiply by 1d.
1	analysis of accuracy
　there are two causes for potential inaccuracy in the approximate ndvs algorithm. one is due to counting hash values instead of actual distinct values. collisions in the hash domain can cause an underestimation of the actual ndvs. we will see that in practice the inaccuracy is insignificant in section 1.1. the other inaccuracy is due to the probabilistic nature of the algorithm. we will see how to choose a proper memory size to get the appropriate accuracy with the appropriate probabilistic confidence in section
1.1.
1.1	accuracy of counting hash values
　first we look at the expected error due to counting hash values instead of the actual values in the column. assuming there were s distinct value in the column and we use k bits for the uniform hash function  we can ask what is the expected number of distinct hash values.
　the domain of hash values has size 1k. each of these possible values has 1   1 k probability for not being the value for a specific value we see in the table. it has  1   1 k s probability of not representing any of the values in the column. the probability that a specific hash value represents a value from the column is 1  1 k s. since we have 1k such hash values  we sum the probabilities for each value to get the expected number of hash values for the column. we get:

we can expand the series as:
!#
s   1 i   i 1 k s   1!#
= 1   1 + s ， 1 k + s ， 1 k x1
	i	i	1
i=1
	s	i
1 
	= s1 +  	1  i 1 k s   1!#
i	i	1 i=1
　note that for our purposes s is much smaller than 1k. we do not expect a table to have more than 1 distinct values in a column so in effect s ， 1 k would be less than
  and usually orders of magnitude smaller. note that
  and for i   1 this becomes
exponentially smaller. therefore  for practical purposes the values of s and  s are almost identical.
　the variance for this distribution is very small even for high values of s. it only gets significant when s gets within two order of magnitudes from 1k  which we do not get in practice for k = 1.
　therefore  we can ignore the potential error caused by counting hash values.
1.1	accuracy of the approximate ndvs algorithm
　assuming no collisions in the hash function  which we showed is a reasonable thing to do  we now show the accuracy of the algorithm for a given memory size n and a number of distinct hash values s.
　there are two main cases. first  suppose s ＋ n. then the algorithm maintains d = 1 and we count the exact number of distinct values.
　second  suppose s   n. then we increment d during the algorithm. each of the distinct hash values we count has probability 1 d of being in the set s  i.e.  having a prefix of at least d 1's in their value . the total number of items in s when the algorithm ends has a binomial distribution with s items and probability 1 d.
　this distribution has mean s，1 d and variance s，1 d 1  1 d . the final results of the algorithm multiplies this by the constant 1d so the result has mean s and variance s ， 1d 1   1 d .
　we can see immediately that the estimate is unbiased  expected value of s . also  we use n that is fairly large  at least 1  so the binomial distribution looks very much like a normal distribution. this means that we have more than 1% confidence that the estimate is within three standard deviations of the true value. we can estimate the error as the ratio of some α standard deviations to the true value s. this gets us:
error
we can replace s by the estimate of s which is at least 1dn/1 and get
error
　for example  for n = 1 we have at most 1% error with about 1% confidence  1% error means that the estimate  s is between 1 and 1 times the true value s   or at most 1% error with over 1% confidence. this corresponds for values of α = 1 and α = 1 respectively.
1	synopsis aggregation
　when running approximate ndvs on a partition  the synopsis of the partition is the structure s accumulated by the algorithm. we aggregate these structures to find the approximate ndvs of the entire table. we call this process the  synopsis aggregation  algorithm. we first make a simple observations on the approximate ndvs algorithm.
1. suppose the input stream for approximate ndvs contained the hash values instead of the original values. then we do not need to apply the hash function  and the algorithm would give the exact same result as if it was running on the original values.
1. suppose the algorithm reaches a specific split level d during its run. suppose further that we run it on the same input  but remove from it some or all values that contain at least one  1  in the first d＞ hash bits  and d＞ ＋ d . since the algorithm discards these hash values anyway when it reaches d＞   1 split level  the result of the algorithm would not be changed.
1. suppose the algorithm reaches a specific split level d during its run. originally  we start with split level 1. however  if we start with any split level d＞ such that d＞ ＋ d we will get the same result.
　we are now ready to describe the synopsis aggregation algorithm. we start with sets of hash values s1 ... sm for m partitions. we run the approximate ndvs algorithm on an input stream that contains all hash values from the sets s1 ... sm. let dmax denote the maximal splitting level among the synopses of all the partitions. we start the synopsis aggregation algorithm with the split level dmax. finally  we make sure that the amount of memory we use is at least as much as the memory we used for the partitions.
　if we use the same memory size for all partitions and the synopsis aggregation algorithm then we get the same result as if we ran approximate ndvs on the entire table  as if it was a single partition   with the same memory size. if we use more memory for the final stage  i.e.  synopsis aggregation  we can potentially increase the accuracy of the algorithm.
1. incremental maintenance of global ndvs
　in this section  we first describe two optimization techniques we have developed to reduce the size of the synopses. these techniques brings two major benefits. first  they reduce the disk space usages by synopses. second  they also reduce synopsis maintenance cost  including the time used to gather the synopses and the time used to aggregate the synopses. we also describe how we use the approximate ndvs and synopsis aggregation techniques introduced in section 1 to incrementally maintain the global ndvs.
1	choosing target columns to maintain synopses
　given a set of columns whose ndvs's are needed  incremental maintenance of a subset of these columns does not give any performance gain. we use a small example to illustrate this. suppose a table has two columns c1 and c1 and we maintain synopses for c1 but not for c1. assume later a partition in this table has been changed. we then need to update the statistics of both c1 and c1. since we do not maintain synopses for c1  we still need to scan all the partitions to gather ndvs for c1. we would not save partition scanning cost compared to not maintaining synopses for any columns at all.
　for this reason  in a naive implementation  we can create synopses for each column in the table. oracle goes one step beyond that. an oracle statistics management module called discovery engine analyzes the workload and discovers those columns whose ndvs's are indeed needed  for example  columns that involve in joins . correspondingly  oracle gathers synopses only for those columns.
1	granularity of synopsis maintenance
　by default  oracle maintains synopses at the granularity of partition level. this means  the synopses of different partitions are managed separately. for example  in figure 1  a   suppose a sales table has four partitions each of which corresponds to a quarter of the year. the synopses of each partition are physically stored on the disk. these partition synopses will be aggregated to get the global ndvs.
　oracle also allows maintenance of synopses at a higher granularity than partition level. oracle does this when only one partition in a partitioned table is active  i.e. updatable . this is quite common for those tables that are partitioned on date. let us consider the sales table in figure 1 again. suppose the current month is november. those partitions on the past quarters will no longer be changed. only the partition containing the sale records in the current quarter will have new entries. for such a table  oracle groups all the partitions that are inactive  i.e.  quarters 1  1 and 1  and maintain synopses for them as if they were one large partition. this can significantly reduce the space required to store synopses and the time required to aggregate synopses.
1	incremental maintenance process
　we now describe the incremental maintenance process when the a statistics gathering command is issued. this process consists of several phases as follows.
　first  the incremental maintenance process finds all the partitions that have undergone data definition language  ddl  changes. oracle supports partition maintenance operations such as adding  dropping  coalescing  merging and

figure 1: grouping synopses of inactive partitions
splitting partitions. the incremental maintenance algorithm views each operation as a sequence of primitive operations such as dropping partitions and adding partitions. for example  splitting a large partition p into smaller partitions p1 and p1 is viewed as dropping a partition p and adding new partitions p1 and p1. for those partitions that have been dropped  the maintenance process deletes all their synopses. for those partitions that have been newly added  the maintenance process gathers their statistics.
　in the second phase  the maintenance process finds all the partitions that have undergone significant data manipulation language  dml  changes. oracle defines a partition as significantly changed if the rows being changed  i.e.  deleted  inserted or updated  are more than 1% of the total rows. the partition changing information can be found out in oracle data dictionaries managed by the dml monitoring module. for all those significantly changed partitions  the maintenance process regathers their statistics.
　after the two phases  all synopses of the partitions are upto-date. if the partition grouping scheme described in section 1 is adopted  the maintenance process goes through an additional phase. in this phase  synopsis aggregation technique is used to generate the synopses at the group level. the synopses at the partition level are then discarded.
　in the final phase  the maintenance process uses the synopsis aggregation technique to derive the global statistics from either the partition level or group level synopses  whichever applicable.
1.	performance studies
　this section presents a performance study of oracle 1g's new method of statistics gathering and incremental maintenance of statistics on partitioned tables. the data set we use includes synthetically generated benchmark data as well as real-world data. we compare the new approach with various old approaches in two aspects. the first aspect is the elapsed time  i.e.  the time needed to gather statistics.
the second aspect is the accuracy of the statistics gathered. we show that our new approach results in accurate column statistics with improved performance.
　the experiments we have run fall into two categories. in the first category  we test the initial statistics gathering time. this illustrates a one-time cost of synopses set up  i.e.  gathering synopses for all target columns. in the second category  we then test the statistics gathering time when changes happen on some partitions. this illustrates the benefits of using incremental maintenance.
1	environment set up
1.1	data sets
　we use three tables for our performance study. the first table is the lineitem table in tpc-h benchmark. the lineitem table exhibits close to uniform distribution. the second table is the storesales table in the tpc-ds benchmark. this table has skewed data. the third table is a real world table privately owned by one of our large customers. we now describe these tables in more details.
1.1	tpc-h lineitem table.
　tpc-h has been widely accepted as the industry standard benchmark for data warehouse applications . its schema consists of eight tables modeling the data warehouse of a typical retail environment. among the eight tables  we use the largest table  i.e.  lineitem  for performance study.
　we use the standard tpc-h data generator  dbgen  to generate the lineitem table. we set the scale factor of the generator to 1. this means that if we were to use this scale factor to generate the entire tpc-h database  the total data size would be approximately 1g. correspondingly  the size of lineitem table that has been generated is about 1g distributed over 1 partitions. the table contains 1 million rows and 1 columns.
1.1	tpc-ds store sales table.
　tpc-ds  1  1   expected to be released this year  is the next generation decision support benchmark developed by the transaction processing performance council. it has multiple snowflake schemas with shared dimensions. it contains 1 tables with an average of 1 columns. its data are more skewed than tpc-h data.
　tpc-ds models the decision support functions of a retail product supplier  which sells goods through three distribution channels  store  catalog  and internet web . the snow flake schema for the store sales channel consists of two fact tables: store sales and store returns. these two fact tables model the sales and return transactions. in our experiment  we used the larger one of these two fact tables  i.e.  store sales.
　the data distribution in store sales mimics the census sales distribution . the data in the table has three comparability zones: 1  january to july; 1  august to october; and 1  november to december. domain values in the first zone occur with a low likelihood in the data set. domain values in the second zone occur with a medium likelihood. domain values in the third zone occur with a high likelihood in the data set. the data generator guarantees that data in the same comparability zone have a uniform distribution.
　we generated a store sales table with the data generator provided by the tpc council. we use a scale factor 1.
the table contains 1 million rows distributed over 1 partitions. each row contains 1 columns. the total table size is 1g.
1.1	real-world customerx table.
　we also experiment on real-world data extracted from the data warehouse belonging to one of the largest financial organizations. we call the table customerx. this table contains records of business transactions. the data distribution is highly skewed. it has 1 columns and 1 million rows in two partitions. only one of the partition is populated. the total size of this table is 1g.
1.1	hardware environment
　we use two machines for our experiments. the first machine is a dell poweredge 1 with quad dual-core 1ghz intel xeon mp. hyper threading is turned on. the storage system is dell power vault 1xs giving us 1 gb/s of aggregated io bandwidth. the operating system is red hat enterprise linux advanced server 1. this machine has 1g memory. this machine is used in all the experiments on the synthetic data.
　the second machine we use is a 1.1ghz intel xeon with hyperthreading simulating 1 cpus. it has 1gb of memory. the operation system is linux red hat release 1. the storage system is an emc clariion cx1 with a 1mb/s io bandwidth. this machine is used in all the experiments on the real-world data.
1	experimental results of initial statistics gathering
　before the introduction of the approximate ndvs technique  oracle used a sampling based statistics gathering technique as described in section 1. the user can specify a sampling percentage for statistics gathering. if a 1% sampling percentage is specified  i.e.  the sample is the table itself  the ndvs gathered is guaranteed to be 1% accurate. generally speaking  the higher the sampling percentage is  the more accurate the statistics are and the longer the statistics gathering time is. if the table is very large and the statistics gathering window is limited  i.e.  the user cannot afford too much time in statistics gathering   oracle recommends 1% sampling percentage.
　in our experimentation charts  we use  approximate ndvs only  and  incremental  to denote our new techniques.  approximate ndvs only  means that we use approximate ndvs technique to gather the partition statistics in one scan of the table and use approximate ndvs to gather the global statistics in the second scan.  incremental  means we use approximate ndvs technique to gather partition statistics in one scan and then use synopsis aggregation technique to derive the global statistics from the partition statistics. note that in our implementation  the amount used for synopsis aggregation is larger than that used for each partition. so we may see a slightly different accuracy rate for  incremental . the exact amount of memory we use for  incremental  is the sum of the memory we use for all the partitions.
　we compare the statistics gathering time and statistics quality using four different methods  i.e.   1% sampling    1% sampling    approximate ndvs only  and  incremental . to measure the statistics quality  we define the accuracy rate of a statistics gathering method as follows:
.
　the higher the accuracy rate is  the more accurate the gathered statistics are. the maximal accuracy rate is 1%.
1.1	synthetic data set results
　we now compare the statics quality of different methods. since 1% sampling always lead to an accuracy rate of 1%  we do not report it. also  for 1 columns in lineitem 
the accuracy rates of the statistics gathered by all four methods are all above 1%. we ignore such columns here. instead we focus on the columns which has at least one statistics accuracy rate below 1%.
　figure 1 shows the quality of the statistics gathered for 1 columns by different methods. for each column  we mark its actual ndvs above its accuracy rates. for example   1 1  above the first group of accuracy rate is the actual ndvs of l order key. we can see that 1% sampling fails to estimate the ndvs of skewed columns such as l orderkey and l comment. the accuracy rates of 1% sampling for these two columns are 1% and 1% respectively. in contrast  both approximate ndvs only and incremental gathering methods generate highly accurate statistics. regardless whether the columns are skewed or not  the accuracy rates of approximate ndvs only and incremental are always above 1%.
　table 1 further gives the elapsed time of gathering statistics on the tpc-h lineitem table by different methods. the elapsed time of  approximate ndvs  is 1 times faster than 1% sampling. the elapsed time of  incremental  is very close to 1% sampling and 1 times faster than 1% sampling.
gathering methodelapsed time  sec 1% sampling1% sampling1approximate ndvs only1incremental1table 1: elapsed time of gathering table statistics on lineitem table
　table 1 reports the process global area memory  pga  usage of gathering statistics on the tpc-h lineitem table by different methods. the pga target is 1 mb  which is the maximal size of the pga memory that can be used. in the sampling methods  the larger the sampling percentage is  the larger the pga usage is. approximate ndvs uses comparable amount of pga as 1% sampling in this experiment. this is because the synopsis size in approximate ndvs is bounded  see section 1.1 . as a result  the memory usage of approximate ndvs is bounded.
gathering methodaverage pga used  mb 1% sampling11% sampling1approximate ndvs only1table 1: process global area  pga  memory usage of gathering table statistics on lineitem table
　we also conduct experiments on tpc-ds store sales table. because we have a large data skew in tpc-ds store sales table   1% sampling  is not able to give us very accurate statistics. in contrast   approximate ndvs only  and  incremental  still deliver very accurate statistics despite the data skew. figure 1 compares the accuracy rate of the statistics gathered for 1 columns by different methods. we ignore 1 columns whose accuracy rates of the statistics gathered by all four methods are all above 1%.
　in figure 1  for each column  we mark its actual ndvs above its accuracy rates. for skewed columns such as ss ext discountamt  the accuracy rate of 1% sampling is as low as 1%. in contrast  the accuracy rates of approximate ndvs only and incremental for all columns are always very close to 1%.
　generally  approximate ndv method performs the same amount of i/o as the sampling method unless in two cases. in the first case  the sampling method uses block sampling  versus row sampling . when block sampling is used  not all blocks are read and thus i/o is reduced. in the second case  the sampling method uses row sampling with an extremely small sampling percentage. the sampling method predicts the block of the next row to be sampled. with a very small sampling percentage  it is possible that the next row to be sampled is a few blocks away from the current row sampled. the sampling method then skips blocks to read the next row. as a result  less i/o may be incurred compared to a full scan. however  in both sampling cases  result accuracy can be heavily impacted and much worse than that of approximate ndv.
1.1	real-world data set results
　figure 1 shows the quality of the statistics gathered for 1 columns by different methods. for each column  we mark its actual ndvs above its accuracy rates. real-world data set of customerx is more skewed than the data of the synthetic benchmark. as a result   1% sampling  leads to much worse accuracy. for example  even for column with low number of distinct values  like c1 whose actual ndvs is 1   the accuracy is only 1%.
　table 1 further reports the elapsed time of gathering table stats on customerx. incremental takes even less time to gather statistics as  1% sampling  while generating much more accurate statistics than  1% sampling .
gathering methodelapsed time  sec 1% sample1% sample1approximate ndvs only1incremental1table 1: elapsed time of gathering table statistics on customerx table
1	performanceresultsofincrementalmaintenance
　it is very common on large data-warehouses to have an initial full load of the database followed by on-line or near on-line modification. in this scenario either only a few partitions  most likely the most recent ones  are updated or new partitions are added. when this happens  statistics needs to be updated to reflect the new data distribution. in this section  we demonstrate the benefits of incremental maintenance of column statistics when we have changes on the partitions both on synthetic and real-world data sets.
　
	1 1 1	1 1 1	1 1

figure 1: accuracy rate of gathering ndvs lineitem using approximate ndvs  incremental and 1% sampling
	1	1	1	1 1 1

figure 1: accuracy rate of gathering ndvs on lineitem using approximate ndvs only  incremental and 1% sampling
	1	1	1	1 1 1

figure 1: accuracy rate of gathering ndvs on customerx using approximate ndvs  incremental and 1% sampling
　
1.1	performance on benchmark data sets
　in this first series of experiments  we used the tpc-h lineitem table. the experimentation process is as follows. first  we turn on the incremental maintenance feature. second  we collect statistics on lineitem table. third  we update a subset of the partition of this table. finally  we gather the statistics on the table using the incremental maintenance feature.
　for each experiment  we vary the number of partitions that are updated. table 1 shows the performance of the final step in various experiments when different numbers of partitions are updated. with incremental statistics maintenance  the elapsed time to gather the statistics scales linearly with the number of partitions updated because we need to regather statistics on these updated partitions. in contrast  the elapsed time of 1% sampling and 1% sampling is not affected by the number of partitions because they scan all partitions  including those that have not been updated  to get the new statistics.
number of par-
titions
updated among
1 partitionselapsed time  sec incremental1% sampling1%
plingsam-1111111111table 1: elapsed time of incremental maintenance
when update occurs on lineitem table
1.1	performance on real-world data set
　recall that the customerx table has two partitions. its second partition is empty. in the following experiment  we repeat the same process as in the experiment in section 1.1  except that we now loading new data in the second partition. after inserting a 1 rows into the empty partition  we measure the elapse time of the statistics maintenance.
　specifically  we run the following for incremental maintenance. first  we turn on the incremental maintenance feature. second  we collect statistics on customerx table once. third  we insert 1 rows into the empty partition. fourth  we collect statistics on customerx table again.
　with incremental maintenance of statistics  only the second partition needs to be scanned. in contrast  without incremental maintenance  the whole table needs to be scanned. the elapsed time saving when using incremental maintenance is huge  as illustrated in table 1.
incrementalelapsed time  sec enabled1disabled1table 1: elapsed time of incremental maintenance when update occurs on customerx table
1.	conclusion
　in this paper we introduced a new approach to statistics gathering for large databases  available in oracle 1g. we explained the techniques underlying the new approach  and demonstrated its superiority to other methods used both in previous releases of oracle and other database systems. its performance is competitive to sampling based methods and its accuracy is close to gathering statistics on the full data set. the new approach is well suited for parallelization and its memory usage is bounded regardless of the data set. the latter makes its well adapted for on-line statistics maintenance since the memory footprint is limited and small. we conducted experiments  using both synthetic and real application data  and showed that the performance and accuracy of the new method are superior to competing methods.
