similarity measures for text have historically been an important tool for solving information retrieval problems. in many interesting settings  however  documents are often closely connected to other documents  as well as other non-textual objects: for instance  email messages are connected to other messages via header information. in this paper we consider extended similarity metrics for documents and other objects embedded in graphs  facilitated via a lazy graph walk. we provide a detailed instantiation of this framework for email data  where content  social networks and a timeline are integrated in a structural graph. the suggested framework is evaluated for two email-related problems: disambiguating names in email documents  and threading. we show that reranking schemes based on the graph-walk similarity measures often outperform baseline methods  and that further improvements can be obtained by use of appropriate learning methods.
categories and subject descriptors
h.1  information search and retrieval : retrieval models  search process
general terms
algorithms  experimentation
keywords
graph-based retrieval  email  name disambiguation  threading
1. introduction
　many tasks in information retrieval can be performed by clever application of textual similarity metrics: in addition to the canonical ir problem of ad hoc retrieval  which is often formulated as the task of finding documents  similar to  a query  textual similarity plays a prominent role in the
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee.
sigir'1  august 1  1  seattle  washington  usa.
copyright 1 acm 1-1/1 ...$1.
literature for diverse tasks such as text categorization   data integration   summarization  and document segmentation .
　in modern ir settings  however  documents are usually not isolated objects: instead  they are frequently connected to other objects  via hyperlinks or meta-data.  an email message  for instance  is connected via header information to other emails and also to the recipient's social network.  thus it is important to understand how text-based document similarity measures can be extended to documents embedded in complex structural settings.
　our similarity metric is based on a lazy graph walk  and is closely related to the well-known pagerank algorithm . pagerank and its variants  e.g.    are based on a graph walk of infinite length with random resets. in a lazy graph walk  there is a fixed probability of halting the walk at each step. in previous work   lazy walks over graphs were used for estimating word dependency distributions: in this case  the graph was one constructed especially for this task  and the edges in the graph represented different flavors of wordto-word similarity. other recent papers have also used walks over graphs for query expansion  1  1 . in these tasks  the walk propagates similarity to a start node through edges in the graph-incidentally accumulating evidence of similarity over multiple connecting paths.
　in contrast to this previous work  we consider schemes for propogating similarity across a graph that naturally models a structured dataset like an email corpus: entities correspond to objects including email addresses and dates   as well as the usual types of documents and terms   and edges correspond to relations like sent-by. we view the similarity metric as a tool for performing search across this structured dataset  in which related entities that are not directly similar to a query can be reached via a multi-step graph walk.
　in this paper  we formulate and evaluate this extended similarity metric. the principal problem we consider is disambiguating personal names in email  which we formulate as the task of retrieving the person most related to a particular name mention. we show that for this task  the graph-based approach improves substantially over plausible baselines. after retrieval  learning can be used to adjust the ranking of retrieved names based on the edges in the paths traversed to find these names  which leads to an additional performance improvement. as a demonstration of generality  we also show performance improvements on a second email-related task-recovering messages from the same email thread. name disambiguation and email threading are particular applications of the suggested general framework  which is also applicable to any real-world setting in which structural data is available as well as text.
　this paper proceeds as follows. sections 1 and 1 formalize the general framework and its instantiation for email. section 1 gives a short summary of the learning approach. section 1 includes experimental evaluation  describing the corpora and results for the person name disambiguation as well as threading tasks. the paper concludes with a review of related work  summary and future directions.
1. email as a graph
　a graph g consists of a set of nodes  and a set of labeled directed edges. nodes will be denoted by letters such as x  y  or z  and we will denote an edge from x to y with label  as. every node x has a type  denoted t x   and we will assume that there is a fixed set of possible types. we will assume for convenience that there are no edges from a node to itself  this assumption can be easily relaxed .
we will use these graphs to represent real-world data.
each node represents some real-world entity  and each edge  asserts that some binary relation   holds. the entity types used here to represent an email corpus are shown in the leftmost column of table 1. they include the traditional types in information retrieval systems  namely file and term. in addition  however  they include the types person  email-address and date. these entities are constructed from a collection of email messages in the obvious way-for example  a recipient of  einat minkov  einat cs.cmu.edu   indicates the existence of a person node  einat minkov  and an email-address node  einat cs.cmu.edu .  we assume here that person names are unique identifiers. 
　the graph edges are directed. we will assume that edge labels determine the source and target node types: i.e.  if  andthen t w  = t x  and t y  = t z .
however  multiple relations can hold between any particular pair of nodes types: for instance  it could be that 
or   where .  for instance  an email message x could be sent-from y  or sent-to y.  note also that edges need not denote functional relations: for a given x and   there may be many distinct nodes y such that. for instance  for a file x  there are many distinct terms y such has-term that x  ★ y holds.
　in representing email  we also create an inverse label for each edge label  relation  . note that this means that the graph will definitely be cyclic. table 1 gives the full set of relations used in our email represention scheme.
1. graph similarity
1 edge weights
　similarity between two nodes is defined by a lazy walk process  and a walk on the graph is controlled by a small set of parameters Θ. to walk away from a node x  one first picks an edge label ; then  given   one picks a node y such that. we assume that the probability of picking the label  depends only on the type t x  of the node x  i.e.  that the outgoing probability from node x of following an edge type  is:

source typeedge typetarget typefilesent-frompersonsent-from-emailemail-addresssent-topersonsent-to-emailemail-addressdate-ofdatehas-subject-termtermhas-termtermpersonsent-from 1filesent-to 1filealiasemail-addressincludes-termtermemail-addresssent-to-email 1filesent-from-email 1filealias 1personis-email 1termtermhas-subject-term 1filehas-term 1fileis-emailemail-addressincludes-term 1persondatedate-of 1filetable 1: graph structure: node and relation types
let sti be the set of possible labels for an edge leaving a node of type ti. we require that the weights over all outgoing edge types given the source node type form a probability distribution  i.e.  that

　in this paper  we will assume that once  is picked  y is chosen uniformly from the set of all y such that. that is  the weight of an edge of type l connecting source node x to node y is:1

this assumption could easily be generalized  however: for instance  for the type t x  = file and  = has-term  weights for terms y such thatmight be distributed according to an appropriate language model .
1 graph walks
　conceptually  the edge weights above define the probability of moving from a node x to some other node y. at each step in a lazy graph walk  there is also some probability γ of staying at x. putting these together  and denoting by mxy the probability of being at node y at time t + 1 given that one is at x at time t in the walk  we define

m
if we associate nodes with integers  and make m a matrix indexed by nodes  then a walk of k steps can then be defined by matrix multiplication: specifically  if v1 is some initial probability distribution over nodes  then the distribution after a k-step walk is proportional to vk = v1mk. larger values of γ increase the weight given to shorter paths between x and y. in the experiments reported here  we consider small values of k  and this computation is carried out directly using sparse-matrix multiplication methods.1 if v1 gives probability 1 to some node x1 and probability 1 to all other nodes  then the value given to y in vk can be interpreted as a similarity measure between x and y.
　in our framework  a query is an initial distribution vq over nodes  plus a desired output type tout  and the answer is a list of nodes y of type tout  ranked by their score in the distribution vk. for instance  for an ordinary ad hoc document retrieval query  like  economic impact of recycling tires   would be an appropriate distribution vq over query terms  with tout = file. replacing tout with person would find the person most related to the query-e.g.  an email contact heavily associated with the retread economics. replacing vq with a point distribution over a particular document would find the people most closely associated with the given document.
1 relation to tf-idf
　it is interesting to view this framework in comparison to a more traditional ir setting  which can be viewed as a special case. suppose we restrict ourselves to only two types  terms and files  and allow only in-file edges. now consider an initial query distribution vq which is uniform over the two terms  the aardvark . a one-step matrix multiplication will result in a distribution v1  which includes file nodes. the common term  the  will spread its probability mass into small fractions over many file nodes  while the unusual term  aardvark  will spread its weight over only a few files: hence the effect will be similar to use of an idf weighting scheme.
1. learning
　as suggested by the comments above  the described graph framework could be used for many types of tasks  and it is unlikely that a single set of parameter values θ will be best for all tasks. it is thus important to consider the problem of learning how to better rank graph nodes.
　previous researchers have described schemes for adjusting the parameters θ using gradient descent-like methods  1  1 . in this paper  we suggest an alternative approach of learning to re-order an initial ranking. this reranking approach has been used in the past for meta-search  and also several natural-language related tasks  1  1 . the advantage of reranking over parameter tuning is that the learned classifier can take advantage of  global  features that are not easily used in a walk.
　note however that node reranking  while can be used as an alternative to weight manipulation  it is better viewed as a complementary approach  as the techniques can be naturally combined by first tuning the parameters θ  and then reranking the result using a classifier which exploits nonlocal features. this hybrid approach has been used successfully in the past on tasks like parsing .
　we here give a short overview of the reranking approach  which is described in more detail elsewhere . the reranking algorithm is provided with a training set containing n examples. example i  for 1 ＋ i ＋ n  includes a ranked list of li nodes. let wij be the jth node for example i  and let p wij  be the probability assigned to wij by the graph walk.
　a candidate node wij is represented through m features  which are computed by m feature functions f1 ... fm. we will require that the features be binary; this restriction allows a closed form parameter update . the ranking function for node x is defined as:
m
	f x α．  = α1l x  +	αkfk x 
k=1
where l x  = log p x   and ．α is a vector of real-valued parameters. given a new test example  the output of the model is the given node list re-ranked by f x α． .
　to learn the parameter weights ．α  we use a boosting method   which minimizes the following loss function on the training data:
li
exploss ．α  =	e  f xi 1 α．  f xi j α．   i	j=1
where xi 1 is  without loss of generality  the correct target node.1 the weights for the function are learned with a boosting-like method  where in each iteration the feature fk that has the most impact on the loss function is chosen  and αk is modified. closed form formulas exist for calculating the optimal additive parameter updates  1  1 .
1. evaluation
　there are currently no available annotated email corpora for evaluation of email-related queries. in this paper we evaluate the system on two tasks: person name disambiguation  and email threading. the key property of these tasks is that a non-subjective correct answer set can be constructed per query. each task was evaluated on three corpora.
1 corpora
　each corpus is of moderate size-representative  we hope  of an ordinary user's collection of saved mail.
　the cspace corpus contains email messages collected from a management course conducted at carnegie mellon university in 1 . in this course  mba students  organized in teams of four to six members  ran simulated companies in different market scenarios. the corpus we used here includes the emails of all teams over a period of four days  plus all messages that were replied to in the four-day period. this subcorpus is convenient for the task of name disambiguation for several reasons  which are outlined below.
　the enron corpus is a collection of mail from the enron corpus that has been made available to the research community . this corpus can be easily segmented by user: here  we used the saved email of four different users.1 to eliminate spam and news postings we removed email files sent from email addresses with suffix  .com  that are not enron's; widely distributed email files sent from addresses such as  enron.announcement  or  enron.chairman  at  enron.com ; and emails sent to  all.employees enron.com  etc. text from forwarded messages  or replied-to messages were also removed from the corpus. in deriving terms for the graph  terms were porter-stemmed and stop words were removed.
　table 1  leftmost columns  gives the size of each processed corpus  and the number of nodes in the graph representation of it. the processed enron-derived corpora are available from the first author's home page.1
corpusperson setthread setfiles	nodestrain	testtrain	testcspace1	1	1sager-e1	1	-	-shapiro-r1	1	-	-germany-c1	-	-	1farmer-d1	-	-	1table 1: corpora details
1 person name disambiguation
1.1 task definition
　consider an email message containing a common name like  andrew . ideally an intelligent mailer would  like the user  understand which person  andrew  refers to  and would rapidly perform tasks like retrieving andrew's preferred email address or home page. resolving the referent of a person name is also an important complement to the ability to perform named entity extraction for tasks like social network analysis or studies of social interaction in email. however  while the referent of the name is usually unambiguous to the recipient of the email  it can be non-trivial for an automated system to find out which  andrew  is indicated. automatically determining that  andrew  refers to  andrew y. ng  and not  andrew mccallum   for instance  is especially difficult when an informal nickname is used  or when the mentioned person does not appear in the email header. as noted above  we model this problem as a search task: based on a name-mention in an email message m  we formulate query distribution vq  and then retrieve a ranked list of person nodes.
1.1 data preparation
　unfortunately  building a corpus for evaluating this task is non-trivial  because  if trivial cases are eliminated  determining a name's referent is often non-trivial for a human other than the intended recipient. we evaluated this task using three labeled datasets  as detailed in table 1.
　the cspace corpus has been manually annotated with personal names . additionally  with the corpus  there is a great deal of information available about the composition of the individual teams  the way the teams interact  and the full names of the team members. using this extra information it is possible to manually resolve name mentions. we collected 1 cases in which single-token names were mentioned in the the body of a message but did not match any name from the header. instances for which there was not sufficient information to determine a unique person entity were excluded from the example set. in addition to names that refer to people that are simply not in the header  the names in this corpus include people that are in the email header  but cannot be matched because they are referred to using: initials-this is commonly done in the sign-off to an email; nicknames  including common nicknames  e.g.   dave  for  david    and unusual nicknames  e.g.   kai  for  keiko  ; or american names that were adopted by persons with foreign-language names  e.g.   jenny  for  qing  .
　for enron  two datasets were generated automatically. we collected name mentions which correspond uniquely to names that are in the email  cc  header line; then  to simulate a non-trivial matching task  we eliminate the collected person name from the email header. we also used a small dictionary of 1 common american nicknames to identify nicknames that mapped uniquely to full person names on the  cc  header line.
　table 1 gives the distribution of name mention types for all datasets. for each dataset  some examples were picked randomly and set aside for learning and evaluation purposes  see table 1 .
initialsnicknamesothercspace1%1%1%sager-e-1%1%shapiro-r-1%1%table 1: person name disambiguation datasets
1 results for person name disambiguation
1.1 evaluation details
　all of the methods applied generate a ranked list of person nodes  where there is exactly one correct answer per example.1 figure 1 gives results1 for two of the datasets as a function of recall at rank k  up to rank 1. table 1 shows the mean average precision  map  of the ranked lists as well as accuracy  which we define as the percentage of correct answers at rank 1  i.e.  precision at rank 1 .
1.1 baseline method
　to our knowledge  there are no previously reported experiments for this task on email data. as a baseline  we apply a reasonably sophisticated string matching method . each name mention in question is matched against all of the person names in the corpus. the similarity score between the name term and a person name is calculated as the maximal jaro similarity score  between the term and any single token of the personal name  ranging between 1 to 1 . in addition  we incorporate a nickname dictionary 1 such that if the name term is a known nickname of the person name  the similarity score of that pair is set to 1.
　the results are shown in figure 1 and table 1. as can be seen  the baseline approach is substantially less effective for the more informal cspace dataset. recall that the cspace corpus includes many cases such as initials  and also nicknames that have no literal resemblance to the person's name  section 1.1   which are not handled well by the string similarity approach. for the enron datasets  the baseline approach perfoms generally better  table 1 . in all the corpora there are many ambiguous instances  e.g.  common names like  dave  or  andy  that match many people with equal strength.
1.1 graph walk methods
　we perform two variants of graph walk  corresponding to different methods of forming the query distribution vq. unless otherwise stated  we will use a uniform weighting of labels-i.e.  1; and a walk of length 1.
　in the first variant  we concentrate all the probability in the query distribution on the name term. the column labeled term gives the results of the graph walk from this probability vector. intuitively  using this variant  the name term propagates its weight to the files in which it appears. then  weight is propagated to person nodes which co-occur frequently with these files. note that in our graph scheme there is a direct path between terms to person names  so that person nodes may recieve weight vis this path as well.
　as can be seen in the results  this leads to very effective performance: e.g.  it leads to 1% vs. 1% accuracy for the baseline approach on the cspace dataset. however  it does not handle ambiguous terms as well as one would like  as the query does not include any information of the context in which the name occurred: the top-ranked answer for ambiguous name terms  e.g.   dave   will always be the same person. to solve this problem  we also used a file+term walk  in which the query vq gives equal weight to the name term node and the file in which it appears.
　we found that adding the file node to vq provides useful context for ambiguous instances-e.g.  the correct  david  would in general be ranked higher than other persons with this same name. on the other hand  though  adding the file node reduces the the contribution of the term node. although the map and accuracy are decreased  file+term has better performance than term at higher recall levels  as can be seen in figure 1.
1.1 reranking the output of a walk
　we now examine reranking as a technique for improving the results. we formed the following types of features f for a node x. edge unigram features indicate  for each edge label   whether  was used in reaching x from vq. edge bigram features indicate  for each pair of edge labels  whether 1 and 1 were used  in that order  in reaching x from vq. top edge bigram features are similar but indicate if were used in one of the two highest-scoring paths between vq and x  where the  score  of a path is the product of
pr   for all edges in the path .
　we believe that these features could all be computed using dynamic programming methods. currently  however  we compute features by using a method we call path unfolding  which is similar to the back-propagation through time algorithm  1  1  used in training recurrent neural networks. graph unfolding is based on a backward breadth-first visit of the graph  starting at the target node at time step k  and expanding the unfolded paths by one layer per each time step. this procedure is more expensive  but offers more flexibility in choosing alternative features  and was useful in determining an optimal feature set.
　in addition  we used for this task some additional problemspecific features. one new feature indicates whether the set of paths leading to a node originate from one or two nodes in vq.  we conjecture that in the file+term walk  nodes that are connected to both the source term and file nodes are more relevant than nodes that are connected to only the file node or only the term node.  we also form features that indicate whether the given term is a nickname of the person

figure 1: person name disambiguation results: recall at rank k
name  per the nicknames dictionary; and whether the jaro similarity score between the term and the person name is above 1. this information is similar to that used by the baseline ranking system.
　the results  for the test set  after training on the train set  are shown in table 1 and  for two representative cases  figure 1. in each case the top 1 nodes were reranked. reranking substantially improves performance  especially for the file+term walk. the accuracy rate is higher than 1% across all datasets. the features that were assigned the highest weights by the re-ranker were the literal similarity features and the source count feature.
1 threading
1.1 task description
　as a test of the generality of our approach  we also considered a second task. threading is the problem of retrieving other messages in an email thread given a single message from the thread. threading is a well known task for email  although there are only few relevant works published  1  1 . as has been pointed out before   users make inconsistent use of the  reply  mechanism  and there are
map mapacc. acccspacebaseline1-1-graph - term11%11%graph - file+term11%11%reranking - term11%11%reranking - file+term11%11%sager-ebaseline1-1-graph - term11%11%graph - file+term11%11%reranking - term11%11%reranking - file+term11%11%shapiro-rbaseline1-1-graph - term11%11%graph - file+term1 1% 11%reranking - term11%11%reranking - file+term11%11%table 1: person name disambiguation results
frequent irregularities in the structural information that indicates threads; thus  thread discourse arguably should be captured using an intelligent approach. it has also been suggested  that once obtained  thread information can improve message categorization into topical folders.
　our primary interest in this task is that threading is an easily-evaluated proxy for the task of finding similar messages in a corpus. finding related messages would be both a useful operation for users  and is also important for automatic email processing at the corpus level. as threads  and more generally  similar messages  are indicated by multiple types of relations including text  social network information  and timing information  we expect this task to benefit from the graph framework.
　more precisely  we formulate threading as follows: given an email file as a query  produce a ranked list of related email files  where the immediate parent and child of the given file are considered to be  correct  answers. we limit the answer set to the adjacent files because of our more general interest in finding related messages: while consecutive thread messages can be assumed to be related to each other  this assumption is weaker if applied on the entire thread. this definition does  however  make the task somewhat more challenging.
1.1 data
　we created three datasets for task evaluation  again from the cspace and enron corpora. the number of queries for each dataset are given in table 1. for each relevant message  its parent was identified by using the subject line and time stamp. about 1% of the messages have both parent and child messages available  otherwise only one file in the thread is a correct answer.
　we used a series of variants of this data  in which we varied the amount of message information that is available. specifically  several information types are available in these corpora: the email header including sender  recipients and date; the body  i.e.  the textual content of an email  excluding any quoted reply lines or attachements from previous messages; reply lines  i.e.  quoted lines from previous messages; and the subject  i.e.  the content of the subject line.
we compared several combinations of these components 
as detailed in table 1. of particular interest is the task which considers header and body information alone  since it best reflects the situation for the more general task of finding  related  messages.
1.1 baseline method
　the baseline approach generates a list of files  ranked by similarity scores using the vector space model  in which a document is represented as a weighted vector in a term space and a document similarity score is the cosine similarity of their vectors. tf-idf term weighting is commonly used for document representation; to apply the tf-idf scheme here  we simply consider all available information as text.
　the results  table 1  show that this approach performs reasonably well. due to space limitations full results are given as map scores; in addition  figure 1 shows the recallat-k curve for the cspace dataset  using header and text. recall of about 1% at rank 1 is reached using header and text information for cspace using the baseline approach. as one might expect  adding information  in particular the subject and reply lines  improves performance substantially.
1.1 graph walk methods
　to formulate this as a problem in the graph model  we let vq assign probability 1 to the file node corresponding to the original message  and let tout = file. in addition to using uniform graph weights  we also use an extremely simple weight-tuning method: specifically  we evaluated 1 randomly-chosen sets of weights and pick the one that performs best  in terms of map  on the cspace training data. we repeated this procedure separately for every experiment setting  so a total of four  random  weight vectors were used. performance for this weight set is shown as  graphrandom  in the table.
　the results show that the graph walk and the tf-idf are comparable when identical chunks of text  such as subject lines  are present in both the query message and the  target . however  the graph walk performs better using only header and body text information  with an absolute improvement of 1% to 1% in map across corpora. note that the  random  weights outperform uniform weights and tf-idf substantially on cspace  and often also on other corpora. this is especially true when reply and subject lines are not available. this suggests that even very simple weight-tuning methods are likely to improve performance.
1.1 reranking the output of walks
　we applied reranking on top of the random-weighted graph walk results. the top 1 file nodes were given to the reranker. the features applied are edge unigram  edge bigram and top edge bigram  described in section 1.1 . we found that the edge bigram features are most informative  leading to large improvement rates. overall  reranking the graph walk almost always yields the best results.1 for example  recall of 1% at rank 1 is achieved for the cspace dataset  with only header and text available  compared to 1% using the tf-idf based method and 1% prior to reranking. most features that were assigned high weight by the learner were bigrams: some examples are: sent from ★ sent to 1  date
header body
subject reply lines〔
〔
〔〔
〔
-〔
-
--
-cspacetf-idf1111graph - uniform1111graph - random1111graph - reranked1111germany-ctf-idf-111graph - uniform-111graph - random-111graph - reranked-111farmer-dtf-idf-111graph - uniform-111graph - random-111graph - reranked-111〔 〔 〔 〔
table 1: threading results: map

figure 1: threading results: recall at rank k
of ★ date of 1  and has term ★ has term 1. these paths are indeed characteristic of a thread: e.g.  the sender of a message is likely to be a recipient of a reply message  there is high temporal proximity between messages in a thread  and some textual overlap.
　note that while such sequences of relations can be readily identified as important in our framework  they cannot be even modeled easily in a flat representation. sequential aspects of a corpora have been shown to be important for other email-related tasks  e.g.  workflows and social interaction .
1. related work
