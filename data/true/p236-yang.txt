the grand tour  one of the most popular methods for multidimensional data exploration  is based on orthogonally projecting multidimensional data to a sequence of lower dimensional subspaces and then moving continuously from one to another. by running experiments on screen and in the cave virtual environment  we were able to use the method for the 1d rendering of very large relational datasets where projections are made onto 1d subspaces. 1d cluster-guided tour is proposed where sequences of projections are determined by centroids of data clusters. it makes inter-clusterdistance-preserving projections in the perspectives that the data clusters are displayed as separate as possible. the exploration of very large datasets is supported by using volume rendering through texture splatting. volume rendering takes as input only the aggregation or part of data needed for rendering  which can be retrieved efficiently by sql queries in an ad hoc manner while we explore or drill down large datasets. to facilitate interactive picking and brushing  a kd-tree multidimensional indexing mechanism is designed. access methods for subspace search and range query are proposed to greatly reduce the cost of searching and picking interesting data records. various add-on features  such as projecting variable axes and cluster similarity graphs  help further the understanding of data.
categories and subject descriptors
h.1  database management : database applications- data mining; i.1  computer graphics : methodology and techniques-interaction techniques; i.1  computer graphics : three dimensional graphics and realism- animation  virtual reality; h.1  information storage and retrieval : information search and retrieval-clustering  selection process; g.1  mathematics of computing : probability and statistics-multivariate statistics
general terms
design  experimentation
1. introduction
visualization techniques have proven to be of high value in exploratory data analysis and data mining. when we talk about very large relational tables  we imply that either the tables are very wide  up to a few hundred dimensions   or very long  a huge number of records   or both. for small dataset with a few dimensions and a few records  scatterplot is an excellent means for visualization. patterns could be efficiently unveiled by simply drawing each data record as a geometric object in the space determined by two or three numeric variables of the data  while its size  shape  color and texture determined by other variables of the data. the ability to draw scatterplots is a common feature of many visualization systems. however  conventional scatterplots lose their effectiveness as either dimensionality or the number of records becomes large.
the ways to handle large datasets are then twofold: to deal with high dimensionality and to deal with large number of records. many techniques  such as scatterplot matrix  parallel coordinates  star glyphs  and dimensional stacking  are developed to visualize data of more than three dimensions. while these techniques are useful to explore moderate dimensioned datasets  they are not intuitive for interactive exploration. to retain the nature of data records as multidimensional points  a good way is to project data orthogonally onto 1d or 1d subspaces which allow us to look at relational data in a geometry that is within the perceptibility of human eyes. since there is an infinite number of possibilities to project high dimensional data onto lower dimensions  the grand tour method  1  1  1  provides an overview of all possible projections through sampling all possible planes randomly. by displaying a number of intermediate projections obtained by interpolation between any two projections  the entire process creates an illusion of continuous smooth motion. this helps to find interesting projections which is hard to find in the original data with only low dimensional plots.
a tour could be further guided by projection pursuit which

permission to make digital or hard copies of part or all of this work or personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers  or to redistribute to lists  requires prior specific permission and/or a fee. 
kdd 1  boston  ma usa 
 c  acm 1-1-1/1 ...$1 
examines the distribution of data and aims at helping the users to find interesting projections. for clustered datasets  the position of data clusters could be used to help choosing projections. the idea is to choose the centroids of four clusters and project all data points onto a 1d subspace determined by these four cluster centroids. the four clusters will then be displayed as separate as possible from each other. furthermore  this projection is distance-preserving in the sense that the distance shown between any two of these
four cluster centroids is exactly the same as their original distance. we call this a cluster-guided projection. by using grand tour linking the cluster-guided projections from one to another with a geodesic  actually pseudo-geodesic after interpolation  path  a viewer can quickly have a good sense of the position of all data clusters by moving smoothly through all cluster-guided projections. this is what we call the cluster guided tour.
datasets could also be very large in terms of the number of data records. modern relational databases often contain so many records that it is impractical to display interactively all of them as points in a single scatterplot. even if the display of so many points were possible  its usefulness would be diminished by overwhelming appearance and excessive occlusion. previous way to deal with this problem is sampling. in this paper we show a better way for the exploration of very large dataset by visualizing 1d density maps using volume rendering.
to handle large number of data records  one improvement to scatterplot is to draw density maps instead of individual data points. the way to draw 1d density map is volume rendering. the main idea behind volume rendering is that data points are discretized and grouped into bins. each bin is a range of values for each of the variables. data points belonging to each range are then categorized into each bin. volume rendering takes each of these bins  and displays them onto screen as voxels. there are many methods of implementing volume rendering. since the result is expected to represent an amorphous cloud of colored data points  it is felt that texture splatting using gaussian footprints is the most natural choice.
volume rendering takes as input only a set of data bins and  in each bin  the number of data records. the size of this highly aggregated data is much smaller than that of the original  making it possible to be transferred from database in an ad hoc manner. more importantly  data bins and the number of records in each bin can be retrieved efficiently from relational database by the sql group by query. to further accelerate the process  the binned and aggregated data can be pre-calculated and stored as summary tables in database. volume rendering  together with database support  enables fast rendering of very large datasets.
picking and brushing are problems for the interactive exploration of very large datasets. picking and brushing are special kinds of range queries that each mouse click on screen selects a  tubular  range in the original n-dimensional space. since the data to be selected are points in high dimensional space  it is felt that kd-tree and its variants such as k-d-btree and kd-dt are favorable multidimensional indexing mechanisms. access method of subspace search and range query is proposed to take advantage of the kd-tree data structure to reduce the cost of searching and picking interesting data points.
there are other issues for the interactive visualization of relational data. for example  a direct interface to databases is absolutely necessary so that only data needed for rendering are retrieved in an ad hoc manner while we drill down large datasets. another issue is that many variables are categorical rather than numerical. the values of categorical variables have no explicit ordering. this makes them difficult to map to a linear scatterplot axis. furthermore  real world datasets have always a lot of missing values. missing values need special treatments in data visualization  for the same reason they are specially treated in databases.
there are many previous work focusing on the visualization of multivariate datasets. xmdvtool is a tool integrating scatterplot matrices  parallel coordinates  star glyphs  and dimensional stacking by linking alternative views using brushing. the idea of using sequences of lower dimensional projections to simulate higher dimensional display was proposed in . an example visualization system that implemented 1d projection and grand tour was xgobi. 1d cluster-guided projections were studied in  and were implemented in cviz  which concentrates on 1d projections determined by any three clusters. there are also examples of exploratory data visualization in immersive virtual reality environments. virtual data visualizer employs a data organization with data arranged hierarchically in classes that can be visualized within the virtual environment. vrgobi  which is a virtual reality extension of xgobi  uses the c1 immersive environment for the dynamic display of statistical graphics. so far  the only application we have encountered that implements volume rendering for visual data mining is the splatviz tool in the sgi mineset software.
this paper presents the n1tool  a visual exploration tool which uses 1d grand tour for relational data and 1d cluster guided tour for data clusters. compared with previous work such as cviz on 1d cluster projections  n1tool is capable of 1d view by taking advantage of modern graphics hardware. it allows tour transition between cluster views. up to four clusters can be displayed in a distance-preserving way in a 1d view. all these features make it easier to discover complex patterns and holes in datasets. n1tool is particularly capable for very large datasets through volume rendering. selection and drill down are instantly supported through interface with databases. two versions of the tool have been implemented: one is an on-screen version; the other is a virtual reality version using the cave immersive virtual environment. the on-screen version supports stereo display which provides depth cues for 1d scatterplot. the virtual reality version is more impressive. with the cave as a 1d  magic canvas   scatterplots can be drawn in mid-air in a 1d virtual space. the n1tool was designed as a high end tool to cater the needs for the visual exploration of very large datasets. it is now routinely employed for database exploration  preprocessing and analyzing clustering results.
1. 1d cluster-guided tour
grand tour is an extension of data rotation for multidimensional datasets. it is based on selecting a sequence of projections and moving continuously from one projection to the next. by displaying a number of intermediate projections obtained by interpolation between any two projections  the entire process creates an illusion of continuous  smooth motion. this helps to find interesting projections which are hard to find with only low-dimensional plots of the original data. furthermore  grand tour allows a viewer to easily

figure 1: moving 1d projections along a geodesic path in a 1d space.
keep track of a specific group of data points throughout the journey of a tour.
for illustration  suppose we are to make a 1d tour of 1d euclidean space figure 1 . the most straight way to move from one 1d projection to the next is a sequence of interpolated projections to move the 1d projection plan  or a 1-frame  a 1-frame is an orthonormal pair of vectors   to the next along a geodesic path. for 1d grand tour of ndimensional  n   1  datasets  in the same way  it is necessary to have an explicitly computable sequence of interpolated 1-frames in n-dimensional euclidean space. the n-dimensional data is then projected  in turn  onto the 1d subspace spanned by each 1-frame. for the shortest path to move from one 1d projection to another  the sequence of the interpolated 1-frames should be along a geodesic path. moving along a geodesic path creates a sequence of intermediate projections moving smoothly from the current to the target projection. this is a way of assuring that the sequence of projections is comprehensible  and also moves rapidly to the target projection. for 1d projections  a geodesic path is simply a rotation in the  at most  1-dimensional subspace containing both the current and the target 1d subspaces. this implies that some preprojection is useful in the implementation to speed up computation.
there are various ways of choosing paths of a tour. a simplest way is random tour. the target projection in each step in a random tour is randomly generated. this creates a way for dynamic browsing of relational data by moving among randomly chosen 1d subspaces. another straightforward way is choosing the span of any three arbitrary variables as a 1d subspace and moving from this span to the next span of another three variables. the projection in a span is exactly a 1d scatterplot. this is more than 1d scatterplots  however  because more information could be unveiled by the motion moving from one projection to another. this is what we call simple projection. simple projection gives a way to continuously check a sequence of scatterplots of data on any three variables. figure 1 shows a simple projection of the

figure 1: simple projection: a 1d scatterplot.
adult dataset from the uci ml repository. two categorical variables  education and occupation  are plotted with their possible values shown along the axes from the origin. a continuous variable  age  is displayed with its mean value set at the origin and its range of values marked by numbers.
more advanced ways of grand tour come from exploratory statistics where data distribution is involved in choosing the path of a tour. for example  one way is to restrict paths of projections to principal components and canonical variate subspace. another way constructs hill-climbing paths that follow gradients of projection pursuit indices 1  1 . these techniques are efficient ways to examine statistical significance of variables. for clustered datasets  however  we have a way  what we call the cluster-guided tour  to show the structure of data clusters.
suppose that we have partitioned an n-dimensional dataset into k  k   1  clusters  and let denote the centroids of these clusters. any combination of four distinct and noncolinear cluster centroids ca  cb  cc and cd in {cj} determines a unique 1d subspace of n-space. let i1  i1 and i1 constitute an orthonormal basis of the 1d subspace  this could be obtained by orthonormalizing  for example  cb ca  cc ca  and cd   ca . we can then compute a 1d projection by projecting the n-dimensional dataset onto the 1-frame  i1 i1 i1 . this projection preserves the inter-cluster distances  that is  the euclidean distances between any two of the four cluster centroids {ca cb cc cd} will remain unchanged after the projection. this projection is a right perspective to view these four clusters because the four clusters are visualized as separate as possible.

figure 1: a 1d cluster-guided projection where the 1d subspace is determined by centroids of 1 clusters 1  1  1  1. the projection-determining cluster centroids are visualized as big spheres  while other cluster centroids are visualized as smaller cubes.
cluster-guided tour is a way to get cluster centroids involved in choosing projection steps. given k cluster centroids  there are at most  combinations of unique 1d cluster projections. the basic idea behind cluster-guided tour is simple: choose a target projection from  possible cluster-guided projections  move smoothly from the current projection to the target projection  and continue. we illustrate the 1d cluster-guided tour on the boston housing data set. the dataset was clustered into 1 clusters. there are  1  = 1 possible 1d cluster-guided projections. one of them is plotted in figure 1. the 1d cluster-guided tour reveals significant information about the position of clusters.
1. volume rendering
one of the problems of displaying large multi-dimensional data sets with 1d scatterplot is the possibility of having more than one data point with the same values. these points would be drawn in the exact same location in a scatterplot  preventing the viewer from seeing more than one data point. another problem is that the visual presentation of a large dataset using a scatterplot would result in millions of data points cluttered together making it nearly impossible for the average human to understand.
table 1: processed data for volume rendering
minoritycommutecrime，，，weight111-1，，，1-1-1.1.1，，，1，，，，，，，，，，，，，，，111-1，，，1-1-1.1.1，，，1，，，，，，，，，，，，，，，an improvement of scatterplot to display large number of data points is to draw density map instead of individual data points. the way to draw 1d density map is volume rendering. volume rendering helps a viewer perceive the density of data points in each location of a 1d scatterplot.
conventionally  volume rendering is the direct display of 1d volume data. however  the volume data it has to take as input here are multidimensional. the multidimensional voxelized data to be rendered are obtained using binning. the tradeoff between accuracy and rendering speed is determined by binning resolution. relational table is a natural data structure for representing the voxelized data because of the sparsity of data points in multidimensional space. each voxel is represented as a record in the table. the weight of each voxel after binning is an aggregation. in most cases  it is the number of data points in a corresponding bin. in some other cases  it may be the sum or even the weight records by the value of some other variable. we use again the boston housing data as an example. the first step is to bin the variables to a desired resolution. then an aggregation is performed to compute counts using binned numeric variables as keys. this results in the processed data shown in table 1. there will be at most one row  bin  for each combination of variables.
uniform binning is used to discretize the continuous variables. categorical variables use unique values as bins. the binning is performed directly on database using aggregation queries. to further speed up the process  a summary table can be created in database to store the binning results. since table is used as the underlying data structure  no storage is wasted on regions with no data.
we decided to use splatting as a way for volume rendering. splatting projects voxels onto the 1d viewing plane. the projection of each voxel is approximated by a gaussian splat  whose opacity and colour depend on those of the voxel. the resulting splats are composited on top of each other in back to front order to produce the final image. splatting was proposed to improve the calculation speed at the price of less accurate rendering. the n1tool utilizes the splatting method using 1d texture splats. a high degree of accuracy is not necessary for our purposes as compared to the rendering speed.
opacity is assigned to each voxel as a function of its weight of the corresponding bin. the function used in the n1tool is:
　　　　　　　　　α = 1   e μ，weight where α is the opacity of a splat at its center  weight is

figure 1: volume rendering of a simple projection.
the weight of aggregated data points in the bin  and μ is a scale factor. this exponential opacity function is effective in modeling light propagation through clouds of tiny lightemitting spheres. the colour of the splat is determined by the average value of colors of all points in the corresponding bin. the splats are drawn in back to front order  at each bin location to form an image that approximates the appearance of a scatterplot of the original data  figure 1 . a slider is used to vary the value of the scale factor μ. this allows global scaling of the opacity for each splat to make an entire display image of rendered splats more or less transparent.
an advantage of the n1tool is that it has direct interface to backend database system. with database support  the volume exploration of a large dataset never needs retrieving the whole dataset. the less aggregated subset of data will not be retrieved until you select a subset of data and drill down. this pick-and-drill-down process could continue until you reach the record level when a set of individual data points are retrieved. in this way  the n1tool is capable of visual exploration of very large datasets.
1. brushing and picking with the kd-tree index
brushing and picking are fundamental requirements for interactive data exploration. during the journey of a tour  a viewer can easily keep track of the movement of selected data points. data points picked up can then be related back to the data  thus make it possible for further analysis such as launching another tour of selected data points or another mining process for drill down. due to the highly interac-
tive nature of brushing and picking  the brute force way of searching all data records for matching points will not work for large datasets. an index and search strategy is needed.

	 a 	 b 
figure 1: kd-tree splitting patterns:  a  cyclic splitting  and  b  domain priority splitting.
there exist a number of multidimensional indexing techniques. since we take data as a set of static points in ndimensional euclidean space  it seems that kd-tree is a good choice. binary kd-trees organize n-dimensional data for efficient search of nearest neighbors. a kd-tree partitions a dataset recursively by the median of the dimension with the greatest range. the  longest  dimension is always split in an attempt to keep each node's geometric region as compact as possible. the user specifies a threshold  that is  the minimum number of data records allowed in a leaf node. the algorithm uses the threshold to decide when to stop partitioning a node. each leaf lists the data records that satisfy the conditions implied by the path to the leaf.
kd-tree is a main-memory data structure generalizing the binary search tree to multidimensional data. to adapt kdtrees to secondary storage  one way is to choose domains cyclically to split interior nodes figure 1 a   and pack multiple interior nodes into a single page. we are better off including in one page a node and all its descendants for some number levels. another way is to have multiway branches at each interior node where interior nodes look more like b-tree nodes which have multiple partitions along a dimension figure 1 b  .
typical inputs to kd-tree search are a  query  instance  a n-dimensional position  and a threshold  which defines the size of neighbor. for brushing and picking on screen  however  each mouse click specifies a n-dimensional  tube  with 1 dimensions bounded by the size of the brush and the rest n   1 dimensions open for free1. furthermore  the orientation of the brushing  tube  will always change depending on the move of projections in a tour. in such a case  it would be desirable to have kd-tree regions as  n-cubical  as possible. the cyclic splitting pattern figure 1 a   would be better than the domain priority splitting figure 1 b  . this is because that  in most cases  the former would have smaller regions to search for brushing and picking.
it is convenient to think of a brushing  tube  as an ndimensional region that satisfies a neighborhood inequation. brushing is to select all data points within this region. the search begins from the root of kd-tree. if that node is not a

leaf  the query region is compared to the node's split point and the appropriate children that intersect with the query region are identified. recursive call to each child is then made. if the node is a leaf  the algorithm checks whether each data point at the leaf is within the query region. the algorithm finally returns a list of selected data points.
1. categorical axes and missing values
it is quite common for many variables to be categorical rather than numerical. a categorical variable can be mapped onto a linear scatterplot axis in the same way as a numeric variable  provided that some order of distinct values of that variable is given along the categorical axis. here we have several options: first  the distinct values of a categorical variable may be explicitly listed. the order of the categorical values being listed will be the order these values be arranged on the axis. second  categorical values could be grouped together  reflecting the natural taxonomy of values. third  values of a categorical variable can also be sorted alphabetically  or numerically by aggregate value of some other variable.
the scatterplot in figure 1 shows two categorical variables  occupation and education. values of occupation are sorted by the variable hours-per-week along the left axis. the occupations  farming-fishing and executive-managerial  listed at the end of the axis have the longest working hours  and private-house-services has the shortest. values of education are given explicitly with some of the values  such as masters and doctorate  are grouped together.
it is common for relational data to contain missing values. these missing values are treated quite differently from one data mining algorithm to another. the remedies for dealing with missing values are based on the randomness of the missing data process and the method used to estimate the missing values. simply removing all nulls isn't a fully satisfactory solution since you significantly bias the data. also  assuming nulls to a certain value  for example  the mean of the variable  is generally not acceptable as this introduces more confusion and creates outliers. there are algorithms that try to estimate a maximum likelihood value for each null. for the purpose of visualization  we think it is better to do nothing more on missing values but to keep what it is. null axis values for a continuous variable are placed below the range of the values for that variable. for a categorical variable  missing values are placed at the origin of the corresponding axis. they are not confused with other values as all categorical values are arranged on the positive part of the categorical axis. in addition  null color values are shown as gray  and null label and message values are shown with a question mark. in figure 1  the value of occupation is sometimes missing. these points appear on the plane through the origin where the value of occupation is zero  offset from the points that have the first occupation value.
1. rendering in the cave
cave is a projection-based virtual environment that uses 1d computer graphics and position tracking to immerse viewers inside a 1d space. the cave allows multiple view-

figure 1: a snapshot of the n1tool cave version. the wireframe box indicates the cave's physical space where data points being plotted in mid-air. the cube at the bottom is for brushing.
ers to enter the space and share the same virtual experience. with the cave as a 1d  magic canvas   1d projection of high dimensional data is rendered as a galaxy in mid-air in the virtual space  figure 1 . this helps visualize the exact 1d position of data points  show similarity or dissimilarity between clusters  and determine which clusters to merge or to split further. the variable vectors  which show the contribution to the projection of each variable  are visualized as lines in white color through the origin and marked by the names of variables at their far ends. there are two ways of interactive picking: brushing with a resizable cube brush  shown in figure 1 ; and cluster-picking by selecting a cluster centroid. the cave has plenty of space for 1d rendering.
the cave was initially designed for scientific and engineering visualization. it has no tool or library for gui design. the n1tool requires a user interface that is fairly complicated for a virtual environment. the interface must be designed to give the user control over the journey of a tour. we have taken the approach that a combination of more-orless traditional menus and more direct means of icon manipulation will do the job. controls in the n1tool include a panel  shown in the lower-right corner of the right wall in fugure 1  and submenus for various actions and controlling animation. tools include a cube brush for picking data points  reclustering using the k-means clustering algorithm  single step forward and backward in a guided tour  and so on.
1. some add-on features
1	where we are in a tour 
a dizzy feeling besets many viewers of high-dimensional data projections and they may ask  how do i know what i am looking at . in geometric terms  the task is to locate the position of a projection 1-frame. in xgobi  a visual way of conveying this information is to project the variable unit vectors in n-space like regular data  and render the result together with data points.
n1tool follows the way used in xgobi. examples of the application are shown throughout all screen snapshots in this paper. a generalized tripod called  n-pod  is an enhanced rendition of the n variable unit vectors in n-space. variable unit vectors in the n-pod can be treated as if they were real data  rendered as lines  and labeled by variable names in the far ends so that they are recognized as guide posts rather than data. continuous variables are displayed as lines with their means set at the origin. this is for the easy mark of both minimum and maximum values at both ends of each line. categorical variables are displayed as rays starting from the origin. the n1tool always maps categorical values onto the positive part of a categorical axis. the n-pod looks like a star with n unequal rays  or lines across the origin for continuous variables  in 1d space  each indicating the contribution of a variable to the current projection.
1 cluster similarity graphs
data projection is a continuous transformation. two points which are close with each other will remain close after projection. however  two points which are close in a projection need not be close themselves. to somewhat mitigate this information loss  we use cluster similarity graph as an enhancement to data projection.
a cluster similarity graph can be defined as follows. let vertices be a set of cluster centroids  and add an edge between two vertices if the distance between them is less than a user-controlled threshold. it is thus intuitively clear that changing the threshold value will reveal the difference of distances among cluster centroids. the cluster similarity graph can be overlaid onto data projections. figure 1 represents a cluster similarity graph at a certain threshold. it can be seen that the clusters 1  1  1 are close to each other  among which cluster 1 and cluster 1 are close to cluster 1 which is close to cluster 1. cluster 1 is standalone from all others. the cluster similarity graph adds yet another information dimension to cluster projections.
other features of the n1tool include parallel clustering and stereo display. the n1tool implemented multithread kmeans clustering on shared memory machines. the many iterations that the clustering function has to perform is spread out over many processes  threads . the on-screen version of the n1tool includes an option to view the scatterplot and volume rendering in stereoscopic images.
1. conclusion and future work
this paper discussed the n1tool  a tool using 1d grand tour and volume rendering to visualize very large relational datasets. grand tour creates an illusion of smooth motion through multidimensional space. cluster-guided tour preserves distances between the cluster centroids. it allows us to capture the inter-cluster structure of complex relational data. volume rendering using texture splatting enables the

figure 1: a cluster similarity graph adds yet another information dimension.
visual exploration of very large datasets. brushing  interactive picking and drill down are well supported by the kd-tree index and the access method for subspace search and range query. with database support  only aggregation or part of data that are needed in rendering are retrieved. categorical variables are processed in the same way as continuous variables  provided that the orders of their distinct  or grouped  values are listed explicitly or sorted numerically by aggregate value of some other variable. a cave virtual reality environment is at our disposal for 1d immersive display. the use of the cave virtual environment maximizes the chance of finding patterns. add-on features and interaction tools invite viewer's interaction with data. this approach of multidimensional visualization provides a natural metaphor to visualize large datasets and data clusters by mapping the data onto a time-indexed family of 1d natural projections suitable for human eye's exploration.
the n1tool scales well to large datasets. the computational complexity of tour is linear to the number of variables. the number of variables matters only in calculating dot products which has a linear complexity to the dimensionality of arguments. making projections and scatterplots have a computational complexity linear to the number of data points. this is in the sense that all data points have to be projected one by one. with volume rendering  this complexity can be greatly reduced. whatever how big an original dataset is  volume rendering takes the binned and aggregated relational data as input.
the n1tool represents a new data mining strategy that allows users to understand both the process of mining and the data at hand. the cluster-guided tour is a way to use data mining as a drive for visualization  that is  clustering identifies homogenous sub-populations of data  and the subpopulations are used to help design the path of a tour. the same principle applies to other data mining techniques  for instance  to identify the significant rules produced by classification and rule induction. we hope that the n1tool will be useful to visually explore results generated by other data mining techniques. this remains as one of the future work.
