taxonomies of the web typically have hundreds of thousands of categories and skewed category distribution over documents. it is not clear whether existing text classification technologies can perform well on and scale up to such large-scale applications. to understand this  we conducted the evaluation of several representative methods  support vector machines  k-nearest neighbor and naive bayes  with yahoo! taxonomies. in particular  we evaluated the effectiveness/efficiency tradeoff in classifiers with hierarchical setting compared to conventional  flat  setting  and tested popular threshold tuning strategies for their scalability and accuracy in large-scale classification problems.  
categories and subject descriptors 
f.1  analysis of algorithms and problem complexity : miscellaneous; i.1  pattern recognition : applications - text processing.  
general terms 
technology assessment  performance and scalability analysis  empirical validation. 
keywords 
text categorization  very large web taxonomies  parameter tuning strategies and algorithm complexity 
1. introduction 
with the fast development of the world wide web  there has emerged a great need to manage the massive information on the web. as compared to manually labeling  automated text categorization  tc  might be more desirable for this purpose. recently  many machine learning algorithms  have been developed or adopted to text categorization  including support vector machines  svm   k-nearest neighbor  k-nn   linear regression  na ve bayes  nb  and so on. although researchers have achieved great progress in tc  empirical studies in the literature have not yet provided us with an answer whether existing methods can successfully solve the problem of large-scale web categorization. the major challenge is that web taxonomies  such as yahoo! directory  often have hundreds of thousands of categories and skewed category distribution over documents  which is quite different from widely-used benchmark data sets  such as rcv1   in the literature of tc. to tackle this challenge  we conducted an experimental study on the effectiveness and efficiency of popular tc methods  svm  k-nn and nb  directly over a specific sub set of yahoo! directory that has very similar statistics to the full domain of yahoo! taxonomy.  
1. data corpus  
yahoo! directory is a famous web taxonomy maintained by the human editors of yahoo.com  and has been used in many previous works on text categorization . considering the large scale of this corpus  in june 1  it contained 1 categories and 1 documents which were organized into a 1-level hierarchy   data sampling was conducted in these works. however  their sampling strategies  i.e. only using the top few levels or selective common categories  could not preserve the original characteristics of yahoo! directory. to tackle this problem  we manually chose a specific sub set of yahoo! directory which has very similar category distribution to the full set. we named this sub set by merg  which consists of five sub trees  news and media    entertainment    reference    government  and  regional   documents in  regional  are selected if they also belong to one of the other four categories . merg has totally 1 categories and 1 documents that are organized into a 1-level hierarchy. as can be seen from figure 1 and 1  both merg and yahoo! directory take similar statistical characteristics: spindle category distribution over levels  and power law distribution of category size  which means that most categories are rare categories with very few positive examples . in this regard  we believe that the experiments on this subset can better reflect the true situation of web directory classification than any previous works.  

 a  yahoo! directory                  b  merg 
figure 1. spindle category distribution over levels. 


 
copyright is held by the author/owner s . 
www 1  may 1  1  chiba  japan. acm 1-1/1. 
*the works of hao wan  qian zhou and bin gao were performed at microsoft research asia. 
1	1	1	1	1
	document number	document number	 
 a  yahoo! directory                  b  merg 
1figure 1.  power law distribution of the category size. 
1. experimental results  
when conducting our experimental study  we followed the settings listed as below. we divided merg into a training set and a test set with a ratio of 1. note that during this process  we removed those categories containing only one document for ease of evaluation. as a result  1 categories of merg were used while the training and the test sets contained 1 and 1 documents respectively. for svm  we selected 1 features using chi algorithm ; for k-nn  we set k to 1 according to ; for nb  we used the logarithm of the probabilities for convenience of computation. for each classifier  we conducted three runs:  flat classification with scut     flat classification with rcut   and  hierarchical classification with scut . for each run  we logged the classification performance as well as the time complexity  a workstation with 1g-hz cpu and 1gb memory was used in our experiments . 
the performance of svm classification was reported in figure 1. from it  we found that the performance decreased with the increasing hierarchy depth. for upper levels  scut outperformed rcut. however  rcut finally went beyond scut for deep levels. we also found that hierarchical svm had higher accuracy than flat svm. from the time complexities of svm classification listed in table 1  we could see that 1  scut had the dominant complexity in the training process; 1  hierarchical classification could save the computations greatly. 

figure 1: classification performance of svm over merg 
the classification performance for k-nn was shown in figure 1  from which we could see similar trend to svm for the performance with respect to hierarchy depth. the difference is that this time hierarchical k-nn performed poorer than flat k-nn. our explanation to this is as follow. since many categories in yahoo! directory only have few documents  for the corresponding local classification tasks of hierarchical k-nn  the number of training examples might be even less than k  thus not enough for reliable instance-based learning. and from table 1  we found that unlike svm  hierarchical classification increased the complexity of k-nn. actually  this is true for all m-way classifiers since only the training of the top-level classifiers will already take the same complexity with flat classification.  

figure 1: classification performance of k-nn over merg 
the performance for nb was shown in figure 1. from this figure we found that unlike svm and k-nn  no matter with which setting  nb always gave very poor classification accuracy. our explanation is that nb  as a generative classifier  suffers more from the data sparseness in yahoo! directory than svm and knn. that is  the lack of positive examples simply can not provide enough information to learn a reliable nb classifier. due to the low classification accuracy  no matter how fast nb could be  we can not use it on real-world yahoo-like corpora.  

figure 1: classification performance of nb over merg table 1. time complexity of different classifiers  hour  
algorithms training test without scut with scut flat svm 1 1 1 hierarchical svm 1 1 1 flat k-nn 1 1 1 hierarchical k-nn 1 1 1 flat nb 1 1 1 hierarchical nb 1 1 1 to summarize  hierarchical svm with scut performed best among all the settings. however  even this best one can not offer satisfactory classification accuracy for real-world applications. for the 1rd and deeper levels  the macro-f1 has gone below 1%. this indicates that automated text categorization with very-large taxonomies still poses unsolved challenges.  
1. conclusions 
in this paper  we conducted the evaluation of representative text categorization methods  support vector machines  k-nearest neighbor and naive bayes  with the yahoo! web-page taxonomy. based on our experiments  we got the following conclusions:  
1  hierarchical setting saved computations and improved classification accuracy for svm  but did harm to k-nn and nb in sense of both effectiveness and efficiency.  
1  threshold tuning  scut in our paper  could be a dominant part of the offline training.  
1  hierarchical svm with scut had the best tradeoff between efficiency and effectiveness. however  its classification accuracy was still rather low  indicating that automated text categorization with very-large taxonomies still poses unsolved challenges. 
