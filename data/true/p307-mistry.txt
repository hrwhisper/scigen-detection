materialized views have been found to be very effective at speeding up queries  and are increasingly being supported by commercial databases and data warehouse systems. however  whereas the amount of data entering a warehouse and the number of materialized views are rapidly increasing  the time window available for maintaining materialized views is shrinking. these trends necessitate efficient techniques for the maintenance of materialized views.
　in this paper  we show how to find an efficient plan for the maintenance of a set of materialized views  by exploiting common subexpressions between different view maintenance expressions. in particular  we show how to efficiently select  a  expressions and indices that can be effectively shared  by transient materialization;  b  additional expressions and indices for permanent materialization; and  c  the best maintenance plan - incremental or recomputation - for each view. these three decisions are highly interdependent  and the choice of one affects the choice of the others. we develop a framework that cleanly integrates the various choices in a systematic and efficient manner. our evaluations show that many-fold improvementin view maintenance time can be achieved using our techniques. our algorithms can also be used to efficiently select materialized views to speed up workloads containing queries and updates.
1.	introduction
materialized views have been found to be very effective in speeding up query  as well as update processing  and are

 work partly supported by a govt. of india  department of science and technology grant  and by an ibm university partnership program grant. the work of prasan roy was supported by an ibm research fellowship. ramamritham was also supported in part by nsf grant iri-1.
work done while the author was at iit-bombay.
increasingly being supported by commercial database systems. materialized views are especially attractive in data warehousing environments because of the query intensive nature of data warehouses. however  when a warehouse is updated  the materialized views must also be updated. typically  updates are accumulated and then applied to a data warehouse. while the need to provide up-to-date responses to an increasing query load is growing and the amount of data that gets added to data warehouses has been increasing  the time window available for making the warehouse up-todate has been shrinking. these trends call for efficient techniques for maintaining the materialized views as and when the warehouse is updated.
　the view maintenance problem can be seen as computing the expressions corresponding to the  delta  of the views  given the  delta s of the base relations that are used to define the views. it is not difficult to motivate that query optimization techniques are important for choosing an efficient plan for maintaining a view  as shown in . for example  consider the materialized view . we assume  as in sql  that relations   and are multisets  i.e.  relations with duplicates . given that the multiset of tuples is inserted into   the change to the materialized view consists of a set of tuples to be inserted into . this expression can equivalently be computed as and by   one of which may be substantially cheaper to compute. further  in some cases the view may be best maintained by recomputing it  rather than by finding the differentials as above.
　our work addresses the problem of optimizing the maintenance of a set of materialized views. if there are multiple materialized views  as is common  significant opportunities exist for sharing computation between the maintenance of different views. specifically  common subexpressions between the view maintenance expressions can reduce maintenance costs greatly.

permission to make digital or hard copies of part or all of this work or personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.  to copy otherwise  to republish  to post on servers  or to redistribute to lists  requires prior specific permission and/or a fee. 
acm sigmod 1 may 1  santa barbara  california usa 
copyright 1 acm 1-1/1...$1 
 
　whether or not there are multiple materialized views  significant benefits can be had in many cases by materializing extra views or indices  whose presence can decrease maintenance costs significantly. the choice of what to materialize permanently depends on the choice of view maintenance plans  and vice versa. the choices of the two must therefore be closely coupled to get the best overall maintenance plans.

figure 1: example view maintenance plan. merge refreshes a view given its  delta .
　to motivate the techniques we propose  consider the following example.
example 1. suppose we have three materialized views
	 	and
             and relations and are updated due to inserts. if the maintenance plans of the three views are chosen independently  the best view maintenance plan  incremental or recomputation  for each would be chosen  without any sharing of computation.
　in contrast  as an illustration of the kind of plans our optimization methods are able to generate  figure 1 shows a maintenance plan for the views that exploits sharing of computation. here  is refreshed incrementally  while and are recomputed. two extra views  and have been chosen to be materialized. of these  is materialized transiently  and is disposed as soon as the views are refreshed; this could happen because there are also updates on and which make it expensive to maintain
as a materialized view. the result has been chosen to be materialized permanently  and is itself refreshed incrementally given the updates to the relation . its full result is then used to recompute as well as
.
contributions. the contributions of this paper are as follows:
1. we show how to exploit transient materialization of common subexpressions to reduce the cost of view maintenance plans.
sharing of subexpressions occurs when multiple views are being maintained  since related views may share subexpressions  and as a result the maintenance expressions may also be shared. furthermore  sharing can occur even within the plan for maintaining a single view if the view has common subexpressions within itself. the shared expressions could include differential expressions  as well as full expressions which are being recomputed.
here  transient materialization means that these results are materialized during the evaluation of the maintenance plan and disposed on its completion.
1. we show how to efficiently choose additional expressions for permanent materialization to speed up maintenance of the given views.
just as the presence of views allows queries to be evaluated more efficiently  the maintenance of the given permanently materialized views can be made more efficient by the presence of additional permanently materialized views  1  1 . that is  given a set of materialized views to be maintained  we choose additional views to materialize in order to minimize the overall view maintenance costs.
the expressions chosen for permanent materialization may be used in only one view maintenance plan  or may be shared between different views maintenance plans. we outline differences between our work and prior work in this area  in section 1.
1. we show how to determine the optimal maintenance plan for each individual view  given the choice of results for transient/permanent materialization.
maintenance of a materialized view can either be done incrementally or by recomputation. incremental view maintenance involves computing the differential   delta s  of a materialized view  given the  delta s of the base relations that are used to define the views  and merging it with the old value of the view. however  incremental view maintenance may not always be the best way to maintain a materialized view; when the deltas are large the view may be best maintained by recomputing it from the updated base relations.
our techniques determine the maintenance policy  incremental or recomputation  for each view in the given set such that the overall combination has the minimum cost.
1. we show how to make the above three choices in an integrated manner to minimize the overall cost.
we propose a framework that cleanly integrates the choice of additional views to be transiently or permanently materialized  the choice of whether each of the given set of  user-specified  views must be maintained incrementally or by recomputation  and the choice of view maintenance plans.
1. we have implemented all our algorithms  and present a performance study  using queries from the tpc-d benchmark  showing very significant benefits due to our techniques.
　although the focus of our work is to speed up view maintenance  and we assume an initial set of views have been chosen to be materialized  our algorithms can also be used to choose extra materialized views to speed up a workload containing queries and updates.
paper organization. related work is outlined in section 1. section 1 gives an overview of the techniques presented in this paper. section 1 describes our system model  and how the search space of the maintenance plans is set up. section 1 shows how to compute the optimal maintenance cost for a given set of permanently materialized views  and a given set of views to be transiently materialized during the maintenance. section 1 describes a heuristic that uses this cost calculation to determine the set of views to be transiently or permanently materialized so as to minimize the overall maintenance cost. section 1 outlines results of a performance study  and section 1 concludes the paper.
1.	related work
in the past decade  there has been a large volume of research on view maintenance  transiently materialized view selection  also known as multi-query optimization  and also on permanently materialized view selection. this work is summarized below. however  each of these problems have been addressed independently since the concerns were considered to be orthogonal; no prior work  to the best of our knowledge  has looked at addressing all of these problems in an integrated manner.
view maintenance. amongst the early work on computing the differential results of operations/expressions was blakeley et al. . gupta and mumick  provide a survey of view maintenance techniques.
　vista  describes how to extend the volcano query optimizer  to compute the best maintenance plan  but does not consider the materialization of expressions  whether transient or permanent.  and  propose optimizations that exploit knowledge of foreign key dependencies to detect that certain join results involving differentials will be empty. such optimizations are orthogonal and complementary to our work.
transiently materialized view selection  multi-query optimization . blakeley et al.  and ross et al.  noted that the computation of the expression differentials has the potential for benefiting from multi-query optimization . in the past  multi-query optimization was viewed as too expensive for practical use. as a result   and  do not go beyond stating that multi-query optimization could be useful for view maintenance. our recent work in  provides efficient heuristic algorithms for multi-query optimization  and demonstrates that multi-query optimization is feasible and effective.
　however  none of the work on multi-query optimization considers updates or view maintenance  which is the focus of this paper. using these techniques naively on differential maintenance expressions would be very expensive  since incremental maintenance expressions can be very large. we utilize the optimizations proposed by   but significant extensions are required to to take update costs into account  and to efficiently optimize view maintenance expressions.
permanently materialized view selection. there has been much work on selection of views to be materialized. one notable early work in this area was by roussopolous . ross et al.  considered the selection of extra materialized views to optimize maintenance of other materialized views/assertions  and mention some heuristics. the problem of materialized view selection for data cubes has seen much work  such as   who propose a greedy heuristic for the problem. gupta  extends some of these ideas to a wider class of queries. agrawal et al.  present heuristics for materialized view selection.
　the major differences between our work and the above work on materialized view selection can be summarized as follows:
1. earlier work in this area has not addressed optimization of view maintenance plans in the presence of other materialized views. earlier work simply assumes that the cost of view maintenance for a given set of materialized views can be computed  without providing any details.
1. earlier work does not consider how to exploit common subexpressionsby temporarily materializing them because of their focus on permanent materialization. in particular  common subexpressions involving differential relations cannot be permanently materialized.
1. earlier work does not cover efficient techniques for the implementation of materialized view selection algorithms  and their integration into state-of-the-art query optimizers. showing how to do the above is amongst our important contributions.
1.	overview of our approach
we extend the volcano query optimization framework  to generate optimal maintenance plans. this involves the following subproblems:
1. setting up the search space of maintenance plans
we extend the query dag representation of  and   which represents just the space of recomputation plans  to include the space of incremental plans as well. this new extension uses propagation-based differential generation  which propagates the effect of one delta relation at a time in a predefined order. our approach has a lower space cost of optimization as compared to using incremental view maintenance expressions  and is easier to implement.
propagation-based differential generation is explained in section 1  and the extended query dag generation is explained in section 1.
1. choosing the policy for maintenance and computing the cost of maintenance
we show how to compute the minimum overall maintenance cost of the given set of permanently materialized views  given a fixed set of additional views to be transiently materialized. in addition to computing the cost  the proposed technique generates the best consolidated maintenance plan for the given set of permanently materialized views. the maintenance plan chosen for each materialized view can be incremental or recomputation  based on costs.
maintenance cost computation is explained in section 1.
1. transient/permanent materialized view selection
finally  we address the problem of determining the respective sets of transient and permanently materialized views that minimize the overall cost. our technique uses  as a subroutine  the previously mentioned technique for computing the best maintenance policy given fixed sets of permanently and temporarily materialized views. the costs of materialization of transiently materialized views and maintenance of permanently materialized views are taken into account by this step.
we propose a greedy heuristic that iteratively picks up views in order of benefit - where benefit is defined as the decrease in the overall materialization cost if this view is transiently or permanently materialized in addition to the views already chosen. then  depending upon whether transient or permanent materialization of the view produces the greater benefit  the view is categorized as such.
the greedy heuristic is presented in section 1  and several optimizations of this heuristic that result in an efficient implementation are described in section 1.
1.	settingupthemaintenanceplan space
in this section  we describe how the search space of maintenance plans is set up. as mentioned earlier  our approach to incremental maintenance is based on the compact propagationbased differential generation technique. this is described in section 1. the query dag representation  used to represent the search space compactly  is described in section 1.
　in this paper  we assume that we are given an initial set of permanently materialized views. we may add more views to this set. we do not consider space limitations on storing materialized views in the main part of the paper  but address this issue in section 1.
　we assume that the updates  inserts/deletes  to relations are logged in corresponding delta relations  which are made available to the view refresh mechanism; for each relation   there are two relations and denoting  respectively  the  multiset of  tuples inserted into and deleted from the relation . the maintenance expressions in our examples assume that the old value of the relation is available  but we can use maintenance expressions based on the new values of the relations in case the updates have already been performed on the base relations.
　we assume that the given set of materialized views is refreshed at times chosen by users  which are typically at regular intervals. for optimization purposes  we need estimates of the sizes of these delta relations. in production environments  the rates of changes are usually stable across refresh periods  and these rates can be used to make decisions on what relations to materialize permanently. we will assume that the average insert and delete sizes for each relation are provided as percentages of the full relation size. the insert and delete percentages can be different for different relations. other statistics  such as number of new distinct values for attributes  in each refresh interval   if available  can also be used to improve the cost estimates of the optimizer.
1 propagation-baseddifferentialgeneration for incremental view maintenance
we generate the differential of an expression by propagating differentials of the base relations up the expression tree  one relation at a time  and only one update type  insertions or deletions  at a time. the differential propagation technique we use is based on the techniques used in  and .
　the differential of a node in the tree is computed using the differential  and if necessary  the old value  of its inputs. we start at the leaves of the tree  the base relations   and proceed upwards  computing the differential expressions corresponding to each node.
　for instance  the differential of a join   given inserts on relation   is computed using the differentials of and and the old full results of and . the differential result is empty if is used in neither nor . if is used only in   the differential is given by ; symmetrically if is used only in   the differential is given by
	. if	is used in both  the differential consists of
.
　the process of computing differentials starts at the bottom  and proceeds upwards  so when we compute the differential to   the differentials of the inputs have been computed already. the full results are computed when required  if they are not available already  materialized views and base relations are available already .
　extending the above technique to operations other than join is straightforward  using standard techniques for computing the differentials of operations  such as those in ; see  for a survey of view maintenance techniques.
　our search space includes differentials of all plans equivalent to	. in the case of joins  in particular  the search space will include plans where every intermediate result includes the differential of	. to illustrate this point  consider the view	. if we wish to compute the differential of the view when tuples are inserted into	  then the plans	and	would both be among the plans considered  and the cheapest plan is selected. similarly  if we wish to compute the differential of the view when tuples are inserted into	  then the plans and	would be amongst
the alternatives. using the differentials of a single expression  such as or   is not preferable for propagating all the base relation differentials.
　our optimizer's search space includes all of the alternatives for computing the differentials to   including the above two  and the cheapest one is chosen for propagating the differential of each base relation.
　propagating differentials of only one type  inserts or deletes  to one relation at a time  simplifies choosing of a separate plan for each differential propagation. it is straightforward to extend the techniques to permit propagation of inserts and deletes to a single relation together  to reduce the number of different expressions computed.
we assume that the updates to the base relations are propagated one relation at a time. after each one is propagated  the base relation is itself updated  and the computed differentials are applied to all incrementally maintained materialized views.1 we leave unspecified the order in which the base relations are considered. the order is not expected to have a significant effect when the deltas of all the relations are small percentages of the relation sizes: the relation statistics then do not change greatly due to the updates  and thus the costs of the plans should not be affected greatly by the order. for large deltas  our experimental results show that recomputation of the view is generally preferable to incremental maintenance  so the order of incremental propagation is not relevant.
　an alternative approach for computing differentials is to generate the entire differential expression  and optimize it  see  e.g.  . however  the resultant expression can be very large - exponential in the size of the view expression. optimizing such large expressions can be quite expensive  since query optimization is exponential in the size of the expression. moreover  creating differential expressions is difficult with more complex expressions containing operations other than join  see  e.g.  . in contrast  the process of propagating differentials can be expressed purely in terms of how to compute the differentials for individual operations  given the differential of their inputs. as a result it is also easy to extend the technique to new operations.
1	the query dag representation
in this section  we briefly describe the representation used in our algorithm to represent the space of recomputation and incremental maintenance plans for the given set of views.
　a query dag is a directed acyclic graph whose nodes can be divided into equivalence nodes and operation nodes; the equivalence nodes have only operation nodes as children and operation nodes have only equivalence nodes as children. we first explain how the space of recomputation plans is represented as a query dag. this is followed by a description of how this query dag is refined to represent differential plans as well.
1.1	query dag representation for recomputation plans
an operation node in the query dag corresponds to an algebraic operation  such as join      select      etc. it represents the expression defined by the operation and its inputs. an equivalence node in the query dag represents the equivalence class of logical expressions that generate the same result set  each expression being defined by a child operation node of the equivalence node  and its inputs.
　figure 1 shows a query dag for the view a b c. note that the dag has exactly one equivalence node for every subset of ; the node represents all ways of computing the joins of the relations in that subset. though the query dag in this example represents only a single view

 the differentials must be logically applied. the database system can give such a logical view  yet postpone physically applying the updates. by postponing physical application  multiple updates can be gathered and executed at once  reducing disk access costs.

figure 1: query dag for a b c. commutativity not shown; every join node has another join node with inputs exchanged  below the same equivalence node.
a b c  in general  as indicated in figure 1  a query dag can represent multiple views in a consolidated manner  with common subexpressions represented only once. simple
subsumption derivations  whereby a result such as
can be computed from a result   or can be generated from   are also introduced when creating the consolidated query dag.
1.1	incorporating incremental plans
consider a database consisting of relations: . then  for each equivalence node in the query dag described above  we introduce additional equivalence nodes
	  where	and	 for	  corre-
spond to the differentials of with respect to and respectively. for example  the equivalence node
is refined into four additional equivalence nodes
	 	 	and
.
　we now describe the structure of   . for each child operation node of   there exists a child operation node of   representing the differential of with respect to the corresponding base relation update. in the example above  consider equivalence node having a child operation node which is a join operation; the children of are the equivalents nodes representing and . the node has as its child an operation node which is a join operation  and the children of are the equivalence nodes for and
　. the other nodes are similar in structure.1 as can be seen from the above example  the children of can be full results as well as differentials. the rationale of this construction was given in section 1. as also mentioned in that section  the approach is easily extended to other operations.
　the equivalence node represents the full result; but this result varies as successive differentials are merged with it. for cost computation purposes  the system keeps an array with   where is the list of logical properties  such as schema and estimated statistics  of the old result and   for   is the list of logical properties of the result after the result has been merged with the

 the structure is a little more complicated when a relation is used in both children of a join node  requiring a union of several join operations. the details are straightforward and we omit them for simplicity.
differentials given by	.
space-efficient implementation. it might seem that by including all the differential expressions for each equivalence node  we have increased the size of the query dag by a factor of . however  our implementation reduces the cost by piggybacking the differential equivalence and operation nodes on the equivalence and operation nodes in the original query dag. these implementation details are explained next; however  for ease of explanation  in the rest of the paper  we stick to the above logical description.
　for space efficiency  the equivalence nodes for each differential are not created separately in our implementation. instead  each equivalence node stores an array   where logically represents the differential equivalence node   and contains:  a  logical properties of the differential result   and  b  the best plan for computing .
　if does not depend on a relation   or if there is no corresponding update  then the logical properties and best plan
  a  and  b  above  for	and	are set as null.
in addition  as in the original representation  the equivalence node stores the best plan for  and cost of  recomputing the entire result of the node after all updates have been made on the base relations.
physical properties. the query dag representation can be extended to incorporate physical properties   such as sort order  that do not form part of the logical data model. the extension results in a physical query dag  in which an equivalence node in the query dag is refined to multiple physical equivalence nodes  one per required physical property. our search algorithms handle physical properties  but to keep our description simple  we do not explicitly consider physical properties further.
　however  it is important to note that  as suggested by   we model the presence of an index on a result as a physical property of the result. our techniques thereby perform index selection as a special case of physical property selection. in fact  significant performance benefits are achieved by selecting appropriate indices for permanent materialization  especially when the number of inserts/deletes is a small percentage of the relation size.
1.	maintenance costcomputation
in this section  we derive formulae for the total maintenance cost for a set of views materialized permanently and a set of views materialized temporarily. the optimizer basically traverses the query dag structure  applying these formulae  to find the overall cost.
　the set can have views corresponding to entire results  e.g.    as well as views corresponding to differentials  e.g.  . in contrast  the set can only have views corresponding to entire results; this is because the differentials are only used during view maintenance.
the computation cost of the equivalence node   denoted   is computed as follows  where is the set
of children operation nodes of .
if
	if	 i.e.	is a relation 
in terms of forming the execution plan  the above equation represents the choice of the operation node with the minimum cost in order to compute the expression corresponding to the equivalence node .
	the computation cost of an operation node	  denoted
  is:
where is the  local  computation cost of the operation   is the set of children equivalence nodes of
   and	is the cost of computing the child equivalence node   given by:
if if
where is the cost of reusing the result of the materialized view .
　during transient materialization  the view is computed and materialized on the disk for the duration of the maintenance processing. thus  the cost of transiently materializing a view
	  denoted by	  is:
where   is the cost of materializing the view  on disk  assuming materialized views do not fit in memory .
　further  for a given   the cost of recomputing the result from the base relations is ; and the cost of computing the differential     is . let denote the cost of merging the differential corresponding to with the view after the differentials corresponding to have already been merged. then  the cost of incrementally maintaining   denoted by
  is:
on the other hand  maintenance by recomputation involves computing the view and materializing it  replacing the old value of the view. the recomputation maintenance cost  denoted by	  is:
where   as before  is the cost of materializing the view. notice that above is the same as
　　　　　　　　  the cost of transiently materializing derived earlier. as such  we do not consider materializing a view permanently and maintaining using recomputation  unless it was already specified as permanently materialized.
for  if recomputation is the cheapest way of maintaining a view  we may as well materialize it transiently: keeping it permanently would not help the next round of view maintenance. thus  the cost of maintaining the permanently materialized view   denoted by   is as follows  where is the set of views given as already materialized in the system.
if if
for   the choice corresponds to selecting the refresh mode - incremental refresh or recomputation - depending on whichever is cheaper.
　thus  the total cost incurred in maintaining the materialized views in given that the views in are transiently materialized  denoted   is:
　given the set of views already materialized in the system  we need to determine the set of views to be
permanently materialized  as well as the set of views to be transiently materialized  such that is minimized. in the next section  we propose a heuristic greedy algorithm to determine and .
　as mentioned earlier  the optimizer performs a depth-first traversal of the query dag structure  applying these formulae at each node  to find the overall cost.
1. transient/permanentmaterialized view selection
we now describe how to integrate the choice of extra materialized views with the choice of best plans for view maintenance. in section 1  we present the basic algorithm for selecting the two sets of views for transient and permanent materialization respectively  followed by a discussion of some optimizations and extensions in section 1.
1	the basic greedy algorithm
given a set of results and already chosen to be respectively permanently and transiently materialized  and a equivalence node   the benefit of additionally materializing
 	  is defined as:
if	is a full result if	is a differential
using the expression for derivedin the previous section  along with the observations that  a  if is a full result  then for all  
	  and also that  b  for all	 
procedure greedy
	input:	  the set of equivalence nodes
for the initial materialized views
  the set of candidate equivalence nodes for materialization
output:	  the set of equivalence nodes to be materialized permanently
     the set of equivalence nodes to be materialized transiently
begin
	=	;
	while  	 
	l1:	pick the node
with the highest
	if  	 
　　break; /* no further benefits  stop */ if  	is a full result and
 
else
return
end
figure 1: the greedy algorithm for selecting views for transient/permanent materialization
 
the above can be simplified to:
where	  the gain due to additionally materializing	  is given by:
and	  the investment in additionally materializing	  is given by:
if	is a full result if	is a differential
　figure 1 outlines a greedy algorithm that iteratively picks nodes to be materialized. the procedure takes as input the set of candidates  equivalence nodes  and their differentials  for materialization  and returns the sets and of equivalence nodes to be materialized permanently and transiently  respectively. is initialized to   the set of equivalence nodes for the initial materialized views  while is initialized as empty. at each iteration  the equivalence node with the maximum benefit is selected for materialization. if is a full result  then it is added to either or based on whether maintaining it or transiently materializing it is cheaper; if is a differential  then it is added to since it cannot be permanently materialized.
naively  the candidate set	can be the set of all equivalence nodes in the query dag  full results as well as differentials . in section 1  we consider approaches to reduce the candidate set.
1	optimizations
three important optimizations to the greedy algorithm for multi-query optimization are presented in . we extend these to handle differentials  as follows.
1. there are many calls to  and thereby to and   at line l1 of figure 1  with different parameters. a simple option is to process each call to the above independent of other calls. however  observe that and change minimally in successive calls - successive calls take parameters of the form
or   where only varies. that is  if one call considers materializing a set of the form  or
            the next call would consider materializing a different set of the form  or  . the best plans computed earlier does not change for nodes that are not ancestors of either or . it makes sense for a call to leverage the work done by a previous call by recomputing best plans only for ancestors of and .
the incremental cost update algorithm presented in  maintains the state of the query dag  which includes previouslycomputed best plans for the equivalencenodes  across calls  and may even avoid visiting many of the ancestors of and . we modify the incremental cost update algorithm to handle differentials as follows.
 a  if the full result of a node is materialized  we update not only the cost of computing the full result of each ancestor node  but also the costs for the differentials of each ancestor node since the full result may be used in any of the differentials. propagation up from an ancestor node can be stopped if there is no change in cost to computing the full result or any of the differentials.
 b  if the differential of a node with respect to a given update is materialized  we update only the differentials of its ancestors with respect to the same update. propagation can stop on ancestors whose differentials with respect to the given update do not change in cost.
1. with the greedy algorithm as presented above  in each iteration the benefit of every candidate node that is not yet materialized is recomputed since it may have changed. the monotonicity optimization is based on the assumption that the benefit of a node cannot increase as other nodes are chosen to be materialized - while this is not always true  it is often true in practice. the monotonicity optimization makes the above assumption  and does not recompute the benefit of a node if the new benefit of some node is higher than the previously computed benefit of . it is clearly preferable to materialize at this stage  rather than - assuming monotonicity holds  the benefit of could not have increased since it was last computed  and it cannot be the node with highest benefit now  hence its benefit need not be recomputed now. thus  recomputations of benefit are greatly reduced.
1. it is wasteful to transiently materialize nodes unless they are used multiple times during the refresh. an algorithm for computing sharability of nodes is proposed in   which detects equivalence nodes that can potentially be used multiple times in a single plan. we consider differential results for transient materialization only if the corresponding full result is detected to be sharable.
the sharability optimization cannot be applied to full results in our context  since a full result may be worth materializing permanently even if it is used in only one query. thus all full results are candidates for optimization.
due to lack of space  we omit details of all the above optimizations.
　we tried out an optimization where all differentials of an expression are considered as a single unit of materialization. that is  the greedy algorithm either chooses all differentials for materialization  based on the benefit of materializing all of them   or none.  as a post-pass of greedy  any materialized result that is not used is discarded.  one benefit of the optimization is that the number of candidates considered by the greedy algorithm decreases  leading to a reduction in optimization time. although the optimization could possibly result in somewhat worse plans  there may also be cases where it may give a better plan. this can occur  for example  when the best plan with no differentials materialized uses recomputation  and materializing any one differential will not change the best plan  and thus have no benefit   but materializing all differentials at once may change the best plan to incremental computation and thus have a positive benefit.
1	extensions
the algorithms outlined above can be extended to deal with limited space for storing materialized results by modifying the greedy algorithm to prioritize results in order of benefit per unit space  computed by dividing the benefit by the size of the result . if the space available for permanent and transient materialized results are separate  we can modify the algorithm to continue considering results for permanent  resp. transient  materialization even after the space of transient  resp. permanent  materialization is exhausted.
1.	performance study
we implemented the algorithms described earlier for finding optimal plans for view maintenance. as mentioned earlier  the implementation performs index selection along with selection of results to materialize. the implementation was performed on top of an existing query optimizer.
1	performance model
we used a benchmark consisting of views representing the results of queries based on the tpc-d schema. in particular  we separately considered the following two workloads:
set of views workload. a set of 1 views  1 with aggregates and 1 without  on a total of 1 distinct relations. there is some amount of overlap across these views  but most of the views have selections that are not present in other views  limiting the amount of overlap.
single views workload. the same views as above  but each optimized and executed separately  and we show the sum of the view maintenance times. since the views are optimized separately  sharing between views cannot be exploited.
the purpose of choosing a simple workload in addition to the complex workload is to show that our methods are very effective not only for big sets of overlapping complex views  where one might argue that simple multi-query optimization may be as effective  but also for singleton views without common subexpressions  where a technique based exclusively on multi-query optimization would be useless.
　the performance measure is estimated maintenance cost. the cost model used takes into account number of seeks  amount of data read  amount of data written  and cpu time for in-memory processing. our cost model is fairly sophisticated and  as reported in our earlier work   we have verified its accuracy by comparing its estimates with numbers obtained by running queries on commercial database systems. we found close agreement  within around 1 percent  on most queries  which indicates that the numbers obtained in our performance study are fairly accurate.
　we provide performance numbers for different percentages of updates to the database relations; we assume that all relations are updated by the same percentage. in our notation  a 1% update to a relation consists of inserting 1% as many tuples are currently in the relation.
　we assume a tpc-d database at scale factor of 1  that is the relations occupy a total of 1 mb. the buffer size is set at 1 blocks  each of size 1kb  for a total of 1 mb  although we also ran some tests at a much smaller buffer size of 1 blocks. however  the numbers are not greatly affected by the buffer size  and in fact smaller buffer sizes can be expected to benefit more from sharing of common subexpressions. the tests were run on an ultrasparc 1  with 1 mb of memory.
1	performance results
the purpose of the experiments reported in this section is to:
1. verify the efficacy of transient and permanent materialization of additional views  section 1.1  
1. verify the efficacy of adaptive determination of maintenance policy for each permanently materialized view  section 1.1   and
1. establish that our methods are indeed practical by showing that the overheads of our optimization-based techniques are reasonable  and that our methods scale with respect to increasing number of views  section 1.1 .
1.1	effect of transient and permanent materialization
we executed the following variations of our algorithm:
no materialization. neither transient nor permanent materialization of additional views is allowed. that is  only the given set of initial views is permanently materialized and maintained without any sharing. this corresponds to the current state of the art.
only transient. transient materialization is allowed  but permanent materialization of additional views is disallowed. this corresponds to using multi-query optimization in view maintenance.
transient and permanent. both transient and permanent materialization of additional results is allowed. this corresponds to the techniques proposed in this paper.
in all the cases  the maintenance policy of each of the views is decided based on whether recomputation and incremental computation is cheaper  given the constraints in each case as above. all the numbers reported incorporate the optimization of treating all differentials of an expression as a single unit of materialization; we consider the effect of not using the optimization later. the results for the single view workload and the set of views workload are reported in figure 1.
　for the single-view workload  transient materialization is not useful if the view maintenance plan used is recomputation  but when incremental computation is used  full results can potentially be shared between differentials corresponding to updates of different base relations. indeed  we found several such instances at low update percentages  although they did not have a large impact on the cost. at higher update percentages we found fewer such occurrences  and using only transient materialization did not offer much benefit. however  permanent materialization of intermediate results reduces the overall materialization cost by nearly 1% for smaller update percentages  the smallest update percentage we considered was 1% . these results clearly illustrate the efficacy of the methods proposed in this paper over and above multi-query optimization.
　the set of views workload has a significant amount of overlap among the constituent views. thus  the reduction  as high as 1%  in the overall maintenance cost due to only transient materialization is as expected. permanent materialization has an even more significant impact in this case  and further reduces the resulting in a total reduction of up to 1% at 1% update. the gains decrease with update percentage  but remain substantial.
　recall from our discussion in section 1 that all additional permanently materialized nodes are always maintained incrementally  since if recomputation-based maintenance of these views is cheaper than incremental maintenance  then they would be chosen for transient materialization instead of permanent materialization. now  the cost of incremental maintenance increases with the size of the updates; for larger updates  recomputation of a permanently materialized view is a better alternative than incremental maintenance  so a smaller fraction of views are permanently materialized. these two facts together account for the slightly decreasing advantage of transient cum permanent materialization over only transient materialization as update percentages increase  as is clear from the convergence of the respective plots in figure 1 for either workload.

	update percentage	update percentage
	single views	set of views
figure 1: effect of transient and permanent materialization　comparing across the two workloads reveals an interesting result: the cost of maintenance without selecting additional materialized view is less for the set of views than for the single view workload  even though they have the same set of queries. the reason is that in the case of set of views  the maintenance of a view can exploit the presence of existing materialized views  even without selecting additional materialized views. our optimizer indeed takes such plans into consideration even when it does not select additional materialized views.
　we also executed tests on a variant of our algorithm  which we call no differential  where materialization of differential results is turned off. full results are still permitted to be materialized  and may be maintained either incrementally or by recomputation. for the single view benchmark  there is no sharing of differential results  so there was no difference. for the set of views benchmark  we found that there were significant benefits at low update percentages  where incremental computation is more likely to be used . for instance at 1% updates  the cost went up to 1 seconds from 1 seconds  or roughly 1%  when materialization of differential results was turned off. even at 1% updates  there was an increase of about 1%  but by 1% the difference became small  since recomputation is used more often.  we omitted the plots for the  no differential  case from our graphs to avoid clutter.  these results clearly indicate the importance of materializing and sharing both differential and full results.
　we also tested the effect of treating the differentials of an expression as separate units of materialization instead of considering them as a single unit. we found that this roughly doubled the time taken for greedy optimization  across the whole range of update percentage  yet yet made no significant difference to the plans generated. thus the optimization of considering all differentials as a single unit has a significant benefit  at no cost  on all the examples we considered.
　to summarize this section  to the best of our knowledge ours is the first study that demonstrates quantitatively the benefits of materializing extra views  transiently or permanently  to speed up view maintenance in a general setting. earlier work on selection of materialized views  as far as we are aware  has not presented any performance results except in the limited context of data cubes or star schemas . 1.1 effectofadaptive maintenance policyselection
in the current database systems  the user needs to specify the maintenance policy  incremental or recomputation  for a materialized view during its definition . in this section  we show that an a priori fixed specification as above may not be the a good idea  and make a case for adaptively choosing the maintenance policy for a view in an adaptive manner.
we explored the following variants of our algorithm:
forced incremental. all the permanent materialized views  including the views given initially as well as the views picked additionally by greedy are forced to be maintained incrementally.
forced recomputation. incremental maintenance is disallowed and all the permanent materialized views are forced to be recomputed.
adaptive. the maintenance policy  incremental or recomputation  for each permanently materialized view is chosen based on the goal of minimizing the overall maintenance cost; one or the other may be chosen for a given view at different update percentages. this corresponds to the techniques proposed in the paper.
in all the cases  additional transient and materialized views were chosen by executing greedy as described earlier in the paper. the results of executing the above variants on each of our workloads are plotted in figure 1.

	update percentage	update percentage
	single views	set of views
figure 1: effect of adaptive maintenance policy selection　the graphs show that incremental maintenance may be much more expensive than recomputation; the incremental maintenance cost increases sharply for medium to large update percentages - by even around 1% for very high update percentages. in both the workloads  the adaptive technique performs better than both forced incremental and forced recomputation; this extra improvement  by up to 1% for the single-view workload and 1% for the set of views workload  is due to its ability to adaptively choose incremental maintenance or recomputation on a per-view basis for the initial as well as additionally materialized views. however  the difference between adaptive and forced recomputation for either workload decreases slightly with increasing update percentage. this is because for large update percentages  incremental maintenance is expensive  and hence every view is recomputed.
　these observations clearly show that blindly favoring incremental maintenance overrecomputation may not be a good idea  this conclusion is similar to the findings of vista  ; and make a case for adaptively choosing the maintenance policy for each view  as done by our algorithms. the ability to mix different maintenance policies for different subparts of the maintenance plan  even for a single view  is novel to our techniques  and not supported by .
1.1	overheads and scalability analysis
to see how well our algorithms scale up with increasing numbers of views and relations  we used the following benchmark. the benchmark uses 1 relations  to   with an identical schema denoting part id  subpart id and number. over these relations  we defined a set of 1 views to : the view was a star query on four relations     and   with joined with
       and . we then grouped these views into 1 sets  where the set consisted of the views
           which together access relations. for each we measured  a  the memory requirements of our algorithm and  b  the time taken by our algorithm  and report the same in figure 1.
the figure shows that the memory consumption of our algorithm increases practically linearly with the number of views in the set. the reason for this is that the memory usage is basically in maintaining the query dag  and for our view set  the increase in the size of the query dag is constant per additional view added to the dag  with a fixed number of base relations . the memory requirement for the view set   containing 1 views on a total of 1 relations  is only about 1 mb.
　further  addition of a new view from our view set to the query dag increases the breadth of the dag  not its height  we think this is the expected case in reality - most views are expected to be of similar size and with only partial mutual overlap . since the height remains constant  the time taken per incremental cost update  ref. section 1  remains constant . however  the number of these incremental cost updates grows quadratically with increasing number of views. this accounts for the quadratic growth in the time spent by our algorithm with increasing number of views  as shown in figure 1. however  despite the quadratic growth  the time spent on the 1-relation 1-view set was less than a couple of minutes. this is very reasonable for an algorithm that needs to be executed only occasionally  and which provides savings of the order of 1's of minutes on each view refresh. for the set of 1 views in the set of views benchmark  the optimization time was around 1 seconds across the range of update percentages  which is quite acceptable.
　thus  we conclude that the memory requirements of our algorithm are reasonable and scale well with increasing number of views. the time taken shows quadratic growth  but this growth is slow enough to make the algorithm practical for reasonably large sets of views.
1.	conclusions and future work

	1	1	1	1	1	1
	number of views	number of views
figure 1: scalability analysis on increasing number of viewsthe problem of finding the best way to maintain a given set of materialized views is an important practical problem  especially in data warehouses and data marts  where the maintenance windows are shrinking. we have presented solutions that exploit commonality between different tasks in view maintenance  to minimize the cost of maintenance. our techniques have been implemented on an existing optimizer  and we have conducted a performance study of their benefits. as shown by the results in section 1  our techniques can generate significant speedup in view maintenance cost  and the increase in cost of optimization is acceptable.
　future work includes implementing the extensions stated in section 1 to handle limited space. another direction of extension would be to select materialized views in order to speed up a workload of queries. the greedy algorithm can be modified for this task as follows: candidates would be final/intermediate results of queries  and benefits to queries would be included when computing benefits. longer term future work would include dealing with large sets of queries efficiently. we also plan to consider extensions of our work to a dynamic query result caching environment.
