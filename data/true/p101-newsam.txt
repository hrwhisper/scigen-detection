this work represents an initial investigation into determining whether correlations actually exist between metadata and content descriptors in multimedia datasets. we provide a quantitative method for evaluating whether the hue of images on the www is correlated with the occurrence of color-words in metadata such as urls  image names  and attendant text. it turns out that such a correlation does exist: the likelihood that a particular color appears in an image whose url  name  and/or attendant text contains the corresponding color-word is generally at least twice the likelihood that the color appears in a randomly chosen image on the www. while this finding might not be significant in and of itself  it represents an initial step towards quantitatively establishing that other  perhaps more useful correlations exist. these correlations form the basis for exciting novel approaches that leverage semi-supervised datasets  such as the www  to overcome the semantic gap that has hampered progress in multimedia information retrieval for some time now.
categories and subject descriptors
h.1  information storage and retrieval : clustering; information filtering; retrieval models.
general terms
algorithms.
keywords
multimedia and metadata data mining  semi-supervised learning  image content descriptors.
1. introduction
the impasse presented by the proverbial semantic gap has hampered progress in multimedia information retrieval over the past several years. the early successes that promised access to multimedia data based solely on its content without manual annotation have failed to develop into useable systems. content descriptors that can be automatically extracted from images  such as color and texture  provide limited high-level information and usually only in highly constrained situations. focus needs to be shifted away from developing new content descriptors to investigating novel ways in which metadata that is available without manual annotation can aid multimedia information retrieval. this work stipulates that one promising approach to addressing the semantic gap is to leverage the semi-supervised multimedia datasets that are appearing in our information society.
early investigations into leveraging semi-supervised datasets are encouraging. examples include:
  searching for images on the world wide web  www  using image urls  image names  image alt tags and attendant text on the webpage containing the images. this includes commercial systems such as google's image search  and yahoo's image search .
  searching for images on the www using a combination of textual information and content descriptors .
  searching for images on the www using category structure  textual information  and content descriptors .
  using annotated stock photography or art collections to learn statistical word-descriptor correlations to perform auto-annotation or auto-illustration .
these investigations suggest that using available metadata  such as urls  annotations  etc.  instead-of or in-addition-to content descriptors results in better performance than solely relying on content descriptors alone. this  in turn  suggests that the metadata and image content are correlated  but improved performance is only anecdotal evidence of such a correlation. the work presented in this paper represents initial investigations into whether such correlations actually exist. we focus on the particular question of whether the colors or hues of images on the www are correlated with the occurrence of color-words  such as red or blue  in the urls  image names  and attendant text corresponding to the images. the existence of such a correlation might not have direct application  such as searching for images on the www  but serves to provide initial insight into the nature of other correlations that might prove more useful.
1. the approach
in summary  the objective is to estimate the likelihood that a particular color appears in an image on the www given that the corresponding color-word occurs in the metadata associated with the image. this metadata includes the image url  the image name  and the text  if any  that appears in attendance with the image on the webpage. this section describes the steps taken towards this end. first  nearly 1 million images and their metadata are downloaded from the www. next  hue histograms are computed for each image. finally  the conditional hue probabilities are estimated by averaging the hue histograms over subsets of images corresponding to different hypotheses  such as the word red occurring in the attendant text. the conditional color likelihoods are then computed based on these conditional probabilities.
1 acquiring the images and attendant text
the first step is to acquire a sizable set of images and their metadata from the www. this data was generously provided by till quack from the cortina content-based web retrieval dataset . the cortina dataset was collected using www uniform resource locators  urls  from the dmoz open directory project . the entire dmoz directory can be downloaded as a resource description framework file which can be parsed for urls. only urls from the shopping and recreation categories were used in creating the cortina dataset. these urls were used to locate webpages containing images. the url for each image was then stored in a database along with other key information extracted from the webpage. this includes up to 1 words above and 1 words below the image. these word sets constitute the attendant text utilized in this paper.
the cortina dataset also includes two color descriptors for each image. we decided  however  that these descriptors were not appropriate for our analysis and so we downloaded each image again using the urls in the cortina dataset to extract our own color descriptor termed hue histograms. only 1 1 of the 1 million image urls obtained from the cortina dataset were still valid. of these  1 were located on webpages that contained attendant text.
1 hue histograms
our analysis required a compact characterization of the color distribution of each image. rather than use a traditional multi-dimensional histogram  we derived a one-dimensional histogram of just the hue values of the pixels in an image. the pixel values are first transformed from the red-greenblue  rgb  colorspace to a hue-lightness-saturation  hls  colorspace. this hue channel is similar to an angle on the color-wheel in that its range from 1 to 1 corresponds to the colors red  orange  yellow  etc.  through pink  and then back to red again. the hue histograms are computed by binning the hue channel into 1 one-degree intervals.
the hls colorspace presented some expected problems. first  even very dark  low lightness value  or very light  high lightness value  colors have associated hue values  the colors corresponding to the hue values are not really perceivable. to
colorcentral hue valuehue rangered1-1orange1-1yellow1-1green1-1blue1-1purple1-1pink1-1table 1: the seven colors and their central hue values and hue ranges.
deal with this we added two additional histogram bins  one for pixels with lightness values below an empirically chosen threshold and another for pixels with lightness values above an empirically chosen threshold. these bins correspond to the  colors  black and white  respectively. the second problem is that grey-ish colors also have an associated hue. this was dealt with by adding a third histogram bin for pixels with saturation values below another empirically chosen threshold.
the complete hue histograms contain 1 bins. three for black  white  and grey  and 1 for the hue values at onedegree intervals. table 1 indicates the central hue values for the seven colors analyzed: red  orange  yellow  green  blue  purple  and pink. it also indicates the range of hues for each color. the ranges for adjacent colors overlap by 1 degrees to account for the ambiguous regions between colors.
finally  the hue histograms are normalized so that they sum to one. this accounts for the different image sizes and makes the histograms interpretable as estimates of probability density functions  pdfs .
1 conditional hue pdfs
the conditional hue pdfs are estimated by averaging the hue histograms corresponding to a particular hypothesis. for example  if histi h  is the value of the hue histogram for image i at hue h then the conditional hue pdf for the hypothesis of  all images whose attendant text contains the word red   is estimated as:
1
p h|red （ text  = #  :	x histi h  .  1 
	i	red （ text 
i:red（text
1 conditional color likelihoods
finally  the conditional hue pdfs  such as p h|red （ text   are used to compute the conditional likelihoods that colors occur in sets of images satisfying hypotheses. for example  the likelihood that the color blue occurs in images whose attendant text contains the color-word blue is computed as:
1
p blue （ image|blue （ text  = x p h|blue （ text  .  1 
                                           h=1 the bounds on the summation for each of the seven color considered are listed in table 1. these conditional color likelihoods can be used to compare different hypotheses  such as color-words appearing in attendant text  urls  image names  etc.  with each other as well as with baseline hypotheses such as the color blue occurring in any image on the www which can be computed as:
1
p blue （ image|all images  = x p h|all images  .	 1 
h=1
1. experiments and results
the conditional hue pdfs and conditional color likelihoods are computed for a variety of hypotheses as well as the baseline hypothesis. this section describes these hypotheses and their results.
1 hypotheses
the conditional hue pdfs and conditional color likelihoods are computed for a total of eight hypotheses:
all this is the baseline of all 1 1 images.
all with text the 1 images with attendant text  many images appear alone on webpages .
color-word （ text a color-word occurs in the attendant text for an image.
color-word （ url a color-word occurs in the url for an image.
color-word （ image name a color-word occurs in the image name. the image name is considered as the substring in the url after the rightmost backslash.
color-word （ text url conjunction of two hypotheses above.
color-word （ text image name conjunction of two hypotheses above.
only color-word （ text a color-word occurs in the attendant text for an image without any other color-words.
the color-words considered are red  orange  yellow  green  blue  purple  and pink. the meaning of occurrence varies by hypothesis above. in the case of attendant text  the colorword must occur as a separate word; that is  it must be preceded and followed by a non-alphabetic character. this constraint is not enforced for occurrence in a url or image name. thus  the color-word red is considered to occur in the url http://threddies.com/images/tinysageside.jpg and the image name redruff computer.jpg. this likely introduces noise but considerably more complex string matching algorithms would be required to identify only those urls and image names that contain the color-word red as a  separate word  as in the attendant text.
1 conditional hue pdf results
the conditional hue pdfs are shown for several hypothesis in figure 1. note that the pdfs are plotted only for hue values corresponding to the 1 color-bins in the hue histograms. the three bins corresponding to black  white and grey have been left out since their magnitudes are generally much larger and their values are not informative for our analysis. thus  the pdfs as plotted do not necessarily sum to one. note  also  that the pdfs have been smoothed by averaging the values over five-degree intervals.
figures 1 a  through 1 f  show the pdf for the proposed hypothesis with a solid line  and the pdf for the baseline hypothesis  all images  with a dashed line for comparison.
the first thing to note from figure 1 is that the baseline pdf is not uniform. there appear to be distinct peaks around the red-orange and green-blue regions. second is that there is approximately only a 1% probability that a pixel is not black  white  or grey. the images corresponding to the baseline hypothesis are approximately 1% black  1% white  and 1% grey.
the pdfs in figure 1 all correspond to hypotheses relating to the color-word red. thus  it is significant that they all exhibit the following noteworthy characteristics. first  they are all greater than the baseline pdf for hue values corresponding to red. second  they are generally all less than the baseline pdf for other hue values. this indicates that there is a correlation between the color-word red occurring in the attendant text  url and/or image name  and the color red appearing in the image.
the conditional hue probabilities for the other color are similar to those for red but space restrictions prevent them from being included.
1 conditional color likelihood results
the conditional color likelihoods allow a more quantitative comparison of the hypotheses. table 1 shows the conditional color likelihoods for a number of hypotheses. the rows represent the hypotheses  such as the color-word red occurring in both the attendant text and url  red （ text url  for an image  and the columns represent the color likelihood conditioned on the hypothesis. the maximum for each column is shown in bold. there is also a column indicating the number of images that satisfy the hypothesis.
the results in table 1 again demonstrate there is a correlation between a color-word occurring in attendant text  url and/or image name  and the color appearing in an image. the correlations are strongest for the color-word occurring in the image name but the correlations for the other hypotheses are not significantly weaker. in general  the likelihood that a color appears in an image given the corresponding color-word occurs in the attendant text  url and/or image name is at least twice the baseline likelihood.
the following specific observations can be made from table 1:
  the hypotheses for the color-word appearing in the image name maximizes the conditional color likelihoods of all hypothesis for orange  yellow  green  blue  and purple  and there is the correct correspondence between the color-word and color; i.e.  p orange|orange （ image name  is maximal.
  the hypothesis for the color-word red appearing in both the text and image name maximizes the likelihood that red appears in the image.
  the hypothesis for the color-word pink appearing in both the text and url maximizes the likelihood that pink appears in the image.
  in all cases but two  the conditional color likelihood for a hypothesis is maximum for the correct color. i.e.  p red|red （ text  is greater than p red|color-word （ text  for any other color-word. the exceptions are p red|color-word （ url  and p red|color-word （ image name .
  the conditional likelihoods  bleed  into adjacent colors. not only are the conditional likelihoods corresponding to the correct color-words large but so are the conditional likelihoods for adjacent colors on the hue axis.
1. discussion
this work represents an initial investigation into determining whether correlations actually exist between metadata and content descriptors in multimedia datasets. we provide a quantitative method for evaluating whether the hue of images on the www is correlated with the occurrence of color-words in metadata such as urls  image names  and attendant text. it turns out that such a correlation does exist: the likelihood that a particular color appears in an image whose url  name  or attendant text contains the corresponding color-word is generally at least twice the likelihood of the color appears in a randomly chosen image on the www. as pointed out in the introduction  this finding might not be significant in and of itself  but represents an initial step towards quantitatively establishing that other  perhaps more useful correlations exist. these correlations form the basis for exciting novel approaches that leverage semi-supervised datasets  such as the www  to overcome the semantic gap that has hampered progress in multimedia information retrieval for some time now.
as this is only an initial investigation  there are plenty of directions for this work to proceed in. establishing quantitative ways to evaluate correlations between higher-level textual concepts and image content would be very useful for designing the learning algorithms for tasks such as retrieval  classification  and auto-annotation.
1. acknowledgments
this work was performed in part under the auspices of the
u.s. department of energy by university of california  lawrence
livermore national laboratory under contract w-1-eng1.
