expense reimbursement is a time-consuming and labor-intensive process across organizations. in this paper  we present a prototype expense reimbursement system that dramatically reduces the elapsed time and costs involved  by eliminating paper from the process life cycle. our complete solution involves  1  an electronic submission infrastructure that provides multi-channel image capture  secure transport and centralized storage of paper documents;  1  an unconstrained data mining approach to extracting relevant named entities from un-structured document images;  1  automation of auditing procedures that enables automatic expense validation with minimum human interaction. 
　extracting relevant named entities robustly from document images with unconstrained layouts and diverse formatting is a fundamental technical challenge to image-based data mining  question answering  and other information retrieval tasks. in many applications that require such capability  applying traditional language modeling techniques to the stream of ocr text does not give satisfactory result due to the absence of linguistic context. we present an approach for extracting relevant named entities from document images by combining rich page layout features in the image space with language content in the ocr text using a discriminative conditional random field  crf  framework. we integrate this named entity extraction engine into our expense reimbursement solution and evaluate the system performance on large collections of real-world receipt images provided by ibm world wide reimbursement center.  
categories and subject descriptors: h.1  information storage and retrieval : general; i.1  artificial intelligence : learning; h.1  information systems applications : office automation; i.1  document and text processing : document capture - optical character recognition  ocr ; 
general terms: algorithms  experimentation  design 
keywords: named entity extraction  learning  document layout analysis  conditional random fields. 
 
1. introduction 
　expense reimbursement is a tedious and laborious process for organizations of all sizes today. even though policies and regulations defining the process vary across organizations and industries  corporate expense reimbursement is facing a set of common challenges. a complete solution to this problem requires technical innovations in the following three key areas. 
 1  a generalized paper-free framework for capturing  transporting  and storing paper documents in digital image form 
　in spite of progress made with electronic tools  paper consumption in the office is growing and paper continues to inhibit business process innovation. expense reporting is a classic example where web-based applications are mostly available in the organization  but the few remaining paper receipts continue to result in unnecessary costs and delays. the problem is that organizations require supporting receipt documents to prove the validity of submitted reimbursement claims. currently  without any pervasive mechanism for electronic submission  paper receipts have to be mailed for centralized processing  together with printed cover sheets. to protect against the risk of loss in the mail  the package is often copied  which again creates more paper. even worse than handling the expanding amount of paper  time to reimbursement remains at the speed of mailed package and manual processing rather than the speed of electronic transactions.  
　fast technology shift in the printing industry from analog copiers to consolidated high-resolution digital multifunction devices  mfds  enables us to close the paper-digital gap in the office environment using these pervasive image capturing and transporting channels. in our system  all it takes to submit paper receipts are a few easy steps: walking to the office mfd  authenticating yourself with your intranet password  selecting the appropriate menu option on the touch screen  and hitting the  big green button  to scan and submit receipts one by one. 
 1  extraction of relevant named entities from receipt images with unconstrained layouts and formatting 
　
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  or republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee. 
kdd'1  august 1  1  san jose  california  usa. 
copyright 1 acm 1-1-1/1...$1. 
　steady progress in the optical character recognition  ocr  technology has significantly increased its usage for image-based information retrieval applications on digitized  scanned  documents  1  1 . however  processing ocr text from unstructured contents like receipts poses serious challenges to traditional data mining approaches based on language modeling. first  text from receipts consists predominantly of terse streams of nouns. the lack of linguistic context  such as punctuation and language constructs  makes both syntactic and semantic analysis very hard. second  the output ascii text from ocr does not contain useful page layout features  such as spatial block region and font information  which may be easily recognizable in the source image. third  the ocr text quality is likely to be poor and full of errors  since receipts are typically printed by lowresolution impact printers  e.g. dot matrix printers  and are received in much worse physical condition compared to normal documents. these degradations on the source image are hard to recover and have significant impact on overall ocr performance. in practice  we encounter 1% character-level recognition errors on real-world receipt collections. 
　it is important to distinguish between the standard named entity extraction and recognition problem in the literature  1  and the one we are addressing here. in our task  the query to the relevant named entity in each category is equivalent to a question. our objective is to find one unique answer that best answers the question using the presented context. for example  given a receipt document  we can ask what the name of the merchant is. if more than one merchant entities exist  the system needs to resolve such ambiguity and provide the one that is most likely to be the relevant answer using all available cues collectively. 
　effective solution to both the entity extraction and question answering  qa  aspects of the problem requires integrating a multi-dimensional mixture of available features from language content and page layout  which is a research area with relatively little work in the literature. in addition  we prefer a formal modelbased approach than a heuristic or rule-based approach. this paper focuses on the unconstrained image-based named entity extraction approach of our system. 
 1  automation of auditing procedures that enables an organization to perform expense validation with minimum human interaction 
　many organizations are limited in their ability to audit expense reports  as it requires dedicated auditors to manually examine incoming receipts and judge their accuracy with information included in the associated report. this labor-intensive approach often causes an organization to downgrade their internal requirements for the percentage of submissions audited. for some organizations  especially those specializing in consulting or sales  which have a very high percentage of employees requiring travel  keeping costs down in expense processing generally requires a much lower rate of oversight than would be desired.  
 
　in this paper  we present an end-to-end expense reimbursement system that integrates an unconstrained data mining engine for extracting relevant named entities from un-structured document images. it dramatically reduces the elapsed time and costs involved in corporate expense reimbursement. 
　our key data mining contributions include  1  a unified model based approach to jointly solving the named entity extraction and question answering aspects of the problem using conditional random fields  crfs  ;  1  a formal framework for efficient probabilistic inference by learning contextual dependencies using both language and page layout features; and  1  demonstrating the feasibility and effectiveness of integrating rich feature sets available in the image space. the techniques presented in this paper can be generalized for solving broader image-based data mining problems  especially when ocr text reveals limited structural information. 

figure 1: system architecture of our fully automated expense reimbursement system. 
　using the crfs relax the strong assumptions on the conditional independence of observations made in models like hidden markov models  hmm   which can be unrealistic when dealing with overlapping features or long-term contextual dependencies in the observation sequence. furthermore  conditional models like the crfs offer a formal model-based framework of representing contextual dependencies  making efficient inference using dynamic programming  and training of parameters using convex optimization.  
　the remainder of this paper is structured as follows: in the next section  we describe the fully automated expense reimbursement system. we present an unconstrained approach to extracting relevant named entities from document images in section 1. we discuss experimental results on collections of real-world receipts in section 1 and conclude in section 1. 
1. system overview 
　in this section  we give a high-level overview of our expense reimbursement system and describe each technical component in its client-server architecture shown in fig. 1. the client in this system can be any computer  multi-function device  mfd   fax machine  or other electronic device  which has built-in capability to transmit native image files. the application server running an ibm intelligent document gateway  idg  server directly interacts with the centralized document image repository  the named entity extraction engine  entityfinder   the dynamic business rule engine server for automated auditing  and the whole range of associated business processes. 
　the electronic document submission  transport  and storage technologies presented here can serve effectively as the underlying infrastructure for a complex multi-document-type system  although our discussion focuses within the context of expense reimbursement in this paper. more elaborate description of the intelligent document gateway  idg  technology is presented in granted us patents  1  1 . 
1 electronic submission 
our system provides multi-channel image capture  transport  and storage of paper documents. on the client side  users have several options to submit paper receipts and scanned receipt images securely to the document gateway server: 
1. multi-function devices  mfds : the touch screens on the mfds display customized ui interfaces for guiding users to scan and submit paper receipts  once they successfully authenticate by providing their corporate directory passwords.  
1. web-based client: the user can upload document image files directly from their computer to the server through a light-weight client. this web-based application allows the user to provide additional information associated with the submitted receipt document  including its language set and personal remainder  along with the image file. 
1. desktop print-job: this option allows the user to submit receipt document in native image format through their desktop printer queue. 
　the minimum meta-data transmitted along with a submitted image file includes the type of the document and the identifier that links the submitted receipt document to the corresponding expense claim. the receipt image and its associated meta-data are encrypted prior to transmission to the document gateway server via the corporate and pubic networks. 
1 named entity extraction 
　the capability to extract relevant named entities from document images is integrated into a data mining module called entityfinder in our system  as shown in fig. 1. at the lower level  entityfinder handles images at their native formats  e.g. multipage tiff images  and provides support for higher-level functions  including document layout analysis and feature extraction  through interfaces with the ocr engine libraries. we present details of the unconstrained image-based data mining approach built into entityfinder in section 1. 
1 automated auditing 
　extracting relevant named entities from un-structured document images opens vast possibilities for business process automation. our system makes use of a business rules engine to analyze the extracted data for relevancy within the context of automated expense auditing  and activate actions based on the result of the rule execution. the set of business rules are defined in xml and are dynamically configurable in the live system. the auditing actions include verification of extracted entities from receipt documents with reference to their corresponding entries in the expense reimbursement claim  flagging of instances of potential fraud  adherence to prescribed organizational policies such as meal limit  and calculation of more complex expense reimbursement activities  such as per diem verification or valueadded-tax determination. automation of these routine procedures enables a significantly higher rate of auditing and a much shorter turnaround time between submission and compensation  bringing tangible productivity gain and cost savings to the organization. 
1 document archival 
　once all business rules for automated auditing have been executed and resulting external business processes have been initiated  the set of extracted named entities  along with the source document  are stored in centralized repositories for archival. this 

figure 1: the named entity extraction module - entityfinder.
task is required to conform to common business and legal requirements for document retention  for future data mining needs of the organization  and for auditing control purpose. the document archival process in our system is governed by a configuration file associated with the document process  which includes the type of repository adapter to use  link to the server and associated authentication data  and the descriptive information including table and column information for database access. this design allows multiple repositories at the backend as required by a given process  and can be flexibly adapted to organization-specific archival requirements. 
1. extraction of relevant named entities with crfs 
1 related work 
　named entity recognition  ner  is an important task in deriving structured information from un-structured sources. historically  it has been traditionally defined on un-structured text due to its root in message understanding conferences . ner capabilities have been demonstrated using un-structured text corpora from a wide range of domains  including identifying personal names and company names in newswire text   identifying titles and authors in on-line publications  1  1   and identifying gene and protein names in biomedical publications  1  1 . more recently  unsupervised ner results are reported on a massive corpus of domain-independent text from the web . 
　the vast majority of ner systems employ rule-based approaches and machine-learning-based approaches. examples of rule-based systems in the literature include  1  1 . machinelearning-based approaches can be further divided into two main categories: classifier-based and markov-model-based. common choices of classifiers include decision trees  na ve bayes  and support vector machines  svms . in addition  studies in  and  have used classifier combination techniques in ner tasks. markov-based models  including hidden markov models  hmms    maximum entropy markov models  memms    and conditional random fields  crfs    are well suited to problems that involve sequential analysis. 
　we choose crfs as our framework as a result of the following motivations. first  crfs relax the strict conditional independence assumptions of observations forced by generative models like hmms for ensuring tractable inference . this gives crfs 

figure 1: a receipt image  left  and the visualization of its segmentation results  right . 
more flexibility to integrate complex  overlapping and nonindependent feature sets that operate at multiple levels of granularity and multiple modalities. second  modeling of conditional probabilities devotes model resources directly to the relevant task of label inference. it requires fewer labeled observation sequences  which generally leads to better generalization performance given limited training data. in addition  crfs avoid the label bias problem exhibited by memms and other discriminative markov models based on directed graphical models . a few studies have shown that crfs outperform both memms and hmms on a number of realworld language related sequence labeling tasks  1  1  1  1 . more recently  crfs have also been extended to computer vision problems  including region classification  and human motion recognition . 
1 task and approach 
　we consider the task of extracting the set of transaction-related nes from receipt documents. obviously  different levels of complexities are involved in extracting nes of distinct natures. the limited variation in nes like transaction amount  date  credit card number and merchant phone number can be handled effectively using regular expressions  in combination with rules. in this paper  we focus on the task of finding the set of nes that have arbitrarily large variation  e.g. the merchant  and present a domain-independent approach to extracting such challenging nes by effectively exploiting context collectively from the source image and its ocr text. 
 the application imposes three requirements: 
1. effectively handle document images with unconstrained layouts and formatting  since the system must be able to process all kinds of receipts. 
1. provide the most likely answer to each ne as inferred collectively from the context presented in the document. 
1. should not rely on large external dictionaries since it is not economic to create and maintain such dictionaries in practice. furthermore  nes on receipts commonly appear in various abbreviated forms that are hard to enumerate. in fact  even with this constraint lifted  the ne extraction task is not trivial  but presents a different set of problems. the challenges involved in improving ner performance using external dictionaries are discussed in . 
　the structural information derived collectively from page layout and language features is important to the ner task on unstructured documents like receipts  whose ocr text stream may not be sufficient. fig. 1 shows a receipt example from a union 1 gas station. the string  1  itself is most likely to be a number when it appears without context. however  people can find out that it refers to a merchant by examining the document layout and linguistic elements collectively. 
　a receipt document with arbitrary physical layout and formatting still conveys structural information in two aspects:  
  many logically and semantically related entities are geometrically placed within spatial proximities  even if the structure of them within the region is not obvious. 
  the sequence of decomposed regions and the combination of layout and linguistic features within these regions reveals important contextual information collectively. 
　our approach to extracting relevant nes involves  1  decomposing the document image into homogeneous regions using page segmentation techniques;  1  learning the sequence of segmented regions and the containment of layout and linguistic features within regions by a discriminative conditional markov model. crfs provide a well-suited framework for integrating these non-independent features at multiple levels of granularity and multiple modalities. 
　two page segmentation strategies can be employed to divide a general document image into homogeneous regions. one is to use a page segmentation algorithm. representative page segmentation approaches from the document image analysis community include the docstrum algorithm by o'gorman  and the voronoi diagram-based algorithm by kise et al. . another approach is to use the ocr engine for this task. fig. 1 shows the page segmentation results by the docstrum algorithm1 and the ocr engine  respectively. each segmented region is plotted using a red bounding box. for better visualization of linguistic elements within each segmented region  we provide the ocr word segmentation result in the right sub-figure of fig. 1 by drawing a blue bounding box around each segmented word.  

figure 1: page segmentation results by the docstrum algorithm  left  and by the ocr engine  right .　using the ocr engine directly to segment a document page has a few practical advantages as opposed to using a stand-alone algorithm. first  it makes region-level attributes easily accessible. most leading commercial ocr packages offer region-level classification capabilities  which allow regions containing text  tables  graphics  and handwriting to be identified and processed accordingly. second  it facilitates feature extraction from the segmented regions  including character-level attributes such as the coordinates of character borders on the image grid  font information  and recognition confidence. last but not least  using ocr for page segmentation avoids the tedious step of training the free parameters involved in a stand-alone algorithm. packaged ocr products provides a convenient black-box solution  in which the engine parameters have been tuned for optimal performance over large collections of documents. at the post-processing stage  the ocr engine can use preliminary recognition results to further improve page segmentation in an iterative fashion. additional information  including consistency in the font style and spatial alignment of segmented regions  help improve overall page segmentation performance  and tend to produce results that are more structurally meaningful  even if the input image is heavily degraded. this is also observed in past empirical studies   where representative page segmentation algorithms are evaluated against built-in page segmentation functions provided by a few early ocr products. 
1 feature selection issues 
　optical character recognition on machine-printed characters has emerged as an industrial-strength technology since its phenomenal advances from early 1s. however  ocr accuracy today is still far from that of a second-grade child in many aspects . it is important to put the strength and weakness of ocr technology in perspective  and understand the factors involved that have significant impact on its performance. these insights provide useful guidelines for selecting feature sets that can be extracted relatively reliably given the practical constraints imposed by a targeted application.  
　the most successful application domain of ocr technology to date is on machine-printed characters. over the last decade  the acceptance rates of form readers on hand-printed digits and constrained alphanumeric fields have also risen significantly. the relatively low recognition errors in these constrained domains are a reflection of the complexities involved in classifying a novel pattern under such limited variation in the data set . in contrast  recognition of unconstrained off-line human handwriting and multi-lingual recognition among a variety of scripts are much more challenging problems  and they still remain as active research frontiers. 
　the accumulated imaging degradations have a significant impact on ocr performance. typical imaging defects in the printing process include blotchy characters caused by dot-matrix printer ribbons  and faint impressions as a result of worn ribbons and printer cartridges. the scanning process introduces various imperfections of its own. digital scanning involves sampling both horizontally and vertically on the image grid. desirable sampling rates by ocr are beyond 1 dots per inch  dpi . although commercial packages can work at as low as 1 dpi by interpolating a low-resolution image to the preferred dpi  this generally leads to significant increase in recognition errors. significant image degradation also occurs when storing an image in binary format by applying thresholds to separate foreground content from the background. using gray-scale and color scans of the image captures more detailed information for pattern recognition and reduces the error rate. most high-end mfds today provide these functions. 
1 feature set 
　we use a rich combination of page layout and linguistic features. the feature extraction process can be viewed as a set of binary-valued functions defined on the appropriate feature space that output either 1 or 1 based on the presence or absence of the corresponding feature. the conditional nature of crfs enables effective learning from these discrete-valued features with different granularity and multiple modalities  which may have extremely complex joint probabilities.  
1.1 layout features 
　as shown in fig. 1  noise speckles and graphic elements in the document  including logos  lines  and region borders  may not be reliably classified and segmented  and thus be wrongly fed to the machine-printed text recognizer. we simply discard those segmented text regions  in which majority of text is unrecognizable or suspicious. we use the following collection of layout-related features extracted by the ocr engine on each segmented region: 
  variation of font size and font face within the region 
  presence of the largest font on the entire page 
  presence of bold font face in the region 
  whether the text block is horizontally aligned to the center 
  whether the text block horizontally aligned to the left 
1.1 text features 
　word tokens that are logically or semantically related to a ne are very useful and relatively robust features for extracting the ne. in fact  a common technique for character-level error 
correction used by current ocr systems is to explicitly make use of context at word level  by choosing a common letter n-gram over a rare one . this gives improvement in recognition performance at word level even if the quality of the image is very poor. we organize word tokens into equivalent groups. for example   inc.  and  companies  are grouped together. the following text features are also used: 
  capitalization of words 
  mixed cases 
  frequent appearance of digit characters  1  
  presence of special characters  /  -  #  -  *  $  ♀  
  presence of special patterns  's  
1.1 named entity features 
　the orthogonality between nes can be effective features for inference. a region of text containing a credit card number is less likely to contain the name of the merchant. we use the set of orthogonally related nes as features. these include addresses  phone numbers  credit card numbers  dates  and monetary amounts. 
1 region labels 
　we use a compact set of labels to categorize the ordered list of regions obtained by page segmentation. this is based on our observation that context change along the sequence of regions is frequent  making the inference of label more effective among neighboring regions. for extracting the merchant  we use three labels of regions  non data  merchant data  and trans data. non data represents region that does not contain details of a transaction or any association with a merchant. merchant data denotes a region that contains a merchant. trans data region includes details of a transaction. 
1 relevant ne extraction with crfs 
　a conditional random field can be viewed as an undirected graphical model  and be used to compute the conditional probability of labels on designated output nodes y  when globally conditioned on x  the random variable representing observation sequences. in a discriminative crf framework  we construct a conditional model p y| x  from paired observation and labeled sequences  and do not explicitly model the marginal p x  .  
　we work with crfs with a linear chain structure. given an instance of observation sequence x  the probability of a particular label sequence y is defined in  as p y| x  『 exp  ‘λj f j  yi 1 yi  x i  +‘μk fk  yi  x i         1  
	j	k
where fk   yi  x  i   is a state feature function of the label at position i and the observation sequence; fj   yi-1  yi  x  i   is a transition feature function of the entire observation sequence and labels at positions i and i - 1. more compactly  the probability of a label sequence y given the observation sequence x is given by 
1
	p y| x λ  =	 exp  ‘λjfj  y x      	       1  
	z x 	j
where z x  is a normalization factor and 
fj  y x  = ‘ f j  yi 1 yi  x i  . 
i
　assuming the training data {xk   yk} are independently and identically distributed  the product of equation  1  over all training sequences as a function of the parameters λ is the likelihood function. maximum likelihood training chooses parameters values such that the log-likelihood is maximized. for a crf  the log-likelihood is a concave function  guaranteeing convergence to the global maximum. 
	 	1	k	k  
	lθ λ  = ‘ log	k +‘ fj  y  x    . 	         1  
	 	z x  
	k  	j	  
　likelihood maximization can be performed efficiently using a quasi-newton method  such as l-bfgs . this method approximates the second derivative of the likelihood by keeping a running  finite window of previous first-derivatives. l-bfgs can simply be treated as a black-box optimization procedure  requiring only the first derivative of the function to be optimized. 
　let y j be the state path up to position t on instance j of the labeled training sequence. the first-derivative of the loglikelihood function is given by 
	 dlθ	n	t dfθ ytj  yij 1 x j  
 =‘‘        dθ	dθ j=1 i=1
	t	j
	 ‘ ‘p y| x j  	dfθ yi  yi 1 x   	            1  
	x	i=1	dθ
　intuitively  when the state paths chosen by the crf parameters match the state paths from the labeled sequence  the derivative given in equation  1  becomes zero. 
1. results and discussion 
1 datasets 
　we used two large real-world receipt collections provided by ibm world wide reimbursement center for training and testing  which contain binary scanned receipt images from both ibm internal business units and ibm global services customers. these two collections are realistic as these paper receipts were gathered and scanned over time using a variety of equipment. 
characteristics of the two datasets are summarized in table 1. 
table 1: the two real-world receipt image collections. 
 collection 1 collection 1 total images 1 1 number of characters 1 1 character error rate 1% 1% image resolution 1 dpi 1 dpi country of origin us uk  
　we used the first two fifth from each dataset for training. groundtruth labels were created by first running a rule-based heuristic on the sequence of segmented regions. human judgment was then employed to correct mistakes in the heuristic labeling. 
1 evaluation and discussion 
　we use the precision-recall metrics to evaluate performance. from a practical point of view  we want our metrics to provide unbiased estimate of performance realistically achievable by including the effect of recognition errors. throughout our evaluation  we define recall as the ratio of the number of nes correctly extracted to the number of nes that are physically present in the collection. precision is the ratio of the number of nes correctly extracted divided by the total number of nes extracted in the category. the f-measure  or f1 measure  is computed by  1 〜 precision 〜 recall  /  precision + recall  . 
　tables 1 and 1 summarize the overall ne extraction performances on the two collections of receipt images  respectively.  on both datasets  extraction of merchant using crf outperformed its heuristic counterpart. this is an encouraging result  since improvements on a rule-based system requires constant changes to the code base  while improvements on the crf system generally require only defining new features that can be automatically extracted. in fact  we observed improvement in performance after modifying the word token sets to reflect locale difference of the two datasets.  
table 1: performance of ne extraction on collection 1. 
 precision recall f-measure date 1 1 1 credit card # 1 1 1 expense total 1 1 1 phone # 1 1 1 address 1 1 1 merchant  by heuristic  1 1 1 merchant  by crf  1 1 1  
　the impact of recognition errors on rule-based ne extraction approaches is evident. almost all the errors made by the heuristic on simple nes were caused by errors in the text. image scan on a higher-resolution device or a device that supports gray-scale or color formats can levitate this problem by effectively containing the recognition errors. in addition  a paper document goes through image capturing  scanning  only once in our system in contrast to some receipts in our evaluation datasets  which are secondgeneration copies  e.g. scanned image of a previously faxed document . the reported figures provide a realistic  and somehow conservative estimate of the performance in a field deployment  as digital printing technologies have significantly improved over the last decade.  
table 1: performance of ne extraction on collection 1. 
 precision recall f-measure date 1 1 1 credit card # 1 1 1 expense total 1 1 1 phone # 1 1 1 address 1 1 1 merchant  by heuristic  1 1 1 merchant  by crf  1 1 1  
　ne extraction approach using crf is shown to be more robust to recognition errors  as it jointly looks at collection of features. for instance  the 1% character error rate on collection 1 translates to a 1% word level error rate for a five-letter word. nevertheless  we achieved 1% f-score on merchant using crf on this dataset. 
　at the current level of ne extraction performance  some human assists are still required in a live expense reimbursement system. of course  manual efforts are necessary for handling practical issues that are unrelated to data mining performance  such as instances of lost or illegible receipts and incorrect submissions. we will present a transformed expense reporting workflow that greatly relaxes these requirements. 
1 practical impacts 
　paper document is the most common form of informationconveying vehicle. humans have developed exceptional capability to extract information from paper documents  even though the text content is un-structured. however  when they are scanned into image form and processed by machines  it becomes very difficult in general to index and mine  given the highvolume  complex and the heterogeneous nature of data in many practical applications. extraction of relevant metadata from semi- and un-structured paper documents is fundamental to a range of novel and important applications in this area. such challenges have been posed at sigkdd 1 conference by a panel of data mining experts .  
　we have presented an effective multimedia mining approach that aims to cross the semantic gap between un-structured image data and semantics by jointly learning page layout and linguistic features. such multimedia mining capability can be an essential technical component in many application domains that require image-based document indexing and retrieval. 
　from an application point of view  extracting transactionrelated named entities from expense receipts provides a good starting point for a range of data mining applications for an organization. for example  we can start to ask a series of questions: how much are employees of an organization spending on a particular expense item  what expense items are redundant  how can an organization analyze these spending patterns and optimize them under practical constraints   
　over the years  we have seen an increasing number of domainspecific applications that address various needs of document image processing at a particular step of a business process. however  integrating these loosely coupled applications proves to be challenging  since their underlying system architectures are very much ad hoc in nature. with the emergence of mfds as a consolidated electronic imaging platform in the office  a common set of document import  transport  and storage facilities becomes very important. our system provides such a flexible and scalable document management infrastructure on which multi-type paper documents can be aggregated in digit form and processed intelligently based on their process requirements. 
1 experiences and lessons learned 
　throughout this project  we have been working closely with teams from ibm global services and ibm printing systems. collaboration across business units offers a fast route of technology transfer from corporate research labs to product and service offerings that make real business impact. working with subject experts from these divisions also provides us with valuable insight into business processes. in fact  many features related to automation of auditing procedures came from discussions with these subject experts.  
　as thearling  has pointed out  the core data mining algorithms are currently a small part of the overall application  being perhaps 1% of a larger part  which itself is only 1% of the whole. finding the killer application for applying data mining algorithms proves to be a key success factor to this project. our solution also leverages on the huge market potential created by the technology shift to consolidated digital mfd platforms in the office environment. 
1 future work 
　evaluation on real-world datasets has shown a very promising perspective on the field deployment of our fully automated expense reimbursement solution. more importantly  this system can evolve into a multi-document-type platform  which integrates variety of business processes that traditionally have been heavily involved with paper documents.  
　one direction we are working towards is to streamline the expense reporting steps and make the entire process more human friendly. our vision is to merge the web-based expense reporting seamlessly with electronic submission. the new workflow outlined below has the advantage that it involves well-informed user decision when making corrections. in addition  with the presence of receipt image  immediate expense claim approval from management is made possible for expenses that exceed certain amount or in special categories  such as procurement and tuition reimbursement.  
- submit receipt documents electronically 
- open the email notification sent by the system once the submitted receipt has been processed  and click on the link in the email to a web-based application 
- with the submitted receipt image side by side  make corrections to the fields on the web form  which have been mostly pre-filled up using the automatically extracted nes 
- submit the completed reimbursement claim 
　with the current trend of globalization  busines travels across countries are frequent. another major feature expected to be integrated into our solution is the multi-language support for global deployment. it includes an additional language identification component that determines the language set of a document before running the recognizer of the language.  
1. conclusion 
　we have described an emerging data mining application for corporate expense reimbursement. at the system level  our endto-end solution involves technical innovations in three areas:  1  a generalized paper-free framework for capturing  transporting  and storing paper documents in digital image form;  1  an unconstrained data mining approach to extracting relevant named entities from un-structured document images;  1  automation of auditing procedures for minimizing manual efforts. we are actively collaborating with ibm global services and ibm 
printing systems for pilot testing our solution. 
　our contributions to the practice of data mining are  1  a unified model-based approach to jointly solving the named entity extraction and question answering aspects of the problem using conditional random fields  crfs ;  1  a formal framework for efficient probabilistic inference by collectively learning the contextual dependencies from both page layout and linguistic features; and  1  evaluation of our data mining approach using unstructured document images. our approach is general and can be applied to image-based information retrieval problems in broader application domains  where the text itself reveals limited structural information. 
