plwap algorithm uses a preorder linked  position coded version of wap tree and eliminates the need to recursively re-construct intermediate wap trees during sequential mining as done by wap tree technique. plwap produces significant reduction in response time achieved by the wap algorithm and provides a position code mechanism for remembering the stored database  thus  eliminating the need to re-scan the original database as would be necessary for applications like those incrementally maintaining mined frequent patterns  performing stream or dynamic mining.
모this paper presents open source code for both the plwap and wap algorithms describing our implementations and experimental performance analysis of these two algorithms on synthetic data generated with ibm quest data generator. an implementation of the apriori-like gsp sequential mining algorithm is also discussed and submitted. a web log pre-processor for producing real input to the algorithms is made available too.
keywords
sequential patterns  web usage mining  wap tree  pre-order linkage
1. introduction
모basic association rule mining with the apriori algorithm  finds database items  attributes  that occur most often together in database transactions. thus  given a set of transactions  similar to database records   where each transaction is a set of items  attributes   an association rule is of the form x 뫸 y   where x and y are sets of items and x 뫌 y =  . association rule mining algorithms generally first find all frequent patterns  itemsets  as all combinations of items or attributes with support  percentage

  a full version of this paper is available in the journal of data mining and knowledge discovery 1  1  1. 
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee.
osdm'1  august 1  1  chicago  illinois  usa. copyright 1 acm 1-1/1 ...$1.
.
occurrence in the entire database   greater or equal to a predefined minimum support. then  in the second stage of mining  association rules are generated from each frequent pattern by defining all possible combinations of rule antecedent  head  and consequent  tail  from items composing the frequent patterns such that antecedent 뫌 consequent =   and antecedent 뫋 consequent = frequentpattern. then  only rules with confidence  number of transactions that contain the rule divided by the number of transactions containing the antecedent  greater than or equal to a pre-defined minimum confidence are retained as valuable  while the rest are pruned.
모sequential mining is an extension of basic association rule mining that accommodates ordered set of items or attributes  where the same item may be repeated in a sequence. while basic frequent pattern has a set of non-ordered items that have occurred together up to minimum support threshold  frequent sequential pattern has a sequence of ordered items that have occurred frequently in database transactions at least as often as the minimum support threshold. thus  the measures of support and confidence used in association rule mining for deciding frequent itemsets are used in sequential mining for deciding frequent sequences. just as an i-itemset contains i items  an n-sequence contains n ordered items  events . one application of sequential mining is web usage mining for finding the relationship among different web users' accesses from web access logs      and . analysis of these access data can help for server performance enhancement and direct marketing in e-commerce as well as web personalization. before applying sequential mining techniques to web log data  the web log transactions are pre-processed to group them into set of access sequences for each user identifier and to create web access sequences in the form of a transaction database  e.g.  abdac  eaebcac  babfaec  babfaec . access sequence s l is called a subsequence of an access sequence  s = e1...en  and s is a super-sequence of s'  denoted as s   s  if and only if for every event ej in s'  there is an equal event ek in s  while the order that events occurred in s is the same as the order of events in s. for example  with s = ab  s = babcd  s is a subsequence of s  and ac is a subsequence of s  although there is b occurring between a and c in s. in the sequence babcd  while bcd is a suffix subsequence of bab  bab is a prefix subsequence of bcd. techniques for mining sequential patterns from web logs fall into apriori or non-apriori.
모this paper presents discussions of the implementations of three key sequential mining algorithms plwap  wap and gsp used in .
1 related work
모work on mining sequential patterns in web log include the gsp   the psp   the g sequence  and the graph traversal  algorithms. agrawal and srikant proposed three algorithms  apriori  aprioriall  apriorisome  for sequential mining in . the gsp  generalized sequential patterns   algorithm is 1 times faster than the apriori algorithm. the gsp algorithm makes multiple passes over data. the first pass determines the frequent 1-item patterns  l1 . each subsequent pass starts with a seed set: the frequent sequences found in the previous pass  lk 1 . the seed set is used to generate new candidate sequences
 ck  by performing an apriori gen join of lk 1 with  lk 1 . this join requires that every sequence s in the first lk 1 joins with other sequences s in the second lk 1 if the last k-1 elements of s are the same as the first k-1 elements of s'. for example  if frequent 1-sequence set l1 has the following 1 sequences: {  1  1      1  1      1  1  1      1  1      1  1      1  1  1  }  to obtain frequent 1sequences  every frequent 1-sequence should join with the other 1-sequences that have the same first two elements as its last two elements. sequence s=  1  1   joins with s=  1  1   to generate a candidate 1-sequence   1  1   since the last 1 elements of s   1  1   match with the first 1 elements of s. similarly    1   1   joins with   1  1  1   to form   1  1  1  . there are no more matching sequences to join in l1. the join phase is followed with the pruning phase  when the candidate sequences with any of their contiguous  k-1 -subsequences having a support count less than the minimum support  are dropped. the database is scanned for supports of the remaining candidate k-sequences to find frequent k-sequences lk   which become the seed for the next pass  candidate  k+1 -sequences. the algorithm terminates when there are no frequent sequences at the end of a pass  or when there are no candidate sequences generated. the gsp algorithm uses a hash tree to reduce the number of candidates that are checked for support in the database.
모the psp  prefix tree for sequential patterns   approach is much similar to the gsp algorithm   but stores the database on a more concise prefix tree with the leaf nodes carrying the supports of the sequences. at each step k  the database is browsed for counting the support of current candidates. then  the frequent sequence set  lk is built.
모the graph traversal mining     uses a simple unweighted graph to store web sequences and a graph traversal algorithm similar to apriori algorithm to traverse the graph in order to compute the k-candidate set from the  k1 -candidate sequences without performing the apriori-gen join. from the graph  if a candidate node is large  the adjacency list of the node is retrieved. the database still has to be scanned several times to compute the support of each candidate sequence although the number of computed candidate sequences is drastically reduced from that of the gsp algorithm. other tree based approaches include  called g sequence mining. this algorithm uses wildcards  templates and construction of aggregate tree for mining.
모the fp-tree structure  first reorders and stores the frequent non-sequential database transaction items on a prefix tree  in descending order of their supports such that database transactions share common frequent prefix paths on the tree. then  mining the tree is accomplished by recursive construction of conditional pattern bases for each table 1: sample web access sequence database for wap-tree
tidweb access sequencefrequent subsequence1abdacabac1eaebcacabcac1babfaecbabac1afbacfcabaccfrequent 1-item  in ordered list called f-list   starting with the lowest in the tree. conditional fp-tree is constructed for each frequent conditional pattern having more than one path  while maximal mined frequent patterns consist of a concatenation of items on each single path with their suffix f-list item. freespan  like the fp-tree method  lists the flist in descending order of support  but it is developed for sequential pattern mining. prefixspan  is a pattern-growth method like freespan  which reduces the search space for extending already discovered prefix pattern p by projecting a portion of the original database that contains all necessary data for mining sequential patterns grown from p.
모web access pattern tree  wap   is a non-apriori algorithm  proposed by pei et al. . the wap-tree stores the web log data in a prefix tree format similar to the frequent pattern tree   fp-tree . wap algorithm first scans the web log to compute all frequent individual events  then it constructs a wap-tree over the set of frequent individual events of each transaction before it recursively mines the constructed wap tree by building a conditional wap tree for each conditional suffix frequent pattern found. the process of recursive mining of a conditional suffix wap tree ends when it has only one branch or is empty.
모an example application of the wap-tree algorithm for finding all frequent events in the web log  constructing the wap-tree and mining the access patterns from the wap tree  is shown with the database in table 1. suppose the minimum support threshold is set at 1%  which means an access sequence  s should have a count of 1 out of 1 records in our example  to be considered frequent. constructing waptree  entails first scanning database once  to obtain events that are frequent  a b c. when constructing the wap-tree  the non-frequent  like d  e  f  part of every sequence is discarded. only the frequent sub-sequences shown in column three of table 1 are used as input. with the frequent sequence in each transaction  the wap-tree algorithm first stores the frequent items as header nodes for linking all nodes of their type in the wap-tree in the order the nodes are inserted. when constructing the wap-tree  a virtual root  root  is first inserted. then  each frequent sequence in the transaction is used to construct a branch from the root to a leaf node of the tree. each event in a sequence is inserted as a node with count 1 from root if that node type does not yet exist  but the count of the node is increased by 1 if the node type already exists. also  the head link for the inserted event is connected  in broken lines  to the newly inserted node from the last node of its type that was inserted or from the header node of its type if it is the very first node of that event type inserted. once the frequent sequential data are stored on the complete wap-tree  figure 1   the tree is mined for frequent patterns starting with the lowest frequent event in the header list  in our example 

figure 1: construction of the original wap tree
starting from frequent event c as the following discussion shows. from the wap-tree of figure 1  it first computes prefix sequence of the base c or the conditional sequence base of c as: aba : 1; ab : 1; abca : 1; ab : -1; baba : 1; abac : 1; aba : -1 the conditional sequence list of a suffix event is obtained by following the header link of the event and reading the path from the root to each node  excluding the node . after discarding the non-frequent part c in the above sequences  the conditional sequences based on c are listed below: aba : 1; ab : 1; aba : 1; ab : -1; baba : 1; aba : 1; aba : -1. using these conditional sequences  a conditional wap tree  wap-tree|c  is built using the same method as shown in figure 1. the re-construction of wap trees that progressed as suffix sequences |c  |bc discovered frequent patterns found along this line c  bc and abc. the recursion continues with the suffix path |c  |ac. the algorithm keeps running  finding the conditional sequence bases of bac  b  a. figure 1 shows the wap trees for mining conditional pattern base c. after mining the whole tree  discovered frequent pattern set is: {c  aac  bac  abac  ac  abc  bc  b  ab  a  aa  ba  aba}.
모although wap-tree algorithm scans the original database only twice and avoids the problem of generating explosive candidate sets as in apriori-like algorithm  its main drawback is recursively re-constructing large numbers of intermediate wap-trees and patterns during mining taking up computing resources.
모pre-order linked wap tree algorithm  plwap      is a version of the wap tree algorithm that assigns unique binary position code to each tree node and performs the header node linkages pre-order fashion  root  left  right . both the pre-order linkage and binary position codes enable the plwap to directly mine the sequential patterns from the one initial wap tree starting with prefix sequence  without re-constructing the intermediate wap trees. to assign position codes to a plwap node  the root has null code  and the leftmost child of any parent node has a code that appends '1' to the position code of its parent  while the position code of any other node has '1' appended to the position code of its nearest left sibling. the plwap technique presents a much better performance than that achieved by the wap-tree technique as shown in extensive performance analysis.
he  ad  er  
ta  bl  e a
co  nd  it  io  na  l   wa  p-  tr  ee  |c  
 a    co  nd  it  io  na  l   wa  p-  tr  ee  |b  c 
 b    he  ad  er  
ta  bl  e a
co  nd  it  io  na  l   wa  p-  tr  ee  |a  c 
 c    co  nd  it  io  na  l   wa  p-  tr  ee  |b  ac  
 d    co  nd  it  io  na  l   wa  p-  tr  ee  |a  ac  
 e    figure 1: reconstruction of wap trees for mining conditional pattern base c
1 motivations and contributions
모plwap algorithm   a recently proposed sequential mining tool in the journal of data mining and knowledge discovery has many attractive features that makes it suitable as a building block for many other sophisticated sequential data mining approaches like incremental mining   web classification and personalization. this paper supplements the detailed and formal presentations of the plwap algorithm  its properties and theorems given in  by focusing on details of the code implementations of plwap  wap and gsp sequential miners as well as making available a real web log data pre-processor and providing further indepth analysis. this paper thus  contributes by discussing our code implementations of the plwap and two other key sequential mining algorithms  wap and gsp  used in performance studies of work in . these algorithms have been tested thoroughly on publicly available data sets  http://www.almaden.ibm.com/software/quest/resources/ index.shtml  and with real data. through this paper  a real web log pre-processor for preparing real input data for the miners is also made available  ask author if needed . a more indepth performance analysis that confirms the stability of the plwap algorithm is another contribution of paper. such code availability motivates adoption of algorithm as a building block for more sophisticated data mining processes like stream and dynamic mining  distributed  incremental  drill-down and roll-up mining  semantic mining and sensor network mining.
1 outline of the paper
모section 1 discusses example mining with the pre-order linked wap-tree  plwap  algorithm. section 1 discusses the c++ implementations of the plwap  wap and the gsp algorithms for sequential mining. section 1 discusses experimental performance analysis  while section 1 presents conclusions and future work.
1. an example sequential mining with plwap algorithm
모unlike the conditional search in wap-tree mining  which is based on finding common suffix sequence first  the plwap technique finds the common prefix sequences first. the main idea is to find a frequent pattern by progressively finding its common frequent subsequences starting with the first frequent event in a frequent pattern. for example  if abcd is a frequent pattern to be discovered  the wap algorithm progressively finds suffix sequences d  cd  bcd and abcd. the plwap tree  on the other hand  would find the prefix event a first  then  using the suffix trees of node a  it will find the next prefix subsequence ab and continuing with the suffix tree of b  it will find the next prefix subsequence abc and finally  abcd. thus  the idea of plwap is to use the suffix trees of the last frequent event in an m-prefix sequence to recursively extend the subsequence to m+1 sequence by adding a frequent event that occurred in the suffix trees. using the position codes of the nodes  the plwap is able to know the descendant and sibling nodes of oldest parent nodes on the suffix root set of a frequent header element being checked for appending to a prefix subsequence if it is frequent in the suffix root set under consideration. an element is frequent if the sum of the supports of the oldest parent nodes on all its suffix root sets is greater than or equal to the minimum support.
모assume we want to mine the web access database  wasd  of table 1 for frequent sequences given a minimum support of 1% or 1 transactions. constructing and mining the plwap tree goes through the following steps.  1  scan wasd  column 1 of table 1 once to find all frequent individual events  l as {a:1  b:1  c:1}. the events d:1  e:1  f:1 have supports less than the minimum support of 1 and  1  scan wasd again  construct a plwap-tree over the set of individual frequent events  column 1 of table 1   by inserting each sequence from root to leaf  labeling each node as  node event: count: position code . then  after all events are inserted  traverse the tree pre-order way to connect the header link nodes. figure 1 shows the completely constructed plwap tree with the pre-order linkages.
  1  recursively mine the plwap-tree using common prefix pattern search: the algorithm starts to find the frequent sequence with the frequent 1-sequence in the set of frequent events fe  {a  b  c}. for every frequent event in fe and the suffix trees of current conditional plwap-tree being mined  it follows the linkage of this event to find the first occurrence of this frequent event in every current suffix tree being mined  and adds the support count of all first occurrences of this frequent event in all its current suffix trees. if the count is greater than the minimum support threshold  then this event is appended  concatenated  to the last subsequence in the list of frequent sequences  f. the suffix trees of these first occurrence events in the previously mined conditional suffix plwap-trees are now in turn  used for mining the next event. to obtain this conditional plwap-tree  we only need to remember the roots of the current suffix trees  which are stored for next round mining. for example  the

figure 1: construction of plwap-tree using preorder traversal
algorithm starts by mining the tree in figure 1 a  for the first element in the header linkage list  a following the a link to find the first occurrencies of a nodes in a:1 and a:1 of the suffix trees of the root since this is the first time the whole tree is passed for mining a frequent 1-sequence. now  the list of mined frequent patterns f is {a} since the count of event a in this current suffix trees is 1  sum of a:1 and a:1 counts   and more than the minimum support of 1. the mining of frequent 1-sequences that start with event a would continue with the next suffix trees of a rooted at {b:1  b:1} shown in figure 1 b  as unshadowed nodes. the objective here is to find if 1-sequences aa  ab and ac are frequent using these suffix trees. in order to confirm aa frequent  we need to confirm event a frequent in the current suffix tree set  and similarly  to confirm ab frequent  we should again follow the b link to confirm event b frequent using this suffix tree set  same for ac. the process continues to obtain same frequent sequence set {a  aa  aac  ab  aba  abac  abc  ac  b  ba  bac  bc  c} as the wap-tree algorithm.
1. c++implementationsofthreesequential mining algorithms
모although  we lay more emphasis on the plwap algorithm developed in our lab  we also provide the source codes of the wap and gsp algorithms used for performance analysis. the source codes are discussed under seven headings of  1  development and running environment   1  input data format and files   1  minimum support format   1  output data format and files   1  functions used in the program   1  data structures used in the program and  1  additional information. all of the codes are documented with information on this section and more for code readability  maintainability and extendability. each program is stored in a .cpp file and compiled with  g++ filename.cpp . it is worth noting that all three algorithms were implemented in the year 1  when no other versions of the wap and gsp algorithms were publicly available. while we cannot still find a publicly available version of the gsp program  there are some subtle differences between our implementation of the wap algorithm and that now available at http://www.cs.ualberta.ca/ tszhu/software.html. one difference we have noticed is with the input formats of the two implementations: while alberta version accepts the input in one sequence  we accept a list of sequences belonging to different users as in web log mining. it also seems like alberta

a:  {1   1  1   1  1  1   1  1   1  1  1  } b:  {1  1   1   1  1  1}  c:  {1  1  1   1  1  1   1  1   1  1  1  1   1  1  1  } a|   s  uf  fi  x   tr  ee  
{b  :1  1    b  :1  1  1}   a     b    
aa  |   su  ff  ix   t  re  e 
{c  :1  1  1    c  :1  1  1  1    c  :1  1  1  1}  aa  c|   s  uf  fi  x   tr  ee  
{c  :1  1  1  }  c     d    figure 1: mining plwap-tree to find frequent sequence starting with aa
version is memory-only as intermediate pattern input is not saved on disk  while it is saved on disk in our implementation. the implication is that running the memory-only version on an environment with less memory than data size would result in operating system swapping of data onto disk.
1 c++ implementation of the plwap sequential mining algorithm
모this is the plwap algorithm program  which is based on the description in   c.i. ezeife and y. lu.  mining web log sequential patterns with position coded pre-order linked wap-tree  in dmkd 1.
1. development environment: although initial version is developed under the hardware/software environment specified below  the program runs on more powerful and faster multiprocessor unix environments as well. initial environment is:  i hardware: intel celeron 1 pc  1m memory;  ii operating system: windows 1;  iii development tool: inprise borland  c++ builder 1. the algorithm is developed under c++ builder 1  but compiles and runs under any standard c++ development tool. 1. input files and format: input file is test.data: for simplifying input process of the program  we assume that all input data have been preprocessed such that all events belonging to the same user id have been gathered together  and formed as a sequence and saved in a text file  called   test.data . the  test.data  file may be composed of hundreds of thousands of lines of sequences where each line represents a web access sequence for each user. every line of the input data file   test.data   includes userid  length of sequence and the sequence which are separated by tab spaces. an example input line is: 1 1 1 1 . here  1 represents userid  the length of sequence is 1  the sequence is 1 1 1.
1. minimum support format: the program also needs to accept a value between 1 and 1 as minimum support. the minimum support input is entered interactively by the user during the execution of the program when prompted. for a minimum support of 1%  user should type 1  and for minsupport of 1%  user should type .1  and so on. 1. output files and format: result plwap.data:
once the program terminates  we can find the result frequent patterns in a file named  resultplwap.data . it may contain lines of patterns  each representing a frequent pattern. 1. functions used in the code:  i buildtree: builds the plwap tree   ii buildlinkage: builds the pre-order linkage for plwap tree   iii makecode: makes the position code for a node   1v checkposition: checks the position between any two nodes in the plwap tree   v miningprocess: mines sequential frequent patterns from the plwap tree using position codes.
1. data structure: three struct are used in this program:  i  the node struct indicates a plwap node which contains the following information: a.the event name  b.the number of occurrence of the event  c. a link to the position code  d. length of position code  e. the linkage to next node with same event name in plwap tree  f. a pointer to its left son  g. a pointer to its right sibling  h. a pointer to its parent  i. the number of its sons.  ii  a position code struct implemented as a linked list of unsigned integer to make it possible to handle data of any size without exceeding the maximum integer size.  iii  a linkage struct.
1. additional information: the run time is displayed on the screen with start time  end time and total seconds for running the program.
1 c++ implementation of the wap sequential mining algorithm
모this is the wap algorithm program based on the description in : jian pei  jiawei han  behzad mortazaviasl  and hua zhu   mining access patterns efficiently from web logs   pakdd 1.
1.development environment: the same as described for plwap and can run on any unix system as well.
1. input files and format:
i  input file test.data: pre-processed sequential input records are read from the file  test.data . the  test.data  file  which is the same format as described for plwap above. ii  input file middle.data: used to save the conditional middle patterns. during the wap tree mining process  following the linkages  once the sum of support for an event is found greater than minimum support  all its prefix conditional patterns are saved in the  middle.data  file for next round mining. the format of  middle.data  is as follows: each line includes the length of the sequence  the occurrence of the sequence  and the events in the sequence. for example  given a line in middle.data: 1 1 1 1  the length of sequence is 1  1 indicates the sequence occurred 1 times in the previous conditional wap tree and the sequence is 1 1 1.
1. minimum support:
the program also needs to accept a value between 1 and 1 for minimum support or frequency. the user is prompted for minimum support when the program starts.
1. output files and format: result wap.data once the program terminates  the result patterns are in a file named  resultwap.data   which may contain lines of patterns.
1. functions used in the code:
 i buildtree: builds the wap tree/conditional wap tree  ii miningprocess: produces sequential pattern/conditional prefix sub-pattern from wap tree/conditional wap tree.
1. data structure: three struct are used in this program:  i  the node struct indicates a wap node which contains the following information: a.the event name  b.the number of occurrence of the event  c. the linkage to next node same event name in wap tree  d. a pointer to its left son  e. a pointer to its rights sibling  f. a pointer to its parent.
 ii  a linkage struct described in the program.
1. additional information: the run time is displayed on the screen with start time  end time and total seconds for running the program.
1 c++ implementation of the gsp sequential mining algorithm
모this is a gsp algorithm implementation  which demonstrates the result described in : r. srikant and r. agrawal.  mining sequential patterns: generalizations and performance improvements   1.
1.development environment:the same as described for plwap and runs in any unix system as well. 1. input files and format: input file test.data: the main input file  test.data  had the same format as for plwap described above.
1. minimum support: the program also needs to accept a value between 1 and 1 as minimum support. the user is prompted for minimum support when the program starts. 1. output files and format: result gsp.data at the termination of the program  the result patterns are in a file named  result gsp.data   which may contain lines of frequent patterns.
1. functions used in the code:  i gsp: reads thefile and mines levelwise according to the algorithm.
1. data structures: there are struct for i  candidatesequence list and its count and ii  sequence.
1. additional information: the run time is displayed on the screen with start time  end time and total seconds for running the program.
1. performanceandexperimental analysis of three algorithms
모the plwap algorithm eliminates the need to store numerous intermediate wap trees during mining  thus  drastically cutting off huge memory access costs. the plwap annotates each tree node with a binary position code for quicker mining of the tree. this section compares the experimental performance analysis of plwap with the waptree mining and the apriori-like gsp algorithms. the three algorithms were initially implemented with c++ language running under inprise c++ builder environment. all initial experiments were performed on 1mhz celeron pc machine with 1 megabytes memory running windows 1  for work in  . current experiments are conducted with the same implementations of the programs and still on synthetic datasets generated using the resource data generator code from http://www.almaden.ibm.com/software/quest/ resources/index.shtml. this synthetic dataset has been used by most pattern mining studies  1  1  1 . experiments were also run on real datasets generated from web log data of university of windsor computer science server and pre-processed with our web log cleaner code. the correctness of the implementations were confirmed by checking that the frequent patterns generated for the same dataset by all algorithms are the same. a high speed unix sun microsystem with a total of 1 mb memory and 1 x 1 mhz processor speed is used for these experiments. the synthetic datasets consist of sequences of events  where each event represents an accessed web page. the parameters shown below are used to generate the data sets. |d| number of sequences in the database
|c| : average length of the sequences
|s|: average length of maximal potentially frequent sequence
|n|: number of events
for example  c1.s1.n1.d1k means that |c| = 1  |s| = 1  |n|= 1  and |d| = 1k. it represents a group of data with average length of the sequences as 1  the average length of maximal potentially frequent sequence is 1  the number of individual events in the database is 1  and the total number of sequences in database is 1 thousand. the datasets with different parameters test different aspects of the algorithms. generally  if the number of these four parameters becomes larger  the execution time becomes longer. experiments are conducted to test the behavior of the algorithms with respect to the four parameters  minimum support threshold  database sizes  number of database table attributes and the average length of sequences. for each experiment  while one of the parameters changes  others are pegged at some constant values. observations are made at three levels of small  medium and large  e.g.  small database size may consist of a table with records less than 1 thousands  medium size table has between 1 nd 1 thousands records  while large has over 1 thousand .
experiment 1: execution time trend with different minimum supports  small size database  1k records :
this experiment uses fixed size database and different minimum support to compare the performance of plwap  wap and gsp algorithms. the datasets are described as c1.s1.n1.d1k  and algorithms are tested with minimum supports between 1% and 1% against the 1 thousand  1k  database with 1 attributes and average sequence length of 1. the results of this experiment are shown in table 1 and figure 1 with the number of frequent patterns found reported as fp. from this result  it can be seen that at minimum support of 1%  the number of frequent patterns found is highest and is 1  the plwap algorithm ran almost 1 times faster than the wap algorithm. as the minimum support increases  the number of frequent patterns found decreases and the gain in performance by the plwap algorithm over the wap algorithm decreases. it can be seen that the more the number of frequent patterns found in a dataset  the higher the performance gain achieved by the plwap algorithm over the wap algorithm. this is table 1: execution times for dataset at different minimum supports  small database 
algruntime  in secs  at different supports % 11111fp=fp=fp =fp=fp=fp=fp1111gsp1111wap1111plwap1111
because the two algorithms spend about the same amount of time scanning the database and constructing the tree  but the plwap algorithm saves on storing and reading intermediate re-constructed tree  which are as many as the number of frequent patterns found. the execution times of the two algorithms are the same when there are nearly no frequent patterns.

figure 1: execution times trend with different minimum supports  small database 
experiment 1: execution times trend with different minimum supports  medium size database  1k records :
this experiment uses fixed size database and different minimum support to compare the performance of plwap  wap and gsp algorithms. the algorithms are tested with minimum supports between 1% and 1% against the 1 thousand  1k  database  1 attributes and average sequence length of 1. the results of this experiment are shown in table 1 and figure 1 with the number of frequent patterns found reported as fp. it can be seen that the trend in performance is the same as with small database. when the minimum support reaches 1%  there are no frequent patterns found and the running times of the two algorithms become the same.
experiment 1: execution times for dataset at different minimum supports  large database :
this experiment uses fixed size database and different minimum support to compare the performance of plwap  wap and gsp algorithms. the algorithms are tested with mini-

minimum support  in % 
figure 1: execution times trend with different minimum supports  medium database 
table 1: execution times for dataset at different minimum supports  medium database 
algruntime  in secs  at different supports % 11111fp=fp=fp =fp=fp=fp=fp1111gsp1111wap1111plwap1111
mum supports between 1% and 1% against one million  1m  record database. the results of this experiment are shown in table 1 and figure 1.
experiment 1a: execution times for dataset at different minimum supports  large database but very low minimum supports :
this experiment uses fixed size database and different minimum support to compare the performance of plwap and wap algorithms  gsp not included because running times get too big or process is killed . the algorithms are tested with minimum supports between 1% and 1% against one million  1m  record database. the results of this experiment are shown in table 1 and figure 1.
table 1: execution times for dataset at different
minimum supports  large database 
algruntime  in secs  at different supports % 11111fp=fp=fp =fp=fp=fp=fp1111gsp1111wap1111plwap1111

minimum support  in % 
figure 1: execution times for dataset at different
minimum supports  large database 

minimum support  in % 
figure 1: execution times for dataset at different minimum supports  large database and low minsupports 
experiment 1: execution times trend with different database sizes  small size database  1k to 1k :
this experiment uses fixed minimum support and different size database to compare the performance of plwap  wap and gsp algorithms. the algorithms are tested on databases of sizes 1k to 1k at minimum support of 1%. the gain in performance by the plwap algorithm is constant across different sizes because the number of frequent patterns in different sized datasets generated by the data generator seem to be about the same at a particular minimum support. the results of this experiment are shown in table 1 and figure 1.
experiment 1: execution times trend with different database sizes  medium size database  1k to 1k :
algruntime  in secs  at different supports % 1111111fp=fp=fp =fp=fp=fp=fp1k1k111wap1111plwap1111this experiment uses fixed minimum support and different size database to compare the performance of plwap and wap algorithms. the algorithms are tested with database sizes between 1 and 1 thousands at minimum support of 1%. the results of this experiment are shown in table 1 and table 1: execution times for dataset at different minimum supports  large database and low minsupports 
database sizes
figure 1: execution times trend with different minimum supports  small database 
figure 1.
모experiment 1: execution times trend with different database sizes  large size database  1k to 1k :
this experiment uses fixed minimum support and different size database to compare the performance of plwap  wap and gsp algorithms. the algorithms are tested with database sizes between 1k and 1k records at minimum support of 1%. the results of this experiment are shown in table 1 and figure 1. since the cpu execution time difference between the wap and plwap from this experiment  seems to diminish as the database size increases  a further experiment was run on larger databases of between one million and 1 million records to check if and when wap would run faster than the plwap. result of this experiment
table 1: execution times for different database
sizes at minsupport  small database 
algruntime  in secs  at different supports % 1k1k1k1k1k1k1kgsp1111wap1111plwap1111

database sizes
figure 1: execution times trend with different database sizes  medium database 
table 1: execution times for different database sizes at minsupport of 1% medium database 
algruntime  in secs  at different db sizes % 1k1k1k1k1k1kgsp111wap111plwap111
on larger databases is given in table 1. from this experiment  we found that at the same minimum support of 1%  when the database size increases much  there are few or no frequent patterns found because an item needs to appear in about 1 thousand sequential records in the 1 million database to be frequent and that is not very possible in the synthetic data leading to about the same execution times for the two algorithms. however  a run on the same 1m records at a minimum support of 1% found 1 patterns and took 1 seconds of cpu time for plwap  while the wap tree algorithm could not complete successfully.
모experiments were also run to check the behavior of the algorithms with varying sequence lengths and number of database attributes  and the plwap always runs faster than the wap algorithm when the average sequence length is less than 1 and there are some found frequent patterns. how-
table 1: execution times for different database
sizes at minsupport of 1%  large database 
algruntime  in secs  at different db sizes % 1k1k1k1k1k1k1kgsp11k1k1k1kwap1111pl-
wap1111

1
1k 1k 1k 1k 1k 1k 1k
database sizes
figure 1: execution times trend with different database sizes  large database 
table 1: execution times for different database sizes at minsupport of 1%  larger database 
algruntime  in secs  at different db sizes % 1m1m1m1m1m1mwap111plwap111
ever  the plwap performance starts to degrade when the average sequence length of the database is more than 1 because with extremely long sequences  there are nodes with position codes that are more than  maxint   in our current implementation  we use a number of variables to store a node's position code that are linked together. thus  managing and retrieving the position code for excessively long sequences could turn out to be time consuming. our experiment on real data of size 1k having about 1 attributes with only a few very long sequences of up to 1 items while most of other records are less than 1 items long  reveals plwap faster than wap by a factor of over 1 times at a very low minimum support of 1% with their execution times as 1  1  at 1%  they are 1  1 and at 1%  1  1 respectively. the execution times of the two algorithms start being the same from minimum support 1% when there are no found frequent patterns. a test on memory usage of the wap and plwap algorithms reveals about the same amount of memory allocated to both programs.
1. conclusions
모this paper discusses the source code implementation of the plwap algorithm presented in  as well as our implementations of two other sequential mining algorithms wap  and gsp  that plwap was compared with. extensive experimental studies were conducted on the three implemented algorithms using ibm quest synthetic datasets. from the experiments  it was discovered that the plwap algorithm  which mines a pre-order linked  position coded version of the wap tree  always outperforms the other two algorithms and is much more efficient. plwap improves on the performance of the efficient tree-based wap tree algorithm by mining with position codes and their suffix tree root sets  rather than storing intermediate wap trees recursively. thus  it saves on processing time and more so when the number of frequent patterns increases and the minimum support threshold is low. plwap's performance seems to degrade some with very long sequences having sequence length more than 1 because of the increase in the size of position code that it needs to build and process for very deep plwap tree. for mining sequential patterns from web logs or databases  the following aspects may be considered for future work. the plwap algorithm could be extended to handle sequential pattern mining in large traditional databases to handle concurrency of events. the position code features of the plwap tree provides a mechanism for concisely storing small items not represented in the tree for future incremental refreshment of mined patterns. it also enables easy multilevel mining of frequent patterns at detailed  e.g.  item level like city level or word level  to more generalized calss level  e.g.  country level or book level  through rollup mining with the same tree by providing levelwise pre-order header linkages. this may make it useful in several sequence oriented applications like frequent word usages in collections of documents  books   cell phone call sequence record data  intrusion detection and sensor network mining as well as biological sequence data. a more efficient implementation of the position code management for long sequences would make the plwap more scalable.
1. acknowledgments
모this research was supported by the natural science and engineering research council  nserc  of canada under an operating grant  ogp-1  and a university of windsor grant.
