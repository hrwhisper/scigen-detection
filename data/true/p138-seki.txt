this paper describes an application of ir and text categorization methods to a highly practical problem in biomedicine  specifically  gene ontology  go  annotation. go annotation is a major activity in most model organism database projects and annotates gene functions using a controlled vocabulary. as a first step toward automatic go annotation  we aim to assign go domain codes given a specific gene and an article in which the gene appears  which is one of the task challenges at the trec 1 genomics track. we approached the task with careful consideration of the specialized terminology and paid special attention to dealing with various forms of gene synonyms  so as to exhaustively locate the occurrences of the target gene. we extracted the words around the gene occurrences and used them to represent the gene for go domain code annotation. as a classifier  we adopted a variant of k-nearest neighbor  knn  with supervised term weighting schemes to improve the performance  making our method among the top-performing systems in the trec official evaluation. moreover  it is demonstrated that our proposed framework is successfully applied to another task of the genomics track  showing comparable results to the best performing system.
categories and subject descriptors
h.1  database management : systems-textual databases; h.1  information storage and retrieval : content analysis and indexing-abstracting methods  indexing methods  linguistic processing; j.1  life and medical sciences : biology and genetics
general terms
algorithm  performance  experimentation
keywords
text categorization  automatic database curation  genomic ir
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee.
sigir'1  august 1  1  salvador  brazil copyright 1 acm 1-1/1 ...$1.
1. introduction
　given the intense interest and fast growing literature  biomedicine is an attractive domain for exploration of intelligent information processing techniques  such as information retrieval  ir   information extraction  and information visualization. as a result  it has been increasingly drawing much attention of researchers in ir and other related communities  1  1  1  1 . as far as we know  however  there have been few products of research efforts focusing on this particular domain in past sigir conferences. this paper introduces a successful application of general ir and text categorization methods to this evolving field of research targeting biomedical texts.
　in the post-genomic era  one of the major activities in molecular biology is to determine the precise functions of individual genes or gene products  which has been producing a large number of publications with the help of high throughput gene analysis. to structure the information related to gene functions scattered over the literature  a great deal of efforts has been made to annotate articles by using the gene ontology1  go  terms. go is a controlled vocabulary developed for describing functions of gene products in order to facilitate uniform queries across different model organism databases  such as flybase  saccharomyces genome database  sgd   and the mouse genome informatics  mgi  database. go terms are basically organized in hierarchical structures  but a child node may have multiple parent nodes  under three top level nodes: molecular function  mf   biological process  bp   and cellular component  cc . figure 1 illustrates the structure of go.

figure 1: structure of gene ontology.
　because of the large number of publications and specialized content  go annotation requires extensive human efforts and substantial domain knowledge  which is usually conducted by experts. thus  there is a potential need to automate or semi-automate go annotation  which could greatly alleviate the human curation. this was one of the primary objectives pursued at the text retrieval conference  trec  1 genomics track .
　the 1 genomics track consisted of two tasks: ad hoc retrieval and categorization tasks. for the former  given 1 topics obtained through interviews with real research scientists  the participants were required to find relevant documents from 1 years' worth of medline data. the latter task  which is our focus in this paper  was composed of two sub-tasks; one was called the triage task and the other the annotation task. both tasks mimicked some parts of go annotation process currently carried out by human experts at mouse genome informatics  mgi . figure 1 depicts the conceptual flow of the two sub-tasks.

figure 1: a conceptual flow of the categorization sub-tasks.
in short  the goal of the triage task was to correctly identify whether an input article contains experimental evidence that warrant go annotation regardless of specific go codes. the annotation task was the next step to the triage decision  and the goal was to correctly assign go domain codes  i.e.  mf  bp  and cc  not the actual go terms  or not to assign them  i.e.  negative  for each of the given genes that appear in the article.1 note that there may be more than one gene associated with an article and there may be more than one domain code assigned to a gene.
　the triage task can be seen as a standard text categorization problem to classify an input article into predefined classes  positive and negative   while the annotation task required to classify not an article as a whole but each given gene appearing in the article. in other words  each harticle genei pair was to be independently classified even when two  or more  genes appeared in a single article. we addressed the problem by extracting document fragments that were likely to contain the gene in question by gene name expansion and a flexible term matching scheme. the resulting set of document fragments were then used for representing the particular gene. for classification  we used a variant of the k-nearest neighbor  knn  classifier with supervised term weighting schemes  which consider word distributions in different classes.
　this paper focuses on an application of general ir and text categorization techniques to the domain-specific  highly practical problems with careful consideration of the properties of the terminology in biomedicine. in the following  we first introduce our proposed framework for go domain code annotation  and then describe the data and evaluation measures used in our experiments. we show the effectiveness of our framework through a number of experiments with various different settings. in addition  it is demonstrated that our framework can be successfully applied to the triage task as well  making it among the top-performing systems for both triage and annotation tasks in the trec official evaluation.
1. methods
　this section details our proposed framework for automatic go domain code annotation. hereafter  we will refer to go domain code annotation as  go annotation  for short.
1 document representation
1.1 identification of relevant paragraphs
　go annotation needs to be made not for each input article but for each gene for which there is experimental evidence that warrants go annotation. therefore  each harticle genei pair needs to be treated as a  document  or  text  in the sense of text categorization. for this purpose  we propose a simple but effective approach to extract only the text fragments that are likely to contain the gene in question and treat a set of the extracted text fragments as a document associated with the harticle genei pair. this process can be broken down into gene name expansion and gene name identification  each explained in the following.
gene name expansion. gene name expansion refers to a process to associate synonyms with a given gene name. gene names are known to have several types of synonyms including aliases  abbreviations  and gene symbols. for instance   membrane associated transporter protein  can be referred to as underwhite  dominant brown  matp  uw  dbr  bls  aim1  etc. therefore  all of these names should be searched to identify text fragments mentioning the gene. to obtain such synonyms  we used two sources of information: the article itself and a gene name dictionary. as described later in section 1  the input article is annotated with sgml tags and there are two relevant fields   keyword  and  glossary   in which a gene name and its synonym may be explicitly defined.1 incidentally  we also examined the use of body text because gene name abbreviations often appear with parentheses immediately following the official names . however  it slightly degraded classification in our preliminary experiments and thus was not used in the following experiments.
　as another source of gene name expansion  a gene name dictionary was automatically complied from existing databases. for this work  we experimentally used the swiss-prot  and locuslink  databases. the resulting name dictionary contained 1 records  where each record had a gene/protein name as a keyword and lists its synonyms. hereafter  we use the word  gene names  to refer to all of official names  aliases  abbreviations  and gene symbols.
　it is often the case that gene name dictionaries automatically compiled from existing databases  such as ours  are not very accurate due to multi-sense gene names  inconsistent format in the databases  etc. it requires manual curation to obtain high-quality dictionaries  1  1   which are important for general-purpose gene name recognition systems. fortunately  the quality of dictionary would not be as important in our application  because even if the dictionary provides wrong gene names as synonyms of a given gene  the wrong names are unlikely to appear in the article as they are irrelevant to the target gene with which the article is associated.
gene name identification. the next step is to find text fragments mentioning the gene in question. here  the problem is that  besides synonyms  gene names often have many variants due to arbitrary use of special symbols  white space  and capital and small letters . to tolerate these minor differences in identifying gene names  both gene names and text were preprocessed as follows  the actual order is not important .
  replace all special symbols  non-alphanumeric characters  with space  e.g.  nf-kappa ★ nf kappa 
  insert space between different character types  such as alphabets and numerals  e.g.  diet1 ★ diet 1 
  insert space between greek alphabets and other words  e.g.  kappab ★ kappa b 
  lowercase all characters
　then  each paragraph  identified by sgml tags  in the article was scanned if it contained any of the gene names associated with the gene in question. note that section titles were appended to each paragraph since they were often found to be descriptive. in
addition  if the paragraph referred to figures and/or tables for the first time in the article  their captions were also appended to the paragraph.
　we have so far obtained gene name synonyms and normalized both gene names and text to facilitate gene name identification. however  there remains another problem. that is  gene names are frequently written in slightly different forms with extra words  different word order  etc. for example   peroxisome proliferator activated receptor binding protein  may be referred to as  peroxisome proliferator activator receptor  ppar -binding protein  where un-

derlines indicate the differences. to deal with the problem  we used approximate word matching. to be precise  for each target gene name and each candidate which mentions any word composing the gene name  a word-overlap score defined below was computed.
                       m   α ， u overlap gene candidate  =		 1  n + β
where m and u denote the numbers of matching and unmatching words  respectively; α is a penalty for unmatching words  set to 1 ; n is the number of words composing the gene name; and β penalizes shorter gene names  set to 1 . if any candidate associated with a paragraph had a score exceeding a predefined threshold  set to 1   the paragraph was used to represent the harticle genei pair after stopword removal based on the pubmed stopword list1and stemming by lovins stemmer . for instance  the example of  peroxisome...  above has five matching and two unmatching words  resulting in an overlap score of 1. because it is greater than the threshold  1   the paragraph containing the candidate is extracted and used in part to represent the corresponding harticle genei pair. incidentally  the values of the parameters were determined based on our preliminary experiments on the training data.
　here  we treated a paragraph as a unit since it is thought to be organized in a single topic and seems to be an appropriate unit of extraction. in section 1  we will examine other alternative units.
1.1 mesh terms
　along with the article itself  we took advantage of external resources  specifically  medical subject heading  mesh 1 terms assigned to the article. mesh terms are controlled vocabularies developed at the national library of medicine  nlm  for indexing biomedical articles and are annotated by human experts at nlm.
　for each input article  all the associated mesh terms were obtained from the medline database1 using entrez utilities.1 because these mesh terms are annotated with articles  not with particular genes   they were added to each document  a set of paragraphs  representing a pair of the article and any gene coupled with it. note that a special symbol mesh+ was concatenated to each mesh term so as to distinguish mesh from other terms.
1.1 feature selection
　feature selection identifies the features  terms  that are more informative in terms of classification according to some statistic measure  which not only reduces the size of data but often improves classification . for this work  we applied the chi-square statistic method to the terms contained in the documents obtained through the previous steps.
chi-square statistic of term t in class c is defined as:
1  c  =	n ad   cb 1	 1 
χ  t
　　　　　　　　 a + c  b + d  a + b  c + d  where c is one of the go domain codes  bp  mf  and cc  or negative  neg   a is the number of documents containing term t in class c  b is the number of documents containing t in classes other than c  c is the number of documents not containing t in c  d is the number of documents not containing t in classes other than c  and n is the total number of documents. for each term t  chi-square statistic was computed for every class  and the maximum score was taken as the chi-square statistic for term t; that is  χ1 t  = maxi χ1 t ci . only the top n terms with higher chi-square statistics were used for the following processes. we empirically chose n=1 based on our preliminary experiments  where 1 terms were highest with class bp  1 with mf  1 with cc  and 1 with neg.
1.1 term weighting
　each harticle genei pair was associated with a set of selected terms in the preceding steps. to apply knn for classification as described in the next section  we converted it to a term vector adopting the classic vector space model  with conventional tfidf  term frequency-inverse document frequency  defined as:
n
	tfidf t d  =  1 + log tf t d   ， log		 1 
df t 
where tf t d  is a term frequency of term t within document d  n is the total number of documents  and df t  is the number of documents in which term t appears. in cases where tf t d  = 1 or df t  = 1  tfidf t d  is defined to be 1.
　we also tested another term weighting scheme  so called supervised term weighting  proposed by debole and sebastiani . it takes into account pre-labeled class information in training data and re-uses statistics computed in the feature selection step  e.g.  chisquare statistics  information gain  ...  in place of idf. we used tfchi which is defined as a product of tf and chi-square statistics. specifically  we tested two variants of the scheme  denoted as tfchi1 and tfchi1.
tfchi1 t d  =  1 + log tf t d   ， χ1 t 
	1 t  	 1 
tfchi1 t d  =  1 + log tf t d   ， log χ
1 knn classifiers
　we used a variant of knn classifiers to assign go domain codes to each pair of article and gene. knn is an instance-based classifier which is reported as one of the best classifiers for text categorization in both newswire and medical domains . in brief  it classifies input v to one or more predefined classes depending on what classes its neighbors belong to. the decision rule can be expressed as:
x
	if score c v  =	sim v nc i    tc  then assign c to v	 1 
　　　　　　　　　　　　　i where nc is the k nearest neighbors having class c （ {bp mf cc neg}  tc is a per-class threshold  and sim v nc i  returns cosine similarity between the arguments. threshold tc can be optimized to maximize an arbitrary metric  e.g. f1-score  using training data.
　we slightly modified the scoring scheme to multiply the similarity scores by the number of k neighbors having class c  denoted as
|nc|.
x
if score c v  =	sim v nc i  〜 |nc|   tc  then assign c to v	 1 
i
it intended to boost the scores for more frequent classes within the k neighbors. this modification slightly but constantly improved classification  around 1% in f1 score .
　although class c includes neg  we did not apply the decision rule above for the negative class. in other words  if none of the go domain codes was assigned to input  then it was considered to be negative. this ensures that an input does not have both positive  bp  mf  or cc  and negative classes together. it should be noted that  however  negative class does affect classification because more negative instances included in k neighbors generally lead to lower scores for the positive classes.
1. data and evaluation measures
1 data sets
　we used the same data set as the genomics track annotation task. the data set is composed of 1 full-text articles for training and 1 for test  both in sgml format. each of the articles is associated with one or more genes and each gene is annotated with one or more classes  bp  mf  and cc  or negative by mgi curators. the total numbers of triplets harticle gene classi are 1  1 positives and 1 negatives  and 1  1 positives and 1 negatives  for the training and test data  respectively. because gene names often contain greek alphabets  character entities used for representing greek alphabets  e.g.   &agr;  for α  were converted to the corresponding english spellings  e.g.  alpha  in advance to facilitate gene name identification.
　the training data were used for tuning several parameters including the number of k neighbors and per-class thresholds tc in equation  1  and were used as pre-labeled instances for knn to classify the test data.
1 measures
following the trec genomics track  we used micro-averaged
f1 score as an evaluation metric for go annotation  so as to make our results comparable with the official evaluation. f1 is defined as the harmonic mean of precision and recall as in equation  1 .
# of classes correctly predicted by the system
recall =
# of pre-labeled classes
# of classes correctly predicted by the system
precision = 1 
# of classes predicted by the system
1 〜 precision 〜 recall
f1 =
precision + recall
where classes are biological process  bp   cellular component  cc   and molecular function  mf  and do not include negative  neg .
1. results and discussions
1 primary results
　our proposed framework for go annotation was applied to the test data  where the per-class thresholds tc in equation  1  and other parameters including the number of k neighbors were optimized to maximize f1 for each term weighting scheme using the training data. for instance  for tfchi1  k was set to 1 and tc was set to 1  1  and 1 for bp  cc  and mf  respectively. table 1 compares our results  tfidf  tfchi1  and tfchi1  on the test data and the representative results from the trec official evaluation.
table 1: the trec official results and our results for go domain code annotation  on the test data set .
precrecallf1best111trecworst111mean111tfidf111ourstfchi1.1.1.1tfchi1.1.1.1　despite the simplicity of our method  it performed quite well  especially  tfidf and tfchi1  as compared with the official results. in the following sections  we take a closer look at major features or components of our framework and empirically investigate their contribution.
1 additional experiments
1.1 alternative settings
　we have made a number of arbitrary decisions in developing our framework. to investigate the effectiveness  we conducted several experiments with various different settings. particularly  we were interested if the features or components below had made any impact.
  gene name identification: we identified paragraphs that were likely to contain the target gene using approximate word matching  see section 1 . did it actually improve go annotation  to examine it  we used exact word matching to identify relevant paragraphs.
  gene name dictionary: assuming gene name identification above worked  did the dictionary for gene name expansion contribute to the performance  we tested our framework without the help of the dictionary.
  glossary and keyword fields: similarly  did the use of sgml tags   glossary  and  keyword   for finding gene name synonyms improve go annotation  we tested our framework without the information.
  mesh terms: did the inclusion of mesh terms contribute to classification  we tested our framework without mesh terms.
  unit of extraction: was a paragraph as a unit of extraction appropriate  we explored other units:
- only the sentence containing the target gene  denoted

as g 
- in addition to g  an immediately succeeding sentence  denoted as g+s 
- in addition to g+s  an immediately preceding sentence

 denoted as p+g+s 
- the entire article irrespective of the target gene  denoted as art 
note that  however  we did not let both g+s and p+g+s exceed paragraph boundaries. incidentally  our framework focusing on paragraphs would be placed between p+g+s and art.
1.1 empirical observations
　table 1 shows the best possible f1 scores for each of the experimental settings above  where the training data were classified using leave-one-out cross-validation  while the test data were classified using the training data as before. note that the bottom row  default  used the same setting as tfchi1 in table 1 but shows higher f1 than tfchi1  because threshold tc for knn was optimized on the test data for the purpose of cross-setting comparison.
table 1: results for alternative settings. numbers in parentheses under  average  indicate percent increase/decrease relative to  default .
experimental settingsf1trainingtestaveragegene name
identificationexact match111   1% gene name
dictionaryunused111   1% glossary and keyword fieldsunused111  +1% mesh termsunused111   1% unit of extractiong
g+s
p+g+s1 1
11 1
11   1% 
1   1% 
1   1% art111   1% default111gene name identification. using exact word matching for gene name identification severely deteriorated the performance on both of the training and test data sets. this supports our observation that gene names are often written in slightly different forms from their canonical ones  database entries . thus  flexible name matching schemes such as the one tested here are needed in order to exhaustively locate gene name occurrences. a possible drawback of approximate word matching is that it may recognize irrelevant word sequences as gene names  i.e.  false positives   leading to an inclusion of irrelevant text fragments into the representation of the target gene. however  the influence can be minimized by tuning the threshold  and parameters  for the word-overlap score defined in equation  1 . according to our experiments  a threshold of 1  which was used for our experiments  constantly yielded the best performance.
gene name dictionary. not using the gene name dictionary also deteriorated classification both on the training and test data by 1% on average. it verifies that gene name expansion using the dictionary did help to identify text fragments relevant to the target gene  even though the dictionary was automatically compiled
without manual curation.
glossary and keyword fields. contrary to our expectation  the use of glossary and keyword fields to search for gene synonyms was not found helpful for go annotation. there was little or no difference between the f1 scores produced with and without the use of the fields. close examination revealed that these fields hardly provided information regarding gene synonyms and thus had little effect on the classification performance. to be exact  there were only 1 pairs of gene and synonyms found in these fields out of 1 articles in the training and test data sets. mesh terms. similarly to the case of glossary and keyword fields  the f1 scores show little or no difference between the settings where mesh terms were used  default  and unused  meshunused . however  the difference becomes more apparent when looking at precision and recall. on the test data  default and meshunused yielded nearly equal precision  1 and 1  respectively   whereas using mesh terms  default  achieved a recall approximately 1% higher than mesh-unused  1 and 1  respectively . it suggests that the inclusion of mesh terms led to predict more potential classes for a given gene  which raised recall   but also produced some amount of false positives  which slightly decreased precision . the lower precision may be due to the fact that mesh terms are not gene-specific.
unit of extraction. four different units were tested in extracting text fragments. in short  as going from g  only sentences containing target genes  to art  entire articles  in table 1  more text was extracted for document representation. as can be seen  there is a trend that f1 slightly increases from g to p+g+s  sentences containing target genes plus immediately preceding and succeeding sentences  and then decreases when entire articles were used  i.e.  art  compared to default. however  we should not overlook that  surprisingly  art performed comparably to default on the test data  suggesting that our framework to use only text fragments containing target genes is not necessarily very effective. possible reasons are that  a  target genes were found everywhere in associated articles so that almost all paragraphs were extracted  making little difference whether entire articles or paragraphs were used;  b  not many articles were associated with multiple genes  and thus gene-specific document representation  such as ours  was not very important for the test data; and  c  multiple genes associated with single articles actually had almost the same classes. we investigated each possibility by comparing the training and test data but there was no noticeable difference found between them. to closely examine the effects of using paragraphs  we plotted recall-precision curves by varying the threshold for knn  where the same thresholds were applied to all classes  as shown in figure 1.
the top two curves were obtained on the test data and the bottom two were based on the training. although it is less apparent compared to the case of training data  it can be seen that  overall  using paragraphs  shown as solid lines  marginally improved the performance also on the test data.
1.1 contributions of different parts of articles
　our current framework  to some extent  takes into account the logical structure of input in a sense that it makes use of paragraph boundaries in extracting text fragments containing target genes. however  it does not consider or distinguish the structure of an article  e.g.  sections. such information may be useful for go annotation because different parts of articles may have different im-

recall
figure 1: the relation between recall and precision where either selected paragraphs or entire articles were used for document representation.
portance with respect to go annotation. for example  result and conclusion sections may be more relevant to go annotation as they usually report findings from experiments. therefore  we examined how useful the individual sections were for go annotation by using only one section at a time from which gene-bearing paragraphs were extracted. specifically  we focused on the following sections: abstract  introduction  procedures  methods  and results. both discussion and conclusion sections were regarded as result sections since they are sometimes not clearly separated from results  e.g.   results and discussion  section . incidentally  these sections were identified based on section names annotated by sgml tags.
　figure 1 shows a histogram for f1 scores produced using single sections on the training data  where we include results from the use of only titles and only mesh terms for comparison. the rightmost bar  all  used all the sections including mesh  which corresponds to  default  in table 1.

sections
figure 1: results produced by individual sections.  all  used all the sections. percentages above bars indicate the respective proportions to  all .
　surprisingly  the result section alone yielded almost as good f1 as all  followed by abs  abstract   mesh  proc  procedures   and so on. on the other hand  the method sections showed the least performance for go annotation. although not presented here  experiments on the test data also showed similar results.
1 the triage task
1.1 overview
the framework we described above aimed at go annotation.
however  it can be also applied to another task from the trec genomics track  i.e.  the triage task  see section 1 . in brief  the triage task is to determine if an input article contains experimental evidence that warrants go annotation  where no particular gene is specified. this task can be naturally regarded as a binary text categorization problem.
　in terms of text categorization  a primary difference between go annotation tackled in the previous sections and the triage task is that the former takes a pair of article and gene as input  whereas the latter takes only an article. as input is not gene-specific  the triage task could simply rely on an entire article for document representation without the necessity to locate the text fragments containing a particular gene. yet  because the triage decision must be made in consideration of the genes mentioned in a given article  our framework to use only gene-bearing paragraphs may be more appropriate. thus  we adapted our system to extract paragraphs that were likely to contain any gene names identified by the gene name recognizer yagi . note that mesh terms associated with a given article were also included as features as in go annotation.
1.1 methods
　we used the same methods described in section 1 for document representation and classification except the followings:
  for document representation  only paragraphs that were likely to contain any gene name  determined by yagi  were used. feature selection and term weighting were done in the same ways as go annotation.
  for classification  the variant of knn classifiers defined in equation  1  was used but had only two classes  i.e.  positive  pos  and negative  neg . if an input article was classified as pos  it was outputted as positive irrespective of whether classified as neg.
1.1 data and evaluation measures
　we used the trec data sets provided for the triage task  which was composed of 1 full text articles for training  1 positives and 1 negatives  and 1 for test  1 positives and 1 negatives . as is the case with go annotation  the training data were used for tuning parameters and were used as pre-labeled instances for knn to classify the test data. specifically  the number of neighbors k and the value of threshold tpos were set to 1 and 1  respectively  which produced the best result in normalized utility measure  explained next  on the training data.
　for the evaluation measure  normalized utility measure unorm defined below was used according to the trec evaluation.
	unorm = uraw/umax	 1 
where
uraw = 1 〜 tp   fp
 1 
umax = 1 〜  tp + fp 
tp and fp denote the number of articles correctly identified as positive  true positive  and the number of articles falsely identified as positive  false positive   respectively.
1.1 results and discussions
　table 1 compares our results with the representative results from the trec official evaluation  where precision and recall results are also presented.
table 1: the trec official results and our results for the triage task  on the test data set .
precrecallunormbest111trecworst111mean111tfidf111ourstfchi1.1.1.1tfchi1.1.1.1　our framework with the term weighting scheme tfchi1 compared favorably with the best performing system reported at trec  while tfidf did not perform as well. this is mainly because the tfidf scheme could not assign an appropriate  high  weight to the mesh term  mice  since it appeared in many documents  leading to a low idf value . it was reported that a simple rule which classifies articles annotated with the mesh term mice as positive and those without it as negative could achieve nearly as good performance as the best reported result .
　unlike tfidf  tfchi considered word distributions across different classes and was able to assign higher weights even to the terms that appeared in many documents but almost only within a class  such as mice in this particular data sets. to contrast the difference between idf and χ1 values  we plotted a scatter diagram for corresponding idf and χ1 as shown in figure 1  where mesh terms are indicated by capitalization.

chi square statistics
figure 1: a scatter plot for χ1 and idf.
as can be seen  high-χ1 words  such as mice  animals  embryon  the stem for embryonic   and knockout  were not necessarily assigned high idf values. interestingly  the correlation coefficient for idf and χ1 turned out to be  1  which is usually strongly and positively correlated as empirically known in the text categorization literature . the result suggests that tfidf  which is often used for text categorization  is not necessarily optimum depending on the characteristics of the target data. this supports the idea of the supervised term weighting schemes  that class-based term weights  e.g.  chi-square statistics  is more appropriate for classification.
　it may be also possible  however  that our framework with tfchi1 performed well solely because of the notably high value of χ1 associated with the mesh term mice  remember that simple heuristics using mice could perform very well . to investigate  we applied the tfchi1 scheme to hypothetical test data where the mesh term mice was completely removed. the resulting normalized utility score was 1  which outperforms the tfidf scheme in table 1 and is still comparable to the second best system   which produced a unorm of 1  in the trec evaluation.
1. related work
　this section discusses representative work by other researchers for the go annotation and triage tasks.
　for go annotation  settles et al.  developed a two-tier classification framework using na： ve bayes  nb  classifiers and maximum entropy  me  models with several external resources and specialized features. they exploited the structure of articles and distinguished six section types  such as introduction and discussion  as a unit of classification. they created an nb classifier for each section and the output probabilities of the nb classifiers were then combined using me models which differently weighted each of the section types and classes. the features used for the nb classifiers included not only words from body text but also syntactic patterns and what they call informative terms. the syntactic patterns are frequent patterns for subjects and direct objects  e.g.   translation of x   automatically collected from training data using a shallow parser. the informative words were word n-grams  1＋n＋1  having high chi-square statistics. to supplement the relatively small size of the training data provided by trec  they used external resources including the biocreative data set and medline abstracts with which specific genes and go codes were associated in existing databases other than mgi. the reported f1 score was 1  which is 1% lower than our best score reported here. the difference is presumably due to the fact that their system did not employ gene name expansion and approximate word matching which we found highly important for go annotation.
　for the triage task  dayanik et al.  applied bayesian logistic regression  blr  models  which estimate a probability that an input belongs to a specific class. for document representation  they used mesh terms from the medline database in addition to input articles. their best result was achieved by applying the following configuration. they used only title  abstract  and mesh terms for features and applied the conventional tfidf term weighting scheme  and proposed a two-stage classifier which assigned negative to all articles not indexed with the mesh term mice and classified those indexed with mice by using blr. the reported normalized utility score is 1. in spite of using tfidf  which yielded suboptimal results in our experiments  their method outperformed other trec participants.
1. summary and future research
　this paper presented our work on automating go domain code annotation. we approached this task by treating it as a text categorization problem and adopted a variant of knn classifiers. to apply knn  we first represented each input  harticle genei pair  by a term vector  where terms were collected from text fragments  paragraphs  containing the target gene. to exhaustively locate the gene name occurrences  we took advantage of existing databases to automatically compile a gene name synonym dictionary and preprocessed both gene names and text to tolerate minor differences between them. in addition  we utilized approximate word matching to identify gene occurrences to deal with other irregular forms of the gene names. the collected words were then fed to feature selection using chi-square statistics  which were re-used for term weights adopting supervised term weighting schemes. we evaluated the proposed framework on the trec genomics track data sets and showed that  overall  our method performed the best compared with the trec official evaluation. further analyses revealed that the flexible gene name matching used in conjunction with the gene name dictionary was notably effective. another finding is that the result sections of articles contributed the most for go annotation. it was also demonstrated that our framework was successfully applied to a related but different problem  the triage task  producing a normalized utility score of 1 which is comparable to the best reported performance at the recently held trec. in addition  the tfidf scheme was found suboptimal for this particular task and data sets.
　for future research  we are planning to explore a better use of structure of articles  e.g.  sections  and local context around the target genes. such information may be incorporated into the current framework by way of term weights. another direction is to extend our work to more advanced  realistic settings. for example  in the real-world go annotation  genes are not given in advance. taking only articles as input without specific genes would be an interesting challenge.
1. acknowledgment
　this project is partially supported by the nsf grant enable #1.
