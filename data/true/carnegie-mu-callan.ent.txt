   we present experiments using language models to rank e-mail messages for the known-item finding task of the enterprise track. we combine evidence from the text of the message  its subject  the text of the thread the in which the message occurs  and the text of messages that are in reply to the message. we find that the only statistically significant differences suggest that in addition to the text of the message  the subject is a very important piece of evidence. we also explore the use of a depth based prior  where emphasis is place on messages near the root of the thread structure  which has mixed results.
1 introduction
in this paper we consider the task of known-item finding of email messages equivalent to other structured retrieval tasks. in doing so  we observe that email messages occur in a thread structure as well as have their own internal structure. viewed in this way  we can consider this task to be identical to the xml component retrieval investigated at inex . we consider  documents  to be a thread of email messages and the components we wish to retrieve as the email messages  which are components contained in the documents.
   structuring email messages in this manner allows us to easily investigate incorporating evidence from the thread as well as structure within the email message itself. we do so using code to be soon released  scheduled for january 1  as part of the indri search engine in the lemur toolkit .
   we use the indri search engine to investigate two methods to combine evidence. one is a hierarchical language modeling approach investigated at inex  and the other is a post query combination method investigated for known-item finding of web pages . within these methods we investigate the use of the text of the emails  the email subjects  the text of the thread  and that of the subthread  messages in reply to a message . we also explore the use of a depth based prior  where depth corresponds to the depth of the message in the thread. the depth based prior was motivated by observations of the training topics.
   section 1 presents the mixture method followed by the post query combination method. it also describes how the depth prior is incorporated into ranking. section 1 describes the implementation in indri  estimation of the prior  and the evaluation methodology. section 1 presents results on the training topics  while section 1 presents the results on the test topics. the paper is concluded in section 1.
1 model
in one approach  we rank email messages by estimating the probability that the a language model estimated for the email message generated the query. we use simple unigram language models  which are multinomial probability distributions over words in the vocabulary. that is  a language model 붿 specifies
p  w|붿 . email messages are then ordered by  where 붿e is the language model estimated for a particular email message e.
   in order to estimate the language model 붿e  we note that we would like to incorporate evidence from the message itself and from other messages in the thread in which e was found. with that in mind  we estimate 붿e as a linear combination of several language models:
		 1 
where em refers to the text of the email  ti refers to the title tag in the documents  the subject of the email   th refers to the text of the entire thread  su refers to the text of the subthread which corresponds to the email itself and all replies to the email  and co refers to the text of the entire collection. 붿mle text  is the maximum likelihood estimate of the multinomial language model on text  which is given by:
		 1 
   the other approach we investigate performs an equivalent of a meta-search ranking model where the different rankings are produced by the different ranking models. here we rank by
		 1 
where
		 1 
this model does allow relative weighting of the different structural components of messages in the thread. this model corresponds to the linear weighted combination of log probabilities  which we investigated in . we will present results on ranking by p  q|붿e  and by the model specified in equation 1. we will refer to ranking by p  q|붿e  as the mixture method and equation 1 as the post query combination approach. our official submissions used the post query combination approach
   inspired by the usefulness of document priors for the similar task of knownitem finding on the web   we experimented with the use of prior probabilities of relevance based on the  depth  of the message. by  depth   we mean refer to the depth of the email in its thread structure. to incorporate the depth prior into either model  we multiple the score  p  q|붿e  or equation 1  by:
	p  e is relevant|depth e  	 1 
which we estimate from the training data.
1 methodology
this section briefly discusses technical details of the implementation and the evaluation techniques that will be used in later sections.
1 implementation
our experiments were performed in a locally enhanced version of the indri search engine  which is a part of the lemur toolkit . the corpus was reorganized so that all messages in a thread are in the same document  where an email message was restructured as:
 lists 
 trec formatted document 
 responses 
 response 1 
 response 1  ...
 response n 
모 /responses   /lists 
where   trec formatted document   refers to an email in the w1c corpus with its   doc   and   /doc   tags and a  response  is a reply to the message formatted as other email messages surrounded by   lists   and   /lists   tags and also containing its responses. thread structure was constructed from william webber's in-reply-to file .
   within indri  we indexed the  lists    responses    doc   and  title  tags  where the  title  tag corresponds to the subject of the original email. we
posterior뫚 priordepthp depth e |e is rel. p depth e  뫚 p e is rel.|depth e  = 1.1.1.1= 1.1.1.1뫟 1.1.1.1table 1: estimation of the thread depth based prior.
stemmed terms using the krovetz stemmer  but we did not use a stopword list. the original topics were converted into nexi  queries to search the structured database using the simple rewrite:
//doc about .   topic terms   
where   topic terms   are the terms contained in the original topic. this query simply requests  doc  components  email messages  matching the original query.
1 prior estimation
we estimated the email message depth based prior for three categories of depths: zero  one  and two or more. to estimate the prior probability in equation 1  we first estimate the posterior p  depth e |e is relevant . we can estimate this directly from the training topics. when performing estimation  we used a laplace estimator of the posterior in the topic set  as we had only 1 training topics:
	p  depth e  = 1|e is relevant 	=
	p  depth e  = 1|e is relevant 	=	 1 
	p  depth e  뫟 1|e is relevant 	=
   the posterior distribution was used to estimate the prior probability of relevance for an email through the use of bayes rule:
p  e is relevant 
p  e is relevant	
모모모모모모모모모모모모모모모모모모모모모모모모모모모모모모모모모 1  p  e is relevant  was assumed constant across all email messages and p  depth e   was estimated by examination of email messages in the corpus. note that we only estimated a value proportional to the prior during ranking  as p  e is relevant  was assumed constant. the values we estimated are presented in table 1.
1 measures
for evaluation measures we present the number found in the top 1 and mean reciprocal rank  mrr   placing emphasis on mrr. mean reciprocal rank is the average over all queries of one divided by the rank the correct document was found in the top 1 results  zero if there is no correct document in the top 1 results . a mrr close to one is good and mrr places much emphasis on the systems ability to rank correct documents near the top of the list.
   when we discuss statistical significance tests  we use a one-tailed pairwise comparison using the bootstrap and the benjamini-hochberg method for multiple test correction . the bootstrap uses repeated samples of topics with replacement from the original topic set. mrr is computed over the samples. this allows the bootstrap to non-parametrically estimate what may happen on other topic sets. from this we can estimate whether a system configuration performs significantly better than another configuration of the system. as we do these comparisons many times  it is important to correct for multiple testing. otherwise  we may incorrectly conclude that two system configurations behaved differently when the differences could be easily due to random chance. to correct for this  we use the benjamini-hochberg method. for more information on the bootstrap and correction for multiple tests  see . the significance tests reported below use 1 bootstrap samples and significance is tested at the 1 level.
1 training topics
tables 1 and 1 show the results of various combinations of using the subject  thread  and subthread information was well as the depth prior of the post query combination method and the mixture combination method. the parameter values were hand chosen and may not be optimal for either the training or testing set. from the tables we see that there is a trend that the subject and depth priors tend to help performance noticeably. we also observe that the post query combination method seems to perform better than the mixture method.
   in order to get a better understanding of the differences found between configurations of the system in the training data  we performed one-tailed pairwise comparisons using the bootstrap test corrected for multiple testing using the benjamini-hochberg method. after running statistical significance tests  we found that there were very few significant differences at the 1 level.
   the few cases where the significance test did find differences between systems involved comparing the post query combination method with weight on the subject of the email with the mixture language model method that did not place extra weight on words in the subject of the email  but did place some weight on the thread or subthread.
   if we rely on the values for mrr on the training set  we would guess that the post query combination method using all features and the depth prior would result in the best performance on the evaluation set of topics. however  noting that this configuration was not significantly better than any of the other approaches tested  one should not be very confident in this guess.
dirichletsubjectthreadsubthreaddepthnumbermrrparameter 뷃뷂ti뷂th뷂supriorfound1.1.1.1yes1.1111no1.1111yes1.1111no1.111.1yes1.111.1no1.111yes1.111no1.11.1.1yes1.11.1.1no1.11.1yes1.11.1no1.111yes1.111no1.111yes1.111no1.1table 1: results of various configurations of the post query combination method  equation 1  evaluated on the training topics.
dirichletsubjectthreadsubthreaddepthnumbermrrparameter 뷃뷂ti뷂th뷂supriorfound1.1.1.1yes1.1111no1.1111yes1.1111no1.111.1yes1.111.1no1.111yes1.111no1.11.1.1yes1.11.1.1no1.11.1yes1.11.1no1.111yes1.111no1.111yes1.111no1.1table 1: results of various configurations of the mixture method  p  q|붿e   evaluated on the training topics.
subj.thr.subthr.depthnum.mrrofficialrun뷃뷂ti뷂th뷂supriorfoundmrrname1.1.1.1yes1.1.1cmuallon1.1.1.1no1.1.1cmunoprior1.1.1yes1.11.1.1no1.11.11yes1.11.11no1.1.1cmunops1.11yes1.11.11no1.1.1cmunopsd111yes1.1111no1.1111yes1.1111no1.111.1yes1.111.1no1.111yes1.111no1.1.1cmunopsdttable 1: results of various configurations of the post query combination method  equation 1  evaluated on the training topics. our official runs have different results than those presented in this table. we have presented the performance of the official runs next to similar system configurations. we are still looking for the source of the disagreement in performance.
1 test topics
tables 1 and 1 show performance of the post query combination and mixture methods on the test topics. due to some system differences  our official submissions had higher mrr than the similar system configurations in table 1. we have presented the official results beside these results for clarity.
   we first note that the depth based prior did not always improve performance as it did in the training set. this suggests that our training set was not representative of the test set with regards the thread depth of a known-item messages.
   another thing to observe is that the subject of the email message consistently provides valuable information for both the post query combination method and the mixture method. the mixture method seems to get additional benefit from the thread and subthread  while the post query combination method does not.
   we also wish to observe that the lower performance of the mixture method when compared to the post query combination method on the test set has disappeared in the test topics. in fact  of the unofficial results  the mixture method using all features except the depth prior has the best mean reciprocal rank.
however  most of these differences are not statistically significant. as with
dirichletsubjectthreadsubthreaddepthnumbermrrparameter 뷃뷂ti뷂th뷂supriorfound1.1.1.1yes1.1111no1.1111yes1.1111no1.111.1yes1.111.1no1.111yes1.111no1.11.1.1yes1.11.1.1no1.11.1yes1.11.1no1.111yes1.111no1.111yes1.111no1.1table 1: results of various configurations of the mixture method  p  q|붿e   evaluated on the training topics.
the test topics  we also found few significant differences between the system configurations in the test topics. variations of the post query combination method placing weight on the subject but not using the depth prior were better than both mixture and post query combination methods that did not use the subject or the depth prior. these observations are fairly consistent with those found in the training set  although more significant differences were found.
1 conclusions
we investigated the use of two combination methods to combine evidence in email messages for the task of known-item finding of email messages. the post query combination method is essentially a meta-search combination method that ranks each email document representation  then combines the scores from each representation using a weighted sum of the log of the scores from the representations. the mixture method combines the language models estimated from each representation. both methods performed well on the corpus  although the mixture combination method may be more stable with the addition of new features.
   when using the combination methods  we examined the subject of the messages as well as the content of the thread and subthread  all messages in reply to the message . the only universally helpful feature was the subject of the thread  which improved performance noticeably for both combination methods. in some cases  this improvement was statistically significant at the 1 level in both the training and testing topics. the only statistically significant differences found between configurations of the systems involved configurations using the subject performing better than configurations that did not use the method.
   we also considered a depth based prior that looked promising on the training topics but did not perform well on the test topics. we would like to investigate this more for the final version of this paper.
   we would also like to note that this was in part an experiment in using the lemur toolkit . apart from the depth prior  which proved to not be very effective  and some data conversion scripts  we were able to use the toolkit without modification. this demonstrates the flexibility and effectiveness of the lemur toolkit.
1 acknowledgements
the authors would like to thank william webber for providing the extracted thread structure. this research was sponsored by national science foundation  nsf  grant no. ccr-1. the views and conclusions contained in this document are those of the author and should not be interpreted as representing the official policies  either expressed or implicit  of the nsf or the us government.
