arabic  a highly inflected language  requires good stemming for effective information retrieval  yet no standard approach to stemming has emerged.  we developed several light stemmers based on heuristics and a statistical stemmer based on co-occurrence for arabic retrieval.  we compared the retrieval effectiveness of our stemmers and of a morphological analyzer on the trec-1 data. the best light stemmer was more effective for cross-language retrieval than a morphological stemmer which tried to find the root for each word. a repartitioning process consisting of vowel removal followed by clustering using co-occurrence analysis produced stem classes which were better than no stemming or very light stemming  but still inferior to good light stemming or morphological analysis.   
categories and subject descriptors 
h.1  information storage and retrieval : content analysis and indexing - indexing methods  linguistic processing; h.1  information storage and retrieval : information search and retrieval - clustering.   general terms: experimentation  performance  algorithms. 
keywords: cross-language information retrieval  crosslingual  stemming  arabic. 
1. introduction 
stemming is one of many tools used in information retrieval to combat the vocabulary mismatch problem  in which query words do not match document words.  stemmers equate or conflate certain variant forms of the same word like  paper  papers  and  fold  folds  folded  folding... . in english and many other western european languages  stemming is primarily a process of suffix removal  1  1 . such stemmers do not conflate irregular forms such as  goose  geese  and  swim  swam .  in this work  we use the term stemming to refer to any process which conflates related forms or groups forms into equivalence classes  including but not restricted to suffix stripping. stemming has been shown to improve performance in information retrieval tasks  usually by a small amount  and is considered to aid recall more than precision . 
stemmers are generally tailored for each specific language.  their design requires some linguistic expertise in the language and an understanding of the needs of information retrieval.  stemmers have been developed for a wide range of languages including malay   latin   indonesian   swedish   dutch   german   french   slovene   and turkish . the effectiveness of stemming across languages is varied and influenced by many factors.  a reasonable summary is that stemming doesn't hurt retrieval; it either makes little difference or it improves performance by a small amount.  stemming appears to improve effectiveness more for highly inflected languages  1  1  and when queries and/or documents are short . 
statistical methods can provide a more language-independent approach to conflation. related words can be grouped based on various string-similarity measures.  such approaches often involve n-grams.  equivalence classes can be formed from words that share word-initial letter n-grams or a threshold proportion of ngrams throughout the word  or by refining these classes with clustering techniques. this kind of statistical stemming has been shown to be effective for many languages  including english  turkish  and malay  1  1  1  1 . 
stem classes can also be built or refined using co-occurrence analysis  which xu and croft proposed as a promising languageindependent approach to stemming .  they demonstrated an improvement in retrieval effectiveness for english and spanish after clustering conventional and n-gram based stem classes.  initial n-gram based stem classes are probably not the right starting point for languages like arabic in which suffixing is not the only inflectional process.  see the overview of arabic language issues below . however  co-occurrence or other clustering techniques can be applied to arabic without using n-grams. 
in the research reported here  we developed several light stemmers for arabic which remove a small number of prefixes and suffixes and a co-occurrence based statistical stemmer which creates large stem classes by vowel removal and then refines these classes using co-occurrence. we evaluate these and several other approaches to arabic stemming. 

permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  or republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee. 
sigir'1  august 1  1  tampere  finland. 
1. the arabic language and orthography 
copyright 1 acm 1-1/1...$1. 
 arabic information retrieval has a particularly acute need for effective normalization and stemming.  both orthography and morphology give rise to a huge amount of lexical variation.  vocalized text includes diacritics for short vowels and other details  conveying a nearly phonetic representation of a word  but it is only found in special contexts.  the newspaper articles that make up the trec-1 corpus are not vocalized.  nonvocalized orthography is more ambiguous  and can cause a mismatch with texts  dictionaries  or queries that are vocalized. regional variations in spelling add to the vocabulary mismatch problem. 
other variability arises from the derivational and inflectional productiveness of arabic.  a given word can be found in huge number of different forms which should possibly be conflated for information retrieval.  many definite articles  conjunctions  particles and other prefixes can attach to the beginning of a word  and large numbers of suffixes can attach to the end.  at a deeper level  most noun  adjective  and verb stems are derived from a few thousand roots by infixing  for example  creating words like maktab  office   kitaab  book   kutub  books   kataba  he wrote   and naktubu  we write   from the root ktb . 
thus  some of the most closely related forms such as singular and plural nouns are irregular  and are not related by simple affixing  prefixing and suffixing .  this situation is seen in english for a tiny fraction of nouns and a small number of very frequent verbs like the examples in the first paragraph of this paper  but is very common in arabic.  
for information retrieval  this abundance of forms means a greater likelihood of mismatch between the form of a word in a query and the forms found in documents relevant to the query.  distributional analyses of arabic newspaper text show more words occurring only once and more distinct words than english text samples of comparable size.1 the token to type ratio  mean number of occurrences over all distinct words in the sample  is smaller for arabic texts than for comparably sized english texts .  stemming should therefore be very important for arabic information retrieval. 
1. previous research 
1 stemming in arabic 
all the factors described in the previous section make arabic very difficult to stem.  first  there is the choice between roots or stems as the desired level of analysis for information retrieval.  considerable research on stemming and morphological analysis is amassing for the arabic language  but no standard ir-oriented algorithm has yet emerged.   
four different approaches to arabic stemming can be identified - manually constructed dictionaries  algorithmic light stemmers which remove prefixes and suffixes  morphological analyses which attempt to find roots  and statistical stemmers  which group word variants using clustering techniques. 
manually constructed dictionaries of words with stemming information are in surprisingly wide use. al-kharashi and evens worked with small text collections  for which they manually built dictionaries of roots and stems for each word to be indexed . tim buckwalter  developed a set of lexicons of arabic stems  prefixes  and suffixes  with truth tables indicating legal combinations. the bbn group used this table-based stemmer in trec1 . 
light stemming refers to a process of stripping off a small set of prefixes and/or suffixes  without trying to deal with infixes  or recognize patterns and find roots.  light stemming is mentioned by some authors without details  1  1 .  no explicit lists of strippable prefixes and/or suffixes or algorithm had been published at the time we did this research.  although light stemming can correctly conflate many variants of words into large stem classes  it can fail to conflate other forms that should go together. for example  broken  irregular  plurals for nouns and adjectives do not get conflated with their singular forms  and past tense verbs do not get conflated with their present tense forms  because they retain some affixes and internal differences. 
several morphological analyzers have been developed for arabic  1  1  1  1  1  but few have received a standard ir evaluation.  such analyzers find the root  or any number of possible roots for each word.  in addition  some attempt a more complete grammatical analysis of the word .  a morphological analyzer developed by kareem darwish was used by some of the trec participants in 1  1  1 . we obtained a simple morphological analyzer from khoja and garside  for this research. 
published comparisons of stems vs. roots for information retrieval have claimed that roots are superior to stems  based on small  nonstandard test sets  1  1 . recent work at trec found no consistent differences between roots and stems .   
1 statistical approaches to stemming 
statistical techniques have widely been applied to automatic morphological analysis in the field of computational linguistics  1  1  1  1  1  1  1  1 .  for example  goldsmith finds the best set of frequently occurring stems and suffixes using an information theoretic measure . oard et al. consider the most frequently occurring word-final n-grams  1  1  1  and 1-grams  to be suffixes .  although such systems can be used on many different languages  they cannot be expected to perform well on languages like arabic in which suffixing is not the only inflectional process. 
mayfield et al. have developed a system which combines wordbased and 1-gram based retrieval  which performs remarkably well for many languages  including arabic .   
al-fares and de roeck  used clustering on arabic words to find classes sharing the same root.  their clustering was based on morphological similarity  using a string similarity metric tailored to arabic morphology  which was applied after removing  a small number of obvious affixes.   they evaluated the technique by comparing the derived clusters to  correct  classes.  they did not assess the performance in an information retrieval context. 
stemmers make two kinds of errors.  weak stemmers fail to conflate related forms that should be grouped together.  strong stemmers tend to form larger stem classes in which unrelated forms are erroneously conflated.  most stemmers fall between these two extremes and make both kinds of errors.  xu and croft  employ a corpus analysis approach which is particularly suited to splitting up stem classes created by strong stemmers. the stemclasses are reclustered based on a co-occurrence measure  which is language independent in that it can be applied to any set of stem classes. 
xu and croft applied their technique to effectively stem english and spanish and showed two important points. first  one can refine an already-good stemmer by co-occurrence analysis and improve average precision.  second  one can start with a strong crude stemmer like an n-gram stemmer and use co-occurrence analysis to yield stem classes that work as well as a sophisticated stemmer.  
in this work we apply the technique to arabic  which has a more complex morphology than spanish or english.  our goal was to determine whether a simple and effective arabic stemmer could be quickly developed without a considerable amount of linguistic knowledge. details of this technique are given in section 1. 
1. our approaches to arabic stemming 
in the present research we compare several different approaches:  no stemming  light stemming  morphological analysis to find roots  and statistical stemming using co-occurrence analysis  on the trec-1 arabic data. 
1 normalization 
before stemming  corpus and queries were normalized as follows: 
  convert to windows arabic encoding  cp1  
  remove punctuation 
  remove diacritics  primarily weak vowels .  some dictionary entries contained weak vowels.  removal made everything consistent. 
  remove non letters 
  replace         and   with  	   
  replace final   with   
  replace final    with   
1 light stemmers 
although several researchers allude to light stemming  we found no publication explicitly listing which affixes should be removed.  our guiding principle was to try to remove strings which would be found as affixes far more often than they would be found as the beginning or end of an arabic word without affixes.  we also benefited from discussions with some colleagues at trec-1  particularly m. aljlayl. we tried several versions of light stemming  all of which followed the same steps: 
1. remove     and   for light1  light1  and light1 if the remainder of the word is 1 or more characters long.  although it is important to remove    it is also problematic  because many common arabic words begin with this character  hence the stricter length criterion here than for the definite articles. 
1. remove any of the definite articles if this leaves 1 or more characters.  
1. go through the list of suffixes once in the  right to left  order indicated in table 1  removing any that are found at the end of the word  if this leaves 1 or more characters. 
the strings to be removed are listed in table 1. the  prefixes  are actually definite articles and a conjunction.  the light stemmers do not remove any strings that would be considered arabic prefixes.   
 
table 1: strings removed by light stemming 
 remove from front remove suffixes light1                         nonelight1                             nonelight1        light1                                          
1 morphological analysis 
for morphological analysis we used software developed by khoja and garside   which first peels away layers of prefixes and suffixes  then checks a list of patterns and roots to determine whether the remainder could be a known root with a known pattern applied.  if so  it returns the root.  otherwise  it returns the original word  unmodified.  this system also removes terms that are found on a list of 1 arabic stop words.  unlike the buckwalter approach  this scheme has no table restricting the patterns and affixes applicable to particular stems and roots. preliminary work with the khoja stemmer revealed problems with proper nouns  so our implementation included a list of country and major city names translated into arabic  considered  unbreakable   and exempted from further stemming.  we tested the morphological analyzer both with and without the unbreakables. 
1 simple stemmers 
many of the variant patterns derived from a single arabic root differ internally only in vowels  see the examples in section 1 .  removing vowels collapses the light stem classes into a smaller number of larger classes  grouping many forms that belong together and many forms that do not. simple stemming consisted of light stemming and removal of vowels           .  short vowels were already removed during normalization . our simple stemmers were intended to be strong  that is  to conflate too many forms  so that subsequent statistical analysis could find better classes by splitting.   
we used three simple stemmers:  simple stems were derived by removing vowels from normalized words.  simple1 applied light1 stemming  and then removal of vowels.  simple1 applied light1 stemming  and then removal of vowels. 
1 co-occurrence analysis 
co-occurrence analysis was used to refine the simple stemmers and the khoja stemmer  which were the strongest stemmers in the sense of creating the largest and overly-inclusive stem classes.  we refer to the combined process of removing vowels and refinement with co-occurrence analysis as repartitioning. 
co-occurrence analysis is based on em  a variant of emim  expected mutual information    which measures the proportion of word co-occurrences that are over and above what would be expected by chance.  for two terms  a and b  em is defined as:  em a b  = max nabn  en+ n ba b   1  a
where nab is the number of times a and b co-occur in a text window of fixed size.  na and nb are the number of occurrences of a and b in the corpus. en a b   the expected number of co-occurrences of a and b  is knanb  where k is a constant based upon the corpus and window size.  k is estimated from a sample of 1 randomly chosen word pairs:   k =‘nab‘nanb  
in our experiments  k = 1x1.  the arabic documents are short  1 words on average   so we used document length as our window size. 
to repartition a stem class  the em metric is calculated for all the pairs of words in the class.  in a first pass  a connected component algorithm is used to connect term pairs if their em score exceeds a threshold  emthresh.  when the size of a resulting cluster is greater than twelve  a second-pass optimization is performed via approximate optimal partitioning .  in this second pass all pair-wise em scores are used to calculate an overall fitness measure  cohesion  for the class.  a greedy algorithm refines the class by keeping terms that maximize cohesion and removing terms that lower it.  this is done by partitioning the class into singleton sets  then repeatedly forming the union of the two sets for which cohesion is greatest.  the algorithm stops when no two classes have a positive cohesion or when all terms belong to one class.  cohesion for a pair of terms  a and b  is calculated as em a b  - δ  where δ is a limit on the amount by which conflating the terms could hurt precision.  cohesion for a set is the sum of cohesions for all pairs of words in the set. 
in xu and croft's work  emthresh = 1 and δ = 1 were found to work well for the range of collections to which they applied the technique.  we varied the values of these parameters for arabic and did not find better values. 
1. monolingual arabic stemming experiments 
1 experimental method 
the trec-1 arabic corpus  also called the afp arb corpus  consists of 1 newspaper articles in arabic from agence france presse.  this fills up almost a gigabyte in utf-1 encoding as distributed by the linguistic data consortium.  there are 1 topics with relevance judgments  available in arabic  french  and english  with title  description  and narrative fields.  although this test collection is small and has some problems  it is the only standard arabic test set available . we used the arabic titles and descriptions as queries in monolingual experiments  and the english titles and descriptions in cross-language experiments. 
corpus and queries were converted to cp1 encoding and indexed using an in-house version of inquery . arabic strings were treated as a simple string of bytes  regardless of how they would be rendered on the screen.  text was broken up into words at any white space or punctuation characters  including arabic punctuation.  words of one-byte length  in cp1 encoding  were not indexed.  the experiments reported here used inquery for retrieval. 
for the normalized conditions and some stemming conditions  we stemmed all tokens before indexing  and stemmed the queries with the same stemmer for retrieval.  the co-occurrence experiments employed query-based stemming  where all retrieval uses a normalized  unstemmed database.  the query was expanded  replacing each query term with a #syn  synonym  operator enclosing all members of the query term's stem class.  we verified for several baseline stemming conditions that we get identical results whether we stem queries and corpus  or use query-based-stemming. 
arabic queries were expanded using the technique of local context analysis  adding 1 terms from the top 1 documents  as described in detail in .  expansion was performed in order to show the ultimate level of performance attainable using the stemmers in the context of our whole system. 
1 results 
1.1 comparison of basic stemmers 
figure 1 shows precision at 1 recall points for the primary stemmers tested.  raw means no normalization or stemming  khoja means the khoja stemmer  and khoja-u refers to the khoja stemmer with the addition of the unbreakables list of items exempted from stemming.   

 
figure 1: monolingual 1 point precision for basic stemmers  unexpanded queries 
 
table 1: monolingual average precision for basic stemmers  unexpanded 
stemmer raw norm light1 light1 light1 av. precision .1    .1 .1 .1 .1 pct. change  1 1 1 1  
stemmer raw khoja-u khoja light1 av. precision .1    .1 .1 .1 pct. change  1 1 1  
table 1 shows uninterpolated average precision for the basic stemmers.  for raw  normalized  and light stemming conditions performance is better with each successive increment in degree of stemming.  each of these increments is statistically significant.1  surprisingly  on this data set  the khoja stemmer performed better without the unbreakable list of countries and cities.  however  this difference is not statistically significant. although the light1 stemmer looks better than khoja these differences are also not significant.  because the khoja stemmer removes stop words and the other stemmers do not  we consider stop word removal next. 
1.1 removing stop words 
table 1 shows the effect of removing stop words.  for all four degrees of stemming: raw  norm  light1  and light1  removing stop words results in a small increase in average precision  which is statistically significant for light1 and light1  but not for raw and normalized conditions. 
 
table 1: monolingual average precision for stemmers with and without removing stop words 
stemmer raw norm light1 light1 stop words in .1 .1 .1 .1 stop words removed .1 .1 .1 .1 pct.change 1 1 1 1  
the fairer comparison between the khoja stemmers and light1 after removing stop words  light1-s  is summarized in table 1.  the difference between light1-s and khoja-u  with unbreakables  is statistically significant  for both unexpanded and expanded queries.  the difference between light1-s and khoja  without unbreakables  is not significant for unexpanded or expanded queries.  in short  the best stemmers for monolingual information retrieval were light1-s  a light stemmer  and khoja  a morphological analyzer.  
 
table 1:  monolingual average precision with and without query expansion 
stemmer raw norm-s khoja-u khoja light1-s unexp. .1 .1 .1 .1 .1 expanded  .1 .1 .1 .1 .1  
1.1 simple stemming and co-occurrence analysis 
the four sections of table 1 show retrieval performance and stem class sizes for each of the four baseline stemmers  in boldface  that were subjected to repartitioning  norm-s  light1-s  light1-s  and khoja . for norm-s  light1-s  and light1-s  the corresponding simple stemmer performance is shown. the khoja stemmer already had very large stem classes  so simple stemming before clustering was unnecessary.  finally  for all four baselines  the clustered stemmer performance is shown. relative to simple stemming  clustering by co-occurrence significantly improves retrieval effectiveness in all cases.  
table 1:  average precision for monolingual retrieval - baseline  simple  and clustered stemmers 
 average precision query words 
class size non-singleton class size   average max average norm-s .1 1 1 - simple .1 1 1 1 simple-c .1 1 1 1 light1-s .1 1 1 1 simple1 .1 1 1 1 simple1-c .1 1 1 1 light1-s .1 1 1 1 simple1 .1 1 1 1 simple1-c .1 1 1 1 khoja .1 1 1 1 khoja-c .1 1 1 1  
relative to the baseline stemmers norm-s and light1-s  repartitioning yields a net improvement.  simple-c  clustered simple stemmer  is significantly better than norm-s  and simple1-c  clustered simple1  is significantly better than light1-s.  in other words  starting with no stemming or very light stemming  removing of definite articles and   from the beginnings of the words   then creating overly inclusive stem classes by removing vowels  and repartitioning the classes by co-occurrence analysis  results in a net improvement in stemming without a great deal of linguistic knowledge. 
on the other hand  co-occurrence analysis did not improve the more sophisticated stemmers: khoja-c is not better than khoja  and simple1-c is not better than light1-s.  
it may seem strange that co-occurrence analysis on the stronger baseline stemmers changed class sizes drastically but did not change performance very much.  we took a closer look at light1-s stem classes to gain some understanding of this phenomenon.  we found that although light1-s is our strongest light stemmer  it is still relatively weak in that it fails to conflate some forms that should be conflated.  on the positive side  it rarely groups unrelated forms  and when it does  it groups variants of relatively few words e.g. 1 or 1  except for stop words where we see 1 or 1.  the clusters for light1-s are fairly large  avg class size=1   and correctly so. removing vowels  simple stemming  conflates many unrelated forms  avg class size=1 ; the co-occurrence clustering generally separates the unrelated forms back out.  however  these repartitioned stem classes are much smaller than would be desired  mean class size=1  and contained only the highest frequency forms. this behavior was appropriate for the english and spanish  for which this algorithm was developed  but not for arabic.  an algorithm that was not so biased against low frequency forms might have yielded a net improvement. 
the example of stem classes for the word         arab n. or adj.  in table 1 is probably typical  given these numbers.  the light1-s stem class contains 1 words  of which 1 are variants of the arab.  nine words are variants of chariot.  two other words mean earnest money.  removing vowels  simple1  results in a stem class with 1 members  not shown  for the target word  which co-occurrence analysis  simple1-c  reduces to the 1 words shown.  all of the variants of chariot and earnest money have gone away  but so have many good variants of arab.  this small new set includes one correct variant which was not in the original set of 1.   
ideally  the final stem class should include more of the original variants from light1-s and add more new variants if they appeared in simple1 and still keep the chariot and earnest money variants out.  we are continuing to experiment with parameters and cooccurrence measures to see whether we can produce the larger classes appropriate to arabic without bringing in too many unrelated forms. 
 
table 1: example of stem classes under different stemmers 
stem class for        under light1-s variants of arab of chariot of earnest  money                                                                                                                                                                                                                                                                                          stem class under simple1-c all arab        	      	    	       
      	      	     	         
1 discussion 
although stemming is difficult in a language with complex morphology like arabic  it is particularly important.  for monolingual retrieval  we saw around 1% increase in average precision from raw retrieval to the best stemmer. the best stemmer in our experiments  light1-s was very simple and did not try to find roots or take into account most of arabic morphology.  it is probably not essential for the stemmer to yield the correct forms  whether stems or roots.  it is sufficient for it to group most of the forms that belong together. 
it was interesting that removing stop words had a significantly positive effect for stemmed arabic  but not for unstemmed arabic.  this difference is probably due to the fact noted in section 1.1 that stem classes for stop words contain larger numbers of unrelated word variants than stem classes for other words. 
1. cross-language english-arabic experiments 
for generality  the stemmers are compared on the cross-language retrieval task.  the cross-language experiments reported here were carried out using the 1 english trec-1 queries and the same arabic afp arb corpus used for the monolingual experiments.  our approach is the common dictionary-based approach  in which each english query word is looked up in a bilingual dictionary.  all the arabic translations for that word are gathered inside an inquery #syn  synonym  operator.  for an arabic-english dictionary  we used a lexicon collected from several online english-arabic and arabic-english resources on the web  described more completely in .  query expansion was carried out in conjunction with stemming.  when english queries were expanded  1 terms were added from the top 1 documents.  when arabic queries were expanded  1 terms were added from the top 1 documents  as described . 
figure 1 shows precision on unexpanded queries for cross-language retrieval at 1 recall points for raw  norm-s  normalization and stop word removal   light1-s  light1 stemming with stop word removal   khoja-u  with unbreakables   and khoja stemmers.  table 1 shows uninterpolated average precision for unexpanded and expanded queries. 

　　　　　　　　　　　　　　　　　　　　　　　　　　 figure 1:  cross-language 1 point precision for unexpanded queries. 
table 1:  cross-language average precision different stemmers  unexpanded and expanded queries 
stemmer raw norm-s khoja-u khoja light1-s av.precision .1   .1  .1 .1 .1 pct. change  1 1 1 1 with english query expansion av.precision .1 .1 .1 .1 .1 pct. change  1 1 1 1 with english and arabic query expansion av.precision .1 .1 .1 .1 .1 pct. change  1 1 1 1  
the results are somewhat different from the monolingual results.  raw retrieval without any normalization or stemming is far worse for cross-language retrieval than for monolingual retrieval.  this is probably because many of the arabic words occurred in vocalized form  with diacritics  in the online dictionary we used for cross-language retrieval. without normalization these dictionary entries do not match their counterparts in the corpus.  other differences from the monolingual case are that here  the light1-s stemmer is significantly better than the root stemmer  khoja  which is no better than normalization for cross-language retrieval. 
1. conclusions 
stemming has a large effect on arabic information retrieval  at least in part due to the highly inflected nature of the language.  for monolingual retrieval we have demonstrated improvements of around 1% in average precision due to stemming and related processes  and an even larger effect for dictionary-based crosslanguage retrieval.  this stemming effect is very large  compared to that found in many other stemming studies  but is consistent with the hypothesis of popovi  and willett  and pirkola  that stemming should be particularly effective for languages with more complex morphology. 
it may seem contradictory that while we find a very large stemming effect for both mono- and cross-language arabic retrieval  xu et al. found stemming to make a difference only for monolingual arabic  on the same trec-1 data .  we believe that the reason is that xu et al. had a parallel corpus  so their bilingual lexicon contained all the variants of the arabic words that were likely to occur in documents.  our bilingual lexicon was derived from an online dictionary  so it contained far fewer variants.  without stemming  the dictionary translations of query terms were unlikely to match the forms found in documents.  in short  with sufficient parallel data  stemming may be unnecessary. 
the best stemmer was a light stemmer that removed stop words  definite articles  and     and   from the beginning of words  and a small number of suffixes from the ends of words  light1-s . with query expansion  light1-s yielded results comparable to that of the top performers at trec  monolingual and cross-language.  we have not ruled out the possibility that a better morphological analyzer could work as well as or better than the light stemmer. 
a repartitioning process consisting of vowel removal followed by clustering using co-occurrence analysis performed better than no stemming or very light stemming.  however  stemmers produced this way were still inferior to the best light and morphological stemmers.  repartitioning one of  these good hand-designed stemmers changes stem classes a great deal  but does not improve  or hurt  overall retrieval performance.  we suspect that performance might be improved by modifying the clustering method to have less bias against low frequency variants.  
1. acknowledgments 
we would like to thank shereen khoja for providing her stemmer  nicholas j. dufresne for writing some of the stemming and dictionary code  fang-fang feng for helping with dictionary collection over the web  mohamed taha mohamed  mohamed elgadi  and nasreen abdul-jaleel for help with the arabic language  victor lavrenko for the use of his vector and language modeling code.  this work was supported in part by the center for intelligent information retrieval and in part by spawarsyscen-sd grant number n1-1.  any opinions  findings and conclusions or recommendations expressed in this material are the authors' and do not necessarily reflect those of the sponsor. 
