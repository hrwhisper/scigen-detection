 although most time-series data mining research has concentrated on providing solutions for a single distance function  in this work we motivate the need for a single index structure that can support multiple distance measures. our specific area of interest is the efficient retrieval and analysis of trajectory similarities. trajectory datasets are very common in environmental applications  mobility experiments  video surveillance and are especially important for the discovery of certain biological patterns. our primary similarity measure is based on the longest common subsequence  lcss  model  that offers enhanced robustness  particularly for noisy data  which are encountered very often in real world applications. however  our index is able to accommodate other distance measures as well  including the ubiquitous euclidean distance  and the increasingly popular dynamic time warping  dtw . while other researchers have advocated one or other of these similarity measures  a major contribution of our work is the ability to support all these measures without the need to restructure the index. our framework guarantees no false dismissals and can also be tailored to provide much faster response time at the expense of slightly reduced precision/recall. the experimental results demonstrate that our index can help speed-up the computation of expensive similarity measures such as the lcss and the dtw.
categories and subject descriptors: h.1  database management : database applications  data mining keywords: trajectories  longest common subsequence  dynamic time warping
1. introduction
　in this work we present an efficient and compact  external memory index for fast detection of similar trajectories. trajectory data are prevalent in diverse fields of interest such as meteorology  gps tracking  wireless applications  video tracking  and motion capture . recent advances in mobile computing  sensor and gps technology have made it possible to collect large amounts of spatiotemporal data and

  the research of this author was supported by nsf itr 1  nsf career 1  nsf iis 1  and nrdrp
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  or republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee. sigkdd '1  august 1  1  washington  dc  usa.
copyright 1 acm 1-1/1...$1.
there is increasing interest in performing data analysis tasks over such data . in mobile computing  users equipped with mobile devices move in space and register their location at different time instances to spatiotemporal databases via wireless links. in environmental information systems  tracking animals and weather conditions is very common and large datasets can be created by storing locations of observed objects over time. human motion data generated by tracking simultaneously various body joints are also multidimensional trajectories. in this field of computer graphics fundamental operations include the clustering of similar movements  leading to a multitude of applications such as interactive generation of motions . spatiotemporal data are also produced by migrating particles in biological sciences  where the focus can be on the discovery of subtle patterns during cellular mitoses . in general  any dataset that involves storage of multiple streams  attributes  of data can be considered and treated as a multidimensional trajectory. one very common task for such data is the discovery of objects that follow a certain motion pattern  for purposes of clustering or classification. the objective here is to efficiently organize trajectories on disk  so that we can quickly answer k-nearest-neighbors  knn  queries. a frequent obstacle in the analysis of spatiotemporal data  is the presence of noise  which can be introduced due to electromagnetic anomalies  transceiver problems etc. another impediment is that objects may move in a similar way  but at different speeds. so  we would like our similarity model to be robust to noise  support elastic and imprecise matches.
　choosing the euclidean distance as the similarity model is unrealistic  since its performance degrades rapidly in the presence of noise and this measure is also sensitive to small variations in the time axis. we concentrate on two similarity models: the first is an extension of dynamic time warping for higher dimensions. we note that dtw has been used so far for one-dimensional time series. here we present a formulation for sequences of arbitrary dimensions. the second distance measure is a modification of the longest common subsequence  lcss   specially adapted for continuous values. both measures represent a significant improvement compared to the euclidean distance. however  lcss is more robust than dtw under noisy conditions  as figure 1 shows. euclidean matching completely disregards the variations in the time axis  while dtw performs excessive matchings  therefore distorting the true distance between sequences. the lcss produces the most robust and intuitive correspondence between points.
by incorporating warping in time as a requirement to

figure 1: a lucid example about the quality matching of the lcss compared to other distance functions. the euclidean distance performs an inflexible matching  while the dtw gives many superfluous and spuriousmatchings  in the presence of noise.
our model  our algorithms are automatically challenged with quadratic execution time. moreover  these flexible functions are typically non-metric  which makes difficult the design of indexing structures. to speed up the execution of a similarity function  one can devise a low cost  upper bounding function  since the lcss model captures the similarity  which is inversely analogous to the distance . we utilize a fast prefiltering scheme that will return upper bound estimates for the lcss similarity between the query and the indexed trajectories. in addition to providing similarity measures that guarantee no false dismissals  we also propose approximate similarity estimates that significantly reduce the index response time. finally  we show that the same index can support other distance measures as well.
　our technique works by splitting the trajectories in multidimensional mbrs and storing them in an r-tree. for a given query  we construct a minimum bounding envelope  mbe  that covers all the possible matching areas of the query under warping conditions. this mbe is decomposed into mbrs and then probed in the r-tree index. using the index we can discover which trajectories could potentially be similar to the query. the index size is compact and its construction time scales well with the trajectory length and the database size  therefore our method can be utilized for massive datamining tasks.
the main contributions of the paper are:
　 we present the first external memory index for multidimensional trajectories  that supports multiple distance functions  such as lcss  dtw and euclidean   without the need to rebuild the index.
　 we give efficient techniques for upper lower  bounding and for approximating the lcss dtw  for a set of trajectories. we incorporate these techniques in the design of an efficient indexing structure for the lcss and the dtw.
　 we provide a flexible method that allows the user to specify queries of variable warping length  and the technique can be tuned to optimize the retrieval time or the accuracy of the solution.
1. related work
　there has been a wealth of papers that use an lp distance family function to perform similarity matching for 1d time-series. work on multidimensional sequences can be found in  1  1 . however  they support only euclidean distance  which  as mentioned in the introduction  cannot capture flexible similarities.
　although the vast majority of database/data mining research on time series data mining has focused on euclidean distance  virtually all real world systems that use time series matching as a subroutine  use a similarity measure which allows warping. in retrospect  this is not very surprising  since most real world processes  particularly biological processes  can evolve at varying rates. for example  in bioinformatics  it is well understood that functionally related genes will express themselves in similar ways  but possibly at different rates. because of this  dtw is used for gene expression data mining  1  1 . dynamic time warping is a ubiquitous tool in the biometric/surveillance community. it has been used for tracking time series extracted from video   classifying handwritten text  and even fingerprint indexing .
　while the above examples testify to the utility of a time warped distance measure  they all echo the same complaint; dtw has serious scalability issues. work that attempted to mitigate the large computational cost has appeared in  and   where the authors use lower bounding measures to speed up the execution of dtw. however  the lower bounds can be loose approximations of the original distance  when the data are normalized. in  a different approach is used for indexing time warping  by using suffix trees. nonetheless  the index requires excessive disk space  about 1 times the size of the original data .
　the flexibility provided by dtw is very important  however its efficiency deteriorates for noisy data  since by matching all the points  it also matches the outliers distorting the true distance between the sequences. an alternative approach is the use of longest common subsequence  lcss   which is a variation of the edit distance. the basic idea is to match two sequences by allowing them to stretch  without rearranging the order of the elements but allowing some elements to be unmatched. using the lcss of two sequences  one can define the distance using the length of this subsequence . in  an internal memory index for the lcss has been proposed. it also demonstrated that while the lcss presents similar advantages to dtw  it does not share its volatile performance in the presence of outliers.
　closest in spirit to our approach  is the work of  which  however  only addresses 1d time-series. the author uses constrained dtw as the distance function  and surrounds the possible matching regions by a modified version of a piecewise approximation  which is later stored as equi-length
mbrs in an r-tree. however  by using dtw  such an approach is susceptible to high bias of outliers. also  the
fixed mbr size  although simplifies the index operations  can lead to degenerate approximations of the original sequence. moreover  the embedding of the envelope in the indexed sequences can slow the index construction time and limit the user's query capabilities to a predefined warping length. the use of lcss as our primary similarity measure  lends itself to a more natural use of the r-tree  where the similarity estimates are simply computed by calculating the mbr intersection areas. since the index is not constructed for a specific warping window  the user can pose queries with variable warping length.
　the purpose of this paper is to reconcile the best of both worlds. we provide a framework that can support in the same index  the lcss  dtw and euclidean distance functions. the only aspect that changes  is the different representation of the query for each distance measure.
1. distance measures
　in this section we present details of how the dynamic time warping and the lcss model can be extended to describe the similarity between trajectories.
1 dynamic time warping for 1d trajectories
　we describe an extension in 1d of the original dtw function as described by berndt and clifford . let a and b be two trajectories of moving objects with size n and m respectively  where a =   ax 1 ay 1  ...  ax n ay n   and b =   bx 1 by 1  ...  bx m by m  . for a trajectory a  let head a  =   ax 1 ay 1  ...  ax n-1 ay n-1  .
　definition 1. the time warping between 1-dimensional sequences a and b is:
dtw a b 	=	lp  ax n ay n   bx m by m   + min{dtw head a  
head b   dtw head a  b  
	dtw a head b  }	 1 
where lp is any p-norm. using dynamic programming and constraining the matching region within δ  the time required to compute dtw is o δ n + m  . in order to represent an accurate relationship of distances between sequences with different lengths  the quantity in equation 1 is normalized by the length of the warping path. the extension to n dimensions is similar. in figure 1 we show an example of time warping for two trajectories.
1 lcss model for 1d trajectories
　the original lcss model refers to 1d sequences  we must therefore extend it to the 1d case. in addition  the lcss paradigm matches discrete values  however in our model we want to allow a matching  when the values are within a certain range in space and time  note that like this  we also avoid distant and degenerate matchings .
definition 1. given an integer δ and a real number 1  
  we define the as follows:


figure 1: the support of flexible matching in spatiotemporal queries is very important. however  we can observe that dynamic time warping matches all points  so the outliers as well   therefore distorting the true distance. in contrast  the lcss model can efficiently ignore the noisy parts.
where sequences a and head a  are defined similarly as before. the constant δ controls the flexibility of matching in time and constant  is the matching threshold is space. the aforementioned lcss model has the same o δ n+m   computational complexity as the dtw  when we only allow a matching window δ in time .
　the value of lcss is unbounded and depends on the length of the compared sequences. we need to normalize it  in order to support sequences of variable length. the distance derived from the lcss similarity can be defined as follows:
　definition 1. the distance expressed in terms of the lcss similarity between two trajectories a and b is given by:
		 1 
1. index construction
even though imposing a matching window δ can help
speed up the execution  the computation can still be quadratic when δ is a significant portion of the sequence's length. therefore  comparing a query to all the trajectories becomes intractable for large databases. we are seeking ways to avoid examining the trajectories that are very distant to our query. this can be accomplished by discovering a close match to our query  as early as possible. a fast pre-filtering step is employed that eliminates the majority of distant matches. only for some qualified sequences will we execute the costly  but accurate  quadratic time algorithm. this philosophy has also been successfully used in  1  1 . there are certain preprocessing steps that we follow:
　1. based on the mbr intersections  similarity estimates are computed and the exact lcss  or dtw  is performed only on the qualified trajectories.

the above notions are illustrated in figure 1 and we explain in detail how they can be applied for the lcss case in the sections that follow.

figure 1: an example of our approach  in 1d for clarity ; a query is extended into a bounding envelope  which in turn is also split into the resulting mbrs. overlap between the query and the index mbrs suggest areas of possible matching.
1 bounding the matching regions
let us first consider a 1d time-series and let a sequence
a be  ax 1 ... ax n . ignoring for now the parameter   we would like to perform a very fast lcssδ match between sequence a and some query q. suppore that we replicate each point qi for δ time instances before and after time i. the envelope that includes all these points defines the areas of possible matching. everything outside this envelope can never be matched.

figure 1: the minimum bounding envelope  mbe  within δ in time and  in space of a sequence. everything that lies outside this envelope can never be matched.
　we call this envelope  the minimum bounding envelope  mbe  of a sequence. also  once we incorporate the matching within  in space  this envelope should extent  above and below the original envelope  figure 1 . the notion of the bounding envelope can be trivially extended in more dimensions  where for a 1d trajectory q =   qx 1 qy 1   ...  qx n qy n  covers the area between the following timeseries:
  where:

the lcss similarity between the envelope of q and a sequence a is defined as:
if a i  within envelope
	 	q	  =	1	otherwise
i=1
for example  in figure 1 the lcss similarity between mbeq and sequence a is 1  as indicated in the figure. this value represents an upper bound for the similarity of q and a. we can use the mbeq to compute a lower bound on the distance between trajectories:
lemma 1. for any two trajectories q and a the following
holds:  
proof  sketch :  therefore it is sufficient to show that: 
 this is true since mbeq by construction contains all possible areas within δ and  of the query q. therefore  no possible matching points will be missed. 1
　the previous lemma provides us with the power to create an index that guarantees no false dismissals. however  this lower bound refers to the raw data. in the sections that follow  we will 'split' the mbe of a trajectory  into a number of minimum bounding rectangles  mbrs   to accommodate their storage into a multidimensional r-tree. we will show that the above inequality still holds between trajectory mbrs.
　the mbr generation procedure is orthogonal to our approach  since any segmentation methodology can be applied to our framework. therefore  the description of the potential mbr generation methods  and of our implementation choice  will be delayed until later.
1. quickpruningofdissimilartrajectories
　suppose that we have an index with the segmented trajectories and the user provides a query q. our goal is the discovery of the k closest trajectories to the given query  according to the lcss similarity. a prefiltering step will aid the quick discovery of a close match to the query  helping us discard the distant trajectories without using the costly quadratic algorithm. therefore  in this phase  we compute upper bound estimates of the similarity between the query and the indexed sequences using their mbrs.
　below we describe the algorithm to find the closest trajectory to a given query:
input: query q  index i with trajectory mbrs  method output: most similar trajectory to q.
box ; vector vq = creatembrs env ; // vq contains a number of boxes.
priority queue pq ○entry ; per trajectory sorted
// pq keeps one
// according to the similarity estimate
for each box b in vq:
v = i.intersectionquery b ;
// v contains all trajectory mbrs that intersect with b.
if method == exact: // upper bound
　pq ○ computel-similarityestimates v  b ; else: // approximate
pq ○ computev-similarityestimates v  b ;
bestsofar = 1; best ○ ; while pq not empty:
ife ○ pq.top;   bestsofar: break; e.estimate else:
 ; // exact
if d   bestsofar:
bestsofar = d; best ○ e;
report best;

　the above algorithm can be adjusted to return the knn sequences  simply by comparing with the kth bestsofar match. next  we examine the possible similarity estimates. some of them guarantee that will find the best match  they lower bound the original distance or upper bound the original similarity   while other estimates provide faster but approximate results.
1 similarity estimates
　here we will show how to compute estimates of the lcss similarity  based on the geometric properties of the trajectory mbrs and their intersection. an upper bound estimate is provided by the length of the mbr intersection and an approximate estimate is given as a parameter of the intersecting volume. to formalize these notions  first we present several operators. then we will use these operators to derive the estimates.
1.1 estimates for the lcss
　each trajectory t can be decomposed into a number of mbrs. the ith 1d mbr of t consists of six numbers: mt i = {tl th xl xh yl yh}. now  let us define the operators t tc   t tp  and tv between two 1d mbrs mp i and mr j  belonging to objects p and r  respectively:
1. t tc  mp i mr j＋  = ||intersection＋	||t 
	where mr j.xl	mp i.xl	mr j.xh and
mr j.xl ＋ mp i.xh ＋ mr j.xh and mr j.yl ＋ mp i.yl ＋ mr j.yh and
　　　m	.yl ＋ m	.yh ＋ m	.yh or similarly by
therefore  this operator computes the time intersection of two mbr when one fully contains the other in the x y dimensions.
1. t||t tp  mp i mr j||   =||||intersection|||| ||t  otherwise	||  
1. v  mp i mr j  =	intersection t	intersection x intersection y
we can use upper bound or approximate estimates for the similarity:

figure 1:	top left:	intersection recorded in list
lt partial. top right: intersection recorded in list lt complete. bottom left: percentage of volume intersection kept in lv .
1. upper bound estimates  l-similarity estimate .
such estimates are computed using the following data-structures:  the list lt complete   an element l p  of which is defined as:
 c 
l p  =mq m   mp n
t m	n where q is a query and p is a trajectory in the index. so the list stores for each trajectory the total time that its mbrs intersected with the query's mbrs. we record into this list only the intersections  where a query mbr is fully contained in all spatial dimensions by a trajectory mbr  or vice versa -it is equivalent. see figure 1  top right .
 the list lt partial  an element l p  of which is defined as:

　this list records for each sequence the total intersection in time for those query mbrs that are not fully contained within the x y dimensions by the trajectory mbrs  or vice versa. figure 1  top left .
　regarding a query q  for any trajectory p the sum of lt complete p  + lt partial p  will provide an upper bound on the similarity of p and q.
　the reason for the distinction of the l-similarity estimate in two separate lists derives from the fact that the estimates stored in list lt partial can significantly overestimate the lcss similarity. if one wishes to relax the accuracy  in favor of enhanced performance  it is instructive to give a weight 1   wp   1 to all estimates in list lt partial. even though now we may miss the best match to our query  we are going to find a close match in less time. this weighted approach is used when we are seeking for approximate  but very good quality answers  however it will not be explained further due to space limitations.
1. approximate estimates  v-similarity estimate . this second estimate is based on the intersecting volume of the mbrs. this type of estimates are stored in list lv :
 any element lv  p  of list lv records similarity estimates between trajectory p and query q  based on the total volume intersection between the mbrs of p and q.

where ||m||v denotes the volume of mbr m and ||m||t its length on the time axis.
　the l-similarity overestimates the between two sequences a and b and so it can be deployed for the design of an index structure.
　lemma 1. the use of the l-similarity estimate upper bounds the similarity between two sequences a and b and therefore does not introduce any false dismissals.
　the v-similarity estimate can be used for approximate query answering. even though it does not guarantee the absence of false dismissals  the results will be close to the optimal ones with high probability. also  because this estimate provides a tighter approximation to the original distance  we expect faster response time. indeed  as we show in the experimental section  the index performance is boosted  while the error in similarity is frequently less then 1%.
1 estimates for the dtw
　when the distance function used is the time warping  using the index we obtain a lower bound of the actual distance. in this case we have the inverse situation from the lcss; instead of calculating the degree of overlap between the mbrs of the indexed trajectories and the query  we evaluate the distance between the mbrs. the overall distance between the mbrs underestimates the true distance of the trajectories  and no false dismissals are introduced. using the mbrs we can also calculate upper bound estimates on the distance  which hadn't been exploited in previous work  1  1 . sequences with lower bound larger than the smallest upper bound can be pruned. with this additional prefiltering step we can gain on average an additional 1% speedup in the total execution time.
　due to space limitations only a visual representation of this approach is provided in figure 1.
1. mbr generation
　given a multidimensional time-series  or an mbe  our objective is to minimize the volume of the sequence using k mbrs. clearly  the best approximation of a trajectory  or an mbe  using a fixed number of mbrs is the set of mbrs that completely contain the sequence and minimize the volume consumption. we can show the following lemma:
　lemma 1. minimizing the volume of the minimum bounding envelope  minimizes the expected similarity approximation error.
three different approaches are considered:
1. k-optimal. we can discover the k mbrs of a sequence that take up the least volume  using a dynamic programming algorithm that requires o n1k  time     where n is the length of the given sequence. since this approach is not reasonable for large databases  we are motivated to consider approximate and faster solutions.
1. equi-split. this technique produces mbrs of fixed length l. it is a simple approach with cost linear in the length of a sequence. however  in pathological cases increasing the number of splits can result to larger space utilization therefore the choice of the mbr length becomes a critical parameter  see figure 1 for an example .

figure 1: a visual intuition of the dtw indexing technique  the one-dimensional case is shown for clarity . the original query  a  is enclosed in a minimum-bounding envelope  b  like the lcss approach. the mbe is split into its mbrs using equi or greedy split  fig.  c  . the candidate sequences in the database have their mbrs stored in the index  d . between the query and any sequence in the index  the minimum and maximum distance can be quickly determined by examining the distance between the mbrs and the query's bounding envelope  as represented by the arrows in  e  and  f .
1. greedy-split. the greedy approach is our implementation choice in this paper. initially we assign an mbr to each of the n sequence points and at each subsequent step we merge the consecutive mbrs that will introduce the least volume consumption. the algorithm has a running time of o nlogn . we can see a sketch of the method in fig. 1. alternatively  instead of assigning the same number of splits to all objects  according to our space requirements we can assign a total of k splits to be distributed among all objects. this method can provide better results  since we can assign more splits for the objects that will yield more space gain. also  this approach is more appropriate when one is dealing with sequences of different lengths. the complexity of this approach is o k + nlogn   for a total of n objects   .
input: a spatiotemporal trajectory t and an integer k denoting the number of final mbrs.
mergingfor 1  t＋i  iand    tni +1compute. the  resultsthe volume are stored of the in  mbra priority produced queue. by
　while #mbrs   k: using the priority queue  merge the pair of consecutive mbrs that yield the smallest increase in volume. delete the two merged mbrs and insert the new one in the priority queue.
output: a set of mbrs that cover t.
figure 1: the greedy algorithm for producing k mbrs that cover the trajectory t.
　after a trajectory is segmented the mbrs can be stored in a 1d-rtree. using the greedy split each additional split will always lead to smaller  or equal  volume  figure 1 . a similar greedy split algorithm is also used for splitting the mbe of the query trajectory q.

figure 1:  a : 1 mbrs produced using equi-split. the volume gain over having 1 mbr is 1.  b : segmenting into 1 mbrs decreases the volume gain to 1. so  disk space is wasted without providing a better approximation of the trajectory.  c : 1 mbrs using greedy-split. the volume gain over having 1 mbr is 1.  d : every additional split will yield better space utilization. segmentation into 1 mbrsincreases volume gain to 1.
1. supporting multiple measures
　the application of the minimum bounding envelope only on the query suggests that user queries are not confined to a predefined and rigid matching window δ. the user can pose queries of variable warping in time. in some datasets  there is no need to perform warping  since the euclidean distance performs acceptably . in other datasets  by using the euclidean distance we can find quickly some very close matches  while using warping we can distinguish more flexible similarities. so  we can start by using a query with δ = 1  no bounding envelope   and increase it progressively in order to find more flexible matches  figure 1 .
　therefore  our framework offers the unique advantage that multiple distance functions can be supported in a single index. the index sequences have been segmented without any envelope applied on them and never have to be adjusted again. for different measures  the aspects that change are  the creation of the query envelope and the type of operation between mbrs. in order to pose queries based on euclidean distance we follow the steps:
the query is segmented with no envelope applied on it.
the mindist and maxdist estimators for the euclidean distance are derived by calculating the distance between the query and index mbrs  just like in the dtw case.

figure 1: by incorporating the bounding envelope on the query  our approach can support euclidean distance  constrained or full warping. this is accomplished by progressively expanding the mbe.
1. experimental evaluation
　in this section we compare the effectiveness of various splitting methods and we demonstrate the superiority of our lower bounding technique  for the dtw  compared to other proposed lower bounds. we describe the datasets we used and present comprehensive experiments regarding the index performance for the two similarity estimates. in addition  we evaluate the accuracy of the approximate estimates. all experiments conducted were run on an amd athlon 1 ghz with 1gb ram and 1gb of hard drive.

figure 1: datasets used for testing the efficiency of various mbr generation methods.
1 mbr generation comparison
　the purpose of our first experiment is to test the space consumption of the presented mbr generation methods. we have used eight datasets with diverse characteristics  in order to provide objective results.
　we evaluate the space consumption  by calculating the  average volume gain   avgv olgain   which is defined as the percentage of volume when using i mbrs  over the volume when using only 1 mbr  normalized by the maximum gain provided over all methods  for various number of splits .

figure 1: the greedy-split mbr generation algorithm presents the highest volume gain  by producing mbrs that consume consistently less space  over a number of datasets and for diverse number of generated mbrs
dataseteqs1 d1grs1 d1eqs1 d1grs1 d1eqs1 d1grs1 d1eqs1 d1grs1 d1lb-kimlb-yilcssdtwasl1111111111vt1.1.1.1.1.1.1.1.1.1.1marine1111111111word1111111111random1111111111vt1.1.1.1.1.1.1.1.1.1.1
table 1: some indicative results of how close our similarity estimates are to the exact value  for 1 and 1 splits  & δ = 1% . for all datasets the greedy-split approach provides the closest similarity estimates to theactual similarity.
　avgv olgain is a number between 1 and 1  where higher numbers indicate increased volume gain  or less space consumption  against the competitive methods. in figure 1 we observe the average volume gain for the eight datasets. the greedy-split algorithm produced mbrs that took at least half the space  compared to equi-split. the equi-split offers slightly better results  than producing mbrs at random positions. the volume gain of greedy-split was less  only for the buoy sensor  which is a very busy and unstructured signal. this experiment validates that our choice to use the greedy-split method was correct. since  the indexed mbr trajectories will take less space  we also expect tighter similarity estimates  therefore fewer false positives.
1 tightness of bounds
　in table 1 we show how close our similarity estimates are  for lcss and dtw  to the actual similarity between sequences. numbers closer to 1  indicate higher similarity to the value returned by the exact algorithm. to our best knowledge  this paper introduces the first upper bounding technique for the lcss. for dtw there have been a few approaches to provide a lower bound of the distance; we refer to them as lb-kim  and lb-yi . these lower bounds originally referred to 1d time-series; here we extend them in more dimensions  in order to provide unambiguous results about the tightness of our estimates. note that the previously proposed methods operate on the raw data. our approach can still provide tighter estimates  while operating only on the trajectory mbrs. using the raw data our experiments indicate that we are consistently 1 times better than the best alternative approach. however  since our index operates on the segmented time-series we only report the results on the mbrs.
　the greedy-split method approximates the similarity consistently tighter than the equi-split. in table 1 only the results for δ = 1% of the query's length are reported  but similar results are observed for increasing values of δ. it is evident from the table that using our method we can provide very tight lower bounds of the actual distance.
1 matching quality
　we demonstrate the usefulness of our similarity measures in a real world dataset. the library of congress maintains thousands of handwritten manuscripts  and there is an increasing interest to perform automatic transcribing of these documents. given the multiple variations of each word and due to the manuscript degradations  this is a particularly challenging task and the need for a flexible and robust distance function is essential.
we have applied the lcss and dtw measures on word

figure 1: results for a real world application. 1nn reported for each query  using dynamic time warping to match features extracted from scanned manuscript words.
images extracted from a 1 page scanned manuscript. 1dimensional time-series features have originally been extracted for each word. here we maintain the 1 least correlated timeseries features and treat each word as a trajectory. in figure 1 we observe the 1-knn results using dtw for various word queries. the results are very good  showing high accuracy even for similarly looking words. analogous results have been obtained using the lcss.
1 index performance
　we tested the performance of our index using the upper bound and the approximate similarity estimates  and compared it to the sequential scan. because of limited space  the majority of the figures record the index performance using the lcss as a similarity measure. the performance measure used is the total computation time required for the index and the sequential scan to return the nearest neighbor for the same one hundred queries. for the linear scan  one can also perform early termination of the lcss  or the dtw  computation. therefore  the lcss execution can be stopped at the point where one is sure that the current sequence will not be more similar to the query than the bestsofar. we call this optimistic linear scan. pessimistic linear scan  is the one than does not reuse the previously computed similarity values and can be an accurate time estimate  when the query match resides at the end of the dataset. we demonstrate the index performance relative to

figure 1: index performance. for small warping windows the index can be up to 1 times faster than sequential scan without compromising accuracy. the gray regions indicate the range of potential speedup.

figure 1: using the approximate similarity estimates the response time can be more than 1 times faster.both types of linear scan  because this provides a realistic upper or lower bound on the index speedup.
　the dataset we used contained 1 ...1 trajectories. taking under consideration that the average trajectory size is around 1 points  this resulted to a database with more than 1 million 1d points. the trajectories have been normalized by subtracting the average value in each direction of movement. all data and queries can be obtained by emailing the first author.
mixed two-dimensional time-series  1d-mixed . this second dataset consists of time-series of variable length  ranging from less than 1 points to over 1 points. the dataset is comprised by the aggregation of the eight datasets we used for comparing the mbr generation methods. since the total number of these trajectories is less than 1  we have used them as seeds to generate increasingly larger datasets. we create multiple copies of the original trajectories by incorporating the following features:
   addition of small variations in the original trajectory pattern
　　addition of random compression and decompression in time
　the small variations in the pattern were added by interpolating peaks of gaussian noise using splines. in this manner we are able to create the smooth variations that existed in the original datasets.
1.1 results on the upper bound estimates
　the index performance is influenced be three parameters: the size of the dataset  the warping length δ  as a percentage of the query's length  and the number of splits. for all experiments the parameter   matching in space  was set to std/1 of the query  which provided good and intuitive results.
　 dataset size: in figure 1 we can observe how the performance of the index scales with the database size  for various lengths of matching window . we record the index response time relative to both optimistic and pessimistic linear scan. therefore  the gray region in the figures indicates the range of possible speedup. it is evident that the early termination feature of the sequential scan can significantly assist its performance. the usefulness of an index becomes obvious for large dataset sizes  where the quadratic computational cost dominates the i/o cost of the index. for these cases our approach can be up to 1 times faster than linear scan. in figure 1 we also demonstrate the pruning power of the index  as a true indicator  not biased by any implementation details  about the efficacy of our index. using the index we perform 1 times fewer lcss computations than the linear scan. we observe similar speedup when using the dtw as the distance function in figure 1.
　 parameter δ: the index performance is better for smaller warping lengths  parameter δ . the experiments record the performance for warping from 1% to 1% of the query's length. increasing δ values signify larger bounding envelopes around the query  therefore larger space of search and less accurate similarity estimates. the graphs suggest that an index cannot not be useful under full warping  when the data are normalized .
 number of splits: although greater number of mbrs
for each trajectory implies better volume utilization  nonetheless more mbrs also lead to increased i/o cost. when we are referring to x% splits  it means that we have assigned a total of 1/x pni=1 ||ti||   splits  for all sequences ti. in our figures we provide the 1% splits scenario for the mbrs  which offers better performance than 1% and 1% splits  since for the last two cases the i/o cost negates the effect of the better query approximation. the index space requirements for 1% splits is less than a quarter of the dataset size. 1.1 results on the approximate estimates
　here we present the index performance when the volume intersections of the mbrs are used as estimates of the sim-
dataset size
figure 1: each gray band indicates  for a certain warping window δ  the percentage of lcss computations conducted by the index compared to linear scan.dataset size
figure 1: using the v-similarity estimate  we can retrieve answers faster with very high accuracy. the lcss similarity is very close  1%  to the exact answer returned by the sequential scan.dataset size
figure 1: index performance using dtw as the distance measure.  δ = 1% . we can observe up to 1 times speedup.	similarity error  1% splits	δ=1%ilarity and the results are shown in figure 1. we observe that using this approximate similarity estimate  our index performance is boosted up. the use of the v-similarity estimate leads to more tight approximations of the original similarity compared to the l-similarity estimate  however now we may miss finding the best match.
　naturally  comes the question of the quality of the results. we capture this by calculating the absolute difference between the similarity of the best match returned by the index  and the best match found by the sequential scan for each query. then we average the results over a number of queries |q|. therefore  the average similarity error  ase  is:
	|q|	| 
　the results are shown in figure 1. we can see that the similarity returned by the v-similarity estimate is approximately within 1% of the actual similarity  1% splits used . therefore  by providing two similarity estimates the user can decide for the trade-off between the expedited execution time and the quality of results. since by using the latter estimator we can significantly increase the performance of the index  this is the approach we recommend for mining large datasets.
1. conclusions and future work
　in this paper we have presented an external memory indexing method for discovering similar multidimensional timeseries. the unique advantage of our approach is that it can accommodate multiple distance measures. the method guarantees no false dismissals and depicts a significant execution speed up for the lcss and dtw compared to sequential scan. we have shown the tightness of our similarity estimates and demonstrated the usefulness of our measures for challenging real world applications. we hope that our effort can act as a bridge between metric and non-metric functions  as well as a tool for understanding better their strengths and weaknesses. in the future we plan to investigate the combination of several heuristics  in order to provide even tighter estimates.
acknowledgements: we would like to thank margrit betke for providing us the video track i and ii datasets. we also feel obliged to t. rath and r. manmatha for kindly providing the manuscript words dataset.
