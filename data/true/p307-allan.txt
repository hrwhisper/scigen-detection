query ambiguity is a generally recognized problem  particularly in web environments where queries are commonly only one or two words in length. in this study  we explore one technique that finds commonly occurring patterns of parts of speech near a one-word query and allows them to be transformed into clarification questions. we use a technique derived from statistical language modeling to show that the clarification queries will reduce ambiguity much of the time  and often quite substantially.
categories and subject descriptors
h.1  information storage and retrieval : content analysis and indexing-linguistic processing; h.1  information storage and retrieval : information search and retrieval-query formulation  search process
keywords
clarity  part of speech  query ambiguity
1. introduction
　a generally acknowledged issue in information retrieval  particularly with web search engines  is that users provide very short queries  that are sometimes very ambiguous. a classic example of this problem is the meaning of  java  as a query: is the searcher's interest in coffee  a programming language  or tourism in indonesia  there is quite a range of ways in which ambiguity can appear. in the  java  example  it is based on subject matter. a query could also be ambiguous because the user's underlying task is unclear  e.g.  buy java  use java  introduction to java   because the type of user is unknown  e.g.  expert or novice   or because the style of querying is not clear  e.g.  obtain facts  an overview  exhaustive coverage  or summary .
　in this study  we investigate a particular technique for resolving ambiguity that is motivated by task-level ambiguity. how do the query words relate to other words in the text 
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee.
sigir'1  august 1  1  tampere  finland.
copyright 1 acm 1-1/1 ...$1.
what roles can they assume and which is the user interested in  for example  given a query  boat   the user might be interested in:
  things a boat does  floats  anchors  overturns 
  types of boats  whaling  fishing  red 
  ways to boat  quickly  safely 
  things to do with boats  drive them  paint them  sink them 
the intent is for the system to present a list of clarifying options to the searcher that can be selected if needed. choosing one of those options focuses the query by including only those documents that use the query words in the right manner.
　ultimately  these ideas should be evaluated by field-testing a system that incorporates them. in this study we are laying the groundwork for such a system. our focus is a novel evaluation to demonstrate that this approach generates useful clarifications of an ambiguous query. in the next section  we sketch some prior work toward coping with ambiguity. in section 1 we discuss the approach that we use to find the clarifying options; the actual implementation is described in section 1. we describe our evaluation technique in section 1 and present results showing the value of this approach in section 1. we conclude in section 1 by describing where this work is headed.
1. related work
　there has been substantial work investigating issues surrounding word sense disambiguation   a type of query ambiguity that arises regularly in information retrieval. that type of ambiguity is often resolved implicitly when queries are long enough-the additional words provide sufficient context to clear up confusion-but is still a critical problem when queries are short . users of web search engines generally provide short queries   and we are focusing on that situation in this study.
　there is a range of information retrieval interface ideas that attempt to help the user deal with ambiguous queries. sanderson  lawrie  and croft have been working on concept hierarchies that provide a hierarchical map of words and their relationships  1  1  1  1 . a user can navigate the hierarchy to find the sense that is relevant. to date that research has not directly investigated whether the hierarchies help with disambiguation  looking instead at their ability to affect recall and precision.
　clustering the retrieved document set is another way to deal with ambiguity: ideally documents covering different senses of a word will be placed in different clusters. much work has been done on clustering  either investigating the clustering directly  1  1  1  or exploring issues related to clustering and interactive search  1  1  1 . the web service northern light1 classifies returned documents into a set of labeled clusters  showing the clusters as well as the top ranked documents. all of these clustering techniques group documents by topic rather than by the way that the query word is used.
　a limited number of studies have been done that directly evaluate the effectiveness of query reformulation when searching. it has been shown that query reformulation can improve the effectiveness of a query   though the focus was on the cognitive burden it places on the searcher.
　this work was inspired by tables 1 and 1 of a paper by church et al. . that work describes how statistical occurrence patterns of words in text can be used to find lexically interesting items. one of those is to look for verbs that occur near a particular word in an interesting way  measured by mutual information   allowing someone to find  what does a boat do   or  what do you typically do with food and water   we felt that if a query  boat  were used  then a possible clarification might be that question  and that documents containing the appropriate pattern  viz.  boat as a subject and a verb  interestingly  near it  would be appropriate matches.
　altavista1 at one point provided a service called livetopics  that showed the inter-relationships between query terms and other terms in the corpus. this map was derived from the corpus  and human corrections  and provided another form of a  hyperindex  to allow the user to select words to improve a query.
　the hib system  allows the user to clarify  refine  the query by offering well-formed phrases in which the query appears. the user's query is mapped into a  hyperindex  by this approach  that shows relationships between words based on their occurrence in the titles of retrieved documents. the motivation for this work is similar to ours  but requires a much more elaborate infrastructure. they do not appear to have evaluated the value of the technique for query disambiguation. grefenstette also suggests a system similar to ours   but also has no evaluation of its effectiveness.
　anick and tipirneni  developed a query refinement technique based on calculating the lexical dispersion of words occurring in the top-ranked documents. their work is similar to this study in that the candidates are identified by part-ofspeech patterns at index time  but they use a substantially reduced set of patterns   adjective  noun+    they present patterns to the user on the assumption that the top ranked documents are a good source for them  and they are more focussed on query expansion than disambiguation  though the difference is often subtle . we believe that some aspects of their approach  e.g.  using dispersion to find good candidates  may be valuable for our work  but we have not yet investigated those ideas.
1. experimental setup
all experiments in this study were conducted using about
tagpart-of-speechnncommon noun  singular npproper nounnnscommon noun  plural vbverb  present tense vbnverb past participle vbdverb past tense jjadjectiveatdeterminerccconjunctioninprepositioncdnumberfigure 1: some of the common part of speech tags and their corresponding parts of speech in the brown corpus.
1 documents from the trec1-fbis  the fbis subset of the fifth trec volume. these are documents from fbis dated 1. we also used a second corpus  tdt1  which includes the english news stories from the tdt-1 collection  amounting to approximately 1 news stories from newswire and broadcast news sources. for stories from an audio source  the closed caption was used rather than speech recognition output.
　our indexing and retrieval was done using v1 of the ciir's inquery retrieval system . this system incorporates fast and reasonably accurate part of speech tagging using jtag . jtag uses the brown tag-set  some tags of which are listed in figure 1 .
　when documents were indexed  each word was indexed along with its part of speech. proximity operators allow a particular part of speech to be selected for a word  as well as restrictions on which parts of speech occurred nearby. for example  #1 boat vbd  means the word  boat  immediately followed by the past participle of a verb  e.g.   boat sank  . the query #1 boat nn  means the word  boat  used as a noun rather than as another part of speech. the combined query 
#1  #1 boat nn  vbz 
means  boat  as a noun followed within three words by the present third person singular form a verb  e.g.   boat sinks  or  boat quickly sinks  . this type of construction allows us to build up quite complex restrictions on query words and nearby parts of speech.
1. approach
　given a corpus that has parts of speech indexed and that provides flexible query support such as that outlined above  we can attempt query disambiguation as follows. we  1  analyze the text to find patterns of parts of speech that occur frequently near the query word   1  map the patterns to questions that reflect the patterns   1  present the questions to the user as options to consider  and  1  re-run the retrieval based on the disambiguated question s  the searcher selects. in this section  we sketch how this approach works in a functional system. we show several examples that illustrate the value of this approach and suggest that it will be effective. in section 1 we empirically evaluate the effectiveness of this approach toward reducing ambiguity. our longer term goal is to implement these ideas in a fully functioning system to get user feedback.
1 finding patterns
　the patterns that we are looking for center around a single query word and incorporate a small number of words on either side. for example  given the query word boat we might look for the pattern  an adjective followed by the noun boat.  in the trec1-fbis corpus  we would find adjectives such as haitian  fishing  wooden  speed  and so on. if we find a sufficient number of occurrences of that pattern  regardless of how many different adjectives there are   we would note that  jj boat:nn  is an interesting pattern   jj  is the part of speech code for an adjective  and  nn  denotes a singular noun .
　looking for all such patterns near a query word would be prohibitively expensive to carry out at search time. for that reason  we enhanced inquery's indexing stage to extract all patterns centered around non-stopwords so that we could use it at run-time  and organized them by that keyword. to make this process slightly less expensive we used a 1% random sample of the corpus. for example  figure 1 shows a sample of patterns and counts that appear in the 1 document subset of the trec1-fbis corpus.
　we found by observation that any pattern that occurs more than 1 times in the corpus is  interesting  and ignored all others  a pattern might occur less than 1 times with particular query word  but many more than 1 times overall . given the large number of patterns  making this decision in that way does not seem unreasonable  though it would ultimately be preferable to use a measure such as mutual information to select and keep the more interesting patterns .
1 patterns to questions
　the patterns are interesting  but they are not appropriate for displaying to a user. instead  we convert them into questions that disambiguate the query. for example  here are some patterns and corresponding questions for the query word party:
	jj party:nn	varieties of a party
	np party:np	names of a party
nn in party:nn nns	things done with a party vb party:nn nn	things done to a party
for each pattern that has a corresponding question  we index the pattern by the query word and keep track of the number of times the pattern occurs.
　given a user's single-word query  all patterns including that query word are obtained from the index  and the list of questions is constructed. patterns that correspond to the same question are collapsed into a single question.
　the questions are presented ranked in order of the most frequently occurring first.  the evaluation in section 1 suggests that questions with many matches are not much less ambiguous than the original query  so it may be preferable to rank them by an approximation of ambiguity reduction.  a partial list of patterns and corresponding questions is presented in figure 1. note that some language processing could be useful to handle variants of queries  e.g.  to change  varieties of mouse  into  varieties of mice  .
we wish to make it clear that the mapping from patterns
patternquestionq:noun vbthings that qq doesq:noun vbdthings that qq didq:noun hv verbthings that qq didvbd q:nnthings that happened to qqq:vbn nn s things that were qqq:vbn toin at nounthings one can qq toadv q:verbways to be qqq:vbg to vbthings you could be qq to doadj q:nounvarieties of qqq:noun ber adjvarieties of qqq:noun ber verbthings done to qqq:noun ber nounthings that qq arefigure 1: partial list of patterns recognized by the query clarification index component  along with the questions corresponding to those patterns. in the pattern   q:pos  means the query word occurring in that part of speech. the codes  noun    verb   and  adj  are macros that indicate all varieties of nouns that the tagger identifies. in the question column  qq would be replaced by the query word.
to questions was created by hand. we found that a surprisingly small set of questions could accommodate most patterns  but it is most likely that some questions are absent. we are currently exploring better approaches for generating this mapping.
　it is likely that the clarifying questions themselves may not be sufficient to help the user recognize the distinction. to help with that  we present the user which a list of several sample phrases that match the corresponding patterns. for example  for the query  boat   we might get  examples taken from our corpora :
are you interested in varieties of boats  haitian boat  makeshift boat  wooden boat  cuban boat  big boat  ...
are you interested in things a boat did 
boat followed  boat capsized  boat sank  boat hit  boat had  ...
are you interested in things done with a boat  rescue the boat  rock the boat  miss the boat 
...
this sort of  keyword in context  list provides more information about the meaning of the clarification question  and does it in a corpus-specific way. that is  on a different corpus  the clarification questions chosen might not be the same  and the sample phrases including the query word would also be different.
1 running the clarification question
　when the user selects one of the query questions  the system then transforms it into an appropriate query and provides a new list of matching documents. the inquery query is a logical  or  of all patterns that correspond to the selected query. for example  for the question  are you interested in things done to a boat    the following query could be generated
	instance	count	examplesjj nn/np in
	jj party:np in	1	democratic party of  communist party of
	jj trade:nn in	1	free trade with  foreign trade with
	jj tax:nn in	1	new tax of  residential tax of
	jj war:nn in	1	nuclear war in  psychological war to
vb nn/nns nn
	vb tax:nn nn	1	improve tax collection  ensure tax fairness
	vb president:np np	1	assassinate president reina  meet president husni
	vb party:nn nn	1	strengthen party membership  promote party style
	vb government:nn nns	1	attend government sessions  include government officials
to vb nn/nns
	to trade:vb nn	1	to trade protectionism  to trade fleece
	to finance:vb nn	1	to finance income  to finance pension
	to transport:vb nns	1	to transport laborers  to transport weapons
	to address:vb nns	1	to address rallies  to address imbalances
nns/nn/np nns/nn/np vb/vbd/vbg/vbz
	np citizens:nns vbg	1	us citizens residing  african citizens living
	np ticket:nn vbz	1	samper-de la calle ticket clears
	np clinton:np vbd	1	bill clinton began  bill clinton met  president clinton expressed
	np airlines:np vbd	1	world airlines said  lufthansa airlines openedfigure 1: some patterns that occur frequently in the trec1-fbis corpus  and selected instances of the patterns with a query word. the instances list the pattern with the query word inserted  the number of times that pattern occurs in the 1 document subset of the corpus  and then one or two examples of the pattern inthe text.
#or  #1  #1 boat nn  ber verb  
#1  #1 boat nn  nv ben verb  
#1  hvz vbn #1 boat nn   
...  
in practice  the patterns generally need to be relaxed slightly to find matches that are very close to the patterns. we have observed that allowing a few extra words improves the recall of useful documents  though we have not carried out a formal study of that effect. the above query is transformed into 
#or  #1  #1 boat nn  ber verb  
#1  #1 boat nn  nv ben verb  
#1  hvz vbn #1 boat nn   
...  
1. evaluation
　we are interested in whether the clarifying questions result in a more focused set of documents in response to the searcher's query. one way to measure that would be to ask someone to judge each set of returned documents to decide whether they were more or less focused than the original set. such a process is time consuming and unwieldy.
　instead  we will use a measure of query clarity based on vocabulary distribution in both sets of retrieved documents  1  1 . if one query has more  clarity  than another  it is less ambiguous  and perhaps more useful for retrieval.
1 query clarity
　clarity is defined  as the kullback-liebler  kl  divergence between the collection and the query:
clarity 
（
where v is the set of all terms in the collection  e.g.  trec1fbis or tdt1   q represents the query  and p w  represents the probability of the word occurring in a document in the collection. to estimate the probability distribution of words given the query  the  query language model    we use 
p w|q  ゛= x p w|d p d|q 
d（r
where r is the set of documents retrieved in response to the query  and p w|d  = λpml w|d  +  1   λ p w   a linear combination of the corpus probability and the maximum likelihood estimate based on the document. we set λ = 1. what the clarity measure does is compare the language model  probability distribution of words  of the corpus with the language model generated by a query. the way it is calculated means that if the distributions are identical  the clarity will be zero  and as they become more and more different  the value will rise. as a result  if the set of retrieved documents has roughly the same coverage as the entire corpus  the query that generated them will have a low clarity value-i.e.  it is an ambiguous query.
　it has also been shown that there is a strong correlation between clarity and the performance of the query as measured by average precision   so it is possible to predict  to some extent  the performance of a query on a collection without relevance information.
1 using clarity
　to determine whether the clarification questions are providing any focusing of the results  we compare the clarity of the original query word with that of the modified query. each query qi has a set of clarifying questions qi 1 through qi nq where nq varies by query and indicates the number of questions whose patterns occurred more than 1 times in the corpus.
　we compute the following measures to compare the effectiveness of the system.
  the number of times that the clarification question is clearer than the original query.
nq
xi clarity qi j    clarity qi  
j=1
  the increase in clarity moving from the original query to the clarification question. if the number is negative or near zero  it means that the questions were not an improvement.
nq
xclarity qi j    clarity qi 
j=1
in addition  both measures are averaged across all clarification questions  per-question average  also called a pooled average   and weighted by the original queries  per-query average . the latter is important because nq can vary dramatically between queries and we do not want queries with few clarification possibilities to be overshadowed by the others.
1. results
　to evaluate the disambiguation potential of this technique  we choose 1 one-word queries using a mix of several different ways:
  we used 1 common one word queries from web logs. this we found from multiple sources as follows:  1  words that were listed as being common single word queries using a word tracker1 report that lists commonly used query terms mined from a large log of metasearch queries;  1  common one-word queries as reported by google1 and metacrawler1. these words were all verified to occur within the trec1-fbis corpus.
  since our database is a trec-1 collection  we analyzed the trec-1 topics 1 that could be narrowed down to one word. we used 1 such queries. for example trec topic 1 is  foreign trade   which we generalized to  trade .
we report below analysis of the clarity impact in the aggregate and then present detailed analysis of some of the query words.
1 overall trends
　overall  the query clarity improves an average of 1% for trec queries and 1% for web queries  per-query average . the top of figure 1 shows a breakdown of the improvement on a per-query basis for trec queries and the bottom half shows the same for web queries. almost all queries have average improvements in clarity  and even when the average is negative  most of the clarification questions reduce ambiguity.

figure 1: graph shows the clarity values for the clarifying questions related to tour  the values shown in figure 1. the values were sorted in order of clarity. the original clarity of tour is the solid horizontal line at 1
　for example  for the original query word defense there were 1 patterns that occurred often enough to be recorded. the clarity of defense was 1  not shown in the table . of the 1 patterns  1 of them  1%  showed an improvement in clarity  averaging 1 or 1%  the values ranged from -1% to 1% .
　about 1% of the questions for the trec1 questions and 1% for the general web queries improved query clarity  strongly suggesting their value in reducing ambiguity. the reasonable similarity between the pooled and query-weighted averages suggests that the results are comparable across queries.
　the percent improvement in clarity ranged from 1% to improve mines to jj mines:nns np down to -1% trying to improve heart to cd heart:nn cc in the set of trec questions. in the set of general web queries this range is from 1% improving apartment to at apartment:nn vbn to -1% for trying to improve computer to nn computer:nn nns. it appears that the queries where ambiguity could be reduced the most were cases where the word could be either a noun or a verb  e.g.  tour  defense  or where the word often appeared as a proper noun  e.g.  airline .
　if clarity numbers are calculated or approximated in advance  it would be possible to remove clarification questions that actually reduce clarity  i.e.  increase ambiguity   making this technique even more useful.
1 detailed analysis
　the query word tour is not very common in the trec1-fbis corpus that we used: it occurs in 1 out of the 1 stories. the word tour has a clarity value of 1. we show a partial breakdown of the results for tour clarification in figure 1. the results are ordered by percent improvement in the original clarity value  ranging from a 1% improvement to a drop of almost 1%. figure 1 shows a graph of the clarity values  with a straight line representing the original clarity of the query. it is clear that improvement is usually seen  and often quite large.
the pattern jj tourist:nn vbg corresponds to phrases
　
trecquerynum.numberpercentchange inpercenttopicwordquestsimprovedimprovedclarityimproved1cigarette11-1-11crime11111defense11111diet11111drug11111environment11111gun11-1-11health11111heart11-1-11hospital11111husbandry11111magnetic11111military11111mines11111security11111smuggling11111solar11111submarine11111surveillance11111tax11-1-11trade11111traffic11111uniform11111violence11111welfare1111per-question averages1111per-query averages1111airlines1111apartment1111attorney1111author11-1-1biotech1111birthday1111cheap1111computer11-1-1divorce11-1-1employment1111fish1111free1111homes11-1-1house1111international1.1.111investing1111job1111loan1111marijuana1111master1111software11-1-1tour1111travel1111vacation1111vietnam11-1-1per-question averages1111per-query averages1111figure 1: summary evaluation of change in clarity broken down by query and overall for trec queries  top  and general web queries  bottom .
　
percentpatterncountclarityimprovementnp tourists:nns cc1.1.1nn toured:vbd at1.1.1jj tour:nn np1.1.1np tourist:np np1.1.1np tourist:nn nn1.1.1cc tourism:nn np1.1.1jj tourists:nns cc1.1.1cc tourism:nn nn1.1.1jj tour:nn wdt1.1.1jj tour:nn in1.1.1nn tourism:nn nns1.1.1cd tourist:nn nns1.1.1at tour:nn nn1.1.1nn tourism:in nn1.1.1in tour:at nn1.1.1jj tours:nns in1.1.1cc tourism:nn at1.1.1in tourism:nn at1.1.1...
...
cc tourist:nn nns1.1.1jj tourists:nns vbg1.1-1np tour:nn in1.1-1figure 1: breakdown of changes in clarity for the patterns recorded for the query tour. the original clarity of that query was 1
percentpatterncountclarityimprovementin defense:np bez1.1.1np defense:np in1.1.1punc defense:np np1.1.1at defense:nn cc1.1.1at defense:np in1.1.1in defense:np rb1.1.1in defense:nn at1.1.1nns defense:nn np1.1.1in defense:np cc1.1.1np defense:np np1.1.1in defense:nn nns1.1.1nn defense:np np1.1.1nn defense:cc nn1.1.1at defense:nn nn1.1.1in defense:np nn1.1.1np defense:np nn1.1.1cc defense:np np1.1.1nn defense:np1.1.1nn defense:in nn1.1.1...
...
toin defense:np np1.1.1in defense:nn in1.1-1figure 1: breakdown of changes in clarity for the patterns recorded for the query defense. the original clarity of that query was 1
such as  typical tourist visiting  and does not provide much focusing of the query. on the other hand  the pattern np tourist:np np represents phrases such as  national tourist board  and the documents in which such phrases are present focus more on information  announcements  etc.  for tourists  providing a fairly tight set of retrieved documents.
　figure 1 shows a similar effect for the query word defense  the word with a high improvement of clarity in the trec query set. note that defense also occurs about as often as tour: 1 times in trec1-fbis. the clearest clarification in this case is  in defense:np bez   which corresponds to   department/ministry  of defense is  and occurs 1 times. the clarification  cd defense:nn cc  corresponding to phrases such as   team will use  a 1 defense and  which although it occurs an equal number of times  does not show as great an improvement in clarity. in the first case almost all documents are military related  whereas defense as a common noun could appear in any context- viz. defense  sports  law  etc. there is no apparent relation between the number of occurrences of a pattern and clarity.
1. conclusion and future work
　we have shown a method for extracting patterns of word usage from a corpus and for using those patterns to help the user clarity an ambiguous query. the patterns represent sequences of parts of speech that occur around the query word often enough in the corpus that they are likely to be meaningful. frequent patterns are mapped to human-generated clarification questions that the user may choose from. note that we envision this as an optional side-bar to the return of query results-there seems little value in requiring the searcher to clarify the question if his or her desired document is already in the top ranks.
　once the user has selected a clarification question  we can re-issue the query based on the part of speech patterns  though slightly relaxed to increase recall. a list of sample patterns is generally helpful for the user interpreting the question.
　we used a statistical measure called query clarity  to demonstrate that the clarification questions generally provide a much more focused set of documents.
　we are working on extending these ideas to build a better set of clarification questions for the patterns and to determine ways for automatically constructing such questions  because it is tedious to do so by hand . in figure 1 it is apparent that certain clarification questions have multiple patterns associated with them. we are studying methods by which these patterns for a given question can be learned using training data. we are also building a system that implements these ideas to field test an interface to find out what works best in live settings.
acknowledgments
the original motivation for this work arose out of conversations with w. bruce croft. we are grateful to ted allen and hema krishnan for some preliminary work they did suggesting that this technique could succeed. we also thank victor lavrenko  steve cronen-townsend  margie connell  and steve harding for their help making software work.
　this material is based on work supported in part by the center for information retrieval  in part by nsf grant numbers iis-1 and iis-1  and in part by advanced research and development activity under contract number mda1-c-1. any opinions  findings and conclusions or recommendations expressed in this material are the authors' and do not necessarily reflect those of the sponsors.
