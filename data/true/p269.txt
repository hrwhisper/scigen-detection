an important issue in the dissemination of time-varying web data such as sports scores and stock prices is the maintenance of temporal coherency. in the case of servers adhering to the http protocol  clients need to frequently pull the data based on the dynamics of the data and a user's coherency requirements. in contrast  servers that possess push capability maintain state information pertaining to clients and push only those changes that are of interest to a user. these two canonical techniques have complementary properties with respect to the level of temporal coherency maintained  communication overheads  state space overheads  and loss of coherency due to  server  failures. in this paper  we show how to combine push- and pull-based techniques to achieve the best features of both approaches. our combined technique tailors the dissemination of data from servers to clients based on  i  the capabilities and load at servers and proxies  and  ii  clients' coherency requirements. our experimental results demonstrate that such adaptive data dissemination is essential to meet diverse temporal coherency requirements  to be resilient to failures  and for the efficient and scalable utilization of server and network resources.
keywords
dynamic data  temporal coherency  scalability  resiliency  world wide web  data dissemination  push  pull
1. introduction
　recent studies have shown that an increasing fraction of the data on the world wide web is time-varying  i.e.  changes frequently . examples of such data include sports information  news  and financial information such as stock prices. the coherency requirements associated with a data item depends on the nature of the item

 pavan deolasee was supported in part by a ibm fellowship  amol katkar by a imc fellowship  ankur panchbudhe by a d. e. shaw fellowship  krithi ramamritham by national science foundation  nsf  grant iri-1  tata consultancy services  ibm and merl  and prashant shenoy by nsf grant ccr-1  emc  ibm  intel  and sprint. additional support was provided by nsf grants cda-1 and eia-1.
copyright is held by the author/owner.
www1  may 1  1  hong kong.
acm 1-1/1.
and user tolerances. to illustrate  a user may be willing to receive sports and news information that may be out-of-sync by a few minutes with respect to the server  but may desire to have stronger coherency requirements for data items such as stock prices. a user who is interested in changes of more than a dollar for a particular stock price need not be notified of smaller intermediate changes.
　in the rest of this section  we  a  describe the problem of temporal coherency maintenance in detail   b  show the need to go beyond the canonical push- and pull-based data dissemination  and  c  outline the key contributions of this paper  namely  the development and evaluation of adaptive protocols for disseminating dynamic i.e.  time-varying data.
1 the problem of maintaining temporal coherency on the web
　suppose users obtain their time-varying data from a proxy cache. to maintain coherency of the cached data  each cached item must be periodically refreshed with the copy at the server. we assume that a user specifies a temporal coherency requirement     for each cached item of interest. the value of denotes the maximum permissible deviation of the cached value from the value at the server and thus constitutes the user-specified tolerance. observe that can be specified in units of time  e.g.  the item should never be out-of-sync by more than 1 minutes  or value  e.g.  the stock price should never be out-of-sync by more than a dollar . in this paper  we only consider temporal coherency requirements specified in terms of the value of the object  maintaining temporal coherency specified in units of time is a simpler problem that requires less sophisticated techniques . as shown in figure 1  let
　　  and denote the value of the data item at the server  proxy cache and the user  respectively. then  to maintain temporal coherency we should have

figure 1: the problem of temporal coherency
　the fidelity of the data seen by users depends on the degree to which their coherency needs are met. we define the fidelity observed by a user to be the total length of time that the above inequality holds  normalized by the total length of the observations . in addition to specifying the coherency requirement   users can also specify their fidelity requirement for each data item so that an algorithm that is capable of handling users' fidelity and temporal coherency requirements   s  can adapt to users' needs.
　in this paper we develop adaptive push- and pull-based data dissemination techniques that maintain user-specified coherency and fidelity requirements. we focus on the path between a server and a proxy  assuming that push is used by proxies to disseminate data to end-users. since proxies act as immediate clients to servers  henceforth  we use the terms proxy and client interchangeably  unless specified otherwise  the latter term is distinct from the ultimate end-users of data .
1 the need for combining push and pull to disseminate dynamic data
　in the case of servers adhering to the http protocol  proxies need to periodically pull the data based on the dynamics of the data and a user's coherency requirements. in contrast  servers that possess push capability maintain state information pertaining to clients and push only those changes that are of interest to a user/proxy.
　the first contribution of this paper is an extensive evaluation of the canonical push- and pull-based techniques using traces of realworld dynamic data. our results  reported in section 1 and summarized in table 1  show that these two canonical techniques have complementary properties with respect to resiliency to  server  failures  the level of temporal coherency maintained  communication overheads  state space overheads  and computation overheads.
specifically  our results indicate that
a pull-based approach does not offer high fidelity when the data changes rapidly or when the coherency requirements are stringent. moreover  the pull-based approach imposes a large communication overhead  in terms of the number of messages exchanged  when the number of clients is large.
a push-based algorithm can offer high fidelity for rapidly changing data and/or stringent coherency requirements. however  it incurs a significant computational and state-space overhead resulting from a large number of open push connections. moreover  the approach is less resilient to failures due to its stateful nature.
　these properties indicate that a push-based approach is suitable when a client requires its coherency requirements to be satisfied with a high fidelity  or when the communication overheads are the bottleneck. a pull-based approach is better suited to less frequently changing data or for less stringent coherency requirements  and when resilience to failures is important.
     s of clients may vary across clients and bandwidth availability may vary with time  so a static solution to the problem of disseminating dynamic  i.e.  time-varying  data will not be responsive to client needs or load/bandwidth changes. we need an intelligent and adaptive approach that can be tuned according to the client requirements and conditions prevailing in the network or at the server/proxy. moreover  the approach should not sacrifice the scalability of the server  under load  or reduce the resiliency of the system to failures. one solution to this problem is to combine push- and pull-based dissemination so as to realize the best features of both approaches while avoiding their disadvantages. the goal of this paper therefore is to develop techniques that combine push and pull in an intelligent and adaptive manner while offering good resiliency and scalability.
1 research contributions of this paper
　in this paper  we propose two different techniques for combining push- and pull-based dissemination.
1.   our first algorithm  presented in section 1  simultaneously employs both push and pull to disseminate data  but has tunable parameters to determine the degree to which push and pull are used. conceptually  the proxy is primarily responsible for pulling changes to the data; the server is allowed to push additional updates that are undetected by the proxy. by appropriate tuning  our algorithm can be made to behave as a push algorithm  a pull algorithm or a combination. since both push and pull are simultaneously employed  albeit to different degrees  we refer to this algorithm as pushand-pull  pap .
1.   our second algorithm  presented in section 1  allows a server to adaptively choose between push- and pull-based dissemination for each connection. moreover  the algorithm can switch each connection from push to pull and vice versa depending on the rate of change of data  the temporal coherency requirements and resource availability. since the algorithm dynamically makes a choice of push or pull  we refer to it as push-or-pull  pop .
　we have implemented our algorithms into a prototype server and a proxy. we demonstrate the efficacy of our approaches via simulations and an experimental evaluation. complete source code for our prototype implementation and the simulator as well as the data used in our experiments is available from our web site.
　table 1 summarizes the properties of our pap and pop algorithms vis-a-vis the canonical push and pull approaches.
　the semantics of most of the entries in the table are self-evident even though the reason behind the stated properties of pap and pop will be clear only after they are described and evaluated. but a few words of explanation are in order.
with respect to resiliency  pap offers graceful degradation upon loss of state at the server or when the server loses a push connection. this is because  with pap  a client normally obtains data through pushes and pulls  and when pushes from the server stop  pulls come to its rescue. so pap seamlessly recovers from such failures. similarly  pop is designed so that a client comes to know of state space losses or connection losses after a delay  at which point it needs to explicitly switch to pulling. hence it too experiences graceful degradation  albeit after a delay. so  both pap and pop offer better failure handling properties than push.
the behavior of pap and pop can be adjusted to suit the temporal coherency requirements imposed on data. in the case of pap  this is done by adjusting its parameters which can be done even on short time scales; with pop  switching from push to pull or vice versa for a particular connection is viable over large time scales and this will change the temporal coherency of the disseminated data.
the scalability properties of pop and pap are preferable to those of pull or push by themselves.
the last row of table 1 shows the behavior of a protocol popopap that chooses one of push  pull  or pap  thereby getting the benefits of all three where it is most appropriate to deploy them. this allows it to behave the best along all dimensions: resiliency  temporal coherency  and scalability.
1. push vs. pull: algorithms and their performance
　in this section  we present a comparison of push- and pull-based data dissemination and evaluate their tradeoffs. these techniques will form the basis for our combined push-pull algorithms.
table 1: behavioral characteristics of data dissemination algorithms
algorithmresiliencytemporal cohere
 fidelity ncyoverheads  scalability communicationcomputationstate spacepushlowhighlowhighhighpullhighlow  for smalls highlowlowhigh  for larges papgraceful degradationadjustable  fine grain low/mediumlow/mediumhighpopdelayed graceful degradation adjustable  coarse grain low/mediumlow/mediumlow/mediumpopopapgraceful degradationadjustablelow/mediumlow/mediumlow/medium1 pull
　to achieve temporal coherency using a pull-based approach  a proxy can compute a time to refresh  ttr  attribute with each cached data item. the ttr denotes the next time at which the proxy should poll the server so as to refresh the data item if it has changed in the interim. a proxy can compute the ttr values based on the rate of change of the data and the user's coherency requirements. rapidly changing data items and/or stringent coherency requirements result in a smaller ttr  whereas infrequent changes or less stringent coherency requirement require less frequent polls to the server  and hence  a larger ttr.1 observe that a proxy need not pull every single change to the data item  only those changes that are of interest to the user need to be pulled from the server  and the ttr is computed accordingly .
　clearly  the success of the pull-based technique hinges on the accurate estimation of the ttr value. next  we summarize a set of techniques for computing the ttr value that have their origins in . given a user's coherency requirement  these techniques allow a proxy to adaptively vary the ttr value based on the rate of change of the data item. the ttr decreases dynamically when a data item starts changing rapidly and increases when a hot data item becomes cold. to achieve this objective  the adaptive ttr approach takes into account  a  static bounds so that ttr values are not set too high or too low   b  the most rapid changes that have occurred so far and  c  the most recent changes to the polled data.
　in what follows  we use       to denote the values of a data item at the server in chronological order. thus  is the latest value of data item . is computed as:
where
denote the range within which ttr
values are bound.
　　　　denotes the most conservative  i.e.  smallest  ttr value used so far. if the next ttr is set to   temporal coherency will be maintained even if the aximum ate of change observed so far recurs. however  this ttr is pessimistic since it is based on worst case rate of change at the source. if this worst case rapid change occurs for only a small duration of time  then this approach is likely to waste a lot of bandwidth especially if the user can handle some loss of fidelity.
　　　　is a learning based ttr estimate founded on the assumption that the dynamics of the last few  two  in the

 note that the time to refresh  ttr  value is different from the time to live  ttl  value associated with each http request. the former is computed by a proxy to determine the next time it should poll the server based on the ; the latter is provided by a web server as an estimate of the next time the data will be modified.
case of the formula below  recent changes are likely to be reflective of changes in the near future.
where
- is an estimate of the ttr value  based on the most recent change to the data.

if the recent rate of change persists  will ensure that changes which are greater than or equal to are not missed.
- weight     initially 1  is a measure of the relative preference given to recent and old changes  and is adjusted by the system so that we have the recency effect  i.e.  more recent changes affect the new more than the older changes.
　　　　　is a parameter of the algorithm and can be adjusted dynamically depending on the fidelity desired  with a higher fidelity demanding a higher value of .
the adaptive ttr approach has been experimentally shown to have the best temporal coherency properties among several ttr assignment approaches . consequently  we choose this technique as the basis for pull-based dissemination.
1 push
　in a push-based approach  the proxy registers with a server  identifying the data of interest and the associated   i.e.  the value
 . whenever the value of the data changes  the server uses the value to determine if the new value should be pushed to the proxy; only those changes that are of interest to the user  based on the   are actually pushed. formally  if was the last value that was pushed to the proxy  then the current value is pushed if and only if   . to achieve this objective  the server needs to maintain state information consisting of a list of proxies interested in each data item  the of each proxy and the last update sent to that proxy.
　the key advantage of the push-based approach is that it can meet stringent coherency requirements-since the server is aware of every change  it can precisely determine which changes to push and when.
1 performance of push vs. pull
　in what follows  we compare the push and pull approaches along several dimensions: maintenance of temporal coherency  communication overheads  computational overheads  space overheads  and resiliency.
1.1 experimental model
　these algorithms were evaluated using a prototype server/proxy that employed trace replay. for pull  we used a vanilla http web server with our prototype proxy. for push  we used a prototype server that uses unicast and connection-oriented sockets to push data to proxies. all experiments were done on a local intranet. we also ran carefully instrumented experiments on the internet and the trends observed were consistent with our results.
　note that it is possible to use multicast for push; however  we assumed that unicast communication is used to push data to each client  thus  results for push are conservative upper-bounds; the message overheads will be lower if multicast is used .
1.1 traces used
　quantitative performance characteristics are evaluated using real world stock price streams as exemplars of dynamic data. the presented results are based on stock price traces  i.e.  history of stock prices  of a few companies obtained from http://finance.yahoo.com. the traces were collected at a rate of 1 or 1 stock quotes per second. since stock prices only change once every few seconds  the traces can be considered to be  real-time  traces. for empirical and repetitive evaluations  we  cut out  the history for the time intervals listed in table 1 and experimented with the different mechanisms by determining the stock prices they would have observed had the source been live. a trace that is 1 hours long  has approximately 1 data values. all curves portray the averages of the plotted metric over all these traces. few of the experiments were done with quotes obtained in real-time  but the difference was found to be negligible when compared to the results with the traces.
　the pull approach was evaluated using the adaptive ttr algorithm with an value of 1  of 1 second and three values of 1  1 and 1 seconds.
table 1: traces used for the experiment
companydatetimedelljun 1  1:1:1 istutsijun 1  1:1:1 istcbukjun 1  1:1:1 istinteljun 1  1:1:1 istciscojun 1  1:1:1 istoraclejun 1  1:1:1 istveritasjun 1  1:1:1 istmicrosoftjun 1  1:1:1 ist1.1 maintenance of temporal coherency
　since a push-based server communicates every change of interest to a connected client  a client's is never violated as long as the server does not fail or is so overloaded that the pushes are delayed. thus  a push-based server is well suited to achieve a fidelity value of 1. on the other hand  in the case of a pull-based server  the frequency of the pulls  translated in our case to the assignment of ttr values  determines the degree to which client needs are met. we quantify the achievable fidelity of pull-based approaches in terms of the probability that user's will be met. to do so  we measure the durations when . let denote these durations when user's is violated.
letdenote the total time for which data was observed by a user. then fidelity is


and is expressed as a percentage. this then indicates the percentage of time when a user's desire to be within units of the source is met.
　figure 1 shows the fidelity for a pull-based algorithm that employs adaptive ttrs. recall that the push algorithm offers a fidelity of 1%. in contrast  the figure shows that the pull algorithm has a fidelity of 1% for stringent coherency requirements and its fidelity improves as the coherency requirements become less stringent.  the curve marked pap is for the pap algorithm that combines push and pull and is described in section 1. 

figure 1: fidelity for varying coherence requirements

figure 1: overheads for varying coherence requirements
1.1 communication overheads
　in a push-based approach  the number of messages transferred over the network is equal to the number of times the user is informed of data changes so that the user specified temporal coherency is maintained.  in a network that supports multicasting  a single push message may be able to serve multiple clients.  a pull-based approach requires two messages-an http ims request  followed by a response-per poll. moreover  in the pull approach  a proxy polls the server based on its estimate of how frequently the data is changing. if the data actually changes at a slower rate  then the proxy might poll more frequently than necessary. hence a pull-based approach is liable to impose a larger load on the network. however  a push-based approach may push to clients who are no longer interested in a piece of information  thereby incurring unnecessary message overheads. we quantify communication overheads in terms of the number of messages exchanged between server and proxy. figure 1 shows the variation in the number of messages with coherence requirement . as seen in figure 1  the push approach incurs a small communication overhead because only values of interest to a client are transferred over the network. the pull approach  on the other hand  imposes a significantly higher overhead.
1.1 computational overheads
　computational overheads for a pull-based server result from the need to deal with individual pull requests. after getting a pull request from the proxy  the server has to just look up the latest data value and respond. on the other hand  when the server has to push changes to the proxy  for each change that occurs  the server has to check if the for any of the proxies has been violated. this computation is directly proportional to the rate of arrival of new data values and the number of unique temporal coherency requirements associated with that data value. although this is a time varying quantity in the sense that the rate of arrival of data values as well as number of connections change with time  it is easy to see that push is computationally more demanding than pull. on the other hand  it is important to remember that servers respond to individual pull requests and so may incur queueing related overheads.
1.1 space overheads
　a pull-based server is stateless. in contrast  a push-based server must maintain the for each client  the latest pushed value  along with the state associated with an open connection. since this state is maintained throughout the duration of client connectivity  the number of clients which the server can handle may be limited when the state space overhead becomes large  resulting in scalability problems . to achieve a reduction in the space needed  rather than maintain the data and needs of individual client separately  the server combines all requests for a particular data item and needing a particular ; as soon as the change to is greater than equal to   all the clients associated with are notified. let the above optimization process convert connections into unique     pairs. the state space needed is:
 1 
also  since   this space is less than the space required if above optimization was not applied  in which case in the first term of 1 will be replaced by  .
1.1 resiliency
　by virtue of being stateless  a pull-based server is resilient to failures. in contrast  a push-based server maintains crucial state information about the needs of its clients; this state is lost when the server fails. consequently  the client's coherency requirements will not be met until the proxy detects the failure and re-registers the requirements with the server.
　the above results are summarized in table 1. in what follows  we present two approaches that strive to achieve the benefits of the two complementary approaches by adaptively combining push and
pull.
1. pap: dynamic algorithm with push and pull capabilities
　in this section  we present push-and-pull  pap  - a new algorithm that simultaneously employs both push and pull to achieve the advantages of both approaches. the algorithm has tunable parameters that determine the degree to which push and pull are employed and allow the algorithm to span the entire range from a push approach to a pull approach. our algorithm is motivated by the following observations.
　the pull-based adaptive ttr algorithm described in section 1 can react to variations in the rate of change of a data item. when a data item starts changing more rapidly  the algorithm uses smaller ttrs  resulting in more frequent polls . similarly  the changes are slow  ttr values tend to get larger. if the algorithm detects a violation in the coherency requirement  i.e. 
    then it responds by using a smaller ttr for the next pull. a further violation will reduce the ttr even further. thus  successive violations indicate that the data item is changing rapidly and the proxy gradually decreases the ttr until the ttr becomes sufficiently small to keep up with the rapid changes. experiments reported in  show that the algorithm gradually  learns  about such  clubbed   i.e.  successive  violations and reacts appropriately. so  what we need is a way to prevent even the small number of temporal coherency violations that occur due to the delay in this gradual learning process. furthermore  if a rapid change occurs at the source and then the data goes back to its original value before the next pull  this  spike  will go undetected by a pull-based algorithm. the pap approach described next helps the ttr algorithm to  catch  all the  clubbed  violations properly; moreover  spikes  also get detected. this is achieved by endowing push capabilities to servers and having the server push changes that a proxy is unable to detect. this increases the fidelity for clients at the cost of endowing push capability to servers. note that  sinc'e proxies continue to have the the ability to pull  the approach is more resilient to failures than a push approach  which loses all state information on a failure .
1 the pap algorithm
　suppose a client registers with a server and intimates its coherency requirement . assume that the client pulls data from the server using an algorithm  say   to decide its ttr values  e.g.  adaptive ttr . after initial synchronization  server also runs algorithm . under this scenario  the server is aware of when the client will be pulling next. with this  whenever server sees that the client must be notified of a new data value  the server pushes the data value to the proxy if and only if it determines that the client will take time to poll next. the state maintained by this algorithm is a soft state in the sense that even if push connection is lost or the clients' state is lost due to server failure  the client will continue to be served at least as well as under . thus  compared to a pushbased server  this strategy provides for graceful degradation.
　in practice  we are likely to face problems of synchronization between server and client because of variable network delays. also  the server will have the additional computational load imposed by the need to run the ttr algorithm for all the connections it has with its clients. the amount of additional state required to be maintained by the server cannot be ignored either. one could argue that we might as well resort to push which will have the added advantage of reducing the number of messages on the network. however  we will have to be concerned with the effects of loss of state information or of connection loss on the maintenance of temporal coherency.
　fortunately  for the advantages of this technique to accrue  the server need not run the full-fledged ttr algorithm. a good approximation to computing the client's next ttr will suffice. for example  the server can compute the difference between the times of the last two pulls     and assume that the next pull will occur after a similar   at . suppose is the time of the most recent value. the server computes   the next predicted pulling time as follows: let
server predicts the next client polling time as
.
if a new data value becomes available at the server before and it needs to be sent to the client to meet the client's   the server pushes the new data value to the client.
　in practice  the server should allow the client to pull data if the changes of interest to the client occur close to the client's expected pulling time. so  the server waits  for a duration of   a small quantity close to   for the client to pull. if a client does not pull when server expects it to  the server extends the push duration by adding     to . it is obvious that if   pap reduces to push approach; if is large then the approach works similar to a pull approach. thus  the value of can be varied so that the number of pulls and pushes is balanced properly. is hence one of the factors which decides the temporal coherency properties of the pap algorithm as well as the number of messages sent over the network.
1 details of pap
　the arguments at the beginning of this section suggest that it is a good idea to let the proxy pull when it is polling frequently anyway and violations are occurring rapidly. suppose  starting at a series of rapid changes occurs to data . this can lead to a sequence of  clubbed  violations of unless steps are taken. the adaptive ttr algorithm triggers a decrease in the ttr value at the proxy. let this ttr value be . the proxy polls next at . according to the pap algorithm  the server pushes any data changes above during . since a series of rapid changes occurs  the probability that some violation s  may occur in is very high and thus these changes will also be pushed by the server further forcing a decrease in the ttr at the proxy and causing frequent polls from the proxy. now  the ttr value at the proxy will tend towards and will also approach zero  thus making the durations of possible pushes from the server close to zero. it is evident that if rapid changes occur  after a few pushes  the push interval will be zero  and client will pull almost all the rapid changes thereafter. thus the server has helped the proxy pull sooner than it would otherwise. this leads to better fidelity of data at the proxy than with a pull approach.
　if an isolated rapid change  i.e.  spike  occurs  then the server will push it to the proxy leading to a decrease in the ttr used next by the proxy. it will poll sooner but will not find any more violations and that in turn will lead to an increase in the ttr.
　thus  the proxy will tend to pull nearly all but the first few in a series of rapid changes helped by the initial pushes from the server  while all  spikes  will be pushed by the server to the proxy. the result is that all violations will be caught by the pap algorithm in the ideal case  e.g.  with the server running the adaptive ttr algorithm in parallel with the proxy . in case the server is estimating the proxy's next ttr  the achieved temporal coherency can be made to be as close to the ideal  as exemplified by pure push  by proper choice of .
　overall  since the proxy uses the pushed  as well as pulled  information to determine ttr values  the adaptation of the ttrs would be much better than with a pull-based algorithm alone.
　although the amount of state maintained is nearly equal to push  the state is a soft state. this means that even if the state is lost due to some reason or the push connection with a proxy is lost  the performance will be at least as good as that of ttr algorithm running at the proxy as clients will keep pulling.
1 performance analysis of pap
　figure 1 shows that for pap algorithm  the fidelity offered is more than 1% for stringent and 1% for less stringent . from figure 1  we see that compared to pull  the pap algorithm has very little network overhead because of the push component. its network overheads are  however  slightly higher than that of push.
　the value of needs to be chosen to balance the number of pushes and pulls. experimental results  not shown here  indicate  as one would expect  that when is large the number of successful pushes is large  but as we decrease   the number of pushes decreases slowly until a point where pulls start dominating.

figure 1: effect of epsilon on pap's fidelity
　figure 1 shows the variation in fidelity when is varied. when is zero  the algorithm reduces to push and hence fidelity is 1%. but as we start increasing the value of the fidelity starts suffering. for values of   the fidelity is above 1%. and for
                   fidelity is approximately 1%. for values of closer to  in this case 1   fidelity is low as the pulls overtake pushes and the algorithm behaves like a ttr algorithm.
　figure 1 also shows the effect of changing in conjunction with on the fidelity offered by the algorithm. as decreases  pulls increase. as pulls become more dominant  the server has less chance to push the data values  and a bigger gives the server fewer opportunities to push. this explains the effect in
figure 1 for or . as pulls increase and the server has less and less chance to push  fidelity suffers and decreases more rapidly than in the case of . it can also be observed that  as takes values greater than   fidelity offered becomes constant. this is because even if server sets greater than client will keep polling at the maximum rate of . in effect  setting greater than is equivalent to setting it to . this explains the crossover of curves in figure 1.
　as expected  as is increased the number of pulls become higher and higher. for   there are no pulls and for there are no pushes. more fidelity requires more number of pushes and for the case where number of pushes is equal to number of pulls  fidelity is close to 1%. the more we increase the number of pulls  i.e.     the lower the obtained fidelity.
1 tuning of pap: making the approach adaptive and intelligent
　one of the primary goals of our work was to have an adaptive and intelligent approach which can be tuned according to conditions prevailing in the system. from the previous analysis of the pap algorithm it is clear that it has a set of tunable parameters using which one can achieve push capability or pull capability or anything in between. so it is fairly flexible. some of the typical scenarios are:
if the bandwidth available is low and yet  high fidelity is desired  then we choose a moderate  e.g.  in our experimental setup  close to 1  and low  e.g.  close to 1 as in figure 1 .
if the bandwidth available is low  and fidelity desired is also not high  then we can set and both to a moderate value  close to 1 and 1 respectively .
if the bandwidth available is high and fidelity desired is also high  then we can set low  close to 1  and equal to   thus having less pushes  and more pulls  but still good fidelity.
if the bandwidth available is high and fidelity desired is not stringent  then a lower value can be set for   thereby making the system resort to pulls.
if the load on the server is high  due to more pushes   can be set to a moderate/high value and/or can be set to low/moderate value so that the amount of pushes decreases and there are more pulls.
1. pop: dynamically choosing between push or pull
　pap achieves its adaptiveness through the adjustment of parameters such as and   and thereby obtains a range of behaviors with push and pull at the two extremes. we now describe a somewhat simpler approach wherein  based on the availability of resources and the data and temporal coherency needs of users  a server chooses push or pull for a particular client. consequently  we refer to our approach as push-or-pull  pop .
1 the pop algorithm
　pop is based on the premise that at any given time a server can categorize its clients either as push clients or pull clients and this categorization can change with system dynamics. this categorization is possible since the server knows the parameters like the number of connections it can handle at a time and can determine the resources it has to devote to each mode  push/pull  of data dissemination so as to satisfy its current clients. the basic ideas behind this approach are:
allow failures at a server to be detected early so that  if possible  clients can switch to pulls  and thereby achieve graceful degradation to such failures. to achieve this  servers are designed to push data values to their push clients when one of two conditions is met:  1  the data value at the server differs from the previously forwarded value by or more.  1  a certain period of time has passed since the last change was forwarded to the clients. the first condition ensures that the client is never out of sync with the values at the server by an amount exceeding the of the client. the second condition assures the client after passage of every interval that  a  the server is stillup and  b  the state of the client with the server is not lost. this makes the approach resilient. in case of the state of the client being lost or the connection being closed because of network errors  the client will come to know of the problem after time interval  after which the client can either request the server to reinstate the state or start pulling the data itself. this ensures that in the worst case  the time for which the client remains out of sync with the server never exceeds .
in this approach  the server can be designed to provide push service as the default to all the clients provided it has sufficient resources.
when a resource constrained situation arises  upon the registration of a new client or network bandwidth changes  some of the push-based clients are converted to become pull-based clients based on the criteria that we had determined earlier.
figure 1 gives the state diagram for achieving this adaptation.

figure 1: pop: choosing between push and pull
1 details of pop
　whenever a client contacts a server for a data item  the client also specifies its and fidelity requirements.
irrespective of the fidelity requirement  if the server has sufficient resources  such as a new monitoring thread  memory  etc.   the client is given a push connection.
otherwise  if the client can tolerate lower fidelity  then server disseminates data to that client based on client pull requests.
if the request desires 1% fidelity and the server does not have sufficient resources to satisfy it  then the server takes steps to convert some push clients to pull. if this conversion is not possible  then the new request is denied.
in the latter case  the push clients chosen are those who can withstand the resulting degraded fidelity  i.e.  those who had originally demanded less than 1% fidelity but had been offered higher fidelity because resources were available then for push connections. which client s  to choose is decided based on additional considerations including  a  bandwidth available  b  rate of change of data and  c  . if bandwidth available with a client is low  then forcing the client to pull will only worsen its situation since pull requires more bandwidth than push. if the rate of change of data value is low or the is high  then pull will suffice. thus  from amongst the clients which had specified low fidelity requirement  we choose proxies which have  a  specified a high value of   or  b  volume of data served is small. if a suitable  set of  client s  is found  the server sends appropriate  connection dropped  intimation to the client so that it can start pulling.
1 performance of pop
　using the same traces given in table 1 we evaluated pop. the experiments were performed by running the server on a load free pentium-ii machine and simulating clients from four different load free pentium-ii machines. there were 1 users on each client machine  accessing 1 data items. keeping the server's communication resources constant  the ratio of push to pull connections was varied and the effect on average fidelity experienced by clients in pull mode as well as across all the clients was measured.
　as expected  experimental results indicate that the communication overheads drop when the percentage of push sockets is increased. this is to be expected because push algorithms are optimum in terms of communication overheads. as we increase the percentage of push sockets  while the push clients may be able to experience 1% coherence  the percentage of pull requests that are denied due to queue overflow grows exponentially. these results indicate that a balance between pull and push connections must be struck if we want to achieve scalability while achieving high coherency.

figure 1: effect of %push connections on pop's fidelity
　we measured the effect of increasing the percentage of push connections on fidelity. as the number of push connections increases  proxies which were serving the largest number of data items or data items with stringent temporal coherency requirements are moved from pull to push mode. the implemented system worked with a fixed number of clients/data items and so the results below do not reflect the effect of admission control  i.e. request denial based on server load and client profile  which includes its requirements  volume of data served to it and its network status  that is part of pop. the results are plotted in figure 1 for two cases of computational overheads per pull request:  1  no computational overheads  except for those connected with the use of the socket  and  1  a 1 msec computational overhead per pull request  in addition to the socket handling overheads.
　when the computational overheads for a pull are negligible  average fidelity across all clients improves gradually as we increase the percentage of push clients. when a small computational overhead of 1 msecs per pull is added  while fidelity improves up to a point  when the number of pull connections becomes small  some of the pull requests experience denial of service thereby affecting the average fidelity across all clients. in fact  the overall fidelity drops nearly 1%.
　recall that all push clients experience 1% fidelity. so  the above drop in fidelity is all due to the pull clients. this is clear when we study the variation of the average fidelity of pull clients. with zero computational overheads for pulls  as we increase the number of push clients  fidelity for pull clients improves from 1% to 1% before dropping to 1%. the improvement as well as drop is more pronounced under 1 msec pull overheads. when a large percentage of the clients are in pull mode  the number of pull requests is very high. this increases the average response time for each client  which in effect  decreases the fidelity for pull clients. this scalability problem is due to computation load at the server when a large number of pull clients are present. as more and more clients switch to push mode  the number of pull requests drops  the response time of the server improves  and better fidelity results. the fidelity for pull clients peaks and then starts deteriorating. at this point the incoming requests cause overflows in the socket queues and the corresponding requests are denied. these again cause an increase in the effective response time of the client and fidelity decreases. the last portion of the curve clearly brings out the scalability issue arising because of resource constraints.
　these results clearly identify the need for the system to allocate push and pull connections intelligently. an appropriate allocation of push and pull connections to the registered clients will provide the temporal coherency and fidelity desired by them. in addition  when clients request access to the server and the requisite server resources are unavailable to meet needs of the client  access must be denied. as figure 1 indicates  this is precisely what pop is designed to do.
1 tuning of pop
　it is clear from the results plotted in figure 1  that the way in which clients are categorized as push and pull clients affects the performance of pop. so the system must dynamically and intelligently allocate the available resources amongst push and pull clients. for example   a  when the system has to scale to accommodate more clients  it should preempt a few push clients  ideally  those which can tolerate some loss in fidelity  and give those resources to pull clients;  b  if the number of clients accessing the server is very small  a server can allocate maximum resources to push clients thus ensuring high fidelity. thus  by varying the allocation of resources  a server can either ensure high fidelity or greater scalability.
1. beyond pap and pop: popopap
popopap is a combination of the pop and pap approaches:
the pap alternative is added to a pop server: to keep things simple  we can simply replaced push clients by pap clients:  a  the average resiliency offered would be better than pop   b  the degradation in service is also also likely to be more graceful  and  c  the average coherency offered is likely to be higher than with pop alone.
integration of pap with pop makes the approach more adaptive  by fine tuning using the parameters of pap .
the pop algorithm at the server improves the average scalability offered by the system.
　together  these arguments motivate the properties of popopap mentioned in table 1: by adaptively choosing pull or pap for its clients  popopap can be designed to achieve the desired temporal coherency  scalability desired for a system.
1. related work
　several research efforts have investigated the design of pushbased and pull-based dissemination protocols from the server to the proxy  on the one hand  and the proxy to the client  on the other. push-based techniques that have been recently developed include broadcast disks   continuous media streaming   publish/subscribe applications  1  1   web-based push caching   and speculative dissemination . research on pull-based techniques has spanned the areas of web proxy caching and collaborative applications  1  1  1 . whereas each of these efforts has focused on a particular dissemination protocol  few have focused on supporting multiple dissemination protocols in web environment.
　netscape has recently added push and pull capabilities to its navigator browser specifically for dynamic documents . netscape navigator 1 gives two new open standards-based mechanisms for handling dynamic documents. the mechanisms are  a  server push  where the server sends a chunk of data; the browser displays the data but leaves the connection open; whenever the server desires  it continues to send more data and the browser displays it  leaving the connection open; and  b  client pull where the server sends a chunk of data  including a directive  in the http response or the document header  that says  reload this data in 1 seconds   or  go load this other url in 1 seconds . after the specified amount of time has elapsed  the client does what it was told - either reloading the current data or getting new data. in server push  a http connection is held open for an indefinite period of time  until the server knows it is done sending data to the client and sends a terminator  or until the client interrupts the connection . server push is accomplished by using a variant of the mime message format  multipart/mixed   which lets a single message  or http response  contain many data items. client pull is accomplished by an http response header  or equivalent html tag  that tells the client what to do after some specified time delay. the computation  state space and bandwidth requirements in case of server push will be at least as much as was discussed in section 1. in addition  since we are using http mime messages  the message overhead will be more  on average mime messages are bigger than raw data . because of the same reason  it is not feasible to use this scheme for highly dynamic data  where the changes are small and occur very rapidly. also  it would be very difficult to funnel multiple connections into one connection as envisaged in our model 1  see equation 1 . this will clearly increase the space and computation requirements at the server. for the client pull case  for reasons discussed in section 1  it is very difficult to use this approach for highly dynamic data. still  these mechanisms may be useful for implementing the algorithms discussed in this paper as they are supported by standard browsers.
　turning to the caching of dynamic data  techniques discussed in  primarily use push-based invalidation and employ dependence graphs to track the dependence between cached objects to determine which invalidations to push to a proxy and when. in contrast  we have looked at the problem of disseminating individual timevarying objects from servers to proxies.
　several research groups and startup companies have designed adaptive techniques for web workloads  1  1  1 . whereas these efforts focus on reacting to network loads and/or failures as well dynamic routing of requests to nearby proxies  our effort focuses on adapting the dissemination protocol to changing system conditions.
　the design of coherency mechanisms for web workloads has also received significant attention recently. proposed techniques include strong and weak consistency  and the leases approach  1  1 . our contribution in this area lie in the definition of temporal coherency in combination with the fidelity requirements of users.
　finally  work on scalable and available replicated servers  and distributed servers  are also related to our goals. whereas  addresses the issue of adaptively varying the consistency requirement in replicated servers based on network load and application-specific requirements  we focus on adapting the dissemination protocol for time-varying data.
　we end this section with a detailed comparison of two alternatives to our approaches: leases  1  1   a technique that also combines aspects from pull-based and push-based approaches  and server-based prediction  instead of our client-based prediction  for setting time-to-live attributes for web objects  1  1  1 .
1 comparison with leases
　in the leases approach  the server agrees to push updates to a proxy so long as the lease is valid; the proxy must pull changes once the lease expires  or renew the lease . thus  the technique employs push followed by pull. in contrast  the pap approach simultaneously combines both push and pull-most changes are pulled by the proxy  changes undetected by the proxy are pushed to it. the leases approach has high fidelity so long as the lease is valid and then has the fidelity of pull until the lease is renewed. as shown earlier  by proper tuning  the fidelity of the pap algorithm can approach that of push. the leases approach is more resilient to failures than a push  the duration of the lease bounds the duration for which the can be violated; the lease can be renewed thereafter . the pap approach has even greater resiliency than leases  since proxies continue to pull even if the server stops pushing. finally  we note that the leases approach can be combined with the pap algorithm-the lease duration then indicates the duration for which the server agrees to push  missed   i.e.  undetected  changes.
1 client prediction vs. server prediction
　pap and pop are based on using prediction capabilities at the clients/proxies. an alternative  of course  is to leave the prediction to the server. such schemes are discussed in  1  1  1 . they use the if-modified-since field associated with the http get method  also known as conditional get   together with the ttl  time-to-live  fields used in many of proxy caches. these schemes in general work as follows:
client does not use any ttr or prediction algorithm  but instead depends on some meta information associated with the data to decide the time at which to refresh the data.
since the server has access to all the data  it can use a prediction algorithm to predict a time when the data is going to change by . the server then attaches this time value with outgoing data. client will use this meta information to decide when to poll next. there is no need for a push connection.
since server has better access to data than client  server predictions will be in general more  accurate  than using a ttr algorithm at the client.
　though the server-prediction approach looks like a better option than pap  it runs into following problems:
the approach requires that previous history for the relevant data be maintained at the server. this will imply increased state information and computational needs at the server and will consequently adversely affect the scalability. since in pop  section 1  we reserve the pull method to serve clients when faced with problems of scalability  we prefer to make pull relatively lightweight.
the approach is more suitable for data that changes less frequently  e.g.  say once every few hours . we are interested in web data that is highly dynamic and inherently unpredictable  e.g.  data that changes every few seconds/minutes such as stock quotes . for dynamic data  the performance will be slightly better than adaptive ttr  but at a cost of server resources and scalability.
if the server prediction is wrong and still a change of interest occurs in data  the server is helpless since it cannot push the change to the client. the change is lost. this will never happen in pap.
　in summary  so far dynamic data has been handled at the server end  1  1 ; our approaches are motivated by the goal of offloading this work to proxies.
1. concluding remarks
　since the frequency of changes of time-varying web data can itself vary over time  as hot objects become cold and vice versa   in this paper  we argued that it is a priori difficult to determine whether a push- or pull-based approach should be employed for a particular data item. to address this limitation  we proposed two techniques that combine push- and pull-based approaches to adaptively determine which approach is best suited at a particular instant. our first technique  pap  is inherently pull-based and maintains soft state at the server. the proxy is primarily responsible for pulling those changes that are of interest; the server  by virtue of its soft state  may optionally push additional updates the proxy  especially when there is a sudden surge in the rate of change that is yet to be detected by the proxy. since the server maintains only soft state  it is neither required to push such updates to the proxy  nor does it need to recover this state in case of a failure. our second technique  pop  allows a server to adaptively choose between a push- or pull-based approach on a per-connection basis  depending on observed rate of change of the data item or the coherency requirements . we also showed how pop can be extended to use pap for some of its connections  leading to the algorithm popopap.
　another contribution of our work is the design of algorithms that allow a proxy or a server to efficiently determine when to switch from a pull-based approach to push and vice versa. these decisions are made based on  i  a client's temporal coherency requirements       ii  characteristics of the data item  and  iii  capabilities of servers and proxies  e.g.  a pure http-based server precludes the use of push-based dissemination and necessitates the use of a pullbased approach by a proxy .
　our techniques have several characteristics that are desirable for time-varying data: they are user-cognizant  i.e.  aware of user and application requirements   intelligent  i.e.  have the ability to dynamically choose the most efficient set of mechanisms to service each application   and adaptive  i.e.  have the ability to adapt a particular mechanism to changing network and workload characteristics . our experimental results demonstrated that such tailored data dissemination is essential to meet diverse temporal coherency requirements  to be resilient to failures  and for the efficient and scalable utilization of server and network resources.
　currently we are extending the algorithms developed in this paper to design algorithms suitable for cooperative proxies and also for disseminating the results of continual queries  posed over dynamic data.
