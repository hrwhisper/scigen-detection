monitoring is an issue of primary concern in current and next generation networked systems. for example  the objective of sensor networks is to monitor their surroundings for a variety of different applications like atmospheric conditions  wildlife behavior  and troop movements among others. similarly  monitoring in data networks is critical not only for accounting and management  but also for detecting anomalies and attacks. such monitoring applications are inherently continuous and distributed  and must be designed to minimize the communication overhead that they introduce. in this context we introduce and study a fundamental class of problems called  thresholded counts  where we must return the aggregate frequency count of an event that is continuously monitored by distributed nodes with a user-specified accuracy whenever the actual count exceeds a given threshold value.
　in this paper we propose to address the problem of thresholded counts by setting local thresholds at each monitoring node and initiating communication only when the locally observed data exceeds these local thresholds. we explore algorithms in two categories: static thresholds and adaptive thresholds. in the static case  we consider thresholds based on a linear combination of two alternate strategies  and show that there exists an optimal blend of the two strategies that results in minimum communication overhead. we further show that this optimal blend can be found using a steepest descent search. in the adaptive case  we propose algorithms that adjust the local thresholds based on the observed distributions of updated information in the distributed monitoring system. we use extensive simulations not only to verify the accuracy of our algorithms and validate our theoretical results  but also to evaluate the performance of the two approaches. we find that both approaches yield significant savings over the naive approach of performing processing at a centralized location.
1.	introduction
many emerging systems are fundamentally distributed in nature.
the current and next generation of networks are large-scale  and widespread. within this distributed networked systems  a principal concern is monitoring: either monitoring the environment surrounding each of the network nodes  or monitoring the behavior of the network itself. two prototypical applications are in:  i  sensor networks  whose raison d'etre is for monitoring and collating information on atmospheric conditions  wildlife behavior  and troop movements in military applications among others  and  ii  network traffic monitoring in  wired or wireless  data networks  for traffic management  routing optimization  and anomaly and attack detection.
　over the past few years  the defining characteristics of these applications have been identified to pose new challenges that are not answered by traditional data management systems. the challenges in monitoring arise mainly because the systems are fundamentally:
  continuous: unlike the traditional database  on-demand  view of the world  where queries are posed in sql and an answer returned to the user  queries in these monitoring situations are typically long running queries over the data  which must continuously run and return answers as and when they are found.
  distributed: the data required to answer the monitoring queries is distributed throughout the network. typically  a query requires information to be collated and aggregated from many  if not all  nodes in the network.
  resource-constrained: efficiency of operation is absolutely vital in the distributed monitoring world. in sensor networks  we must ensure that the life of the network is extended as long as possible by minimizing the energy drain of running the monitoring protocol; in data networks  we must ensure that the protocol does not hinder the principal operation of the network  allowing the delivery of messages unencumbered by the monitoring overhead. these concerns manifest themselves principally as a requirement to minimize  to the extent possible  the communication cost of the monitoring protocols: communication is the principal energy drain for a sensor  and excess communication in a data network reduces the capacity for normal operation. as a secondary concern  computation and memory usage should also be minimal for efficient execution of the monitoring.
thresholded counts. within this framework of continuous  distributed  and resource-constrained systems  there are many possible types of monitoring queries that can be posed. prior work has looked at particular query types such as top-k monitoring   set expression cardinality   and holistic aggregates such as quantiles . but many queries rely at heart on monitoring sums or counts of values  in combination with thresholds  lower bounds . consider the following queries from a variety of different domains:
   from   report when at least 1 soldiers have crossed a specified boundary.
  raise an alert when the total number of cars on the highway exceeds 1 and report the number of vehicles detected.
  which species have more than 1 members within a certain region for more than an hour 
  identify all destinations that receive more than 1gb of traffic from the monitored network in a day  and report their transfer
totals
   query q1 of   monitor the volume of remote login  telnet  ssh  ftp etc.  request received by hosts within the organization that originate from the external hosts.   which users within the monitored network receive more than 1 different connections 
　in each case there are two parts to the query: a request for a sum or count of a particular quantity  vehicles  animals  network connections etc.   and a minimum threshold  or trigger  for when we need to know this information. such thresholds are vital in focusing the information returned to the user  and in reducing the monitoring burden on the network. in almost every application involving measuring quantities like these  it is only important to know the quantities when they exceed a specified level. small counts  of remote logins  human activity  network traffic  are prevalent and can be ignored to reduce the reporting burden on the monitoring system. but in all the above situations we can define a threshold  such that it is critical to know when this threshold has been crossed. our focus in this paper is on designing protocols and algorithms to monitor such sums and counts with thresholds. in the extreme case  these thresholds can be trivial  i.e. zero or one   but in all the scenarios we have outlined  there exists a non-trivial threshold which can be used to reduce the communication cost. in general  the thresholds can be specified either as part of the query  or learned by the system in response to the observed data. for this work  without loss of generality we assume that the threshold is fixed a priori and focus on answering queries for thresholded counts given such a threshold; dynamic thresholds can be accommodated  but we do not discuss them here.
　the second component of these types of queries is to return a count of a particular set of values. here  one can make the observation that an application rarely needs to know the exact count so long as the answer is given with reasonable precision: it is not necessary to know whether the number of cars on the highway is 1 or 1  if either answer is accurate to within 1%. so instead of demanding exact results  we can explore the tradeoff between accuracy and communication: clearly  allowing larger uncertainties about counts allows monitoring sites to be more conservative about when they send their updates to a central monitor. this benefit becomes clear in our experiments  which show significant savings as the allowable uncertainty increases.
our contributions. we address the problem of continuously monitoring thresholded counts in a distributed environment. our contributions are as follows:
　1. we introduce and formalize the thresholded counting problem  which is fundamental to several distributed monitoring scenarios. we give guaranteed solutions to the problem based on monitors comparing their local counts to local thresholds  and postponing communication until these thresholds are violated. we consider two approaches  depending on whether the thresholds are determined statically in advance  or can be allocated adaptively as the distribution of updated information is observed.
　1. in the static case  we show two different fundamental techniques for setting the local thresholds. we introduce a blended approach  based on a linear combination of the two fundamental methods while retaining the correctness guarantee. we give a careful and detailed analysis of the optimal setting of this blend which depends only on coarse properties of the total count.
　1. in the adaptive case  we introduce a variety of increasinglysophisticated algorithms that attempt to capture the observed distribution of count updates  and hence reduce the overall number of messages sent within the system.
　1. we show that our static and adaptive algorithms can be easilyextended to include negative updates  sliding windows  approximate counts  and time-dependent threshold values.
　1. we conduct a thorough and detailed set of experiments toverify the efficacy of our methods for giving a low cost monitoring scheme for thresholded queries. we compare to applications of prior work on a variety of real and synthetic data  and show that there are significant savings for using our methods.
outline. in section 1  we review prior work in continuous  distributed monitoring. we formally define the problem of thresholded counts in section 1. we propose algorithms which set static thresholds in section 1  and adaptive thresholds in section 1. we discuss some extensions to our current work in section 1. we present results from our experimental evaluation in section 1 and conclude in section 1.
1.	related work
　our work is related to the design and construction of systems to handle large streams of data. there are several general purpose  data stream management systems   dsmss   such as aurora   stream   and telegraph   and special purpose systems  such as for network data streams  including gigascope  and tribeca . however  our problem is inherently distributed  whereas these systems are primarily focused on centralized monitoring. recently  distributed data stream management systems have been proposed such as borealis  and medusa  1  1 . the main focus of these systems is how to effectively distribute the work of the system  and hence balance the load; it is therefore assumed possible to redirect data streams. in our model  we explicitly rule out the possibility of sending all observed data to a different processor: in resource constrained situations  our only possibility is to process the stream of data at the monitor where it is observed.  in our experiments  we are able to improve on the cost of sending the whole data stream by three orders of magnitude by processing at the point of observation .
　the model of continuous distributed computation has been adopted by a series of papers over recent years. within this context  a number of different problems have been addressed  including monitoring the  exact  top-k set   evaluating set expressions   and quantiles and heavy hitters  1  1 . techniques have been proposed which allow the continuous  distributed monitoring of a variety of queries based on using sketches   from which join-sizes and many other functions can be estimated accurately  and based on techniques that are resilient to duplication of information .
　the problem we consider  of maintaining accurate counts above a threshold  is not covered by any of these approaches. we now discuss previous work that is closer to this problem. various works have considered accurate maintenance of sums and counts in a distributed sensor network setting  but these are typically for duplicateresilient  on-demand  computations  rather than continuous  1  1  1 . the  heavy hitters  problem is to find all items whose count is above some fraction φ of the count of all items  e.g. users in a wired network consuming more than 1% of the total bandwidth . while semantically related to our threshold based problem  con-

       figure 1: distributed monitoring architecture tinuous monitoring of the heavy hitters is a somewhat easier problem  since there can be at most 1/φ heavy hitters at any one time  whereas there can be an unbounded number of monitored counts exceeding their thresholds. the permitted error for heavy hitters also scales with the sum of the counts  rather than the count of the individual item  as we demand in our formal definition of this problem  see next section . a continuous  distributed algorithm for heavy hitters follows as a special case of quantile monitoring   but this cannot be applied to our problem since the guarantees are insufficient to meet our requirements.
　more closely related to our problem is the work of jain et al   which considers triggers. the authors make a compelling argument for continuous distributed monitoring of trigger conditions based on local counts fi  and suggest some potential approaches. the method outlined relates to triggers of the form i fi   c  i.e. the trigger should be raised if the total of the fis at different sites exceeds the threshold c. this is clearly a simplified version of our problem. the algorithms given are randomized  and in expectation give errors of constant factors times c  which are much larger than the δ guarantees we provide.
　olston et al  propose a filter based approach to maintaining accurate counts. there  the central site wishes to know each sum fj = i fi j with uncertainty at most δj for a fixed δj. the approach is to allocate  filters   allowable ranges  at each site  and when values are observed that lie within these filters  no action is taken; if they fall outside the range  then they are passed up to the central site. to adapt to the observed distribution  filters are periodically resized based on how long the filter has been valid. this approach can be modified to apply to our problem  and we compare against this algorithm in our experimental section.
　most recently  an approach to monitoring general functions has been proposed by sharfman et al . applied to our problem  their technique gives algorithms of a similar nature to those we propose  however our algorithms are designed to take advantage of specific features of our problem. it will be of interest to compare the two in future.
1.	problemdefinitionandapproach
　we define the problem of efficiently maintaining approximate counts in a distributed scenario in this section and describe our approach.
1	system architecture
　we consider a distributed monitoring system as shown in figure 1. the system consists of m remote sites and a central coordinator site. the remote sites observe a continuous stream of updates  which taken together define a distribution of values. the remote sites can communicate with the coordinator in order to ensure that the coordinator is able to accurately answer queries over the union of the update streams. in general  the remote sites can communicate amongst themselves as well as with the coordinator; however  in line with previous work  we only consider protocols that have  pairwise  communications between the coordinator and remote sites. this is the model that is adopted in most prior work on continuous  distributed monitoring problems  1  1  1  1  1.
　each site i （ {1...m} monitors a set of k values nv i  v （ {1...k}  which are defined incrementally. we model each stream of updates observed at the remote site i as a sequence of tuples . this is interpreted as an update of ci v t to nv in site i at time t. we assume that updates are ordered by timestamp  and site i only sees updates to itself1. then nv i t   the value of the count in site i at time t  is defined as. the global count  nv t   is defined as nv t  = i（{1...m} nv i t . our goal is to monitor the value of each nv t  within specified accuracy bounds. since we are interested only in the  current  value of counts  in the rest of the paper we drop reference to t and use nv and nv i to represent the global and local counts.
　this model accurately captures the scenarios we described in the introduction. for example  in network traffic monitoring  each update might correspond to the observation of a packet at a remote site  or monitor . in this context  t is the current time  i is the identifier of the monitor  and v and ci v t are properties of the packet  such as destination ip address and size of packet  respectively. based on the inputs from all the remote sites  the coordinator tracks the aggregate traffic to various destinations and raises an alarm when the total traffic becomes high  indicative of an unusual activity  like a ddos attack . monitoring in sensor networks can also be mapped onto this model in a natural way.
　in general  the updates  ci v t  can be negative  corresponding to a decrease in nv i  such as temperature updates in sensor networks  or fractional  like rainfall measurements . all our methods will handle such settings  but for clarity we focus on the case where ci v ts are positive integers  and postpone discussion of negative updates to section 1.
1	the thresholded count problem
　our focus is on monitoring the nv at the central coordinator. since nv is defined by updates to remote sites  if we require to know nv exactly  then we must eagerly send every update from a remote site to the coordinator as soon as it is observed. this ensures accurate values at the coordinator at all times  but comes with huge communication overhead. as observed in section 1  such fine accuracy is not needed in practice. another possibility is for the remote sites to send their counts periodically to the coordinator site. this reduces the communication burden  but still has some issues in practice: updates in real systems are typically bursty  i.e.  counts change rapidly in some time periods while it may hardly change in others. the former results in inaccurate values at the coordinator  while the latter results in unnecessary communications. in this paper  we define the problem of continuously monitoring thresholded counts  which ensures that the coordinator always has an accurate count with minimal delay1.
　definition 1. given a threshold tv and an error guarantee δv  the δv-deficient thresholded count  n v satisfies the following

1
　as in the cited prior work  we concentrate on the key algorithmic challenges in designing effective protocols for this setting  and hence we do not consider issues of message loss. instead  we assume that there are sufficient mechanisms in place such as message acknowledgments  retransmissions  and timestamping to ensure that the correct behavior is observed. 1
this is not a strong assumption; typically  the site observes only
the pair v ci v t  and supplies t and i itself. 1
 since network delay from remote sites to coordinator is unavoidable  every tracking algorithm must incur some minimum delay. properties
  1 ＋ n v   tv when nv   tv
  nv 1   δv    n v   nv when nv − tv
　where it is clear from context  we will drop the qualification v and refer to n t δ. note that this definition is distinct from the heavy hitter definition in data streams   which requires an additive error that scales as the sum of all monitored counts; instead  we have a much more demanding requirement to monitor all counts with relative error on each count  above the threshold. without a threshold  t  the communication overhead is high to begin with  as low counts require every update to be pushed to the coordinator in order to maintain the error guarantee δ. since low counts are typically uninteresting for monitoring applications  by supressing communication for these counts  the overhead of the monitoring can be kept low.
　the value of the threshold depends on individual applications. for applications in network monitoring that track anomalous behavior  like ddos attacks  the value of the threshold can be high  while applications like traffic accounting  that count the traffic sent by hosts or networks beyond a certain initial minimum can use a lower threshold value.
1	our approach
　our basic approach is to set local thresholds at each remote site such that the current count is bounded by the local threshold. when a local threshold in a remote site is violated  the remote site will communicate this to the coordinator and sets a new threshold. the ith remote site maintains local thresholds  ti j j = 1 ...  and ensures that ti f i  ＋ nv i   ti f i +1 for some threshold f i  that is known to the coordinator. if the ith remote site's count violates this condition  it sends an update to the coordinator with a new  and  such that  for the current value of nv i. the coordinator can use the set of ti f i s to estimate any global count as.
　note that while the count at a remote site obeys the ti f i  ＋ nv i   ti f i +1 bounds  the remote site does not send any updates until the count is outside these bounds. until the coordinator receives the next threshold update the actual count can lie anywhere between the two threshold values. hence  the maximum error contributed to the global count error by remote site i is given by ti f i +1   ti f i . an algorithm that tracks counts must ensure that the error is within the δ-deficient requirement when the count is greater than the specified threshold. formally  we must ensure that 1   i（{1...m} ti f i +1   ti f i    δnv when nv   t. thus  adjacent thresholds need to be chosen to be close enough to satisfy this requirement. the total number of updates sent from remote sites to the coordinator corresponds to the number of threshold boundaries crossed at the remote sites. this means we want to set the local thresholds as far apart as possible to minimize the communication overhead.
　algorithms that track the δ-deficient thresholded count of an item need to balance the error requirement with minimal communication overhead. we consider two fundamental categories for setting threshold: static thresholding  and adaptive thresholding. in static thresholding methods  each remote site is assigned a predetermined set of thresholds that do not change over the entire course of tracking the count. it simply tracks between which pair of thresholds its count currently lies  and informs the coordinator when this changes. in the adaptive case  when old thresholds are violated  new thresholds at the remote sites are chosen by the central site according to the observed conditions  to dynamically reduce the communication overhead.
　while the adaptive thresholding methods can be expected to perform better than the static methods  the static methods are desirable when the capabilities of the remote sites and the coordinator are limited. the adaptive thresholding places additional processing overhead and additional functional requirements on the remote sites and the coordinator. the coordinator needs to recompute new thresholds and export them to the remote sites  in addition to processing updates from the remote sites to maintain the count. in certain cases  like sensor networks or high speed routers  this additional processing overhead may be too expensive to accommodate. a further practical issue with using adaptive thresholding is that the system has to be more resilient to network delays. specifically  the coordinator may need to collect current values from sites  and send out many new thresholds  which incurs appreciable delay where the current counts may be outdated. the static thresholding scheme does not have this problem because the communication is performed from the remote site to the coordinator only. thus the choice of adaptive or static thresholds will depend not only on their relative cost  which we analyze in detail in subsequent sections   but also on the underlying network properties and performance.
1.	static thresholds
　we now describe the static thresholding scheme to maintain the δ-deficient thresholded counts. in these schemes  the threshold values in the remote sites are predetermined and do not change over the period of tracking. we present three such threshold assignment regimes to determine the local threshold values at the remote sites and discuss their complexity in terms of communication overhead. in this work we consider all the remote sites to be symmetric and hence use the same set of static threshold values. our focus is on determining the local threshold values in the remote sites for a given value of δ and t. the static threshold assignment problem can be formally stated as:
　definition 1. given m remote sites  a global threshold t  an error guarantee δ  and f i   the current threshold level at site i   determine threshold values  tj j =  1 ±   such that the following constraints are satisfied
   j1 : tj+1   tj  and t1 = 1
	m	m
  when
　the first constraint ensures that the threshold values are increasing. the second constraint captures the error requirement of the thresholded count problem. the maximum error in the ith remote site when f i  is the threshold in force at site i is tf i +1   tf i . thus  the second constraint states that the total error in the count at the coordinator must satisfy the thresholded error guarantee for all possible threshold values at the remote sites.
1	uniform threshold assignment
　the simplest solution is to keep the maximum global error level at δt at all times even when the global count  n  is much greater than t. this can be accomplished by setting the threshold levels in each monitor as tj = jδtm . when n − t  we have the total error  thus satisfying the δdeficient thresholded count constraints. if the global count is n  the maximum number of updates sent to the coordinator is given by . this simplicity comes at a price. the method works well for counts that are small  below t or only above t by a small amount   since the threshold gaps are relatively large. but as n increases above t  the cost scales linearly with n  as the overly tight error guarantee is maintained. in summary 
　lemma 1. the total number of messages from all remote sites	thus  the total error in the global count is given by to the coordinator with uniform threshold assignments is o mnδt  .
1	proportional threshold assignment
a more scalable solution is to assign threshold values propor-tional to the local count at the remote site. the thresholds at the remote sites are assigned as tj =  1 + δ tj 1 and t1 = 1 t1 = 1. if the threshold value reported by site i to the coordinator is tf i   the maximum possible error from the site is tf i +1   tf i  = δtf i .
the maximum error at the coordinator is:　lemma 1. the total number of messages from all remote sites to the coordinator with blended threshold assignments and 1   α   1 is o αδm log 1 + α nt   1   
　proof. the threshold values using the blended assignment for α  1  can be written as		（	
where n is the global count. this assignment satisfies the error requirement even when the global count is less than the thresholdthus  the number of updates from remote site i when the threshold value exceeded is f i  ist.
　lemma 1. the total number of messages from all remote sites to the coordinator with proportional threshold assignments is.　proof. if tf i  ＋ ni   tf i +1  the number of updates from remote site i is given by f i . since tf i  =  1 + δ f i  1 we get

the total number of messages is bounded by

　we use the fact that    and is maximized when . since for δ   1  log 1 + δ  = o 1δ   the stated bound follows. 
　this method of assignment performs well when. the relative cost of the uniform assignment to the proportional assignment is o m/δ log n/m  /o nm/ δt   = o t/n log n/m  . when t is greater than n  the uniform spread assignment performs better  but as n increases above t  the proportional assignment requires fewer communications.
1	blended threshold assignment
　the main idea of blended threshold assignment is to exploit the best features of the previous two assignments and provide a mechanism to tune the performance for different values of n.
　definition 1. the blended assignment sets the local threshold values as
　　　　　　　　　　　　　　  for a parameter 1 ＋ α ＋ 1   t1 = 1  and when α = 1  t1 = 1
　note that α = 1 corresponds to the uniform assignment while α = 1 corresponds to the proportional assignment. varying the value of α helps in tuning the threshold values to combine uniform and proportional thresholds.
　theorem 1. the blended threshold assignment satisfies the δdeficient thresholded error guarantee for all values of α （  1 .
　proof. using the blended threshold assignment  the maximum error in the ith remote site is

 since tf i  ＋ ni
 where
　note that given mi=1 hi = nmt  m  the expression is maximized when  i : hi = h = nt   1. the total number of
updates from all remote sites is
 1 
=1
		 1 
upper bounding this expression gives the stated worst case bound.	
determining the optimum value of α. for small values of n   t  α = 1 gives us the best possible assignment and for large values of  α = 1 gives us the best assignment. for intermediate values of n  the best value of α can be determined by minimizing the number of updates.
　note that the communication cost in lemma 1 is dependent on the global count  n. hence  the optimal value of α depends on n. we advocate two approaches to determining the best value of α. the first approach is to track the global count and determine an expected value of n  ne after a long period of observation  and use this value to determine the optimal value of α. this can be expected to result in good performance if the actual value of n does not vary a lot from the estimate ne. a more sophisticated approach is to track the distribution of n over a large set of observations and determine the value of α that minimizes the expected number of update messages over this distribution.
theorem 1. the total number of updates  from eqn 1   kn =
 is a convex function in α in the range
α （  1  for small values of δ.
the proof of this theorem is presented in appendix a.
　theorem 1. given an expected value of n or a discrete probability distribution of n  we can find a value of α that minimizes the number of messages with blended threshold assignments.
　proof. first  observe that if p n  is the probability density function of n  then the expected maximum number of updates given by is a convex function in α in the range α （  1 . since k is a convex combination of convex functions kn  k is itself convex.
　since k and kn are convex functions in α in the range  1   there exists a single minimum for k and kn that can be searched by using techniques like gradient descent. the descent algorithm can be used to determine the optimal values of α for both the proposed approaches. in the first approach where we are given the expected value ne  we determine the optimal value of α by minimizing kne. in the second approach where we are given the distribution of n  we can use the descent method to determine the optimal value of α by minimizing the function k as defined above. 
1.	adaptive thresholds
　unlike the static thresholding scheme  in the adaptive thresholding scheme the thresholds in the monitoring nodes are adaptively set by the coordinator every time there is a threshold violation in a node. in other words  the coordinator not only receives the threshold violations from the monitoring nodes  but also reacts to them by sending new thresholds back. this gives the coordinator more power to set thresholds based on more information about how the distributions at each site are evolving  and hence try to reduce the number of threshold violations. in a general scenario  the coordinator may wait for multiple violations before resetting thresholds  and may reset thresholds for arbitrary subsets of the nodes based on a complete history of past violations. in this work  we react to each threshold violation  and consider only recent history.
1	adaptive threshold assignment problem
　in the adaptive thresholding scheme  two levels of thresholds  lower and higher thresholds  are maintained at every node at all times. the lower threshold at node i is denoted by til  and the higher threshold by tih  so that at all times til ＋ ni   tih. if these thresholds are violated  i.e. if this condition is no longer true  then the site i contacts the coordinator site with its current count ni  and it resets its lower threshold til = ni. the coordinator estimates the count as the sum of the reported counts from the remote sites  . the coordinator then updates the tih for node i  and possibly those of other nodes  to ensure that its count still meets the δ-deficient requirement. to minimize the communication in the system  the coordinator needs to set the upper thresholds to as high a value as possible. note that the maximum error contributed by site i is tih   til.
　the problem of setting the upper thresholds of the remote sites by the coordinator can be formally stated as follows.
　definition 1. given m remote monitoring nodes  a global threshold t  an error guarantee δ  and a threshold violation from node j  our objective is to determine the higher threshold values  tih  in all m monitoring nodes such that the number of messages in the monitoring system is kept as low as possible  and the following constraints are satisfied:
	  when	
　similar to the static thresholding scheme  the first constraint ensures that the higher thresholds are greater than the lower thresholds in all the nodes and the second constraint ensures that the total error in the count at the coordinator must satisfy the thresholded error guarantee.
basicadapt δ t m 
1: til ○ 1; tih ○ mt ; n  ○ 1
1: loop {receive update  i ni ; }
1:	then
1:	poll all sites	;
1:	;
1:	if  n   	 1   δ t  then
1:	for all;
1:	else
1:	send tih ○ til 1 + δ  to i

figure 1: basic adaptive thresholding algorithm
　in the static threshold method  the remote sites do not know if the current global count is greater than t or lesser at any time. hence  the thresholds need to be set to handle both these cases. a key advantage of the adaptive algorithm is that when the global count is less than the threshold  the coordinator can afford to set higher thresholds at the remote sites than in the static algorithm. to illustrate this  define the slack in the system as the difference between the threshold and the current estimate of the global count  s = t   n . the coordinator can now split this slack among the remote sites in any manner and still be able to satisfy the δdeficient error requirement. assume that the slack is split among the remote sites as ηi i = 1 ... m  such that .
thus  tih = til + ηi. if the counts at all the remote sites are less than their respective upper thresholds  then the global count must be lesser than the global threshold because.
if at any point the global count exceeds the threshold  at least one of the thresholds in the remote sites will be exceeded. this allows the coordinator to determine when the count exceeds the threshold and switch to the case when n − t and track the count closely to satisfy the δ-deficient error requirement.
1	basic adaptive algorithm
　when the total count estimated at the central site  n   is less than t  a naive approach is to split the slack equally among all the nodes; instead  we propose to split the difference proportional to the current count in the nodes  since nodes that have larger counts than others are likely to grow larger. we set the new tih = til +
.
　if n  −  1 δ t  we set tih  til = δtil  so that the maximum error in each node is δtil. this approach is similar to the proportional spread threshold assignment algorithm for static thresholding problem presented in section 1. the adaptive thresholding algorithm is presented in figure 1. line 1 performs the proportional split when the counts are small  and line 1 performs the proportional growth when the counts are large. lines 1 and 1 handle the case when we switch from having n     1 δ t to n  −  1 δ t.
　lemma 1. the adaptive thresholding assignment algorithm presented in figure 1 satisfies the δ-deficient thresholded count constraints.
	n 	  we have that n =
m
  so we know that the
total count is less than the threshold t. when n  −  1   δ t  we know that the total count exceeds  1   δ t and the algorithm is similar to the proportional spread threshold assignment algorithm for the static thresholding scheme. in this case  tih   til = δtil and so   as required. 
modifiedadapt δ t m 
1: til ○ 1; tih ○ mt ; r ○  ; n  = 1;
1: loop {receive update  i ni ; }
1:	if	then
1:	poll all sites	;
1:	if  r =    then
1:	for j = 1 to m do
1:	poll site j for nj; tjl ○ nj; sj ○ max{tjl  δtm };
1:	if nj   δtm then send tjh ○ δtm to j
1:	til ○ ni; n  ○	j tjl; si ○ til; r ○ r “{i};
1:	if
1:;
1:	for all j （ e do
1:	if then send	;
1:	else send
1:	else send tih ○  1 + δ til to i;

figure 1: modified adaptive thresholding algorithm
　although this algorithm is simple and intuitive  it has some drawbacks: the first time there is a threshold violation from some remote site i  the tih value at the node is set to t while the value at all other nodes will be set to 1  since nj = 1 at the coordinator site initially. this could unnecessarily trigger a lot of communications especially when several nodes have non-zero counts. secondly  when the estimated aggregate count at the central node is close to t the new threshold will be very close to the old threshold  thus triggering a lot of threshold violations. in the following section we present a modified algorithm that addresses the above shortcomings.
1	modified adaptive algorithm
　in order to avoid the problems in the original algorithm for adaptive thresholds we modify the original algorithm  which is illustrated in figure 1. there are two main differences between the original and modified algorithms:  a  as soon as the central node receives the first threshold violation the tih values in all the nodes whose counts ni are below are initialized to δtm   and  b  when the difference between global threshold and the estimated aggregate count is small  i.e.  below    instead of using the adaptive strategy of distributing the difference to all the nodes  we maintain a constant difference between the upper and lower thresholds  i.e. 
. in our algorithm in figure 1  we maintain a set r of nodes whose count exceeds . lines 1 deal with the first threshold violation  by polling all nodes to initialize s  and setting upper bounds for the nodes not in r. if the total count is sufficiently below t  lines 1 allocate the slack in proportion to the counts; however  we ensure that the difference between higher and lower thresholds is at least  using extra variables si  to ensure that the total amount of slack allocated stays within the permitted bounds. lines 1 deal with the case when the count first exceeds t  and from that point on  we switch to proportionally increasing counts  line 1  as before.
　lemma 1. the modified adaptive thresholding assignment algorithm presented in figure 1 satisfies the δ-deficient thresholded count constraints.
　proof. consider the case when n     1   δ t. if a remote site i does not belong to. in line 1  the rest of the available slack  t   s  is proportionally divided to the rest of the sites （ r. tmin denotes the minimum of the slack values. if tmin   δtm   then all sites （ r are allocated a slack of in line 1 of the algorithm. hence.
if   then the slacks are proportionally allocated to the sites. hence n   i=1 tih = t  because the algorithm allocates the slack in the system to the sites. thus  if n     1   δ t  n   t. when n  −  1   δ t  the total count exceeds  1   δ t and the algorithm follows the proportional spread threshold assignment in the static scheme  and the proof is the same as the previous lemma. thus  the modified algorithm satisfies the δ-deficient error constraints. 
   theorem 1. the total number of messages from all remote sites to the coordinator using the modified adaptive algorithm is  when when n ＋ t.
　proof. we split our analysis into two parts  first when the total count is less than t  and the second when it exceeds t. in the first part  the algorithm ensures that the  slack  in each threshold  i.e. tih   til is always at least . thus  there can be at most  threshold violations before the count reaches t  simplifying to when n first exceeds t. each threshold violation causes at most o m  messages to be sent  to inform the sites of their new high thresholds tih. when the count is above t  the algorithm mimics the proportional threshold assignment case in section 1  and adapting lemma 1  the number of messages between remotes sites and the central site to go from. the result follows by summing these two bounds. 
　note that one can easily force Ω m1+mδ log nm t   messages by first making one site have count   then setting counts  to set up the adaptive thresholds . then for each of the same 1 sites in turn  set their local count to ni = mt : each of these settings causes θ m  messages  over sites gives the Ω m1  bound. using the remaining sites  currently with zero local count each   one can then elicit the cost from the proportional threshold settings. however  in general  we expect to do much better than this worst case bound  since the analysis is somewhat pessimistic.
1.	extensions
negative updates. thus far we have assumed that all updates received at remote sites are non-negative. however  a simple observation is that our static protocols remain correct when negative updates are permitted. instead of checking for thresholds being exceeded  we must check that the upper threshold remains an upper bound  and also that the lower threshold remains a lower bound. similarly  our adaptive protocols can also handle negative updates with minor modifications. the analysis in previous sections that relates the cost of the protocol to the value of the global count no longer applies: positive and negative updates can cause a lot of communication but leave the global count quite low  thus the communication bound cannot still hold. indeed  if the updates cause counts to repeatedly cross the same threshold boundaries  in the static case   then the best bound we can state is one that is linear in the number of updates. in the adaptive case  this adverse outcome can be avoided.
sliding windows. being able to handle negative updates means that we can apply our methods to other models of computing counts. typically  we do not want to monitor counts which increase indefinitely. indeed  in several of the queries outlined in the introduction  time windows were implicitly given in the form of  within an hour  or  in a day . there are several models for dealing with such timewindowed queries:  a  periodic reset. after the time period has elapsed  reset all counts to zero  and restart the protocol.  b  sliding window. ensure that the current count covers exactly the last hour  for example  by keeping track of past updates  and applying updates older than one hour as negative updates. in the case that there is insufficient storage to retain this many updates  then approximate information can be kept  as explained below.  c  overlapping window. a compromise between periodic reset and sliding window is to apply the overlapping window approach: for example  the window consists of one hour's data  and the start of the window is advanced by five minute intervals every five minutes  so the window contains between 1 hour and 1 hour and five minutes of updates . now we just have to record the sum of updates in each five minutes and apply these as a single negative update when the start of the window is advanced.
approximate counts. so far we have assumed that there is sufficient storage capacity at the remote nodes to store all local count values. but in the case when there are very many updates of different values  for example  tracking network activity   we cannot make this assumption. we may use the same  static  thresholds and δ value for all counts to reduce space usage  but still there may be too many counts to store. the natural solution is to adopt an approximate way of storing the counts  such as lossy counting  or count-min sketch . however  using such approximate structures mean that the guarantees that we can give are much weaker: instead of the δ-deficient guarantee  we must now give a guarantee relative to  since the approximate counting methods return counts of each item with error. although we can reduce   at the cost of more space   in general it is not possible to set a non-zero value of  that gives a δ-deficient guarantee. hence  the result appear more in line with those that follow for heavy-hitter style problems .
time-dependent thresholds. prior work has built models of how data varies with time in order to reduce the communication cost further  1  1 . we could apply a similar approach to our methods: the result is time-dependent local thresholds. now we would set our thresholds so that they can increase or decrease as time passes  so that we ensure that the total uncertainty still remains within the same bounds. the idea is that the varying thresholds predict where the true count will lie at time t; if this prediction is correct  then no communication cost is incurred. if any  now time dependent  local threshold is broken  then communication is triggered with the coordinator  and the model can be recalibrated with the recent history. we hope to investigate such extensions in future work.
1.	experimental study
　in this section we present the experimental evaluation of our static and adaptive algorithms. we also compare the performance of these algorithms with a technique proposed by olston et al in   referred to as the ojw algorithm in the rest of this work  where the authors try to minimize communication overhead while maintaining a certain accuracy for continuous queries over a distributed data stream.
　we begin by presenting our experimental setup in section 1. we then experimentally show that our algorithms always satisfy the problem requirements. we also validate our blended approach for static thresholds by comparing the theoretical results from the model with the results from our experiments. then we present some observations that provide more insights about the usefulness of our algorithms.
1	experimental setup
　to gain a better understanding of our theoretical analysis  we built a simulator with m monitoring nodes and one central node.
data sets. although the definition of thresholded counts problem is applicable in a variety of different scenarios  as pointed out in section 1   our focus in the experiments is on a distributed network monitoring system. in this scenario  every node monitors traffic on a link for all the registered events and increments the count for all the events that are observed. we define an event as the occurrence of a combination of destination ip address and the destination port number in a packet seen by a monitoring node.
　we use publicly available link traces from nlanr  as input to our distributed monitoring system. these traces are for a single ingress link  and we transform this data for our distributed system by assigning a probability distribution for distributing packets randomly to the various monitors. by using different probability distributions  we can simulate various scenarios that can occur in real networks. for example  a skewed probability distribution function represents a scenario where a few nodes  that are monitoring large inter-domain  peering  links  receive large number of events while others do not. similarly  a uniform distribution represents a scenario where events are equally likely to occur in any of the monitoring nodes. although we track all the events that occur in the link traces from nlanr  for the ease of illustration  we present the results for tracking one event whose overall count was 1.
implementation issues. we implemented the static and adaptive algorithms described earlier in sections 1 and 1. since the ojw algorithm was not proposed to address the thresholded counts problem  we need to set certain parameters of the algorithm in  to apply it to our problem. the main issues are:   the ojw algorithm assumes that a single node can monitor all the updates for a given object/event and a single query can include multiple objects. since we are interested in tracking the same objects/events in multiple monitors  we treat each item in each site as a separate object/event that is the subject of a single query.
  in the thresholded counts problem definition  the error values are relative  i.e.  the maximum error allowed for an event in the system depends on its current count. the original ojw algorithm uses absolute errors  i.e.  the total error in the system is required to be below a certain constant value   so to apply to our problem  we set the maximum allowed error for each count to be fixed at δt  divided evenly between all sites where it can occur.
　these parameter settings of the ojw algorithm are our best effort to make the algorithm apply to our δ-deficient thresholded count problem. they ensure that the algorithm generates results that are correct according to our problem definition  and the algorithm falls into our class of adaptive algorithms ; however  we will see that the cost is much higher than our algorithms that were designed for this problem.
1	performance accuracy
count accuracy. in figure 1 a  we examine the total error in the distributed monitoring system as packets arrive at various monitoring nodes while using the blended static threshold assignment. we set the values of t  δ  and m to be 1  1%  and 1 respectively. when the count of the event is less than t the error in the system can be as high as 1%  but after the count exceeds the value of t the error is always less than the value specified by δ  indicated by

	1.1	1	1.1				
1
	# of packets seen by the distributed monitoring system 	x 1	 
	 a  n vs error percentage in the static case	 b  n vs error percentage in the adaptive case
figure 1: testing accuracy for static and adaptive casesfigure 1: comparing the optimal theoretical values of α with the results obtained from simulation. the x-axis represents different combinations of t  δ  and n. each combination is referred to as a  parameter setting  and represents a point on the x-axis.
the heavy line on the figure . different parameter settings yielded similar results.
　the results for the same experiment performed with the adaptive algorithms  but varying values of t  are shown in figure 1 b . the distinctive shape of the curve for the modified adaptive algorithm is explained by the different parts of the algorithm: the initial high error is due to allocating in the initial phase of the algorithm. the error drops to zero when the central node polls all the monitoring nodes and hence has accurate count information. the error gradually increases when nodes are allocated adaptive thresholds  which allows the total error to grow  within the allowed bounds   until the count reaches  1   δ t. finally  the algorithm switches to proportionally growing thresholds  which keep the fractional error within the necessary bounds. thus we observe that the total error in the system is less than the value specified by δ after the total count exceeds t. meanwhile  the basic adaptive algorithm has consistently higher error for n   t  but also higher communication cost.
setting α for the static algorithm. to validate our theoretical results  we compare the optimal value of α obtained from our theoretical model using a gradient descent approach to the ideal value of α obtained from experiments. for this experiment  we use a uniform distribution to send a given packet from the input file to the monitoring nodes. this is because the static threshold assignment algorithms have a worst case when the packets are uniformly distributed across the remote sites. we repeat the experiment 1 times to ensure that the outcome is not biased by outliers  while generating uniform distribution   and the experimental results presented here are the average value from all the 1 runs.
　in our experiments we consider several different values for t and δ. the range of values for t was  1  and the range of values δ was  1  1 . as we showed in section 1  the total number of messages in a monitoring system using blended static thresholding approach also depends on ni  the count of the event in the monitor i. hence in our experiments we also vary the overall count of the event that we track in the range  1  1 . for each combination of values for t  δ  and n  referred to as a parameter setting   we vary the value of α from 1 to 1 with increments of 1. for every parameter setting we compute the value of α that resulted in the minimum number of communications  both using simulations and the theoretical model.
　the comparison of the ideal values of α from the simulations and theoretical model is shown in the top of figure 1. although the theoretical results closely match the experimental values in most of the cases  there are a few cases where the difference between the two is significant. however  these have minimal impact on the overall cost  as shown in the lower half of the figure. the discrepancies are mainly due to the fact that we use integer values in our simulator while our theoretical model ignores this condition and considers thresholds to be real values. the difference between the experimental and theoretical results are significant only when the values of both t and δ are small  i.e.  when the system requires high accuracy . we see that in most cases  the cost using the theoretically predicted alpha is as good as or better than the value found by simulations  and in only a few cases is there a slight benefit for the empirically found value.
1.1.1.1.1	1	1	1 α	t	x 1
	 a  communication cost as α varies in static case	 b  communication case of the adaptive algorithms
figure 1: communication cost of static and adaptive algorithms
α
figure 1: variation in communication cost with varying α in the static model over 1 repetitions with random incoming packet distribution.
1	communication cost
uniformly distributed events. figure 1 a  examines the impact of α on the number of messages exchanged in a monitoring system using static thresholds. the total count  n  of the event that is tracked is 1. for a small value of t  i.e.  a high value of the ratio    as the value of α increases  the number of messages exchanged in the system decreases. in other words  the optimal value of α is close to 1. for a larger value of t  i.e.  a small value of nt    the optimal value of α is closer to 1. in essence  as the ratio  decreases  the optimal value of α moves towards 1. however  there is a broad range of settings of α which achieve similarly low costs  showing that an approximate value of α will often suffice. lastly  in line with expectations  decreasing δ increases total cost.
　in figure 1 b  we compare the performance of the basic adaptive  modified adaptive  and the ojw algorithms. the top graph in the figure compares the total number of messages exchanged in the system  from the monitors to the central node and vice versa  using

figure 1: comparing cost of adaptive and static threshold settings. each combination of t  δ  and ni is referred to as a  parameter setting  and represents a single point on the x-axis.
basic adaptive and modified adaptive algorithms. the modified algorithm outperformed the basic algorithm by an appreciable factor in all our experiments. the bottom graph in the figure compares the performance of ojw algorithm with modified adaptive algorithm. note that the y-axis in this graph is in log scale. the graph shows that the modified algorithm performs at least two orders of magnitude better than the ojw algorithm confirming that the existing techniques are insufficient for this problem.
	$oskdydoxh	t
 a  number of messages vs. α for static thresholds using one  b  number of messages vs. t for adaptive thresholds using one hour's data from a live network. hour's data from a live network.
figure 1: experiments on real network datarandomly distributed events. previous results were based on selecting which node to update uniformly. in figure 1 we explore the effect of using random distributions to update different nodes. random distributions are created by generating random probabilities associated with each of the monitoring nodes. these probabilities are used to send the updates from the input trace to the monitoring nodes. note that a different random distribution is generated for every simulation run. we repeat the simulation 1 times to ensure that we capture a variety of different random distributions. in figure 1 we plot the average number of messages exchanged due to these random distributions. the error bars in the figure represent the range of values for the number of messages generated by the 1 runs of the simulator. we can see that the effect of using random distributions is relatively small. as before  the optimal value of α that results in the minimum number of messages in the system decreases as the ratio decreases. note that the total number of messages in the best case  1  is approximately 1% of the total number of updates. hence we observe a thousand-fold reduction in cost compared to the cost of sending every update to the central site.
comparing costs of static and adaptive algorithms. figure 1 compares the blended static thresholding algorithm and the modified adaptive algorithm in terms of the number of messages in the monitoring system for different parameter settings. for both the algorithms  we vary the values of t  δ  and n in the range  1    1  1   and  1  1  respectively. in the static algorithm  we used the empirically determined optimal value of α for the given parameter setting. we can see that the performance of the adaptive algorithm is always slightly better than the static algorithm. however  which method is best will depend on the scenario in which they are being applied: every message in the static algorithm is only a few bytes long  to indicate the current threshold being used by the site   while the messages are longer in adaptive algorithms since the central site must give more information  the type of message  the new threshold being sent  etc. . in power constrained sensor networks  the energy consumption of the adaptive algorithms may therefore be higher  whereas in more traditional wired networks  the size of message headers will make the difference in size of the messages insignificant.
experiments on real network data. the results from our experiments presented until now tracked a single event. in order to explore a more realistic and practical scenario  we obtained complete network packet traces from a research network. the network consists of several routers and we obtained anonymized traces of all the packets that entered the network at each of the routers for one hour on aug 1  1 our network monitoring system architecture consisted of monitoring nodes  one collocated with every router in the network. we used the traces from the collocated router as the input to the monitoring node. the monitoring nodes tracked all the incoming events for one hour  approximately 1 million in total.
　figure 1 a  shows the number of messages required by the static monitoring system to track all the events with δ-accuracy. we can see that when the value of t is small  a high value of α results in minimum communication overhead  and at higher values of t  the best value of α reduces. figure 1 b  shows the number of messages in the monitoring system using adaptive thresholds. comparing figures 1 a  and 1 b  we can see that  at large values of t  the adaptive algorithm performs significantly better than the static algorithm. since figure 1 b  is plotted on a log-log scale  it shows an approximately linear relation between the logarithm of the number of messages and logt  implying an inverse polynomial dependency on t. this agrees with our analysis of the adaptive algorithm  suggesting that the bulk of the cost is due to items whose count nv   t: for these items  the number of messages is proportional to nδtv   which agrees with the observed behavior.
1.	conclusions and future work
　we have given a number of algorithms to efficiently monitor distributed sets of counts in a continuous fashion  a fundamental problem at the heart of many network and sensor monitoring problems. in our experimental evaluation  we observed that our adaptive algorithms typically outperform those based on maintaining static thresholds. however  the adaptive algorithms may be more expensive in terms of resources required to run and computational power of the participants.
　several problems remain open to study in future work: firstly  to compare the cost of deploying the these algorithms in real network scenarios such as a particular sensor network environment or ip network monitoring setting  so far we have focused on the pervasive cost issues rather than considering any particular situation . in these situations  we can consider other network topologies  such as more hierarchical approaches to avoid overwhelming the central coordinator. it will be of interest to extend our approach to other query types with a similar thresholded nature  such as arithmetic combinations of thresholds   report x + y when x + y   t  or  report x   y when x   y   t   or apply across sites   report the number of sites observing event e when e is observed by more than n sites  .
