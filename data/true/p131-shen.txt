web query classification  qc  aims to classify web users' queries  which are often short and ambiguous  into a set of target categories. qc has many applications including page ranking in web search  targeted advertisement in response to queries  and personalization. in this paper  we present a novel approach for qc that outperforms the winning solution of the acm kddcup 1 competition  whose objective is to classify 1 real user queries. in our approach  we first build a bridging classifier on an intermediate taxonomy in an offline mode. this classifier is then used in an online mode to map user queries to the target categories via the above intermediate taxonomy. a major innovation is that by leveraging the similarity distribution over the intermediate taxonomy  we do not need to retrain a new classifier for each new set of target categories  and therefore the bridging classifier needs to be trained only once. in addition  we introduce category selection as a new method for narrowing down the scope of the intermediate taxonomy based on which we classify the queries. category selection can improve both efficiency and effectiveness of the online classification. by combining our algorithm with the winning solution of kddcup 1  we made an improvement by 1% and 1% in terms of precision and f1 respectively compared with the best results of kddcup 1.
categories and subject descriptors
h.1.m  information storage and retrieval : miscellaneous; i.1  pattern recognition : design methodology-classifier design and evaluation
general terms
algorithms  experimentation
keywords
web query classification  bridging classifier  category selection  kddcup 1
permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. to copy otherwise  to republish  to post on servers or to redistribute to lists  requires prior specific permission and/or a fee.
sigir'1  august 1  1  seattle  washington  usa.
copyright 1 acm 1-1/1 ...$1.
1. introduction
　with exponentially increasing information becoming available on the internet  web search has become an indispensable tool for web users to gain desired information. typically  web users submit a short web query consisting of a few words to search engines. because these queries are short and ambiguous  how to interpret the queries in terms of a set of target categories has become a major research issue. in this paper  we call the problem of generating a ranked list of target categories from user queries the query classification problem  or qc for short.
　the importance of qc is underscored by many services provided by web search. a direct application is to provide better search result pages for users with interests of different categories. for example  the users issuing a web query  apple  might expect to see web pages related to the fruit apple  or they may prefer to see products or news related to the computer company. online advertisement services can rely on the qc results to promote different products more accurately. search result pages can be grouped according to the categories predicted by a qc algorithm. however  the computation of qc is non-trivial  since the queries are usually short in length  ambiguous and noisy  e.g.  wrong spelling . direct matching between queries and target categories often produces no result. in addition  the target categories can often change  depending on the new web contents as the web evolves  and as the intended services change as well.
　kddcup 1   http://www.acm.org/sigkdd/kddcup   highlighted the interests in qc  where 1 real web queries are to be classified into 1 target categories. each query can belong to more than one target category. for this task  there is no training data provided. as an example of a qc task  given the query  apple   it should be classified into  computers hardware; living food&cooking .
　the winning solution in the kddcup 1 competition  which won on all three evaluation metrics  precision  f1 and creativity   relied on an innovative method to map queries to target categories. by this method  an input query is first mapped to an intermediate category  and then a second mapping is applied to map the query from the intermediate category to the target category. however  we note that this method suffers from two potential problems. first  the classifier for the second mapping function needs to be trained whenever the target category structure changes. since in real applications  the target categories can change depending on the needs of the service providers  as well as the distribution of the web contents  this solution is not flexible enough. what would be better is to train the classifiers once and then use them in future qc tasks  even when the target categories are different. second  the winners used the open directory project  odp  taxonomy as the intermediate taxonomy. since the odp contains more than 1 different categories  it is costly to handle all mapping functions. it is better to select a portion of the most relevant parts of the intermediate categories.
　in this paper  we introduce a novel qc algorithm that solves the above two problems. in particular  we first build a bridging classifier on an intermediate taxonomy in an offline mode. this classifier is then used in online mode to map users' queries to the target categories via the above intermediate taxonomy. therefore  we do not have to build the classifier each time the target categories change. in addition  we propose a category-selection method to select the categories in the intermediate taxonomy so that the effectiveness and efficiency of the online classification can be improved.
　the kddcup 1 winning solution included two kinds of base classifiers and two ensemble classifiers of them. by comparing our new method with any base classifier in the winner's solution for the kddcup 1 competition  we found that our new method can improve the performance by more than 1% and 1% in terms of precision and f1 respectively  while our method does not require the extra resource such as wordnet . the proposed method can even achieve a similar performance to the winner's ensemble classifiers that achieved the best performance in the kddcup 1 competition. furthermore  by combining the our method with the base classifiers in the winner's solution  we can improve the classification results by 1% in terms of precision and 1% in terms of f1 as compared to the winner's results.
　this rest of the paper is organized as follows. we define the query classification problem in section 1. section 1 presents the methods of enriching queries and target categories. in section 1  we briefly introduce the previous methods and put forward a new method. in section 1  we compare the approaches empirically on the tasks of kddcup 1 competition. we list some related works in section 1. section 1 gives the conclusion of the paper and some possible future research issues.
1. problem definition
　the query classification problem is not as well-formed as other classification problems such as text classification. the difficulties include short and ambiguous queries and the lack of training data. in this section  inspired by kddcup 1  we give a stringent definition of the qc problem.
query classification:
* the aim of query classification is to classify a userquery qi into a ranked list of n categories ci1  ci1  ...  cin  among a set of n categories {c1  c1  ...  cn}. among the output  ci1 is ranked higher than ci1  and ci1 is higher than ci1  and so on.
* the queries are collected from real search engines sub-mitted by web users. the meaning and intension of the queries are subjective.
* the target categories are a tree with each node rep-resenting a category. the semantic meaning of each category is defined by the labels along the path from the root to the corresponding node.
　in addition  the training data must be found online because  in general  labeled training data for query classification are very difficult to obtain.
　figure 1 illustrates the target taxonomy of the kddcup 1 competition. because there are no data provided to define the content and the semantics of a category  as in conventional classification problems  a new solution needs be found. as mentioned above  an added difficulty is that the target taxonomy may change frequently. the queries in this problem are from the msn search engine  http://search.msn.com . several examples of the queries are shown in table 1. since a query usually contains very few words  the sparseness of queries becomes a serious problem as compared to other text classification problems.
table 1: examples of queries.
1 shelby mustangactress hildegardea & r management  property management marylandnetconfig.exe
figure 1: an example of the target taxonomy.
1. queryandcategoryenrichment
　in this section  we discuss the approaches for enriching queries and categories  which are critical for the query classification task.
1 enrichment through search engines
　since queries and categories usually contain only a few words in the qc problem  we need to expand them to obtain richer representations. one straightforward method is to submit them to search engines to get the related pages  for categories  we can take their labels as the queries and submit them to search engines  such as  computers hardware  in figure 1 . the returned web pages from search engines provide the context of the queries and the target categories  which can help determine the meanings/semantics of the queries and categories.
　given the search results for a query or category  we need to decide what features should be extracted from the pages to construct the representation. three kinds of features are considered in this paper: the title of a page  the snippet generated by the search engines  and the full plain text of a page. the snippet is in fact a short query-based summary of a web page in which the query words occur frequently. the full plain text is all the text in a page with the html tags removed. since the title of a page is usually very short  1 words on average for our data set   we combine it with other kinds of features together. these features are studied in our experiments.
　besides the above textual features  we can also obtain the category information of a web page through the directory information from search engines. for example  google's  directory search  can provide the labels of the returned web pages. such labels will be leveraged to classify a query  as stated in section 1.
1 word matching between categories
　the query classification problem can be converted to a traditional text classification problem by finding some training data online for each category in the target taxonomy. our method of collecting the training data is by finding documents in certain intermediate taxonomies that are found online. to do so  we need to construct mapping functions between the intermediate categories and the target categories. given a certain category in an intermediate taxonomy  we say that it is directly mapped to a target category if and only if the following condition is satisfied: one or more terms in each node along the path in the target category appear along the path corresponding to the matched intermediate category. for example  the intermediate category  computers hardware  storage  is directly mapped to the target category  computers hardware  since the words  computers  and  hardware  both appear along the path computers ★ hardware ★ storage as shown in figure 1. we call this matching method direct matching.
　after constructing the above mapping functions by exact word matching  we may still miss a large number of mappings. to obtain a more complete mapping function  we expand the words in the labels of the target taxonomy through a thesaurus such as the wordnet . for example  the keyword  hardware  is extended to  hardware & devices & equipments . then an intermediate category such as  computers devices  can now be mapped to  computers hardware . this matching method is called extended matching in this paper.

	 1  intermediate taxonomy	 1  target taxonomy
figure 1: illustration of the matching between taxonomies.
1. classification approaches
　in this section  we first describe the state-of-the-art query classification methods. then we describe our new bridging classifier to address the disadvantages of the existing methods.
1 classification by exact matching
　as described in section 1  a query can be expanded through search engines which results in a list of related web pages together with their categories from an intermediate taxonomy. a straightforward approach to qc is to leverage the categories by exact matching. we denote the categories in the intermediate taxonomy and the target taxonomy as ci and ct respectively. for each category in ci  we can detect whether it is mapped to any category in ct according to the matching approaches given in section 1. after that  the most frequent target categories to which the returned intermediate categories have been successfully mapped are regarded as the classification result. that is:
n
c  = argmax	i ci i  is mapped to cjt 	 1  cjt	i=1
　in equation  1   i ，  is the indicator function whose value is 1 when its parameter is true and 1 otherwise.   is the category in the intermediate taxonomy for the i page returned by the search engine. n result pages are used for query classification and the parameter n is studied in our experiments.
　it is not hard to imagine that the exact matching approach tends to produce classification results with high precision but low recall. it produces high precision because this approach relies on the web pages which are associated with the manually annotated category information. it produces low recall because many search result pages have no intermediate categories. moreover  the exact matching approach cannot find all the mappings from the existing intermediate taxonomy to the target taxonomy which also results in low recall.
1 classification by svm
　to alleviate the low-recall problem of the exact matching method  some statistical classifiers can be used for qc. in the kddcup 1 winning solution  support vector machine  svm  was used as a base classifier. query classification with svm consists of the following steps: 1  construct the training data for the target categories based on mapping functions between categories  as discussed in section 1. if an intermediate category ci is mapped to a target category ct  then the web pages in ci are mapped into ct; 1  train svm classifiers for the target categories; 1  for each web query to be classified  use search engines to get its enriched features as discussed in section 1 and classify the query using the svm classifiers. the advantage of this qc method is that it can improve the recall of the classification result. for example  assume two intermediate categories 
   are semantically related with a target category. can be matched with	 through word matching but
cannot. for a query to be classified  if a search engine only returns pages of  this query cannot be classified into the target category if the exact matching classification method is used. however  if the query is classified by a statistical classifier  it can also be assigned the target category  as the classifier is trained using pages of  which may also contain terms ofbecause the two intermediate categories are similar in topic.
　although statistical classifiers can help increase the recall of the exact matching approach  they still need the exact matching for collecting the training data. what is more  if the target taxonomy changes  we need to collect the training data by exact matching and train statistical classifiers again. in the following sections  we develop a new method to solve the above problems.
1 our new method: classifiers by bridges
1.1 taxonomy-bridging algorithm
　we now describe our new qc approach called taxonomybridging classifier  or bridging classifier in short  by which we connect the target taxonomy and queries by taking an intermediate taxonomy as a bridge. the idea is illustrated in figure 1  where two vertical lines separate the space into three parts. the square in the left part denotes the queries to be classified; the tree in the right part represents the target taxonomy; the tree in the middle part is an existing intermediate taxonomy. the thickness of the dotted lines reflects the similarly relationship between two nodes. for example  we can see that the relationship between cit and cji is much stronger than that between cit and cki. given a category cit in the target taxonomy and a query to be classified qk  we can judge the similarity between them by the distributions of their relationship to the categories in the intermediate taxonomy. by defining the relationship and similarity under the probabilistic framework  the above idea can be explained by equation  1 .

figure 1: illustration of the bridging classifier.
		 1 
in equation  1   p cit|q  denotes the conditional probability of cit given q. similarly  p cit|cji  and p q|cji  denotes the probability of cit and q given cji respectively. p cji  is the prior probability of cji which can be estimated from the web pages in ci. if cit is represented by a set of words  w1 w1 ... wn  where each word wk appears nk times  p cit|cji  can be calculated through equation  1 
		 1 
where p wk|cji  stands for the probability that the word wk occurs in class cji  which can be estimated by the principle of maximal likelihood. p q|cji  can be calculated in the same way as p cit|cji .
a query q can be classified according to equation  1 :
	c  = argmaxp cit|q 	 1 
cit
　to make our bridging classifier easier to understand  we can explain it in another way by rewriting equation  1  as equation  1  
		 1 
　let us consider the numerator on the right side of the equation  1 . given a query q and cit  p cji|cit  and p cji|q  are fixed and 
p cji|cit  and p cji|q  represent the probability that cit and q belong to cji. it is easy to prove that p cit|q  tends to be larger when q and cit tends to belong to the same category in the intermediate taxonomy. the denominator p cji  reflects the size of category cji which acts as a weighting factor. it guarantees that the higher the probability that q and cit belong to the smaller sized category  where size refers to the number of nodes underneath the category in the tree  in the intermediate taxonomy  the higher the probability that q belongs to cii. such an observation agrees with our intuition  since a larger category tends to contain more subtopics while a smaller category contains fewer sub-topics. thus we can say with higher confidence that q and cii are related to the same sub-topic when they belong to the same smaller category.
1.1 category selection
　the intermediate taxonomy may contain enormous categories and some of them are irrelevant to the query classification task corresponding with the predefined target taxonomy. therefore  to reduce the computation complexity  we should perform  category selection  in a similar sense of  feature selection  in text classification . two approaches are employed in this paper to evaluate the goodness of a category in the intermediate taxonomy. after sorting the categories according to the scores calculated by the following two approaches  category selection can be fulfilled by selecting the top n categories.
total probability  tp : this method gives a score to each category in the intermediate taxonomy according to its probability of generating the categories in the target taxonomy  as shown in equation  1 .
	score cji  =	p cit|cji 	 1 
cit
mutual information  mi : mi is a criterion commonly used in statistical language modeling of word associations and other related applications . given a word t and a category c  the mutual information between t and c is defined as:
		 1 
by considering the two-way contingency table for t and c  where a is the number of times t and c co-occur  b is the number of times that t occurs without c  c is number of times c occurs without t and n is the total number of documents  then the mutual information between t and c can be estimated using:
		 1 
since the name of a category in the target taxonomy usually contains more than one term  we define the  mutual information  between a category in the intermediate taxonomy cji and a category in the target taxonomy cit as:
	 	 1 
where |cit| is the number of terms in the name of cit.
　to measure the goodness of cji in a global category selection  we combine the category-specific scores of cji by:
	miavg cji  =	mi cit cji 	 1 
cjt
1.1 discussions
　as we can see  in the bridging classifier  we do not need to train a classifier function between an intermediate taxonomy and the target taxonomy. we only need to build the classifiers on the intermediate taxonomy once and it can be applied to any target taxonomy. the framework can be extended in two directions. one is to include some training data for each target category. with the training data  we do not have to treat the labels of the target categories as queries and retrieve related web pages through search engines to represent the categories. we can extract features from the training data directly. the second extension is to use other sophisticated models such as the n-gram model  or svm  for computing p cit|cji  and p q|cji .
1. experiments
　in this section  we first introduce the data set and the evaluation metrics. then we present the experiment results and give some discussions.
1 data set and evaluation metrics
1.1 data sets
　in this paper  we use the data sets from the kddcup 1 competition which is available on the web1 . one of the data sets contains 1 sample queries together with the category information. these samples are used to exemplify the format of the queries by the organizer. however  since the category information of these queries is truthful  they can serve as the validation data. another data set contains 1 queries with category information labeled by three human labelers. in fact  the organizers provided 1 queries in total which are selected from the msn search logs for testing the submitted solutions. since manually labeling all the 1 queries is too expensive and time consuming  the organizers randomly selected 1 queries for evaluation.
　we denote the three human query-labelers  and sometimes the dataset labeled by them if no confusion is caused  as l1  l1 and l1  respectively. each query has at most five labels in ranked order. table 1 shows the average precision and f1 score values of each labeler when evaluated against the other two labelers. the average values among the three labelers are around 1 which indicates that the query classification problem is not an easy task even for human labelers. in this paper  all the experiments use only the 1 queries  except in the ensemble classifiers  where we use the 1 sample queries to tune the weight of each single classifier.
table 1: the average scores of each labeler when evaluated against the other two labelers
l1l1l1averagef1.1.1.1.1pre1111　the existing intermediate taxonomy used in the paper is from open directory project  odp  http://dmoz.org/ . we crawled 1 1 web pages from odp which spanned over 1 categories. the categories have a hierarchical structure as shown in figure 1 . we can consider the hierarchy at different levels. table 1 shows the number of categories on different levels. the first row counts all the categories while the second row counts only the categories containing more than 1 web pages. table 1 summarizes the statistics of web page numbers in the categories with more than 1 documents on different levels. as we can see  when we move down to the lower levels along the hierarchy  more categories appear while each category contains fewer web pages. in order to remove noise  we consider the categories with more than 1 pages in this paper.
table 1: number of categories on different levels
top 1top 1top 1top 1top all#doc   11111#doc   11111table 1: statistics of the numbers of documents in the categories on different levels
top 1top 1top 1top 1top alllargest11111smallest111mean1.1.1.1.1.1.1 evaluation measurements
　in kddcup 1  precision  performance and creativity are the three measures to evaluate the submitted solutions.  creativity  refers to the novelty of the solutions judged by experts. the other two measures are defined according to the standard measures to evaluate the performance of classification  that is  precision  recall and f1-measure . precision  p  is the proportion of actual positive class members returned by the system among all predicted positive class members returned by the system. recall  r  is the proportion of predicted positive members among all actual positive class members in the data. f1 is the harmonic mean of precision and recall as shown below:
	f1 = 1 〜 p 〜 r/ p + r 	 1 
 performance  adopted by kddcup 1 is in fact f1. therefore  we denote it by f1 instead of  performance  for simplicity.
　as 1 labelers were asked to label the queries  the results reported are averaged over the values evaluated on each of them.
1 results and analysis
1.1 performance of exact matching and svm
　in this section  we study the performance of the two methods which tightly depend on word matching: exact matching and svm  as well as the effect of query and category expansion. table 1 shows the results of the category expansion through intermediate taxonomy by word matching  that is the results of collecting training data for the target taxonomy. each element in the table represents the number of documents collected for the target categories. the first row contains the results by direct matching while the second row contains the results after expanding the category names through extended matching. we can see that after extending the names of the target categories  the number of documents collected for the target categories increases. we expect that the expansion with the help of wordnet should provide more documents to reflect the semantics of the target categories which is verified by table 1.
table 1: number of pages collected for training under different category expansion methods
minmaxmedianmeandirect matching1 1 1 1extended matching1 1 1 1　table 1 presents the result comparisons of the exact matching method and svm. we enrich the query by retrieving the relevant pages through google  http://www.google.com . the
top n returned pages are used to represent the query where n varies from 1 to 1  with the step size of 1. two approaches are used to extract features from the returned pages. one is to extract the snippet of the returned pages and the other is to extract all the text in the web pages except the html tags. the web pages' titles will be added to both of these two kinds of features. the column  1  means that we use only the terms in the query without enrichment.
　in our experiments  we expand the target categories through the odp taxonomy; that is  we collect the training data for the target categories from odp. when constructing the mapping relationship as shown in section 1  if we use direct matching  we denote svm and the exact matching method with  svm-d  and  extact-d  respectively. otherwise if we use the extended matching method  we denote svm and the exact matching method with  svm-e  and  extact-e  respectively. the exact matching method needs the category list of the retrieved web pages for each query. the table 1: performance of exact matching and svm
 1 measured by f1
n111exact-dnull1111exact-enull1111svm-dsnippet11111full text1111svm-esnippet11111full text1111 1  measured by precision
n111exact-dnull1111exact-enull1111svm-dsnippet11111full text1111svm-esnippet11111full text1111category information is obtained through google's  directory search  service  http://www.google.com/dirhp .
　from table 1 we can see that  exact-e  is much better than  exact-d   and  svm-e  is much better than  svmd . this indicates that the extended matching with the help of wordnet can achieve a more proper representation of the target category. we can also observe that  exacte  performs better than  svm-e . another observation is that the  snippet  representation outperforms  full text  consistently. the reason is that the  snippet  provides a more concise context of the query than the  full text  which tends to introduce noise. we can also see that most of the classifiers achieve the highest performance when the queries are represented by the top 1 search result pages. therefore  in the later experiments  we use snippets of the top 1 pages to represent queries.
1.1 performance of the bridging classifier
　as we can see in the above experiments  the thesaurus wordnet plays an important role in both the exact matching method and svm since it can help expand the words in the labels of the target categories  which can further improve the mapping functions. however  the effect of a thesaurus may be limited due to the following reasons: 1  there may be no thesaurus in some fields; 1  it is hard to determine the precise expansion of the words even with a high-quality thesaurus  especially with the rapidly changing usage of words on the web. therefore  we put forward the bridging classifier which only relies on the intermediate taxonomies.
　in order to expand a target category  we can treat its name as a query and submit it to search engines. we use the snippet of the top n returned pages to represent a category since we learned from the query expansion that snippet performs better than  full text . the parameter n varies from 1 to 1. table 1 shows the results when  top all  categories in the odp taxonomy are used for bridging the queries and the target taxonomy. the effect of different levels of the intermediate taxonomy will be studied later. from table 1  we can see that the bridging classifier achieves the best performance when n equals 1. the best f1 and precision achieved by the bridging classifier is higher than those achieved either by the exact matching method or svm. the relative improvement is more than 1% and 1% in terms of precision and f1 respectively. the main reason for the improvement is that the bridging classifier can make thorough use of the finer grained intermediate taxonomy in a probabilistic way. while the previous methods including the exact matching method and svm exploit the intermediate taxonomy in a hard way when constructing the mapping function as shown in section 1.
table 1: performances of the bridging classifier with different representations of target categories
n111f1.1.1.1.1.1precision11111table 1: performances of the bridging classifier with different granularity
top 1top 1top 1top 1top allf1.1.1.1.1.1precision11111　table 1 shows the performance of the bridging classifier when we change the granularity of the categories in the intermediate taxonomy. to change the granularity of the categories  we use the categories on the top l level by varying l. it is clear that the categories have larger granularity when l is smaller. from table 1  we can see that the performance of the bridging classifier improves steadily by reducing the granularity of categories. the reason is that categories with large granularity may be a mixture of several target categories which prohibit distinguishing the target categories.

figure 1: effect of category selection.
　however  reducing the granularity of categories in the intermediate taxonomy will certainly increase the number of the intermediate categories which will thus increase the computation cost. one way to solve this problem is to do category selection. figure 1 shows the performance of the bridging classifier when we select the categories from all the odp taxonomy through the two category selection approaches proposed in section 1.1. we can see that when the category number is around 1  the performance of the bridging classifier is comparable to  if not better than  the previous approaches  including the exact matching method and svm. mi works better than tp in that mi can not only measure the relevance between the categories in the target taxonomy and those in the intermediate taxonomy  but also favors the categories which are more powerful to distinguish the categories in the target taxonomy. however  tp only cares about the merit of relevance.
1.1 ensemble of classifiers
　the winner of the kddcup 1 competition found that the best result was achieved by combining the exact matching method and svm. in the winning solution  besides the exact matching method on google's directory search  two other exact matching methods are developed using looksmart  http://www.looksmart.com  and a search engine based on lemur  http://www.lemurproject.org  and their crawled web pages from odp . two classifier-combination strategies are used  with one aiming at higher precision  denoted by ev  where 1 samples are used as the validation data to tune the weight of each base classifier  and the other aiming at higher f1  denoted by en in which the validation data set is ignored . ev assigns a weight to a classifier proportional to the classifier's precision while en gives equal weights to all classifiers. we follow the same strategy to combine our new method with the winner's methods  which is denoted as  exact-e + svm-e +bridging as shown in table 1. the numbers in the parentheses are the relative improvement. note that the bridging classifier alone achieves similar f1 measurement as the kddcu 1 winning solution   exact-e + svm-e  with the ev combination strategy  but improves the precision by 1%. from table 1 we can also find that the combination of the bridging classifier and the kddcup 1 winning solution can improve the performance by 1% and 1% in terms of precision and f1  respectively  when compared with the winning solution. this indicates that the bridging classifier works in a different way as the exact matching method and svm  and they are complimentary to each other.
table 1: performances of ensemble classifiers
 exact-e  exact-e  +  svm-e +  svm-e +bridgingevf1.1.1 +1 precision11 +1 enf1.1.1 +1 precision11 +1 1. related work
　though not much work has been done on topical query classification  some work has been conducted on other kinds of query classification problems. gravano et al. classified the web queries by geographical locality  while kang et al. proposed to classify queries according to their functional types .
　beitzel et al. studied the same problem in  as we pursued in this paper  with the goal to classify the queries according to their topic s . they used two primary data sets containing the queries from the aol web search service. these queries were manually classified into a set of 1 categories. the main difference between our problem and that of  is that we did not have training data as given input. in fact  it is a very difficult and time consuming task to provide enough training examples  especially when the target taxonomy is complicated. another potential problem related to the training data  as pointed out in   is caused by the ongoing changes in the query stream  which makes it hard to systematically cover the space of queries. in this paper  we just rely on the structure and category names of the target taxonomy without training data  which is consistent with the task of kddcup 1.
　kddcup 1 provides a test bed for the web query classification problem. there are a total of 1 solutions from 1 teams attending the competition. as summarized by the organizers   most solutions expanded the queries through search engines or wordnet and expanded the category by mapping between some pre-defined/existing taxonomy to the target taxonomy. some solutions require human intervention in the mapping process  1  1 .
　besides classifying the queries into target taxonomy  we can also cluster the queries to discover some hidden taxonomies through unsupervised methods. both beeferman  and wen  used search engines' clickthrough data to cluster the queries. the former makes no use of the actual content of the queries and urls  but only how they co-occur within the clickthrough data  while the latter exploits the usage of the content. although the work in  and  proved the effectiveness of the clickthrough data for query clustering  we did not utilize them in our solution due to the following two reasons: 1  the clickthorugh data can be quite noisy and is search engine dependent; 1  it is difficult to obtain the clickthrough data due to privacy and legal issues.
1. conclusion and future work
　this paper presented a novel solution for classifying web queries into a set of target categories  where the queries are very short and there are no training data. in our solution  an intermediate taxonomy is used to train classifiers bridging the queries and target categories so that there is no need to collect the training data. experiments on the kddcup 1 data set show that the bridging classifier approach is promising. by combining the bridging classifier with the winning solution of kddcup 1  we made a further improvement by 1% and 1% in terms of precision and f1 respectively compared with the best results of kddcup 1. in the future  we plan to extend the bridging classifier idea to other types of query processing tasks  including query clustering. we will also conduct research on how to leverage a group of intermediate taxonomies for query classification.
1. acknowledgments
　dou shen and qiang yang are supported by a grant from nec  neclc1.eg1 . we thank the anonymous reviewers for their useful comments.
